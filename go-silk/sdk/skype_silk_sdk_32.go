// Code generated by 'ccgo -host-config-cmd i686-w64-mingw32-cpp -export-fields F -pkgname silk -replace-fd-zero -compiledb -trace-translation-units "" -o silk_windows_386.go typedef.h A2NLSF.c ana_filt_bank_1.c apply_sine_window.c array_maxabs.c autocorr.c biquad.c biquad_alt.c burg_modified.c bwexpander.c bwexpander_32.c CNG.c code_signs.c common_pitch_est_defines.h control.h control_audio_bandwidth.c control_codec_FIX.c corrMatrix_FIX.c create_init_destroy.c decoder_set_fs.c decode_core.c decode_frame.c decode_parameters.c decode_pitch.c decode_pulses.c dec_API.c define.h detect_SWB_input.c encode_frame_FIX.c encode_parameters.c encode_pulses.c enc_API.c errors.h find_LPC_FIX.c find_LTP_FIX.c find_pitch_lags_FIX.c find_pred_coefs_FIX.c gain_quant.c HP_variable_cutoff_FIX.c init_encoder_FIX.c Inlines.h inner_prod_aligned.c interpolate.c k2a.c k2a_Q16.c LBRR_reset.c lin2log.c log2lin.c LPC_inv_pred_gain.c LPC_synthesis_filter.c LPC_synthesis_order16.c LP_variable_cutoff.c LSF_cos_table.c LTP_analysis_filter_FIX.c LTP_scale_ctrl_FIX.c MA.c macros.h main.h main_FIX.h NLSF2A.c NLSF2A_stable.c NLSF_MSVQ_decode.c NLSF_MSVQ_encode_FIX.c NLSF_stabilize.c NLSF_VQ_rate_distortion_FIX.c NLSF_VQ_sum_error_FIX.c NLSF_VQ_weights_laroia.c noise_shape_analysis_FIX.c NSQ.c NSQ_del_dec.c pitch_analysis_core.c pitch_est_defines.h pitch_est_tables.c PLC.c PLC.h prefilter_FIX.c process_gains_FIX.c process_NLSFs_FIX.c quant_LTP_gains_FIX.c range_coder.c regularize_correlations_FIX.c resampler.c resampler_down2.c resampler_down2_3.c resampler_down3.c resampler_private.h resampler_private_AR2.c resampler_private_ARMA4.c resampler_private_copy.c resampler_private_down4.c resampler_private_down_FIR.c resampler_private_IIR_FIR.c resampler_private_up2_HQ.c resampler_private_up4.c resampler_rom.c resampler_rom.h resampler_structs.h resampler_up2.c residual_energy16_FIX.c residual_energy_FIX.c scale_copy_vector16.c scale_vector.c schur.c schur64.c SDK_API.h setup_complexity.h shell_coder.c sigm_Q15.c SigProc_FIX.h solve_LS_FIX.c sort.c structs.h structs_FIX.h sum_sqr_shift.c tables.h tables_gain.c tables_LTP.c tables_NLSF_CB0_10.c tables_NLSF_CB0_10.h tables_NLSF_CB0_16.c tables_NLSF_CB0_16.h tables_NLSF_CB1_10.c tables_NLSF_CB1_10.h tables_NLSF_CB1_16.c tables_NLSF_CB1_16.h tables_other.c tables_pitch_lag.c tables_pulses_per_block.c tables_sign.c tables_type_offset.c tuning_parameters.h VAD.c VQ_nearest_neighbor_FIX.c warped_autocorrelation_FIX.c "" -DNDEBUG', DO NOT EDIT.
//go:build 386 || arm
// +build 386 arm

package sdk

import (
	"math"
	"reflect"
	"sync/atomic"
	"unsafe"

	"modernc.org/libc"
	"modernc.org/libc/sys/types"
)

var _ = math.Pi
var _ reflect.Kind
var _ atomic.Value
var _ unsafe.Pointer
var _ types.Size_t

type ptrdiff_t = int32 /* <builtin>:3:26 */

type size_t = uint32 /* <builtin>:9:23 */

type wchar_t = uint16 /* <builtin>:15:24 */

type va_list = uintptr /* <builtin>:50:27 */

type ssize_t = int32 /* crtdefs.h:47:13 */

type rsize_t = size_t /* crtdefs.h:52:16 */

type intptr_t = int32 /* crtdefs.h:64:13 */

type uintptr_t = uint32 /* crtdefs.h:77:22 */

type wint_t = uint16   /* crtdefs.h:106:24 */
type wctype_t = uint16 /* crtdefs.h:107:24 */

type errno_t = int32 /* crtdefs.h:113:13 */

type time_t = int32 /* crtdefs.h:136:20 */

type threadlocaleinfostruct struct {
	Frefcount      int32
	Flc_codepage   uint32
	Flc_collate_cp uint32
	Flc_handle     [6]uint32
	Flc_id         [6]LC_ID
	Flc_category   [6]struct {
		Flocale    uintptr
		Fwlocale   uintptr
		Frefcount  uintptr
		Fwrefcount uintptr
	}
	Flc_clike            int32
	Fmb_cur_max          int32
	Flconv_intl_refcount uintptr
	Flconv_num_refcount  uintptr
	Flconv_mon_refcount  uintptr
	Flconv               uintptr
	Fctype1_refcount     uintptr
	Fctype1              uintptr
	Fpctype              uintptr
	Fpclmap              uintptr
	Fpcumap              uintptr
	Flc_time_curr        uintptr
} /* crtdefs.h:422:1 */

type pthreadlocinfo = uintptr /* crtdefs.h:424:39 */
type pthreadmbcinfo = uintptr /* crtdefs.h:425:36 */

type localeinfo_struct struct {
	Flocinfo pthreadlocinfo
	Fmbcinfo pthreadmbcinfo
} /* crtdefs.h:428:9 */

type _locale_tstruct = localeinfo_struct /* crtdefs.h:431:3 */
type _locale_t = uintptr                 /* crtdefs.h:431:19 */

type tagLC_ID struct {
	FwLanguage uint16
	FwCountry  uint16
	FwCodePage uint16
} /* crtdefs.h:422:1 */

type LC_ID = tagLC_ID  /* crtdefs.h:439:3 */
type LPLC_ID = uintptr /* crtdefs.h:439:9 */

type threadlocinfo = threadlocaleinfostruct /* crtdefs.h:468:3 */

// ISO C Standard:  7.17  Common definitions  <stddef.h>

// Any one of these symbols __need_* means that GNU libc
//    wants us just to define one data type.  So don't define
//    the symbols that indicate this file's entire job has been done.

// In 4.3bsd-net2, machine/ansi.h defines these symbols, which are
//    defined if the corresponding type is *not* defined.
//    FreeBSD-2.1 defines _MACHINE_ANSI_H_ instead of _ANSI_H_

// Sequent's header files use _PTRDIFF_T_ in some conflicting way.
//    Just ignore it.

// On VxWorks, <type/vxTypesBase.h> may have defined macros like
//    _TYPE_size_t which will typedef size_t.  fixincludes patched the
//    vxTypesBase.h so that this macro is only defined if _GCC_SIZE_T is
//    not defined, and so that defining this macro defines _GCC_SIZE_T.
//    If we find that the macros are still defined at this point, we must
//    invoke them so that the type is defined as expected.

// In case nobody has defined these types, but we aren't running under
//    GCC 2.00, make sure that __PTRDIFF_TYPE__, __SIZE_TYPE__, and
//    __WCHAR_TYPE__ have reasonable values.  This can happen if the
//    parts of GCC is compiled by an older compiler, that actually
//    include gstddef.h, such as collect2.

// Signed type of difference of two pointers.

// Define this type if we are doing the whole job,
//    or if we want this type in particular.

// Unsigned type of `sizeof' something.

// Define this type if we are doing the whole job,
//    or if we want this type in particular.

// Wide character type.
//    Locale-writers should change this as necessary to
//    be big enough to hold unique values not between 0 and 127,
//    and not (wchar_t) -1, for each defined multibyte character.

// Define this type if we are doing the whole job,
//    or if we want this type in particular.

//  In 4.3bsd-net2, leave these undefined to indicate that size_t, etc.
//     are already defined.
//  BSD/OS 3.1 and FreeBSD [23].x require the MACHINE_ANSI_H check here.

// A null pointer constant.

// Copyright (C) 1989-2018 Free Software Foundation, Inc.
//
// This file is part of GCC.
//
// GCC is free software; you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation; either version 3, or (at your option)
// any later version.
//
// GCC is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// Under Section 7 of GPL version 3, you are granted additional
// permissions described in the GCC Runtime Library Exception, version
// 3.1, as published by the Free Software Foundation.
//
// You should have received a copy of the GNU General Public License and
// a copy of the GCC Runtime Library Exception along with this program;
// see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
// <http://www.gnu.org/licenses/>.

// ISO C Standard:  7.17  Common definitions  <stddef.h>

// Any one of these symbols __need_* means that GNU libc
//    wants us just to define one data type.  So don't define
//    the symbols that indicate this file's entire job has been done.
// snaroff@next.com says the NeXT needs this.

// This avoids lossage on SunOS but only if stdtypes.h comes first.
//    There's no way to win with the other order!  Sun lossage.

// On 4.3bsd-net2, make sure ansi.h is included, so we have
//    one less case to deal with in the following.
// On FreeBSD 5, machine/ansi.h does not exist anymore...

// In 4.3bsd-net2, machine/ansi.h defines these symbols, which are
//    defined if the corresponding type is *not* defined.
//    FreeBSD-2.1 defines _MACHINE_ANSI_H_ instead of _ANSI_H_.
//    NetBSD defines _I386_ANSI_H_ and _X86_64_ANSI_H_ instead of _ANSI_H_

// Sequent's header files use _PTRDIFF_T_ in some conflicting way.
//    Just ignore it.

// On VxWorks, <type/vxTypesBase.h> may have defined macros like
//    _TYPE_size_t which will typedef size_t.  fixincludes patched the
//    vxTypesBase.h so that this macro is only defined if _GCC_SIZE_T is
//    not defined, and so that defining this macro defines _GCC_SIZE_T.
//    If we find that the macros are still defined at this point, we must
//    invoke them so that the type is defined as expected.

// In case nobody has defined these types, but we aren't running under
//    GCC 2.00, make sure that __PTRDIFF_TYPE__, __SIZE_TYPE__, and
//    __WCHAR_TYPE__ have reasonable values.  This can happen if the
//    parts of GCC is compiled by an older compiler, that actually
//    include gstddef.h, such as collect2.

// Signed type of difference of two pointers.

// Define this type if we are doing the whole job,
//    or if we want this type in particular.

// If this symbol has done its job, get rid of it.

// Unsigned type of `sizeof' something.

// Define this type if we are doing the whole job,
//    or if we want this type in particular.

// Wide character type.
//    Locale-writers should change this as necessary to
//    be big enough to hold unique values not between 0 and 127,
//    and not (wchar_t) -1, for each defined multibyte character.

// Define this type if we are doing the whole job,
//    or if we want this type in particular.

//  In 4.3bsd-net2, leave these undefined to indicate that size_t, etc.
//     are already defined.
//  BSD/OS 3.1 and FreeBSD [23].x require the MACHINE_ANSI_H check here.
//  NetBSD 5 requires the I386_ANSI_H and X86_64_ANSI_H checks here.

// A null pointer constant.

// Offset of member MEMBER in a struct of type TYPE.

// Type whose alignment is supported in every context and is at least
//    as great as that of any standard type not using alignment
//    specifiers.
type max_align_t struct {
	F__max_align_ll   int64
	F__max_align_ld   float64
	F__max_align_f128 float64
} /* stddef.h:438:3 */

// 7.18.1.1  Exact-width integer types
type int8_t = int8     /* stdint.h:35:21 */
type uint8_t = uint8   /* stdint.h:36:25 */
type int16_t = int16   /* stdint.h:37:16 */
type uint16_t = uint16 /* stdint.h:38:25 */
type int32_t = int32   /* stdint.h:39:14 */
type uint32_t = uint32 /* stdint.h:40:20 */
type int64_t = int64   /* stdint.h:41:38 */
type uint64_t = uint64 /* stdint.h:42:48 */

// 7.18.1.2  Minimum-width integer types
type int_least8_t = int8     /* stdint.h:45:21 */
type uint_least8_t = uint8   /* stdint.h:46:25 */
type int_least16_t = int16   /* stdint.h:47:16 */
type uint_least16_t = uint16 /* stdint.h:48:25 */
type int_least32_t = int32   /* stdint.h:49:14 */
type uint_least32_t = uint32 /* stdint.h:50:20 */
type int_least64_t = int64   /* stdint.h:51:38 */
type uint_least64_t = uint64 /* stdint.h:52:48 */

// 7.18.1.3  Fastest minimum-width integer types
//  Not actually guaranteed to be fastest for all purposes
//  Here we use the exact-width types for 8 and 16-bit ints.
type int_fast8_t = int8     /* stdint.h:58:21 */
type uint_fast8_t = uint8   /* stdint.h:59:23 */
type int_fast16_t = int16   /* stdint.h:60:16 */
type uint_fast16_t = uint16 /* stdint.h:61:25 */
type int_fast32_t = int32   /* stdint.h:62:14 */
type uint_fast32_t = uint32 /* stdint.h:63:24 */
type int_fast64_t = int64   /* stdint.h:64:38 */
type uint_fast64_t = uint64 /* stdint.h:65:48 */

// 7.18.1.5  Greatest-width integer types
type intmax_t = int64   /* stdint.h:68:38 */
type uintmax_t = uint64 /* stdint.h:69:48 */

// 7.18.2  Limits of specified-width integer types

// 7.18.2.1  Limits of exact-width integer types

// 7.18.2.2  Limits of minimum-width integer types

// 7.18.2.3  Limits of fastest minimum-width integer types

// 7.18.2.4  Limits of integer types capable of holding
//     object pointers

// 7.18.2.5  Limits of greatest-width integer types

// 7.18.3  Limits of other integer types

// wint_t is unsigned short for compatibility with MS runtime

// 7.18.4  Macros for integer constants

// 7.18.4.1  Macros for minimum-width integer constants
//
//     Accoding to Douglas Gwyn <gwyn@arl.mil>:
// 	"This spec was changed in ISO/IEC 9899:1999 TC1; in ISO/IEC
// 	9899:1999 as initially published, the expansion was required
// 	to be an integer constant of precisely matching type, which
// 	is impossible to accomplish for the shorter types on most
// 	platforms, because C99 provides no standard way to designate
// 	an integer constant with width less than that of type int.
// 	TC1 changed this to require just an integer constant
// 	*expression* with *promoted* type."
//
// 	The trick used here is from Clive D W Feather.

//  The 'trick' doesn't work in C89 for long long because, without
//     suffix, (val) will be evaluated as int, not intmax_t

// 7.18.4.2  Macros for greatest-width integer constants

/* assertions */

// *
// This file has no copyright assigned and is placed in the Public Domain.
// This file is part of the mingw-w64 runtime package.
// No warranty is given; refer to the file DISCLAIMER.PD within this package.

// *
// This file has no copyright assigned and is placed in the Public Domain.
// This file is part of the mingw-w64 runtime package.
// No warranty is given; refer to the file DISCLAIMER.PD within this package.

// Copyright (C) 1992-2018 Free Software Foundation, Inc.
//
// This file is part of GCC.
//
// GCC is free software; you can redistribute it and/or modify it under
// the terms of the GNU General Public License as published by the Free
// Software Foundation; either version 3, or (at your option) any later
// version.
//
// GCC is distributed in the hope that it will be useful, but WITHOUT ANY
// WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// for more details.
//
// Under Section 7 of GPL version 3, you are granted additional
// permissions described in the GCC Runtime Library Exception, version
// 3.1, as published by the Free Software Foundation.
//
// You should have received a copy of the GNU General Public License and
// a copy of the GCC Runtime Library Exception along with this program;
// see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
// <http://www.gnu.org/licenses/>.

// This administrivia gets added to the beginning of limits.h
//    if the system has its own version of limits.h.

// We use _GCC_LIMITS_H_ because we want this not to match
//    any macros that the system's limits.h uses for its own purposes.

// Use "..." so that we find syslimits.h only in this same directory.
// syslimits.h stands for the system's own limits.h file.
//    If we can use it ok unmodified, then we install this text.
//    If fixincludes fixes it, then the fixed version is installed
//    instead of this text.

// *
// This file has no copyright assigned and is placed in the Public Domain.
// This file is part of the mingw-w64 runtime package.
// No warranty is given; refer to the file DISCLAIMER.PD within this package.
// *
// This file has no copyright assigned and is placed in the Public Domain.
// This file is part of the mingw-w64 runtime package.
// No warranty is given; refer to the file DISCLAIMER.PD within this package.

// File system limits
//
// NOTE: Apparently the actual size of PATH_MAX is 260, but a space is
//       required for the NUL. TODO: Test?
// NOTE: PATH_MAX is the POSIX equivalent for Microsoft's MAX_PATH; the two
//       are semantically identical, with a limit of 259 characters for the
//       path name, plus one for a terminating NUL, for a total of 260.

// Copyright (C) 1991-2018 Free Software Foundation, Inc.
//
// This file is part of GCC.
//
// GCC is free software; you can redistribute it and/or modify it under
// the terms of the GNU General Public License as published by the Free
// Software Foundation; either version 3, or (at your option) any later
// version.
//
// GCC is distributed in the hope that it will be useful, but WITHOUT ANY
// WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// for more details.
//
// Under Section 7 of GPL version 3, you are granted additional
// permissions described in the GCC Runtime Library Exception, version
// 3.1, as published by the Free Software Foundation.
//
// You should have received a copy of the GNU General Public License and
// a copy of the GCC Runtime Library Exception along with this program;
// see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
// <http://www.gnu.org/licenses/>.

// Number of bits in a `char'.

// Maximum length of a multibyte character.

// Minimum and maximum values a `signed char' can hold.

// Maximum value an `unsigned char' can hold.  (Minimum is 0).

// Minimum and maximum values a `char' can hold.

// Minimum and maximum values a `signed short int' can hold.

// Maximum value an `unsigned short int' can hold.  (Minimum is 0).

// Minimum and maximum values a `signed int' can hold.

// Maximum value an `unsigned int' can hold.  (Minimum is 0).

// Minimum and maximum values a `signed long int' can hold.
//    (Same as `int').

// Maximum value an `unsigned long int' can hold.  (Minimum is 0).

// Minimum and maximum values a `signed long long int' can hold.

// Maximum value an `unsigned long long int' can hold.  (Minimum is 0).

// Minimum and maximum values a `signed long long int' can hold.

// Maximum value an `unsigned long long int' can hold.  (Minimum is 0).

// This administrivia gets added to the end of limits.h
//    if the system has its own version of limits.h.

type _onexit_t = uintptr /* stdlib.h:49:15 */

type _div_t struct {
	Fquot int32
	Frem  int32
} /* stdlib.h:59:11 */

type div_t = _div_t /* stdlib.h:62:5 */

type _ldiv_t struct {
	Fquot int32
	Frem  int32
} /* stdlib.h:64:11 */

type ldiv_t = _ldiv_t /* stdlib.h:67:5 */

type _LDOUBLE struct{ Fld [10]uint8 } /* stdlib.h:76:5 */

type _CRT_DOUBLE struct{ Fx float64 } /* stdlib.h:83:5 */

type _CRT_FLOAT struct{ Ff float32 } /* stdlib.h:87:5 */

type _LONGDOUBLE struct{ Fx float64 } /* stdlib.h:94:5 */

type _LDBL12 struct{ Fld12 [12]uint8 } /* stdlib.h:101:5 */

type _purecall_handler = uintptr /* stdlib.h:142:16 */

type _invalid_parameter_handler = uintptr /* stdlib.h:147:16 */

type lldiv_t struct {
	Fquot int64
	Frem  int64
} /* stdlib.h:699:61 */

// *
// This file has no copyright assigned and is placed in the Public Domain.
// This file is part of the mingw-w64 runtime package.
// No warranty is given; refer to the file DISCLAIMER.PD within this package.

// *
// This file has no copyright assigned and is placed in the Public Domain.
// This file is part of the mingw-w64 runtime package.
// No warranty is given; refer to the file DISCLAIMER.PD within this package.

// Return codes for _heapwalk()

// Values for _heapinfo.useflag

// The structure used to walk through the heap with _heapwalk.
type _heapinfo struct {
	F_pentry  uintptr
	F_size    size_t
	F_useflag int32
} /* malloc.h:46:11 */

// *
// This file has no copyright assigned and is placed in the Public Domain.
// This file is part of the mingw-w64 runtime package.
// No warranty is given; refer to the file DISCLAIMER.PD within this package.

// *
// This file has no copyright assigned and is placed in the Public Domain.
// This file is part of the mingw-w64 runtime package.
// No warranty is given; refer to the file DISCLAIMER.PD within this package.

// Return codes for _heapwalk()

// Values for _heapinfo.useflag

// The structure used to walk through the heap with _heapwalk.
type _HEAPINFO = _heapinfo /* malloc.h:50:5 */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*																		*
 * File Name:	resampler_structs.h							*
 *																		*
 * Description: Structs for IIR/FIR resamplers							*
 *                                                                      *
 * Copyright 2010 (c), Skype Limited                                    *
 * All rights reserved.													*
 *																		*
 *                                                                      */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/* Flag to enable support for input/output sampling rates above 48 kHz. Turn off for embedded devices */

type _resampler_state_struct struct {
	FsIIR               [6]int32
	FsFIR               [16]int32
	FsDown2             [2]int32
	Fresampler_function uintptr
	Fup2_function       uintptr
	FbatchSize          int32
	FinvRatio_Q16       int32
	FFIR_Fracs          int32
	Finput2x            int32
	FCoefs              uintptr
	FsDownPre           [2]int32
	FsUpPost            [2]int32
	Fdown_pre_function  uintptr
	Fup_post_function   uintptr
	FbatchSizePrePost   int32
	Fratio_Q16          int32
	FnPreDownsamplers   int32
	FnPostUpsamplers    int32
	Fmagic_number       int32
} /* resampler_structs.h:53:9 */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*																		*
 * File Name:	resampler_structs.h							*
 *																		*
 * Description: Structs for IIR/FIR resamplers							*
 *                                                                      *
 * Copyright 2010 (c), Skype Limited                                    *
 * All rights reserved.													*
 *																		*
 *                                                                      */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/* Flag to enable support for input/output sampling rates above 48 kHz. Turn off for embedded devices */

type resampler_state_struct = _resampler_state_struct /* resampler_structs.h:75:3 */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

// This is an inline header file for general platform.

// (a32 * (int32)((int16)(b32))) >> 16 output have to be 32bit int

// a32 + (b32 * (int32)((int16)(c32))) >> 16 output have to be 32bit int

// (a32 * (b32 >> 16)) >> 16

// a32 + (b32 * (c32 >> 16)) >> 16

// (int32)((int16)(a3))) * (int32)((int16)(b32)) output have to be 32bit int

// a32 + (int32)((int16)(b32)) * (int32)((int16)(c32)) output have to be 32bit int

// (int32)((int16)(a32)) * (b32 >> 16)

// a32 + (int32)((int16)(b32)) * (c32 >> 16)

// a64 + (b32 * c32)

// (a32 * b32) >> 16

// a32 + ((b32 * c32) >> 16)

// (int32)(((int64)a32 * b32) >> 32)

/* add/subtract with output saturated */

func CLZ16(tls *libc.TLS, in16 int16) int32 { /* macros.h:79:22: */
	var out32 int32 = 0
	if int32(in16) == 0 {
		return 16
	}
	/* test nibbles */
	if (int32(in16) & 0xFF00) != 0 {
		if (int32(in16) & 0xF000) != 0 {
			in16 >>= 12
		} else {
			out32 = out32 + (4)
			in16 >>= 8
		}
	} else {
		if (int32(in16) & 0xFFF0) != 0 {
			out32 = out32 + (8)
			in16 >>= 4
		} else {
			out32 = out32 + (12)
		}
	}
	/* test bits and return */
	if (int32(in16) & 0xC) != 0 {
		if (int32(in16) & 0x8) != 0 {
			return (out32 + 0)
		} else {
			return (out32 + 1)
		}
	} else {
		if (int32(in16) & 0xE) != 0 {
			return (out32 + 2)
		} else {
			return (out32 + 3)
		}
	}
	return int32(0)
}

func CLZ32(tls *libc.TLS, in32 int32) int32 { /* macros.h:115:22: */
	/* test highest 16 bits and convert to int16 */
	if (uint32(in32) & 0xFFFF0000) != 0 {
		return CLZ16(tls, (int16(in32 >> 16)))
	} else {
		return (CLZ16(tls, int16(in32)) + 16)
	}
	return int32(0)
}

/********************************************************************/
/*                                MACROS                            */
/********************************************************************/

/* Rotate a32 right by 'rot' bits. Negative rot values result in rotating
   left. Output is 32bit int.
   Note: contemporary compilers recognize the C expressions below and
   compile them into 'ror' instructions if available. No need for inline ASM! */
/* PPC must use this generic implementation. */
func ROR32(tls *libc.TLS, a32 int32, rot int32) int32 { /* SigProc_FIX.h:456:22: */
	var x uint32 = uint32(a32)
	var r uint32 = uint32(rot)
	var m uint32 = uint32(-rot)
	if rot <= 0 {
		return (int32((x << m) | (x >> (uint32(32) - m))))
	} else {
		return (int32((x << (uint32(32) - r)) | (x >> r)))
	}
	return int32(0)
}

/* Allocate int16 alligned to 4-byte memory address */

/* Useful Macros that can be adjusted to other platforms */
/* fixed point macros */

// (a32 * b32) output have to be 32bit int

// (a32 * b32) output have to be 32bit uint

// a32 + (b32 * c32) output have to be 32bit int

/* ((a32 >> 16)  * (b32 >> 16)) output have to be 32bit int */

/* a32 + ((a32 >> 16)  * (b32 >> 16)) output have to be 32bit int */

// (a32 * b32)

/* Adds two signed 32-bit values in a way that can overflow, while not relying on undefined behaviour
   (just standard two's complement implementation-specific behaviour) */
/* Subtractss two signed 32-bit values in a way that can overflow, while not relying on undefined behaviour
   (just standard two's complement implementation-specific behaviour) */

/* Multiply-accumulate macros that allow overflow in the addition (ie, no asserts in debug mode) */

/* Add with saturation for positive input values */

/* saturates before shifting */

/* Requires that shift > 0 */

/* Number of rightshift required to fit the multiplication */

/* Macro to convert floating-point constants to fixed-point */
func FIX_CONST(tls *libc.TLS, C float64, Q int32) int32 { /* SigProc_FIX.h:568:5: */
	return (int32(((C) * (float64(int64(int64(1)) << (Q)))) + 0.5))
}

/* min() versions with typecast in the function call */
func min_int(tls *libc.TLS, a int32, b int32) int32 { /* SigProc_FIX.h:573:20: */
	return func() int32 {
		if (a) < (b) {
			return a
		}
		return b
	}()
}

func min_32(tls *libc.TLS, a int32, b int32) int32 { /* SigProc_FIX.h:578:22: */
	return func() int32 {
		if (a) < (b) {
			return a
		}
		return b
	}()
}

/* min() versions with typecast in the function call */
func max_int(tls *libc.TLS, a int32, b int32) int32 { /* SigProc_FIX.h:584:20: */
	return func() int32 {
		if (a) > (b) {
			return a
		}
		return b
	}()
}

func max_16(tls *libc.TLS, a int16, b int16) int16 { /* SigProc_FIX.h:588:22: */
	return func() int16 {
		if (int32(a)) > (int32(b)) {
			return a
		}
		return b
	}()
}

func max_32(tls *libc.TLS, a int32, b int32) int32 { /* SigProc_FIX.h:592:22: */
	return func() int32 {
		if (a) > (b) {
			return a
		}
		return b
	}()
}

// Static assertion.  Requires support in the compiler.

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/* count leading zeros of int64 */
func CLZ64(tls *libc.TLS, in int64_t) int32 { /* Inlines.h:44:22: */
	var in_upper int32

	in_upper = (int32((in) >> (32)))
	if in_upper == 0 {
		/* Search in the lower 32 bits */
		return (32 + CLZ32(tls, int32(in)))
	} else {
		/* Search in the upper 32 bits */
		return CLZ32(tls, in_upper)
	}
	return int32(0)
}

/* get number of leading zeros and fractional part (the bits right after the leading one */
func CLZ_FRAC(tls *libc.TLS, in int32, lz uintptr, frac_Q7 uintptr) { /* Inlines.h:59:17: */
	var lzeros int32 = CLZ32(tls, in)

	*(*int32)(unsafe.Pointer(lz)) = lzeros
	*(*int32)(unsafe.Pointer(frac_Q7)) = (ROR32(tls, in, (24-lzeros)) & 0x7f)
}

/* Approximation of square root                                          */
/* Accuracy: < +/- 10%  for output values > 15                           */
/*           < +/- 2.5% for output values > 120                          */
func SQRT_APPROX(tls *libc.TLS, x int32) int32 { /* Inlines.h:72:22: */
	bp := tls.Alloc(8)
	defer tls.Free(8)

	var y int32
	// var lz int32 at bp, 4

	// var frac_Q7 int32 at bp+4, 4

	if x <= 0 {
		return 0
	}

	CLZ_FRAC(tls, x, bp /* &lz */, bp+4 /* &frac_Q7 */)

	if (*(*int32)(unsafe.Pointer(bp /* lz */)) & 1) != 0 {
		y = 32768
	} else {
		y = 46214 /* 46214 = sqrt(2) * 32768 */
	}

	/* get scaling right */
	y >>= ((*(*int32)(unsafe.Pointer(bp /* lz */))) >> (1))

	/* increment using fractional part of input */
	y = ((y) + ((((y) >> 16) * (int32((int16((int32(int16(213))) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 4 /* frac_Q7 */)))))))))) + ((((y) & 0x0000FFFF) * (int32((int16((int32(int16(213))) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 4 /* frac_Q7 */)))))))))) >> 16)))

	return y
}

/* Divide two int32 values and return result as int32 in a given Q-domain */
func DIV32_varQ(tls *libc.TLS, a32 int32, b32 int32, Qres int32) int32 { /* Inlines.h:125:22: */
	var a_headrm int32
	var b_headrm int32
	var lshift int32
	var b32_inv int32
	var a32_nrm int32
	var b32_nrm int32
	var result int32

	/* Compute number of bits head room and normalize inputs */
	a_headrm = (CLZ32(tls, func() int32 {
		if (a32) > 0 {
			return a32
		}
		return -a32
	}()) - 1)
	a32_nrm = ((a32) << (a_headrm)) /* Q: a_headrm                    */
	b_headrm = (CLZ32(tls, func() int32 {
		if (b32) > 0 {
			return b32
		}
		return -b32
	}()) - 1)
	b32_nrm = ((b32) << (b_headrm)) /* Q: b_headrm                    */

	/* Inverse of b32, with 14 bits of precision */
	b32_inv = ((int32(0x7FFFFFFF) >> 2) / ((b32_nrm) >> (16))) /* Q: 29 + 16 - b_headrm        */

	/* First approximation */
	result = ((((a32_nrm) >> 16) * (int32(int16(b32_inv)))) + ((((a32_nrm) & 0x0000FFFF) * (int32(int16(b32_inv)))) >> 16)) /* Q: 29 + a_headrm - b_headrm    */

	/* Compute residual by subtracting product of denominator and first approximation */
	a32_nrm = a32_nrm - ((int32(((int64_t(b32_nrm)) * (int64_t(result))) >> (32))) << (3)) /* Q: a_headrm                    */

	/* Refinement */
	result = ((result) + ((((a32_nrm) >> 16) * (int32(int16(b32_inv)))) + ((((a32_nrm) & 0x0000FFFF) * (int32(int16(b32_inv)))) >> 16))) /* Q: 29 + a_headrm - b_headrm    */

	/* Convert to Qres domain */
	lshift = (((29 + a_headrm) - b_headrm) - Qres)
	if lshift <= 0 {
		return ((func() int32 {
			if (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift)) > (int32((0x7FFFFFFF)) >> (-lshift)) {
				return func() int32 {
					if (result) > (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift))
					}
					return func() int32 {
						if (result) < (int32((0x7FFFFFFF)) >> (-lshift)) {
							return (int32((0x7FFFFFFF)) >> (-lshift))
						}
						return result
					}()
				}()
			}
			return func() int32 {
				if (result) > (int32((0x7FFFFFFF)) >> (-lshift)) {
					return (int32((0x7FFFFFFF)) >> (-lshift))
				}
				return func() int32 {
					if (result) < (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift))
					}
					return result
				}()
			}()
		}()) << (-lshift))
	} else {
		if lshift < 32 {
			return ((result) >> (lshift))
		} else {
			/* Avoid undefined result */
			return 0
		}
	}
	return int32(0)
}

/* Invert int32 value and return result as int32 in a given Q-domain */
func INVERSE32_varQ(tls *libc.TLS, b32 int32, Qres int32) int32 { /* Inlines.h:170:22: */
	var b_headrm int32
	var lshift int32
	var b32_inv int32
	var b32_nrm int32
	var err_Q32 int32
	var result int32

	/* int32_MIN is not handled by abs */

	/* Compute number of bits head room and normalize input */
	b_headrm = (CLZ32(tls, func() int32 {
		if (b32) > 0 {
			return b32
		}
		return -b32
	}()) - 1)
	b32_nrm = ((b32) << (b_headrm)) /* Q: b_headrm                */

	/* Inverse of b32, with 14 bits of precision */
	b32_inv = ((int32(0x7FFFFFFF) >> 2) / ((b32_nrm) >> (16))) /* Q: 29 + 16 - b_headrm    */

	/* First approximation */
	result = ((b32_inv) << (16)) /* Q: 61 - b_headrm            */

	/* Compute residual by subtracting product of denominator and first approximation from one */
	err_Q32 = ((-((((b32_nrm) >> 16) * (int32(int16(b32_inv)))) + ((((b32_nrm) & 0x0000FFFF) * (int32(int16(b32_inv)))) >> 16))) << (3)) /* Q32                        */

	/* Refinement */
	result = (((result) + ((((err_Q32) >> 16) * (int32(int16(b32_inv)))) + ((((err_Q32) & 0x0000FFFF) * (int32(int16(b32_inv)))) >> 16))) + ((err_Q32) * (func() int32 {
		if (16) == 1 {
			return (((b32_inv) >> 1) + ((b32_inv) & 1))
		}
		return ((((b32_inv) >> ((16) - 1)) + 1) >> 1)
	}()))) /* Q: 61 - b_headrm            */

	/* Convert to Qres domain */
	lshift = ((61 - b_headrm) - Qres)
	if lshift <= 0 {
		return ((func() int32 {
			if (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift)) > (int32((0x7FFFFFFF)) >> (-lshift)) {
				return func() int32 {
					if (result) > (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift))
					}
					return func() int32 {
						if (result) < (int32((0x7FFFFFFF)) >> (-lshift)) {
							return (int32((0x7FFFFFFF)) >> (-lshift))
						}
						return result
					}()
				}()
			}
			return func() int32 {
				if (result) > (int32((0x7FFFFFFF)) >> (-lshift)) {
					return (int32((0x7FFFFFFF)) >> (-lshift))
				}
				return func() int32 {
					if (result) < (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (-lshift))
					}
					return result
				}()
			}()
		}()) << (-lshift))
	} else {
		if lshift < 32 {
			return ((result) >> (lshift))
		} else {
			/* Avoid undefined result */
			return 0
		}
	}
	return int32(0)
}

/* Sine approximation; an input of 65536 corresponds to 2 * pi */
/* Uses polynomial expansion of the input to the power 0, 2, 4 and 6 */
/* The relative error is below 1e-5 */
func SIN_APPROX_Q24(tls *libc.TLS, x int32) int32 { /* Inlines.h:220:22: */
	var y_Q30 int32

	/* Keep only bottom 16 bits (the function repeats itself with period 65536) */
	x = x & (65535)

	/* Split range in four quadrants */
	if x <= 32768 {
		if x < 16384 {
			/* Return cos(pi/2 - x) */
			x = (16384 - x)
		} else {
			/* Return cos(x - pi/2) */
			x = x - (16384)
		}
		if x < 1100 {
			/* Special case: high accuracy */
			return ((int32(1) << 24) + (((((x) * (x)) >> 16) * (int32(int16(-5053)))) + (((((x) * (x)) & 0x0000FFFF) * (int32(int16(-5053)))) >> 16)))
		}
		x = (((((x) << (8)) >> 16) * (int32(int16(x)))) + (((((x) << (8)) & 0x0000FFFF) * (int32(int16(x)))) >> 16)) /* contains x^2 in Q20 */
		y_Q30 = ((1059577) + ((((x) >> 16) * (int32(int16(-5013)))) + ((((x) & 0x0000FFFF) * (int32(int16(-5013)))) >> 16)))
		y_Q30 = (((-82778932) + ((((x) >> 16) * (int32(int16(y_Q30)))) + ((((x) & 0x0000FFFF) * (int32(int16(y_Q30)))) >> 16))) + ((x) * (func() int32 {
			if (16) == 1 {
				return (((y_Q30) >> 1) + ((y_Q30) & 1))
			}
			return ((((y_Q30) >> ((16) - 1)) + 1) >> 1)
		}())))
		y_Q30 = ((((1073735400) + 66) + ((((x) >> 16) * (int32(int16(y_Q30)))) + ((((x) & 0x0000FFFF) * (int32(int16(y_Q30)))) >> 16))) + ((x) * (func() int32 {
			if (16) == 1 {
				return (((y_Q30) >> 1) + ((y_Q30) & 1))
			}
			return ((((y_Q30) >> ((16) - 1)) + 1) >> 1)
		}())))
	} else {
		if x < 49152 {
			/* Return -cos(3*pi/2 - x) */
			x = (49152 - x)
		} else {
			/* Return -cos(x - 3*pi/2) */
			x = x - (49152)
		}
		if x < 1100 {
			/* Special case: high accuracy */
			return ((int32(-1) << 24) + (((((x) * (x)) >> 16) * (int32(int16(5053)))) + (((((x) * (x)) & 0x0000FFFF) * (int32(int16(5053)))) >> 16)))
		}
		x = (((((x) << (8)) >> 16) * (int32(int16(x)))) + (((((x) << (8)) & 0x0000FFFF) * (int32(int16(x)))) >> 16)) /* contains x^2 in Q20 */
		y_Q30 = ((-1059577) + ((((x) >> 16) * (int32(int16(- -5013)))) + ((((x) & 0x0000FFFF) * (int32(int16(- -5013)))) >> 16)))
		y_Q30 = (((- -82778932) + ((((x) >> 16) * (int32(int16(y_Q30)))) + ((((x) & 0x0000FFFF) * (int32(int16(y_Q30)))) >> 16))) + ((x) * (func() int32 {
			if (16) == 1 {
				return (((y_Q30) >> 1) + ((y_Q30) & 1))
			}
			return ((((y_Q30) >> ((16) - 1)) + 1) >> 1)
		}())))
		y_Q30 = (((-1073735400) + ((((x) >> 16) * (int32(int16(y_Q30)))) + ((((x) & 0x0000FFFF) * (int32(int16(y_Q30)))) >> 16))) + ((x) * (func() int32 {
			if (16) == 1 {
				return (((y_Q30) >> 1) + ((y_Q30) & 1))
			}
			return ((((y_Q30) >> ((16) - 1)) + 1) >> 1)
		}())))
	}
	return func() int32 {
		if (6) == 1 {
			return (((y_Q30) >> 1) + ((y_Q30) & 1))
		}
		return ((((y_Q30) >> ((6) - 1)) + 1) >> 1)
	}()
}

/* Number of binary divisions */

/* Flag for using 2x as many cosine sampling points, reduces the risk of missing a root */

/* Helper function for A2NLSF(..)                    */
/* Transforms polynomials from cos(n*f) to cos(f)^n  */
func A2NLSF_trans_poly(tls *libc.TLS, p uintptr, dd int32) { /* A2NLSF.c:46:17: */
	var k int32
	var n int32

	for k = 2; k <= dd; k++ {
		for n = dd; n > k; n-- {
			*(*int32)(unsafe.Pointer(p + uintptr((n-2))*4)) -= (*(*int32)(unsafe.Pointer(p + uintptr(n)*4)))
		}
		*(*int32)(unsafe.Pointer(p + uintptr((k-2))*4)) -= ((*(*int32)(unsafe.Pointer(p + uintptr(k)*4))) << (1))
	}
}

/* Helper function for A2NLSF(..)                    */
/* Polynomial evaluation                             */
func A2NLSF_eval_poly(tls *libc.TLS, p uintptr, x int32, dd int32) int32 { /* A2NLSF.c:62:22: */
	var n int32
	var x_Q16 int32
	var y32 int32

	y32 = *(*int32)(unsafe.Pointer(p + uintptr(dd)*4)) /* QPoly */
	x_Q16 = ((x) << (4))
	for n = (dd - 1); n >= 0; n-- {
		y32 = (((*(*int32)(unsafe.Pointer(p + uintptr(n)*4))) + ((((y32) >> 16) * (int32(int16(x_Q16)))) + ((((y32) & 0x0000FFFF) * (int32(int16(x_Q16)))) >> 16))) + ((y32) * (func() int32 {
			if (16) == 1 {
				return (((x_Q16) >> 1) + ((x_Q16) & 1))
			}
			return ((((x_Q16) >> ((16) - 1)) + 1) >> 1)
		}()))) /* QPoly */
	}
	return y32
}

func A2NLSF_init(tls *libc.TLS, a_Q16 uintptr, P uintptr, Q uintptr, dd int32) { /* A2NLSF.c:79:17: */
	var k int32

	/* Convert filter coefs to even and odd polynomials */
	*(*int32)(unsafe.Pointer(P + uintptr(dd)*4)) = (int32((1)) << (16))
	*(*int32)(unsafe.Pointer(Q + uintptr(dd)*4)) = (int32((1)) << (16))
	for k = 0; k < dd; k++ {
		*(*int32)(unsafe.Pointer(P + uintptr(k)*4)) = (-*(*int32)(unsafe.Pointer(a_Q16 + uintptr(((dd-k)-1))*4)) - *(*int32)(unsafe.Pointer(a_Q16 + uintptr((dd+k))*4))) // QPoly
		*(*int32)(unsafe.Pointer(Q + uintptr(k)*4)) = (-*(*int32)(unsafe.Pointer(a_Q16 + uintptr(((dd-k)-1))*4)) + *(*int32)(unsafe.Pointer(a_Q16 + uintptr((dd+k))*4))) // QPoly
	}

	/* Divide out zeros as we have that for even filter orders, */
	/* z =  1 is always a root in Q, and                        */
	/* z = -1 is always a root in P                             */
	for k = dd; k > 0; k-- {
		*(*int32)(unsafe.Pointer(P + uintptr((k-1))*4)) -= (*(*int32)(unsafe.Pointer(P + uintptr(k)*4)))
		*(*int32)(unsafe.Pointer(Q + uintptr((k-1))*4)) += (*(*int32)(unsafe.Pointer(Q + uintptr(k)*4)))
	}

	/* Transform polynomials from cos(n*f) to cos(f)^n */
	A2NLSF_trans_poly(tls, P, dd)
	A2NLSF_trans_poly(tls, Q, dd)
}

/* Compute Normalized Line Spectral Frequencies (NLSFs) from whitening filter coefficients        */
/* If not all roots are found, the a_Q16 coefficients are bandwidth expanded until convergence.    */
func A2NLSF(tls *libc.TLS, NLSF uintptr, a_Q16 uintptr, d int32) { /* A2NLSF.c:119:6: */
	bp := tls.Alloc(80)
	defer tls.Free(80)

	var i int32
	var k int32
	var m int32
	var dd int32
	var root_ix int32
	var ffrac int32
	var xlo int32
	var xhi int32
	var xmid int32
	var ylo int32
	var yhi int32
	var ymid int32
	var nom int32
	var den int32
	// var P [9]int32 at bp+8, 36

	// var Q [9]int32 at bp+44, 36

	// var PQ [2]uintptr at bp, 8

	var p uintptr

	/* Store pointers to array */
	*(*uintptr)(unsafe.Pointer(bp /* &PQ[0] */)) = bp + 8        /* &P[0] */
	*(*uintptr)(unsafe.Pointer(bp /* &PQ[0] */ + 1*4)) = bp + 44 /* &Q[0] */

	dd = ((d) >> (1))

	A2NLSF_init(tls, a_Q16, bp+8 /* &P[0] */, bp+44 /* &Q[0] */, dd)

	/* Find roots, alternating between P and Q */
	p = bp + 8 /* &P[0] */ /* Pointer to polynomial */

	xlo = LSFCosTab_FIX_Q12[0] // Q12
	ylo = A2NLSF_eval_poly(tls, p, xlo, dd)

	if ylo < 0 {
		/* Set the first NLSF to zero and move on to the next */
		*(*int32)(unsafe.Pointer(NLSF)) = 0
		p = bp + 44 /* &Q[0] */ /* Pointer to polynomial */
		ylo = A2NLSF_eval_poly(tls, p, xlo, dd)
		root_ix = 1 /* Index of current root */
	} else {
		root_ix = 0 /* Index of current root */
	}
	k = 1 /* Loop counter */
	i = 0 /* Counter for bandwidth expansions applied */
	for 1 != 0 {
		/* Evaluate polynomial */
		xhi = LSFCosTab_FIX_Q12[k] /* Q12 */
		yhi = A2NLSF_eval_poly(tls, p, xhi, dd)

		/* Detect zero crossing */
		if ((ylo <= 0) && (yhi >= 0)) || ((ylo >= 0) && (yhi <= 0)) {
			/* Binary division */
			ffrac = -256
			for m = 0; m < 3; m++ {
				/* Evaluate polynomial */
				xmid = func() int32 {
					if (1) == 1 {
						return (((xlo + xhi) >> 1) + ((xlo + xhi) & 1))
					}
					return ((((xlo + xhi) >> ((1) - 1)) + 1) >> 1)
				}()
				ymid = A2NLSF_eval_poly(tls, p, xmid, dd)

				/* Detect zero crossing */
				if ((ylo <= 0) && (ymid >= 0)) || ((ylo >= 0) && (ymid <= 0)) {
					/* Reduce frequency */
					xhi = xmid
					yhi = ymid
				} else {
					/* Increase frequency */
					xlo = xmid
					ylo = ymid
					ffrac = ((ffrac) + (int32((128)) >> (m)))
				}
			}

			/* Interpolate */
			if (func() int32 {
				if (ylo) > 0 {
					return ylo
				}
				return -ylo
			}()) < 65536 {
				/* Avoid dividing by zero */
				den = (ylo - yhi)
				nom = (((ylo) << (8 - 3)) + ((den) >> (1)))
				if den != 0 {
					ffrac = ffrac + ((nom) / (den))
				}
			} else {
				/* No risk of dividing by zero because abs(ylo - yhi) >= abs(ylo) >= 65536 */
				ffrac = ffrac + ((ylo) / ((ylo - yhi) >> (8 - 3)))
			}
			*(*int32)(unsafe.Pointer(NLSF + uintptr(root_ix)*4)) = min_32(tls, (((k) << (8)) + ffrac), 0x7FFF)

			root_ix++ /* Next root */
			if root_ix >= d {
				/* Found all roots */
				break
			}
			/* Alternate pointer to polynomial */
			p = *(*uintptr)(unsafe.Pointer(bp /* &PQ[0] */ + uintptr((root_ix&1))*4))

			/* Evaluate polynomial */
			xlo = LSFCosTab_FIX_Q12[(k - 1)] // Q12
			ylo = ((1 - (root_ix & 2)) << (12))
		} else {
			/* Increment loop counter */
			k++
			xlo = xhi
			ylo = yhi

			if k > 128 {
				i++
				if i > 30 {
					/* Set NLSFs to white spectrum and exit */
					*(*int32)(unsafe.Pointer(NLSF)) = ((int32(1) << 15) / (d + 1))
					for k = 1; k < d; k++ {
						*(*int32)(unsafe.Pointer(NLSF + uintptr(k)*4)) = ((int32((int16(k + 1)))) * (int32(int16(*(*int32)(unsafe.Pointer(NLSF))))))
					}
					return
				}

				/* Error: Apply progressively more bandwidth expansion and run again */
				bwexpander_32(tls, a_Q16, d, (65536 - ((int32((int16(10 + i)))) * (int32(int16(i)))))) // 10_Q16 = 0.00015

				A2NLSF_init(tls, a_Q16, bp+8 /* &P[0] */, bp+44 /* &Q[0] */, dd)
				p = bp + 8                 /* &P[0] */ /* Pointer to polynomial */
				xlo = LSFCosTab_FIX_Q12[0] // Q12
				ylo = A2NLSF_eval_poly(tls, p, xlo, dd)
				if ylo < 0 {
					/* Set the first NLSF to zero and move on to the next */
					*(*int32)(unsafe.Pointer(NLSF)) = 0
					p = bp + 44 /* &Q[0] */ /* Pointer to polynomial */
					ylo = A2NLSF_eval_poly(tls, p, xlo, dd)
					root_ix = 1 /* Index of current root */
				} else {
					root_ix = 0 /* Index of current root */
				}
				k = 1 /* Reset loop counter */
			}
		}
	}
}

/* Coefficients for 2-band filter bank based on first-order allpass filters */
// old
var A_fb1_20 = [1]int16{(int16(int32(5394) << 1))}                /* ana_filt_bank_1.c:40:18 */
var A_fb1_21 = [1]int16{(libc.Int16FromInt32(int32(20623) << 1))} /* ana_filt_bank_1.c:41:18 */

/* wrap-around to negative number is intentional */

/* Split signal into two decimated bands using first-order allpass filters */
func ana_filt_bank_1(tls *libc.TLS, in uintptr, S uintptr, outL uintptr, outH uintptr, scratch uintptr, N int32) { /* ana_filt_bank_1.c:44:6: */
	var k int32
	var N2 int32 = ((N) >> (1))
	var in32 int32
	var X int32
	var Y int32
	var out_1 int32
	var out_2 int32

	/* Internal variables and state are in Q10 format */
	for k = 0; k < N2; k++ {
		/* Convert to Q10 */
		in32 = ((int32(*(*int16)(unsafe.Pointer(in + uintptr((2*k))*2)))) << (10))

		/* All-pass section for even input sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S))))
		X = ((Y) + ((((Y) >> 16) * (int32(A_fb1_21[0]))) + ((((Y) & 0x0000FFFF) * (int32(A_fb1_21[0]))) >> 16)))
		out_1 = ((*(*int32)(unsafe.Pointer(S))) + (X))
		*(*int32)(unsafe.Pointer(S)) = ((in32) + (X))

		/* Convert to Q10 */
		in32 = ((int32(*(*int16)(unsafe.Pointer(in + uintptr(((2*k)+1))*2)))) << (10))

		/* All-pass section for odd input sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S + 1*4))))
		X = ((((Y) >> 16) * (int32(A_fb1_20[0]))) + ((((Y) & 0x0000FFFF) * (int32(A_fb1_20[0]))) >> 16))
		out_2 = ((*(*int32)(unsafe.Pointer(S + 1*4))) + (X))
		*(*int32)(unsafe.Pointer(S + 1*4)) = ((in32) + (X))

		/* Add/subtract, convert back to int16 and store to output */
		*(*int16)(unsafe.Pointer(outL + uintptr(k)*2)) = func() int16 {
			if (func() int32 {
				if (11) == 1 {
					return ((((out_2) + (out_1)) >> 1) + (((out_2) + (out_1)) & 1))
				}
				return (((((out_2) + (out_1)) >> ((11) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (11) == 1 {
						return ((((out_2) + (out_1)) >> 1) + (((out_2) + (out_1)) & 1))
					}
					return (((((out_2) + (out_1)) >> ((11) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (11) == 1 {
						return (int16((((out_2) + (out_1)) >> 1) + (((out_2) + (out_1)) & 1)))
					}
					return (int16(((((out_2) + (out_1)) >> ((11) - 1)) + 1) >> 1))
				}()
			}()
		}()
		*(*int16)(unsafe.Pointer(outH + uintptr(k)*2)) = func() int16 {
			if (func() int32 {
				if (11) == 1 {
					return ((((out_2) - (out_1)) >> 1) + (((out_2) - (out_1)) & 1))
				}
				return (((((out_2) - (out_1)) >> ((11) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (11) == 1 {
						return ((((out_2) - (out_1)) >> 1) + (((out_2) - (out_1)) & 1))
					}
					return (((((out_2) - (out_1)) >> ((11) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (11) == 1 {
						return (int16((((out_2) - (out_1)) >> 1) + (((out_2) - (out_1)) & 1)))
					}
					return (int16(((((out_2) - (out_1)) >> ((11) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}
}

/* Apply sine window to signal vector.                                      */
/* Window types:                                                            */
/*    1 -> sine window from 0 to pi/2                                       */
/*    2 -> sine window from pi/2 to pi                                      */
/* Every other sample is linearly interpolated, for speed.                  */
/* Window length must be between 16 and 120 (incl) and a multiple of 4.     */

/* Matlab code for table:
   for k=16:9*4:16+2*9*4, fprintf(' %7.d,', -round(65536*pi ./ (k:4:k+8*4))); fprintf('\n'); end
*/
var freq_table_Q16 = [27]int16{
	int16(12111), int16(9804), int16(8235), int16(7100), int16(6239), int16(5565), int16(5022), int16(4575), int16(4202),
	int16(3885), int16(3612), int16(3375), int16(3167), int16(2984), int16(2820), int16(2674), int16(2542), int16(2422),
	int16(2313), int16(2214), int16(2123), int16(2038), int16(1961), int16(1889), int16(1822), int16(1760), int16(1702),
} /* apply_sine_window.c:40:18 */

func apply_sine_window(tls *libc.TLS, px_win uintptr, px uintptr, win_type int32, length int32) { /* apply_sine_window.c:47:6: */
	var k int32
	var f_Q16 int32
	var c_Q16 int32
	var S0_Q16 int32
	var S1_Q16 int32

	/* Length must be in a range from 16 to 120 and a multiple of 4 */

	/* Input pointer must be 4-byte aligned */

	/* Frequency */
	k = ((length >> 2) - 4)

	f_Q16 = int32(freq_table_Q16[k])

	/* Factor used for cosine approximation */
	c_Q16 = ((((f_Q16) >> 16) * (int32(int16(-f_Q16)))) + ((((f_Q16) & 0x0000FFFF) * (int32(int16(-f_Q16)))) >> 16))

	/* initialize state */
	if win_type == 1 {
		/* start from 0 */
		S0_Q16 = 0
		/* approximation of sin(f) */
		S1_Q16 = (f_Q16 + ((length) >> (3)))
	} else {
		/* start from 1 */
		S0_Q16 = (int32(1) << 16)
		/* approximation of cos(f) */
		S1_Q16 = (((int32(1) << 16) + ((c_Q16) >> (1))) + ((length) >> (4)))
	}

	/* Uses the recursive equation:   sin(n*f) = 2 * cos(f) * sin((n-1)*f) - sin((n-2)*f)    */
	/* 4 samples at a time */
	for k = 0; k < length; k = k + (4) {
		*(*int16)(unsafe.Pointer(px_win + uintptr(k)*2)) = (int16(((((S0_Q16 + S1_Q16) >> (1)) >> 16) * (int32(*(*int16)(unsafe.Pointer(px + uintptr(k)*2))))) + (((((S0_Q16 + S1_Q16) >> (1)) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(px + uintptr(k)*2))))) >> 16)))
		*(*int16)(unsafe.Pointer(px_win + uintptr((k+1))*2)) = (int16((((S1_Q16) >> 16) * (int32(*(*int16)(unsafe.Pointer(px + uintptr((k+1))*2))))) + ((((S1_Q16) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(px + uintptr((k+1))*2))))) >> 16)))
		S0_Q16 = (((((((S1_Q16) >> 16) * (int32(int16(c_Q16)))) + ((((S1_Q16) & 0x0000FFFF) * (int32(int16(c_Q16)))) >> 16)) + ((S1_Q16) << (1))) - S0_Q16) + 1)
		S0_Q16 = func() int32 {
			if (S0_Q16) < (int32(1) << 16) {
				return S0_Q16
			}
			return (int32(1) << 16)
		}()

		*(*int16)(unsafe.Pointer(px_win + uintptr((k+2))*2)) = (int16(((((S0_Q16 + S1_Q16) >> (1)) >> 16) * (int32(*(*int16)(unsafe.Pointer(px + uintptr((k+2))*2))))) + (((((S0_Q16 + S1_Q16) >> (1)) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(px + uintptr((k+2))*2))))) >> 16)))
		*(*int16)(unsafe.Pointer(px_win + uintptr((k+3))*2)) = (int16((((S0_Q16) >> 16) * (int32(*(*int16)(unsafe.Pointer(px + uintptr((k+3))*2))))) + ((((S0_Q16) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(px + uintptr((k+3))*2))))) >> 16)))
		S1_Q16 = ((((((S0_Q16) >> 16) * (int32(int16(c_Q16)))) + ((((S0_Q16) & 0x0000FFFF) * (int32(int16(c_Q16)))) >> 16)) + ((S0_Q16) << (1))) - S1_Q16)
		S1_Q16 = func() int32 {
			if (S1_Q16) < (int32(1) << 16) {
				return S1_Q16
			}
			return (int32(1) << 16)
		}()
	}
}

/* Function that returns the maximum absolut value of the input vector */
func int16_array_maxabs(tls *libc.TLS, vec uintptr, len int32) int16 { /* array_maxabs.c:40:11: */
	var max int32 = 0
	var i int32
	var lvl int32 = 0
	var ind int32
	if len == 0 {
		return int16(0)
	}

	ind = (len - 1)
	max = ((int32(*(*int16)(unsafe.Pointer(vec + uintptr(ind)*2)))) * (int32(*(*int16)(unsafe.Pointer(vec + uintptr(ind)*2)))))
	for i = (len - 2); i >= 0; i-- {
		lvl = ((int32(*(*int16)(unsafe.Pointer(vec + uintptr(i)*2)))) * (int32(*(*int16)(unsafe.Pointer(vec + uintptr(i)*2)))))
		if lvl > max {
			max = lvl
			ind = i
		}
	}

	/* Do not return 32768, as it will not fit in an int16 so may lead to problems later on */
	if max >= 1073676289 { // (2^15-1)^2 = 1073676289
		return int16(0x7FFF)
	} else {
		if int32(*(*int16)(unsafe.Pointer(vec + uintptr(ind)*2))) < 0 {
			return int16(-int32(*(*int16)(unsafe.Pointer(vec + uintptr(ind)*2))))
		} else {
			return *(*int16)(unsafe.Pointer(vec + uintptr(ind)*2))
		}
	}
	return int16(0)
}

/* Compute autocorrelation */
func autocorr(tls *libc.TLS, results uintptr, scale uintptr, inputData uintptr, inputDataSize int32, correlationCount int32) { /* autocorr.c:40:6: */
	var i int32
	var lz int32
	var nRightShifts int32
	var corrCount int32
	var corr64 int64_t

	corrCount = min_int(tls, inputDataSize, correlationCount)

	/* compute energy (zero-lag correlation) */
	corr64 = inner_prod16_aligned_64(tls, inputData, inputData, inputDataSize)

	/* deal with all-zero input data */
	corr64 = corr64 + (int64(1))

	/* number of leading zeros */
	lz = CLZ64(tls, corr64)

	/* scaling: number of right shifts applied to correlations */
	nRightShifts = (35 - lz)
	*(*int32)(unsafe.Pointer(scale)) = nRightShifts

	if nRightShifts <= 0 {
		*(*int32)(unsafe.Pointer(results)) = ((int32(corr64)) << (-nRightShifts))

		/* compute remaining correlations based on int32 inner product */
		for i = 1; i < corrCount; i++ {
			*(*int32)(unsafe.Pointer(results + uintptr(i)*4)) = ((inner_prod_aligned(tls, inputData, (inputData + uintptr(i)*2), (inputDataSize - i))) << (-nRightShifts))
		}
	} else {
		*(*int32)(unsafe.Pointer(results)) = (int32((corr64) >> (nRightShifts)))

		/* compute remaining correlations based on int64 inner product */
		for i = 1; i < corrCount; i++ {
			*(*int32)(unsafe.Pointer(results + uintptr(i)*4)) = (int32((inner_prod16_aligned_64(tls, inputData, (inputData + uintptr(i)*2), (inputDataSize - i))) >> (nRightShifts)))
		}
	}
}

/* Second order ARMA filter */
/* Can handle slowly varying filter coefficients */
func biquad(tls *libc.TLS, in uintptr, B uintptr, A uintptr, S uintptr, out uintptr, len int32) { /* biquad.c:41:6: */
	var k int32
	var in16 int32
	var A0_neg int32
	var A1_neg int32
	var S0 int32
	var S1 int32
	var out32 int32
	var tmp32 int32

	S0 = *(*int32)(unsafe.Pointer(S))
	S1 = *(*int32)(unsafe.Pointer(S + 1*4))
	A0_neg = -int32(*(*int16)(unsafe.Pointer(A)))
	A1_neg = -int32(*(*int16)(unsafe.Pointer(A + 1*2)))
	for k = 0; k < len; k++ {
		/* S[ 0 ], S[ 1 ]: Q13 */
		in16 = int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))
		out32 = ((S0) + ((int32(int16(in16))) * (int32(*(*int16)(unsafe.Pointer(B))))))

		S0 = ((S1) + ((int32(int16(in16))) * (int32(*(*int16)(unsafe.Pointer(B + 1*2))))))
		S0 = S0 + (((((out32) >> 16) * (int32(int16(A0_neg)))) + ((((out32) & 0x0000FFFF) * (int32(int16(A0_neg)))) >> 16)) << (3))

		S1 = (((((out32) >> 16) * (int32(int16(A1_neg)))) + ((((out32) & 0x0000FFFF) * (int32(int16(A1_neg)))) >> 16)) << (3))
		S1 = ((S1) + ((int32(int16(in16))) * (int32(*(*int16)(unsafe.Pointer(B + 2*2))))))
		tmp32 = ((func() int32 {
			if (13) == 1 {
				return (((out32) >> 1) + ((out32) & 1))
			}
			return ((((out32) >> ((13) - 1)) + 1) >> 1)
		}()) + 1)
		*(*int16)(unsafe.Pointer(out + uintptr(k)*2)) = func() int16 {
			if (tmp32) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (tmp32) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return int16(tmp32)
			}()
		}()
	}
	*(*int32)(unsafe.Pointer(S)) = S0
	*(*int32)(unsafe.Pointer(S + 1*4)) = S1
}

/* Second order ARMA filter, alternative implementation */
func biquad_alt(tls *libc.TLS, in uintptr, B_Q28 uintptr, A_Q28 uintptr, S uintptr, out uintptr, len int32) { /* biquad_alt.c:38:6: */
	/* DIRECT FORM II TRANSPOSED (uses 2 element state vector) */
	var k int32
	var inval int32
	var A0_U_Q28 int32
	var A0_L_Q28 int32
	var A1_U_Q28 int32
	var A1_L_Q28 int32
	var out32_Q14 int32

	/* Negate A_Q28 values and split in two parts */
	A0_L_Q28 = ((-*(*int32)(unsafe.Pointer(A_Q28))) & 0x00003FFF)       /* lower part */
	A0_U_Q28 = ((-*(*int32)(unsafe.Pointer(A_Q28))) >> (14))            /* upper part */
	A1_L_Q28 = ((-*(*int32)(unsafe.Pointer(A_Q28 + 1*4))) & 0x00003FFF) /* lower part */
	A1_U_Q28 = ((-*(*int32)(unsafe.Pointer(A_Q28 + 1*4))) >> (14))      /* upper part */

	for k = 0; k < len; k++ {
		/* S[ 0 ], S[ 1 ]: Q12 */
		inval = int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))
		out32_Q14 = (((*(*int32)(unsafe.Pointer(S))) + ((((*(*int32)(unsafe.Pointer(B_Q28))) >> 16) * (int32(int16(inval)))) + ((((*(*int32)(unsafe.Pointer(B_Q28))) & 0x0000FFFF) * (int32(int16(inval)))) >> 16))) << (2))

		*(*int32)(unsafe.Pointer(S)) = (*(*int32)(unsafe.Pointer(S + 1*4)) + (func() int32 {
			if (14) == 1 {
				return ((((((out32_Q14) >> 16) * (int32(int16(A0_L_Q28)))) + ((((out32_Q14) & 0x0000FFFF) * (int32(int16(A0_L_Q28)))) >> 16)) >> 1) + (((((out32_Q14) >> 16) * (int32(int16(A0_L_Q28)))) + ((((out32_Q14) & 0x0000FFFF) * (int32(int16(A0_L_Q28)))) >> 16)) & 1))
			}
			return (((((((out32_Q14) >> 16) * (int32(int16(A0_L_Q28)))) + ((((out32_Q14) & 0x0000FFFF) * (int32(int16(A0_L_Q28)))) >> 16)) >> ((14) - 1)) + 1) >> 1)
		}()))
		*(*int32)(unsafe.Pointer(S)) = ((*(*int32)(unsafe.Pointer(S))) + ((((out32_Q14) >> 16) * (int32(int16(A0_U_Q28)))) + ((((out32_Q14) & 0x0000FFFF) * (int32(int16(A0_U_Q28)))) >> 16)))
		*(*int32)(unsafe.Pointer(S)) = ((*(*int32)(unsafe.Pointer(S))) + ((((*(*int32)(unsafe.Pointer(B_Q28 + 1*4))) >> 16) * (int32(int16(inval)))) + ((((*(*int32)(unsafe.Pointer(B_Q28 + 1*4))) & 0x0000FFFF) * (int32(int16(inval)))) >> 16)))

		*(*int32)(unsafe.Pointer(S + 1*4)) = func() int32 {
			if (14) == 1 {
				return ((((((out32_Q14) >> 16) * (int32(int16(A1_L_Q28)))) + ((((out32_Q14) & 0x0000FFFF) * (int32(int16(A1_L_Q28)))) >> 16)) >> 1) + (((((out32_Q14) >> 16) * (int32(int16(A1_L_Q28)))) + ((((out32_Q14) & 0x0000FFFF) * (int32(int16(A1_L_Q28)))) >> 16)) & 1))
			}
			return (((((((out32_Q14) >> 16) * (int32(int16(A1_L_Q28)))) + ((((out32_Q14) & 0x0000FFFF) * (int32(int16(A1_L_Q28)))) >> 16)) >> ((14) - 1)) + 1) >> 1)
		}()
		*(*int32)(unsafe.Pointer(S + 1*4)) = ((*(*int32)(unsafe.Pointer(S + 1*4))) + ((((out32_Q14) >> 16) * (int32(int16(A1_U_Q28)))) + ((((out32_Q14) & 0x0000FFFF) * (int32(int16(A1_U_Q28)))) >> 16)))
		*(*int32)(unsafe.Pointer(S + 1*4)) = ((*(*int32)(unsafe.Pointer(S + 1*4))) + ((((*(*int32)(unsafe.Pointer(B_Q28 + 2*4))) >> 16) * (int32(int16(inval)))) + ((((*(*int32)(unsafe.Pointer(B_Q28 + 2*4))) & 0x0000FFFF) * (int32(int16(inval)))) >> 16)))

		/* Scale back to Q0 and saturate */
		*(*int16)(unsafe.Pointer(out + uintptr(k)*2)) = func() int16 {
			if (((out32_Q14 + (int32(1) << 14)) - 1) >> (14)) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (((out32_Q14 + (int32(1) << 14)) - 1) >> (14)) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return (int16(((out32_Q14 + (int32(1) << 14)) - 1) >> (14)))
			}()
		}()
	}
}

/* Compute reflection coefficients from input signal */
func burg_modified(tls *libc.TLS, res_nrg uintptr, res_nrg_Q uintptr, A_Q16 uintptr, x uintptr, subfr_length int32, nb_subfr int32, WhiteNoiseFrac_Q32 int32, D int32) { /* burg_modified.c:49:6: */
	bp := tls.Alloc(336)
	defer tls.Free(336)

	var k int32
	var n int32
	var s int32
	var lz int32
	// var rshifts int32 at bp+4, 4

	var rshifts_extra int32
	// var C0 int32 at bp, 4

	var num int32
	var nrg int32
	var rc_Q31 int32
	var Atmp_QA int32
	var Atmp1 int32
	var tmp1 int32
	var tmp2 int32
	var x1 int32
	var x2 int32
	var x_ptr uintptr
	// var C_first_row [16]int32 at bp+8, 64

	// var C_last_row [16]int32 at bp+72, 64

	// var Af_QA [16]int32 at bp+272, 64

	// var CAf [17]int32 at bp+204, 68

	// var CAb [17]int32 at bp+136, 68

	/* Compute autocorrelations, added over subframes */
	sum_sqr_shift(tls, bp /* &C0 */, bp+4 /* &rshifts */, x, (nb_subfr * subfr_length))
	if *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) > (32 - 25) {
		*(*int32)(unsafe.Pointer(bp /* C0 */)) = ((*(*int32)(unsafe.Pointer(bp /* C0 */))) << (*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - (32 - 25)))

		*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) = (32 - 25)
	} else {
		lz = (CLZ32(tls, *(*int32)(unsafe.Pointer(bp /* C0 */))) - 1)
		rshifts_extra = (2 - lz)
		if rshifts_extra > 0 {
			rshifts_extra = func() int32 {
				if (rshifts_extra) < ((32 - 25) - *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */))) {
					return rshifts_extra
				}
				return ((32 - 25) - *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)))
			}()
			*(*int32)(unsafe.Pointer(bp /* C0 */)) = ((*(*int32)(unsafe.Pointer(bp /* C0 */))) >> (rshifts_extra))
		} else {
			rshifts_extra = func() int32 {
				if (rshifts_extra) > (-16 - *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */))) {
					return rshifts_extra
				}
				return (-16 - *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)))
			}()
			*(*int32)(unsafe.Pointer(bp /* C0 */)) = ((*(*int32)(unsafe.Pointer(bp /* C0 */))) << (-rshifts_extra))
		}
		*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) += rshifts_extra
	}
	libc.Xmemset(tls, bp+8 /* &C_first_row[0] */, 0, (uint32(16) * uint32(unsafe.Sizeof(int32(0)))))
	if *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) > 0 {
		for s = 0; s < nb_subfr; s++ {
			x_ptr = (x + uintptr((s*subfr_length))*2)
			for n = 1; n < (D + 1); n++ {
				*(*int32)(unsafe.Pointer(bp + 8 /* &C_first_row */ + uintptr((n-1))*4)) += (int32((inner_prod16_aligned_64(tls, x_ptr, (x_ptr + uintptr(n)*2), (subfr_length - n))) >> (*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)))))
			}
		}
	} else {
		for s = 0; s < nb_subfr; s++ {
			x_ptr = (x + uintptr((s*subfr_length))*2)
			for n = 1; n < (D + 1); n++ {
				*(*int32)(unsafe.Pointer(bp + 8 /* &C_first_row */ + uintptr((n-1))*4)) += ((inner_prod_aligned(tls, x_ptr, (x_ptr + uintptr(n)*2), (subfr_length - n))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */))))
			}
		}
	}
	libc.Xmemcpy(tls, bp+72 /* &C_last_row[0] */, bp+8 /* &C_first_row[0] */, (uint32(16) * uint32(unsafe.Sizeof(int32(0)))))

	/* Initialize */
	*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */)) = libc.AssignPtrInt32(bp+204 /* &CAf */, ((*(*int32)(unsafe.Pointer(bp /* C0 */)) + (int32(((int64_t(WhiteNoiseFrac_Q32)) * (int64_t(*(*int32)(unsafe.Pointer(bp /* C0 */))))) >> (32)))) + 1)) // Q(-rshifts)

	for n = 0; n < D; n++ {
		/* Update first row of correlation matrix (without first element) */
		/* Update last row of correlation matrix (without last element, stored in reversed order) */
		/* Update C * Af */
		/* Update C * flipud(Af) (stored in reversed order) */
		if *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) > -2 {
			for s = 0; s < nb_subfr; s++ {
				x_ptr = (x + uintptr((s*subfr_length))*2)
				x1 = -((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(n)*2)))) << (16 - *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */))))                    // Q(16-rshifts)
				x2 = -((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)-1))*2)))) << (16 - *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)))) // Q(16-rshifts)
				tmp1 = ((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(n)*2)))) << (25 - 16))                                                                // Q(QA-16)
				tmp2 = ((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)-1))*2)))) << (25 - 16))                                             // Q(QA-16)
				for k = 0; k < n; k++ {
					*(*int32)(unsafe.Pointer(bp + 8 /* &C_first_row[0] */ + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer(bp + 8 /* &C_first_row[0] */ + uintptr(k)*4))) + ((((x1) >> 16) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((n-k)-1))*2))))) + ((((x1) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((n-k)-1))*2))))) >> 16)))                       // Q( -rshifts )
					*(*int32)(unsafe.Pointer(bp + 72 /* &C_last_row[0] */ + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer(bp + 72 /* &C_last_row[0] */ + uintptr(k)*4))) + ((((x2) >> 16) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)+k))*2))))) + ((((x2) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)+k))*2))))) >> 16))) // Q( -rshifts )
					Atmp_QA = *(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4))
					tmp1 = ((tmp1) + ((((Atmp_QA) >> 16) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((n-k)-1))*2))))) + ((((Atmp_QA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((n-k)-1))*2))))) >> 16)))                       // Q(QA-16)
					tmp2 = ((tmp2) + ((((Atmp_QA) >> 16) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)+k))*2))))) + ((((Atmp_QA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)+k))*2))))) >> 16))) // Q(QA-16)
				}
				tmp1 = ((-tmp1) << ((32 - 25) - *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)))) // Q(16-rshifts)
				tmp2 = ((-tmp2) << ((32 - 25) - *(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)))) // Q(16-rshifts)
				for k = 0; k <= n; k++ {
					*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr(k)*4))) + ((((tmp1) >> 16) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((n-k))*2))))) + ((((tmp1) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((n-k))*2))))) >> 16)))                                       // Q( -rshift )
					*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */ + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */ + uintptr(k)*4))) + ((((tmp2) >> 16) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((((subfr_length-n)+k)-1))*2))))) + ((((tmp2) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((((subfr_length-n)+k)-1))*2))))) >> 16))) // Q( -rshift )
				}
			}
		} else {
			for s = 0; s < nb_subfr; s++ {
				x_ptr = (x + uintptr((s*subfr_length))*2)
				x1 = -((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(n)*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */))))                    // Q( -rshifts )
				x2 = -((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)-1))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)))) // Q( -rshifts )
				tmp1 = ((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(n)*2)))) << (17))                                                                 // Q17
				tmp2 = ((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)-1))*2)))) << (17))                                              // Q17
				for k = 0; k < n; k++ {
					*(*int32)(unsafe.Pointer(bp + 8 /* &C_first_row[0] */ + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer(bp + 8 /* &C_first_row[0] */ + uintptr(k)*4))) + ((x1) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((n-k)-1))*2))))))            // Q( -rshifts )
					*(*int32)(unsafe.Pointer(bp + 72 /* &C_last_row[0] */ + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer(bp + 72 /* &C_last_row[0] */ + uintptr(k)*4))) + ((x2) * (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)+k))*2)))))) // Q( -rshifts )
					Atmp1 = func() int32 {
						if (25 - 17) == 1 {
							return (((*(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4))) >> ((25 - 17) - 1)) + 1) >> 1)
					}() // Q17
					tmp1 = ((tmp1) + ((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((n-k)-1))*2)))) * (Atmp1)))            // Q17
					tmp2 = ((tmp2) + ((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(((subfr_length-n)+k))*2)))) * (Atmp1))) // Q17
				}
				tmp1 = -tmp1 // Q17
				tmp2 = -tmp2 // Q17
				for k = 0; k <= n; k++ {
					*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr(k)*4)) = (((*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr(k)*4))) + ((((tmp1) >> 16) * (int32((int16((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((n-k))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)))))) + ((((tmp1) & 0x0000FFFF) * (int32((int16((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((n-k))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)))))) >> 16))) + ((tmp1) * (func() int32 {
						if (16) == 1 {
							return ((((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((n-k))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)) >> 1) + (((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((n-k))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)) & 1))
						}
						return (((((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((n-k))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)) >> ((16) - 1)) + 1) >> 1)
					}()))) // Q( -rshift )
					*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */ + uintptr(k)*4)) = (((*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */ + uintptr(k)*4))) + ((((tmp2) >> 16) * (int32((int16((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((((subfr_length-n)+k)-1))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)))))) + ((((tmp2) & 0x0000FFFF) * (int32((int16((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((((subfr_length-n)+k)-1))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)))))) >> 16))) + ((tmp2) * (func() int32 {
						if (16) == 1 {
							return ((((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((((subfr_length-n)+k)-1))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)) >> 1) + (((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((((subfr_length-n)+k)-1))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)) & 1))
						}
						return (((((int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr((((subfr_length-n)+k)-1))*2)))) << (-*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */)) - 1)) >> ((16) - 1)) + 1) >> 1)
					}()))) // Q( -rshift )
				}
			}
		}

		/* Calculate nominator and denominator for the next order reflection (parcor) coefficient */
		tmp1 = *(*int32)(unsafe.Pointer(bp + 8 /* &C_first_row[0] */ + uintptr(n)*4))                                     // Q( -rshifts )
		tmp2 = *(*int32)(unsafe.Pointer(bp + 72 /* &C_last_row[0] */ + uintptr(n)*4))                                     // Q( -rshifts )
		num = 0                                                                                                           // Q( -rshifts )
		nrg = ((*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */))) + (*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */)))) // Q( 1-rshifts )
		for k = 0; k < n; k++ {
			Atmp_QA = *(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4))
			lz = (CLZ32(tls, func() int32 {
				if (Atmp_QA) > 0 {
					return Atmp_QA
				}
				return -Atmp_QA
			}()) - 1)
			lz = func() int32 {
				if (32 - 25) < (lz) {
					return (32 - 25)
				}
				return lz
			}()
			Atmp1 = ((Atmp_QA) << (lz)) // Q( QA + lz )

			tmp1 = ((tmp1) + ((int32(((int64_t(*(*int32)(unsafe.Pointer(bp + 72 /* &C_last_row[0] */ + uintptr(((n-k)-1))*4)))) * (int64_t(Atmp1))) >> (32))) << ((32 - 25) - lz)))                                                                // Q( -rshifts )
			tmp2 = ((tmp2) + ((int32(((int64_t(*(*int32)(unsafe.Pointer(bp + 8 /* &C_first_row[0] */ + uintptr(((n-k)-1))*4)))) * (int64_t(Atmp1))) >> (32))) << ((32 - 25) - lz)))                                                                // Q( -rshifts )
			num = ((num) + ((int32(((int64_t(*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */ + uintptr((n-k))*4)))) * (int64_t(Atmp1))) >> (32))) << ((32 - 25) - lz)))                                                                            // Q( -rshifts )
			nrg = ((nrg) + ((int32(((int64_t((*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */ + uintptr((k+1))*4))) + (*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr((k+1))*4))))) * (int64_t(Atmp1))) >> (32))) << ((32 - 25) - lz))) // Q( 1-rshifts )
		}
		*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr((n+1))*4)) = tmp1 // Q( -rshifts )
		*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */ + uintptr((n+1))*4)) = tmp2 // Q( -rshifts )
		num = ((num) + (tmp2))                                                      // Q( -rshifts )
		num = ((-num) << (1))                                                       // Q( 1-rshifts )

		/* Calculate the next order reflection (parcor) coefficient */
		if (func() int32 {
			if (num) > 0 {
				return num
			}
			return -num
		}()) < nrg {
			rc_Q31 = DIV32_varQ(tls, num, nrg, 31)
		} else {
			/* Negative energy or ratio too high; set remaining coefficients to zero and exit loop */
			libc.Xmemset(tls, (bp + 272 /* &Af_QA */ + uintptr(n)*4), 0, ((uint32(D - n)) * uint32(unsafe.Sizeof(int32(0)))))

			break
		}

		/* Update the AR coefficients */
		for k = 0; k < ((n + 1) >> 1); k++ {
			tmp1 = *(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4))                                                                               // QA
			tmp2 = *(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(((n-k)-1))*4))                                                                       // QA
			*(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4)) = ((tmp1) + ((int32(((int64_t(tmp2)) * (int64_t(rc_Q31))) >> (32))) << (1)))         // QA
			*(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(((n-k)-1))*4)) = ((tmp2) + ((int32(((int64_t(tmp1)) * (int64_t(rc_Q31))) >> (32))) << (1))) // QA
		}
		*(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(n)*4)) = ((rc_Q31) >> (31 - 25)) // QA

		/* Update C * Af and C * Ab */
		for k = 0; k <= (n + 1); k++ {
			tmp1 = *(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr(k)*4))                                                                               // Q( -rshifts )
			tmp2 = *(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */ + uintptr(((n-k)+1))*4))                                                                       // Q( -rshifts )
			*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr(k)*4)) = ((tmp1) + ((int32(((int64_t(tmp2)) * (int64_t(rc_Q31))) >> (32))) << (1)))         // Q( -rshifts )
			*(*int32)(unsafe.Pointer(bp + 136 /* &CAb[0] */ + uintptr(((n-k)+1))*4)) = ((tmp2) + ((int32(((int64_t(tmp1)) * (int64_t(rc_Q31))) >> (32))) << (1))) // Q( -rshifts )
		}
	}

	/* Return residual energy */
	nrg = *(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */)) // Q( -rshifts )
	tmp1 = (int32(1) << 16)                                 // Q16
	for k = 0; k < D; k++ {
		Atmp1 = func() int32 {
			if (25 - 16) == 1 {
				return (((*(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4))) & 1))
			}
			return ((((*(*int32)(unsafe.Pointer(bp + 272 /* &Af_QA[0] */ + uintptr(k)*4))) >> ((25 - 16) - 1)) + 1) >> 1)
		}() // Q16
		nrg = (((nrg) + ((((*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr((k+1))*4))) >> 16) * (int32(int16(Atmp1)))) + ((((*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr((k+1))*4))) & 0x0000FFFF) * (int32(int16(Atmp1)))) >> 16))) + ((*(*int32)(unsafe.Pointer(bp + 204 /* &CAf[0] */ + uintptr((k+1))*4))) * (func() int32 {
			if (16) == 1 {
				return (((Atmp1) >> 1) + ((Atmp1) & 1))
			}
			return ((((Atmp1) >> ((16) - 1)) + 1) >> 1)
		}()))) // Q( -rshifts )
		tmp1 = (((tmp1) + ((((Atmp1) >> 16) * (int32(int16(Atmp1)))) + ((((Atmp1) & 0x0000FFFF) * (int32(int16(Atmp1)))) >> 16))) + ((Atmp1) * (func() int32 {
			if (16) == 1 {
				return (((Atmp1) >> 1) + ((Atmp1) & 1))
			}
			return ((((Atmp1) >> ((16) - 1)) + 1) >> 1)
		}()))) // Q16
		*(*int32)(unsafe.Pointer(A_Q16 + uintptr(k)*4)) = -Atmp1
	}
	*(*int32)(unsafe.Pointer(res_nrg)) = (((nrg) + ((((int32(((int64_t(WhiteNoiseFrac_Q32)) * (int64_t(*(*int32)(unsafe.Pointer(bp /* C0 */))))) >> (32))) >> 16) * (int32(int16(-tmp1)))) + ((((int32(((int64_t(WhiteNoiseFrac_Q32)) * (int64_t(*(*int32)(unsafe.Pointer(bp /* C0 */))))) >> (32))) & 0x0000FFFF) * (int32(int16(-tmp1)))) >> 16))) + ((int32(((int64_t(WhiteNoiseFrac_Q32)) * (int64_t(*(*int32)(unsafe.Pointer(bp /* C0 */))))) >> (32))) * (func() int32 {
		if (16) == 1 {
			return (((-tmp1) >> 1) + ((-tmp1) & 1))
		}
		return ((((-tmp1) >> ((16) - 1)) + 1) >> 1)
	}()))) // Q( -rshifts )
	*(*int32)(unsafe.Pointer(res_nrg_Q)) = -*(*int32)(unsafe.Pointer(bp + 4 /* rshifts */))
}

/* Chirp (bandwidth expand) LP AR filter */
func bwexpander(tls *libc.TLS, ar uintptr, d int32, chirp_Q16 int32) { /* bwexpander.c:31:6: */
	var i int32
	var chirp_minus_one_Q16 int32

	chirp_minus_one_Q16 = (chirp_Q16 - 65536)

	/* NB: Dont use SMULWB, instead of RSHIFT_ROUND( MUL() , 16 ), below. */
	/* Bias in SMULWB can lead to unstable filters                                */
	for i = 0; i < (d - 1); i++ {
		*(*int16)(unsafe.Pointer(ar + uintptr(i)*2)) = func() int16 {
			if (16) == 1 {
				return (int16((((chirp_Q16) * (int32(*(*int16)(unsafe.Pointer(ar + uintptr(i)*2))))) >> 1) + (((chirp_Q16) * (int32(*(*int16)(unsafe.Pointer(ar + uintptr(i)*2))))) & 1)))
			}
			return (int16(((((chirp_Q16) * (int32(*(*int16)(unsafe.Pointer(ar + uintptr(i)*2))))) >> ((16) - 1)) + 1) >> 1))
		}()
		chirp_Q16 = chirp_Q16 + (func() int32 {
			if (16) == 1 {
				return ((((chirp_Q16) * (chirp_minus_one_Q16)) >> 1) + (((chirp_Q16) * (chirp_minus_one_Q16)) & 1))
			}
			return (((((chirp_Q16) * (chirp_minus_one_Q16)) >> ((16) - 1)) + 1) >> 1)
		}())
	}
	*(*int16)(unsafe.Pointer(ar + uintptr((d-1))*2)) = func() int16 {
		if (16) == 1 {
			return (int16((((chirp_Q16) * (int32(*(*int16)(unsafe.Pointer(ar + uintptr((d-1))*2))))) >> 1) + (((chirp_Q16) * (int32(*(*int16)(unsafe.Pointer(ar + uintptr((d-1))*2))))) & 1)))
		}
		return (int16(((((chirp_Q16) * (int32(*(*int16)(unsafe.Pointer(ar + uintptr((d-1))*2))))) >> ((16) - 1)) + 1) >> 1))
	}()
}

/* Chirp (bandwidth expand) LP AR filter */
func bwexpander_32(tls *libc.TLS, ar uintptr, d int32, chirp_Q16 int32) { /* bwexpander_32.c:31:6: */
	var i int32
	var tmp_chirp_Q16 int32

	tmp_chirp_Q16 = chirp_Q16
	for i = 0; i < (d - 1); i++ {
		*(*int32)(unsafe.Pointer(ar + uintptr(i)*4)) = (((((*(*int32)(unsafe.Pointer(ar + uintptr(i)*4))) >> 16) * (int32(int16(tmp_chirp_Q16)))) + ((((*(*int32)(unsafe.Pointer(ar + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(tmp_chirp_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(ar + uintptr(i)*4))) * (func() int32 {
			if (16) == 1 {
				return (((tmp_chirp_Q16) >> 1) + ((tmp_chirp_Q16) & 1))
			}
			return ((((tmp_chirp_Q16) >> ((16) - 1)) + 1) >> 1)
		}())))
		tmp_chirp_Q16 = (((((chirp_Q16) >> 16) * (int32(int16(tmp_chirp_Q16)))) + ((((chirp_Q16) & 0x0000FFFF) * (int32(int16(tmp_chirp_Q16)))) >> 16)) + ((chirp_Q16) * (func() int32 {
			if (16) == 1 {
				return (((tmp_chirp_Q16) >> 1) + ((tmp_chirp_Q16) & 1))
			}
			return ((((tmp_chirp_Q16) >> ((16) - 1)) + 1) >> 1)
		}())))
	}
	*(*int32)(unsafe.Pointer(ar + uintptr((d-1))*4)) = (((((*(*int32)(unsafe.Pointer(ar + uintptr((d-1))*4))) >> 16) * (int32(int16(tmp_chirp_Q16)))) + ((((*(*int32)(unsafe.Pointer(ar + uintptr((d-1))*4))) & 0x0000FFFF) * (int32(int16(tmp_chirp_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(ar + uintptr((d-1))*4))) * (func() int32 {
		if (16) == 1 {
			return (((tmp_chirp_Q16) >> 1) + ((tmp_chirp_Q16) & 1))
		}
		return ((((tmp_chirp_Q16) >> ((16) - 1)) + 1) >> 1)
	}())))
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/******************/
/* Error messages */
/******************/

/**************************/
/* Encoder error messages */
/**************************/

/* Input length is not a multiplum of 10 ms, or length is longer than the packet length */

/* Sampling frequency not 8000, 12000, 16000 or 24000 Hertz */

/* Packet size not 20, 40, 60, 80 or 100 ms */

/* Allocated payload buffer too short */

/* Loss rate not between 0 and 100 percent */

/* Complexity setting not valid, use 0, 1 or 2 */

/* Inband FEC setting not valid, use 0 or 1 */

/* DTX setting not valid, use 0 or 1 */

/* Internal encoder error */

/**************************/
/* Decoder error messages */
/**************************/

/* Output sampling frequency lower than internal decoded sampling frequency */

/* Payload size exceeded the maximum allowed 1024 bytes */

/* Payload has bit errors */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/* Limits on bitrate */

/* Transition bitrates between modes */

/* Integration/hysteresis threshold for lowering internal sample frequency */
/* 30000000 -> 6 sec if bitrate is 5000 bps below limit; 3 sec if bitrate is 10000 bps below limit */

/* DTX settings                                 */

/* Amount of concecutive no FEC packets before telling JB */

/* Maximum delay between real packet and LBRR packet */

/* LBRR usage defines */

/* Frame termination indicator defines */

/* Number of Second order Sections for SWB detection HP filter */

/* Low complexity setting */

/* Activate bandwidth transition filtering for mode switching */

/* Decoder Parameters */

/* Maximum sampling frequency, should be 16 for some embedded platforms */

/* Signal Types used by silk */

/* VAD Types used by silk */

/* Number of samples per frame */

/* Milliseconds of lookahead for pitch analysis */

/* Length of LPC window used in find pitch */

/* Order of LPC used in find pitch */

/* Milliseconds of lookahead for noise shape analysis */

/* Max length of LPC window used in noise shape analysis */

/* Max number of bytes in payload output buffer (may contain multiple frames) */

/* dB level of lowest gain quantization level */
/* dB level of highest gain quantization level */
/* Number of gain quantization levels */
/* Max increase in gain quantization index */
/* Max decrease in gain quantization index */

/* Quantization offsets (multiples of 4) */

/* Maximum numbers of iterations used to stabilize a LPC vector */

/* Find Pred Coef defines */

/* LTP quantization settings */

/* Number of subframes */

/* Flag to use harmonic noise shaping */

/* Max LPC order of noise shaping filters */

/* Maximum number of delayed decision states */

/* number of subframes for excitation entropy coding */

/* number of rate levels, for entropy coding of excitation */

/* maximum sum of pulses per shell coding frame */

/***********************/
/* High pass filtering */
/***********************/

/***************************/
/* Voice activity detector */
/***************************/

/* Sigmoid settings */

/* smoothing for SNR measurement */

/******************/
/* NLSF quantizer */
/******************/

/* Based on above defines, calculate how much memory is necessary to allocate */

/* Transition filtering for mode switching */

/* Row based */

/* Column based */

/* BWE factors to apply after packet loss */

/* Defines for CN generation */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/************************************/
/* Noise shaping quantization state */
/************************************/
type nsq_state struct {
	Fxq                [960]int16
	FsLTP_shp_Q10      [960]int32
	FsLPC_Q14          [152]int32
	FsAR2_Q14          [16]int32
	FsLF_AR_shp_Q12    int32
	FlagPrev           int32
	FsLTP_buf_idx      int32
	FsLTP_shp_buf_idx  int32
	Frand_seed         int32
	Fprev_inv_gain_Q16 int32
	Frewhite_flag      int32
} /* structs.h:56:3 */ /* FIX*/

/* Struct for Low BitRate Redundant (LBRR) information */
type LBRR_struct struct {
	Fpayload [1024]uint8
	FnBytes  int32
	Fusage   int32
} /* structs.h:63:3 */

/********************************/
/* VAD state                    */
/********************************/
type VAD_state struct {
	FAnaState        [2]int32
	FAnaState1       [2]int32
	FAnaState2       [2]int32
	FXnrgSubfr       [4]int32
	FNrgRatioSmth_Q8 [4]int32
	FHPstate         int16
	_                [2]byte
	FNL              [4]int32
	Finv_NL          [4]int32
	FNoiseLevelBias  [4]int32
	Fcounter         int32
} /* structs.h:79:3 */

/*******************************/
/* Range encoder/decoder state */
/*******************************/
type range_coder_state struct {
	FbufferLength int32
	FbufferIx     int32
	Fbase_Q32     uint32
	Frange_Q16    uint32
	Ferror        int32
	Fbuffer       [1024]uint8
} /* structs.h:91:3 */

/* Input frequency range detection struct */
type detect_SWB_state struct {
	FS_HP_8_kHz            [3][2]int32
	FConsecSmplsAboveThres int32
	FActiveSpeech_ms       int32
	FSWB_detected          int32
	FWB_detected           int32
} /* structs.h:100:3 */

/* Variable cut-off low-pass filter state */
type LP_state struct {
	FIn_LP_State         [2]int32
	Ftransition_frame_no int32
	Fmode                int32
} /* structs.h:108:3 */

/* Structure for one stage of MSVQ */
type NLSF_CBS struct {
	FnVectors    int32
	FCB_NLSF_Q15 uintptr
	FRates_Q5    uintptr
} /* structs.h:116:3 */

/* Structure containing NLSF MSVQ codebook */
type NLSF_CB_struct struct {
	FnStages       int32
	FCBStages      uintptr
	FNDeltaMin_Q15 uintptr
	FCDF           uintptr
	FStartPtr      uintptr
	FMiddleIx      uintptr
} /* structs.h:130:3 */

/********************************/
/* Encoder state                */
/********************************/
type encoder_state struct {
	FsRC                           range_coder_state
	FsRC_LBRR                      range_coder_state
	FsNSQ                          nsq_state
	FsNSQ_LBRR                     nsq_state
	FIn_HP_State                   [2]int32
	FsLP                           LP_state
	FsVAD                          VAD_state
	FLBRRprevLastGainIndex         int32
	Fprev_sigtype                  int32
	FtypeOffsetPrev                int32
	FprevLag                       int32
	Fprev_lagIndex                 int32
	FAPI_fs_Hz                     int32
	Fprev_API_fs_Hz                int32
	FmaxInternal_fs_kHz            int32
	Ffs_kHz                        int32
	Ffs_kHz_changed                int32
	Fframe_length                  int32
	Fsubfr_length                  int32
	Fla_pitch                      int32
	Fla_shape                      int32
	FshapeWinLength                int32
	FTargetRate_bps                int32
	FPacketSize_ms                 int32
	FPacketLoss_perc               int32
	FframeCounter                  int32
	FComplexity                    int32
	FnStatesDelayedDecision        int32
	FuseInterpolatedNLSFs          int32
	FshapingLPCOrder               int32
	FpredictLPCOrder               int32
	FpitchEstimationComplexity     int32
	FpitchEstimationLPCOrder       int32
	FpitchEstimationThreshold_Q16  int32
	FLTPQuantLowComplexity         int32
	FNLSF_MSVQ_Survivors           int32
	Ffirst_frame_after_reset       int32
	Fcontrolled_since_last_payload int32
	Fwarping_Q16                   int32
	FinputBuf                      [480]int16
	FinputBufIx                    int32
	FnFramesInPayloadBuf           int32
	FnBytesInPayloadBuf            int32
	Fframes_since_onset            int32
	FpsNLSF_CB                     [2]uintptr
	FLBRR_buffer                   [2]LBRR_struct
	Foldest_LBRR_idx               int32
	FuseInBandFEC                  int32
	FLBRR_enabled                  int32
	FLBRR_GainIncreases            int32
	FbitrateDiff                   int32
	Fbitrate_threshold_up          int32
	Fbitrate_threshold_down        int32
	Fresampler_state               resampler_state_struct
	FnoSpeechCounter               int32
	FuseDTX                        int32
	FinDTX                         int32
	FvadFlag                       int32
	FsSWBdetect                    detect_SWB_state
	Fq                             [480]int8
	Fq_LBRR                        [480]int8
} /* structs.h:221:3 */

/************************/
/* Encoder control      */
/************************/
type encoder_control struct {
	FlagIndex          int32
	FcontourIndex      int32
	FPERIndex          int32
	FLTPIndex          [4]int32
	FNLSFIndices       [10]int32
	FNLSFInterpCoef_Q2 int32
	FGainsIndices      [4]int32
	FSeed              int32
	FLTP_scaleIndex    int32
	FRateLevelIndex    int32
	FQuantOffsetType   int32
	Fsigtype           int32
	FpitchL            [4]int32
	FLBRR_usage        int32
} /* structs.h:246:3 */

/* Struct for Packet Loss Concealment */
type PLC_struct struct {
	FpitchL_Q8         int32
	FLTPCoef_Q14       [5]int16
	FprevLPC_Q12       [16]int16
	_                  [2]byte
	Flast_frame_lost   int32
	Frand_seed         int32
	FrandScale_Q14     int16
	_                  [2]byte
	Fconc_energy       int32
	Fconc_energy_shift int32
	FprevLTP_scale_Q14 int16
	_                  [2]byte
	FprevGain_Q16      [4]int32
	Ffs_kHz            int32
} /* structs.h:261:3 */

/* Struct for CNG */
type CNG_struct struct {
	FCNG_exc_buf_Q10   [480]int32
	FCNG_smth_NLSF_Q15 [16]int32
	FCNG_synth_state   [16]int32
	FCNG_smth_Gain_Q16 int32
	Frand_seed         int32
	Ffs_kHz            int32
} /* structs.h:271:3 */

/********************************/
/* Decoder state                */
/********************************/
type decoder_state struct {
	FsRC                       range_coder_state
	Fprev_inv_gain_Q16         int32
	FsLTP_Q16                  [960]int32
	FsLPC_Q14                  [136]int32
	Fexc_Q10                   [480]int32
	Fres_Q10                   [480]int32
	FoutBuf                    [960]int16
	FlagPrev                   int32
	FLastGainIndex             int32
	FLastGainIndex_EnhLayer    int32
	FtypeOffsetPrev            int32
	FHPState                   [2]int32
	FHP_A                      uintptr
	FHP_B                      uintptr
	Ffs_kHz                    int32
	Fprev_API_sampleRate       int32
	Fframe_length              int32
	Fsubfr_length              int32
	FLPC_order                 int32
	FprevNLSF_Q15              [16]int32
	Ffirst_frame_after_reset   int32
	FnBytesLeft                int32
	FnFramesDecoded            int32
	FnFramesInPacket           int32
	FmoreInternalDecoderFrames int32
	FFrameTermination          int32
	Fresampler_state           resampler_state_struct
	FpsNLSF_CB                 [2]uintptr
	FvadFlag                   int32
	Fno_FEC_counter            int32
	Finband_FEC_offset         int32
	FsCNG                      CNG_struct
	FlossCnt                   int32
	Fprev_sigtype              int32
	FsPLC                      PLC_struct
} /* structs.h:326:3 */

/************************/
/* Decoder control      */
/************************/
type decoder_control struct {
	FpitchL            [4]int32
	FGains_Q16         [4]int32
	FSeed              int32
	FPredCoef_Q12      [2][16]int16
	FLTPCoef_Q14       [20]int16
	FLTP_scale_Q14     int32
	FPERIndex          int32
	FRateLevelIndex    int32
	FQuantOffsetType   int32
	Fsigtype           int32
	FNLSFInterpCoef_Q2 int32
} /* structs.h:347:3 */

/* Generates excitation for CNG LPC synthesis */
func CNG_exc(tls *libc.TLS, residual uintptr, exc_buf_Q10 uintptr, Gain_Q16 int32, length int32, rand_seed uintptr) { /* CNG.c:31:17: */
	var seed int32
	var i int32
	var idx int32
	var exc_mask int32

	exc_mask = 255
	for exc_mask > length {
		exc_mask = ((exc_mask) >> (1))
	}

	seed = *(*int32)(unsafe.Pointer(rand_seed))
	for i = 0; i < length; i++ {
		seed = (int32((uint32(907633515)) + ((uint32(seed)) * (uint32(196314165)))))
		idx = (((seed) >> (24)) & exc_mask)

		*(*int16)(unsafe.Pointer(residual + uintptr(i)*2)) = func() int16 {
			if (func() int32 {
				if (10) == 1 {
					return (((((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) * (func() int32 {
						if (16) == 1 {
							return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
						}
						return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
					}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) * (func() int32 {
						if (16) == 1 {
							return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
						}
						return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
					}()))) & 1))
				}
				return ((((((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) * (func() int32 {
					if (16) == 1 {
						return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
					}
					return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
				}()))) >> ((10) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1))
					}
					return ((((((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) * (func() int32 {
						if (16) == 1 {
							return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
						}
						return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (10) == 1 {
						return (int16(((((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1)))
					}
					return (int16((((((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(exc_buf_Q10 + uintptr(idx)*4))) * (func() int32 {
						if (16) == 1 {
							return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
						}
						return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}
	*(*int32)(unsafe.Pointer(rand_seed)) = seed
}

func CNG_Reset(tls *libc.TLS, psDec uintptr) { /* CNG.c:58:6: */
	var i int32
	var NLSF_step_Q15 int32
	var NLSF_acc_Q15 int32

	NLSF_step_Q15 = ((0x7FFF) / ((*decoder_state)(unsafe.Pointer(psDec)).FLPC_order + 1))
	NLSF_acc_Q15 = 0
	for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order; i++ {
		NLSF_acc_Q15 = NLSF_acc_Q15 + (NLSF_step_Q15)
		*(*int32)(unsafe.Pointer((psDec + 11520 /* &.sCNG */ + 1920 /* &.CNG_smth_NLSF_Q15 */) + uintptr(i)*4)) = NLSF_acc_Q15
	}
	(*decoder_state)(unsafe.Pointer(psDec)).FsCNG.FCNG_smth_Gain_Q16 = 0
	(*decoder_state)(unsafe.Pointer(psDec)).FsCNG.Frand_seed = 3176576
}

/* Updates CNG estimate, and applies the CNG when packet was lost   */
func CNG(tls *libc.TLS, psDec uintptr, psDecCtrl uintptr, signal uintptr, length int32) { /* CNG.c:75:6: */
	bp := tls.Alloc(992)
	defer tls.Free(992)

	var i int32
	var subfr int32
	var tmp_32 int32
	var Gain_Q26 int32
	var max_Gain_Q16 int32
	// var LPC_buf [16]int16 at bp+960, 32

	// var CNG_sig [480]int16 at bp, 960

	var psCNG uintptr
	psCNG = (psDec + 11520 /* &.sCNG */)

	if (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz != (*CNG_struct)(unsafe.Pointer(psCNG)).Ffs_kHz {
		/* Reset state */
		CNG_Reset(tls, psDec)

		(*CNG_struct)(unsafe.Pointer(psCNG)).Ffs_kHz = (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz
	}
	if ((*decoder_state)(unsafe.Pointer(psDec)).FlossCnt == 0) && ((*decoder_state)(unsafe.Pointer(psDec)).FvadFlag == 0) {
		/* Update CNG parameters */

		/* Smoothing of LSF's  */
		for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order; i++ {
			*(*int32)(unsafe.Pointer((psCNG + 1920 /* &.CNG_smth_NLSF_Q15 */) + uintptr(i)*4)) += ((((*(*int32)(unsafe.Pointer((psDec + 11244 /* &.prevNLSF_Q15 */) + uintptr(i)*4)) - *(*int32)(unsafe.Pointer((psCNG + 1920 /* &.CNG_smth_NLSF_Q15 */) + uintptr(i)*4))) >> 16) * (int32(int16(16348)))) + ((((*(*int32)(unsafe.Pointer((psDec + 11244 /* &.prevNLSF_Q15 */) + uintptr(i)*4)) - *(*int32)(unsafe.Pointer((psCNG + 1920 /* &.CNG_smth_NLSF_Q15 */) + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(16348)))) >> 16))
		}
		/* Find the subframe with the highest gain */
		max_Gain_Q16 = 0
		subfr = 0
		for i = 0; i < 4; i++ {
			if *(*int32)(unsafe.Pointer((psDecCtrl + 16 /* &.Gains_Q16 */) + uintptr(i)*4)) > max_Gain_Q16 {
				max_Gain_Q16 = *(*int32)(unsafe.Pointer((psDecCtrl + 16 /* &.Gains_Q16 */) + uintptr(i)*4))
				subfr = i
			}
		}
		/* Update CNG excitation buffer with excitation from this subframe */
		libc.Xmemmove(tls, ((psCNG /* &.CNG_exc_buf_Q10 */) + uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)*4), psCNG /* &.CNG_exc_buf_Q10 */, ((uint32((4 - 1) * (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)) * uint32(unsafe.Sizeof(int32(0)))))
		libc.Xmemcpy(tls, psCNG /* &.CNG_exc_buf_Q10 */, ((psDec + 5432 /* &.exc_Q10 */) + uintptr((subfr*(*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length))*4), (uint32((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length) * uint32(unsafe.Sizeof(int32(0)))))

		/* Smooth gains */
		for i = 0; i < 4; i++ {
			*(*int32)(unsafe.Pointer(psCNG + 2048 /* &.CNG_smth_Gain_Q16 */)) += ((((*(*int32)(unsafe.Pointer((psDecCtrl + 16 /* &.Gains_Q16 */) + uintptr(i)*4)) - (*CNG_struct)(unsafe.Pointer(psCNG)).FCNG_smth_Gain_Q16) >> 16) * (int32(int16(4634)))) + ((((*(*int32)(unsafe.Pointer((psDecCtrl + 16 /* &.Gains_Q16 */) + uintptr(i)*4)) - (*CNG_struct)(unsafe.Pointer(psCNG)).FCNG_smth_Gain_Q16) & 0x0000FFFF) * (int32(int16(4634)))) >> 16))
		}
	}

	/* Add CNG when packet is lost and / or when low speech activity */
	if (*decoder_state)(unsafe.Pointer(psDec)).FlossCnt != 0 { //|| psDec->vadFlag == NO_VOICE_ACTIVITY ) {

		/* Generate CNG excitation */
		CNG_exc(tls, bp /* &CNG_sig[0] */, psCNG, /* &.CNG_exc_buf_Q10 */
			(*CNG_struct)(unsafe.Pointer(psCNG)).FCNG_smth_Gain_Q16, length, (psCNG + 2052 /* &.rand_seed */))

		/* Convert CNG NLSF to filter representation */
		NLSF2A_stable(tls, bp+960 /* &LPC_buf[0] */, psCNG+1920 /* &.CNG_smth_NLSF_Q15 */, (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order)

		Gain_Q26 = (int32(1) << 26) /* 1.0 */

		/* Generate CNG signal, by synthesis filtering */
		if (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order == 16 {
			LPC_synthesis_order16(tls, bp /* &CNG_sig[0] */, bp+960, /* &LPC_buf[0] */
				Gain_Q26, psCNG+1984 /* &.CNG_synth_state */, bp /* &CNG_sig[0] */, length)
		} else {
			LPC_synthesis_filter(tls, bp /* &CNG_sig[0] */, bp+960, /* &LPC_buf[0] */
				Gain_Q26, psCNG+1984 /* &.CNG_synth_state */, bp /* &CNG_sig[0] */, length, (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order)
		}
		/* Mix with signal */
		for i = 0; i < length; i++ {
			tmp_32 = (int32(*(*int16)(unsafe.Pointer(signal + uintptr(i)*2))) + int32(*(*int16)(unsafe.Pointer(bp /* &CNG_sig[0] */ + uintptr(i)*2))))
			*(*int16)(unsafe.Pointer(signal + uintptr(i)*2)) = func() int16 {
				if (tmp_32) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (tmp_32) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return int16(tmp_32)
				}()
			}()
		}
	} else {
		libc.Xmemset(tls, psCNG+1984 /* &.CNG_synth_state */, 0, (uint32((*decoder_state)(unsafe.Pointer(psDec)).FLPC_order) * uint32(unsafe.Sizeof(int32(0)))))
	}
}

//#define enc_map(a)                ((a) > 0 ? 1 : 0)
//#define dec_map(a)                ((a) > 0 ? 1 : -1)
/* shifting avoids if-statement */

/* Encodes signs of excitation */
func encode_signs(tls *libc.TLS, sRC uintptr, q uintptr, length int32, sigtype int32, QuantOffsetType int32, RateLevelIndex int32) { /* code_signs.c:37:6: */
	bp := tls.Alloc(6)
	defer tls.Free(6)

	var i int32
	var inData int32
	// var cdf [3]uint16 at bp, 6

	i = (((int32((int16(10 - 1)))) * (int32((int16(((sigtype) << (1)) + QuantOffsetType))))) + RateLevelIndex)
	*(*uint16)(unsafe.Pointer(bp /* &cdf[0] */)) = uint16(0)
	*(*uint16)(unsafe.Pointer(bp /* &cdf[0] */ + 1*2)) = sign_CDF[i]
	*(*uint16)(unsafe.Pointer(bp /* &cdf[0] */ + 2*2)) = uint16(65535)

	for i = 0; i < length; i++ {
		if int32(*(*int8)(unsafe.Pointer(q + uintptr(i)))) != 0 {
			inData = (((int32(*(*int8)(unsafe.Pointer(q + uintptr(i))))) >> (15)) + 1) /* - = 0, + = 1 */
			range_encoder(tls, sRC, inData, bp /* &cdf[0] */)
		}
	}
}

/* Decodes signs of excitation */
func decode_signs(tls *libc.TLS, sRC uintptr, q uintptr, length int32, sigtype int32, QuantOffsetType int32, RateLevelIndex int32) { /* code_signs.c:64:6: */
	bp := tls.Alloc(12)
	defer tls.Free(12)

	var i int32
	// var data int32 at bp+8, 4

	// var cdf [3]uint16 at bp, 6

	i = (((int32((int16(10 - 1)))) * (int32((int16(((sigtype) << (1)) + QuantOffsetType))))) + RateLevelIndex)
	*(*uint16)(unsafe.Pointer(bp /* &cdf[0] */)) = uint16(0)
	*(*uint16)(unsafe.Pointer(bp /* &cdf[0] */ + 1*2)) = sign_CDF[i]
	*(*uint16)(unsafe.Pointer(bp /* &cdf[0] */ + 2*2)) = uint16(65535)

	for i = 0; i < length; i++ {
		if *(*int32)(unsafe.Pointer(q + uintptr(i)*4)) > 0 {
			range_decoder(tls, bp+8 /* &data */, sRC, bp /* &cdf[0] */, 1)
			/* attach sign */
			/* implementation with shift, subtraction, multiplication */
			*(*int32)(unsafe.Pointer(q + uintptr(i)*4)) *= (((*(*int32)(unsafe.Pointer(bp + 8 /* data */))) << (1)) - 1)
		}
	}
}

// 7.18.2  Limits of specified-width integer types

// 7.18.2.1  Limits of exact-width integer types

// 7.18.2.2  Limits of minimum-width integer types

// 7.18.2.3  Limits of fastest minimum-width integer types

// 7.18.2.4  Limits of integer types capable of holding
//     object pointers

// 7.18.2.5  Limits of greatest-width integer types

// 7.18.3  Limits of other integer types

// wint_t is unsigned short for compatibility with MS runtime

// 7.18.4  Macros for integer constants

// 7.18.4.1  Macros for minimum-width integer constants
//
//     Accoding to Douglas Gwyn <gwyn@arl.mil>:
// 	"This spec was changed in ISO/IEC 9899:1999 TC1; in ISO/IEC
// 	9899:1999 as initially published, the expansion was required
// 	to be an integer constant of precisely matching type, which
// 	is impossible to accomplish for the shorter types on most
// 	platforms, because C99 provides no standard way to designate
// 	an integer constant with width less than that of type int.
// 	TC1 changed this to require just an integer constant
// 	*expression* with *promoted* type."
//
// 	The trick used here is from Clive D W Feather.

//  The 'trick' doesn't work in C89 for long long because, without
//     suffix, (val) will be evaluated as int, not intmax_t

// 7.18.4.2  Macros for greatest-width integer constants

/* assertions */

/***********************************************/
/* Structure for controlling encoder operation */
/***********************************************/
type SDK_EncControlStruct struct {
	FAPI_sampleRate        int32
	FmaxInternalSampleRate int32
	FpacketSize            int32
	FbitRate               int32
	FpacketLossPercentage  int32
	Fcomplexity            int32
	FuseInBandFEC          int32
	FuseDTX                int32
} /* control.h:65:3 */

/**************************************************************************/
/* Structure for controlling decoder operation and reading decoder status */
/**************************************************************************/
type SDK_DecControlStruct struct {
	FAPI_sampleRate            int32
	FframeSize                 int32
	FframesPerPacket           int32
	FmoreInternalDecoderFrames int32
	FinBandFECOffset           int32
} /* control.h:85:3 */

/* Control internal sampling rate */
func control_audio_bandwidth(tls *libc.TLS, psEncC uintptr, TargetRate_bps int32) int32 { /* control_audio_bandwidth.c:31:9: */
	var fs_kHz int32

	fs_kHz = (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz
	if fs_kHz == 0 {
		/* Encoder has just been initialized */
		if TargetRate_bps >= 25000 {
			fs_kHz = 24
		} else if TargetRate_bps >= 14000 {
			fs_kHz = 16
		} else if TargetRate_bps >= 10000 {
			fs_kHz = 12
		} else {
			fs_kHz = 8
		}
		/* Make sure internal rate is not higher than external rate or maximum allowed, or lower than minimum allowed */
		fs_kHz = func() int32 {
			if (fs_kHz) < (((*encoder_state)(unsafe.Pointer(psEncC)).FAPI_fs_Hz) / (1000)) {
				return fs_kHz
			}
			return (((*encoder_state)(unsafe.Pointer(psEncC)).FAPI_fs_Hz) / (1000))
		}()
		fs_kHz = func() int32 {
			if (fs_kHz) < ((*encoder_state)(unsafe.Pointer(psEncC)).FmaxInternal_fs_kHz) {
				return fs_kHz
			}
			return (*encoder_state)(unsafe.Pointer(psEncC)).FmaxInternal_fs_kHz
		}()
	} else if (((int32(int16(fs_kHz))) * (int32(int16(1000)))) > (*encoder_state)(unsafe.Pointer(psEncC)).FAPI_fs_Hz) || (fs_kHz > (*encoder_state)(unsafe.Pointer(psEncC)).FmaxInternal_fs_kHz) {
		/* Make sure internal rate is not higher than external rate or maximum allowed */
		fs_kHz = (((*encoder_state)(unsafe.Pointer(psEncC)).FAPI_fs_Hz) / (1000))
		fs_kHz = func() int32 {
			if (fs_kHz) < ((*encoder_state)(unsafe.Pointer(psEncC)).FmaxInternal_fs_kHz) {
				return fs_kHz
			}
			return (*encoder_state)(unsafe.Pointer(psEncC)).FmaxInternal_fs_kHz
		}()
	} else {
		/* State machine for the internal sampling rate switching */
		if (*encoder_state)(unsafe.Pointer(psEncC)).FAPI_fs_Hz > 8000 {
			/* Accumulate the difference between the target rate and limit for switching down */
			*(*int32)(unsafe.Pointer(psEncC + 18336 /* &.bitrateDiff */)) += (((*encoder_state)(unsafe.Pointer(psEncC)).FPacketSize_ms) * (TargetRate_bps - (*encoder_state)(unsafe.Pointer(psEncC)).Fbitrate_threshold_down))
			(*encoder_state)(unsafe.Pointer(psEncC)).FbitrateDiff = func() int32 {
				if ((*encoder_state)(unsafe.Pointer(psEncC)).FbitrateDiff) < (0) {
					return (*encoder_state)(unsafe.Pointer(psEncC)).FbitrateDiff
				}
				return 0
			}()

			if (*encoder_state)(unsafe.Pointer(psEncC)).FvadFlag == 0 { /* Low speech activity */
				/* Check if we should switch down */
				if ((*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Ftransition_frame_no == 0) && (((*encoder_state)(unsafe.Pointer(psEncC)).FbitrateDiff <= -30000000) || (((*encoder_state)(unsafe.Pointer(psEncC)).FsSWBdetect.FWB_detected * (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz) == 24)) { /* Forced down-switching due to WB input */
					(*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Ftransition_frame_no = 1 /* Begin transition phase */
					(*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Fmode = 0                /* Switch down */
				} else if ((*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Ftransition_frame_no >= (2560 / 20)) && ((*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Fmode == 0) { /* Ready to switch down */
					(*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Ftransition_frame_no = 0 /* Ready for new transition phase */
					(*encoder_state)(unsafe.Pointer(psEncC)).FbitrateDiff = 0

					/* Switch to a lower sample frequency */
					if (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 24 {
						fs_kHz = 16
					} else if (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 16 {
						fs_kHz = 12
					} else {

						fs_kHz = 8
					}
				}

				/* Check if we should switch up */
				if ((((((*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz * 1000) < (*encoder_state)(unsafe.Pointer(psEncC)).FAPI_fs_Hz) && (TargetRate_bps >= (*encoder_state)(unsafe.Pointer(psEncC)).Fbitrate_threshold_up)) && (((*encoder_state)(unsafe.Pointer(psEncC)).FsSWBdetect.FWB_detected * (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz) < 16)) && (((((*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 16) && ((*encoder_state)(unsafe.Pointer(psEncC)).FmaxInternal_fs_kHz >= 24)) || (((*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 12) && ((*encoder_state)(unsafe.Pointer(psEncC)).FmaxInternal_fs_kHz >= 16))) || (((*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 8) && ((*encoder_state)(unsafe.Pointer(psEncC)).FmaxInternal_fs_kHz >= 12)))) &&
					((*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Ftransition_frame_no == 0) { /* No transition phase running, ready to switch */
					(*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Fmode = 1 /* Switch up */
					(*encoder_state)(unsafe.Pointer(psEncC)).FbitrateDiff = 0

					/* Switch to a higher sample frequency */
					if (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 8 {
						fs_kHz = 12
					} else if (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 12 {
						fs_kHz = 16
					} else {

						fs_kHz = 24
					}
				}
			}
		}

		/* After switching up, stop transition filter during speech inactivity */
		if (((*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Fmode == 1) && ((*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Ftransition_frame_no >= (5120 / 20))) && ((*encoder_state)(unsafe.Pointer(psEncC)).FvadFlag == 0) {

			(*encoder_state)(unsafe.Pointer(psEncC)).FsLP.Ftransition_frame_no = 0

			/* Reset transition filter state */
			libc.Xmemset(tls, psEncC+15016 /* &.sLP */ /* &.In_LP_State */, 0, (uint32(2) * uint32(unsafe.Sizeof(int32(0)))))
		}
	}

	return fs_kHz
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/********************************/
/* Noise shaping analysis state */
/********************************/
type shape_state_FIX struct {
	FLastGainIndex          int32
	FHarmBoost_smth_Q16     int32
	FHarmShapeGain_smth_Q16 int32
	FTilt_smth_Q16          int32
} /* structs_FIX.h:49:3 */

/********************************/
/* Prefilter state              */
/********************************/
type prefilter_state_FIX struct {
	FsLTP_shp         [512]int16
	FsAR_shp          [17]int32
	FsLTP_shp_buf_idx int32
	FsLF_AR_shp_Q12   int32
	FsLF_MA_shp_Q12   int32
	FsHarmHP          int32
	Frand_seed        int32
	FlagPrev          int32
} /* structs_FIX.h:63:3 */

/*****************************/
/* Prediction analysis state */
/*****************************/
type predict_state_FIX struct {
	Fpitch_LPC_win_length int32
	Fmin_pitch_lag        int32
	Fmax_pitch_lag        int32
	Fprev_NLSFq_Q15       [16]int32
} /* structs_FIX.h:73:3 */

/********************************/
/* Encoder state FIX            */
/********************************/
type encoder_state_FIX struct {
	FsCmn                           encoder_state
	Fvariable_HP_smth1_Q15          int32
	Fvariable_HP_smth2_Q15          int32
	FsShape                         shape_state_FIX
	FsPrefilt                       prefilter_state_FIX
	FsPred                          predict_state_FIX
	Fx_buf                          [1080]int16
	FLTPCorr_Q15                    int32
	Fmu_LTP_Q8                      int32
	FSNR_dB_Q7                      int32
	FavgGain_Q16                    int32
	FavgGain_Q16_one_bit_per_sample int32
	FBufferedInChannel_ms           int32
	Fspeech_activity_Q8             int32
	FprevLTPredCodGain_Q7           int32
	FHPLTPredCodGain_Q7             int32
	FinBandFEC_SNR_comp_Q8          int32
} /* structs_FIX.h:106:3 */

/************************/
/* Encoder control FIX  */
/************************/
type encoder_control_FIX struct {
	FsCmn                    encoder_control
	FGains_Q16               [4]int32
	FPredCoef_Q12            [2][16]int16
	FLTPCoef_Q14             [20]int16
	FLTP_scale_Q14           int32
	FAR1_Q13                 [64]int16
	FAR2_Q13                 [64]int16
	FLF_shp_Q14              [4]int32
	FGainsPre_Q14            [4]int32
	FHarmBoost_Q14           [4]int32
	FTilt_Q14                [4]int32
	FHarmShapeGain_Q14       [4]int32
	FLambda_Q10              int32
	Finput_quality_Q14       int32
	Fcoding_quality_Q14      int32
	Fpitch_freq_low_Hz       int32
	Fcurrent_SNR_dB_Q7       int32
	Fsparseness_Q8           int32
	FpredGain_Q16            int32
	FLTPredCodGain_Q7        int32
	Finput_quality_bands_Q15 [4]int32
	Finput_tilt_Q15          int32
	FResNrg                  [4]int32
	FResNrgQ                 [4]int32
} /* structs_FIX.h:144:3 */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*******************/
/* Pitch estimator */
/*******************/

/* Level of noise floor for whitening filter LPC analysis in pitch analysis */

/* Bandwidth expansion for whitening filter in pitch analysis */

/* Threshold used by pitch estimator for early escape */

/*********************/
/* Linear prediction */
/*********************/

/* LPC analysis defines: regularization and bandwidth expansion */

/* LTP analysis defines */

/* LTP quantization settings */

/***********************/
/* High pass filtering */
/***********************/

/* Smoothing parameters for low end of pitch frequency range estimation */

/* Min and max values for low end of pitch frequency range estimation */

/* Max absolute difference between log2 of pitch frequency and smoother state, to enter the smoother */

/***********/
/* Various */
/***********/

/* Required speech activity for counting frame as active */

/* Speech Activity LBRR enable threshold (needs tuning) */

/*************************/
/* Perceptual parameters */
/*************************/

/* reduction in coding SNR during low speech activity */

/* factor for reducing quantization noise during voiced speech */

/* factor for reducing quantization noise for unvoiced sparse signals */

/* threshold for sparseness measure above which to use lower quantization offset during unvoiced */

/* warping control */

/* fraction added to first autocorrelation value */

/* noise shaping filter chirp factor */

/* difference between chirp factors for analysis and synthesis noise shaping filters at low bitrates */

/* gain reduction for fricatives */

/* extra harmonic boosting (signal shaping) at low bitrates */

/* extra harmonic boosting (signal shaping) for noisy input signals */

/* harmonic noise shaping */

/* extra harmonic noise shaping for high bitrates or noisy input */

/* parameter for shaping noise towards higher frequencies */

/* parameter for shaping noise even more towards higher frequencies during voiced speech */

/* parameter for applying a high-pass tilt to the input signal */

/* parameter for extra high-pass tilt to the input signal at high rates */

/* parameter for reducing noise at the very low frequencies */

/* less reduction of noise at the very low frequencies for signals with low SNR at low frequencies */

/* noise floor to put a lower limit on the quantization step size */

/* noise floor relative to active speech gain level */

/* subframe smoothing coefficient for determining active speech gain level (lower -> more smoothing) */

/* subframe smoothing coefficient for HarmBoost, HarmShapeGain, Tilt (lower -> more smoothing) */

/* parameters defining the R/D tradeoff in the residual quantizer */

func setup_complexity(tls *libc.TLS, psEncC uintptr, Complexity int32) int32 { /* setup_complexity.h:31:20: */
	var ret int32 = 0

	/* Check that settings are valid */
	if (0 != 0) && (Complexity != 0) {
		ret = -6
	}

	/* Set encoding complexity */
	if (Complexity == 0) || (0 != 0) {
		/* Low complexity */
		(*encoder_state)(unsafe.Pointer(psEncC)).FComplexity = 0
		(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationComplexity = 0
		(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationThreshold_Q16 = FIX_CONST(tls, 0.8, 16)
		(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationLPCOrder = 6
		(*encoder_state)(unsafe.Pointer(psEncC)).FshapingLPCOrder = 8
		(*encoder_state)(unsafe.Pointer(psEncC)).Fla_shape = (3 * (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz)
		(*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision = 1
		(*encoder_state)(unsafe.Pointer(psEncC)).FuseInterpolatedNLSFs = 0
		(*encoder_state)(unsafe.Pointer(psEncC)).FLTPQuantLowComplexity = 1
		(*encoder_state)(unsafe.Pointer(psEncC)).FNLSF_MSVQ_Survivors = 2
		(*encoder_state)(unsafe.Pointer(psEncC)).Fwarping_Q16 = 0
	} else if Complexity == 1 {
		/* Medium complexity */
		(*encoder_state)(unsafe.Pointer(psEncC)).FComplexity = 1
		(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationComplexity = 1
		(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationThreshold_Q16 = FIX_CONST(tls, 0.75, 16)
		(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationLPCOrder = 12
		(*encoder_state)(unsafe.Pointer(psEncC)).FshapingLPCOrder = 12
		(*encoder_state)(unsafe.Pointer(psEncC)).Fla_shape = (5 * (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz)
		(*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision = 2
		(*encoder_state)(unsafe.Pointer(psEncC)).FuseInterpolatedNLSFs = 0
		(*encoder_state)(unsafe.Pointer(psEncC)).FLTPQuantLowComplexity = 0
		(*encoder_state)(unsafe.Pointer(psEncC)).FNLSF_MSVQ_Survivors = 4
		(*encoder_state)(unsafe.Pointer(psEncC)).Fwarping_Q16 = ((*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz * FIX_CONST(tls, 0.015, 16))
	} else if Complexity == 2 {
		/* High complexity */
		(*encoder_state)(unsafe.Pointer(psEncC)).FComplexity = 2
		(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationComplexity = 2
		(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationThreshold_Q16 = FIX_CONST(tls, 0.7, 16)
		(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationLPCOrder = 16
		(*encoder_state)(unsafe.Pointer(psEncC)).FshapingLPCOrder = 16
		(*encoder_state)(unsafe.Pointer(psEncC)).Fla_shape = (5 * (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz)
		(*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision = 4
		(*encoder_state)(unsafe.Pointer(psEncC)).FuseInterpolatedNLSFs = 1
		(*encoder_state)(unsafe.Pointer(psEncC)).FLTPQuantLowComplexity = 0
		(*encoder_state)(unsafe.Pointer(psEncC)).FNLSF_MSVQ_Survivors = 16
		(*encoder_state)(unsafe.Pointer(psEncC)).Fwarping_Q16 = ((*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz * FIX_CONST(tls, 0.015, 16))
	} else {
		ret = -6
	}

	/* Do not allow higher pitch estimation LPC order than predict LPC order */
	(*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationLPCOrder = min_int(tls, (*encoder_state)(unsafe.Pointer(psEncC)).FpitchEstimationLPCOrder, (*encoder_state)(unsafe.Pointer(psEncC)).FpredictLPCOrder)
	(*encoder_state)(unsafe.Pointer(psEncC)).FshapeWinLength = ((5 * (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz) + (2 * (*encoder_state)(unsafe.Pointer(psEncC)).Fla_shape))

	return ret
}

/* Control encoder */
func control_encoder_FIX(tls *libc.TLS, psEnc uintptr, PacketSize_ms int32, TargetRate_bps int32, PacketLoss_perc int32, DTX_enabled int32, Complexity int32) int32 { /* control_codec_FIX.c:56:9: */
	var fs_kHz int32
	var ret int32 = 0

	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fcontrolled_since_last_payload != 0 {
		if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz != (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fprev_API_fs_Hz) && ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz > 0) {
			/* Change in API sampling rate in the middle of encoding a packet */
			ret = ret + (setup_resamplers_FIX(tls, psEnc, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz))
		}
		return ret
	}

	/* Beyond this point we know that there are no previously coded frames in the payload buffer */

	/********************************************/
	/* Determine internal sampling rate         */
	/********************************************/
	fs_kHz = control_audio_bandwidth(tls, (psEnc /* &.sCmn */), TargetRate_bps)

	/********************************************/
	/* Prepare resampler and buffered data      */
	/********************************************/
	ret = ret + (setup_resamplers_FIX(tls, psEnc, fs_kHz))

	/********************************************/
	/* Set packet size                          */
	/********************************************/
	ret = ret + (setup_packetsize_FIX(tls, psEnc, PacketSize_ms))

	/********************************************/
	/* Set internal sampling frequency          */
	/********************************************/
	ret = ret + (setup_fs_FIX(tls, psEnc, fs_kHz))

	/********************************************/
	/* Set encoding complexity                  */
	/********************************************/
	ret = ret + (setup_complexity(tls, (psEnc /* &.sCmn */), Complexity))

	/********************************************/
	/* Set bitrate/coding quality               */
	/********************************************/
	ret = ret + (setup_rate_FIX(tls, psEnc, TargetRate_bps))

	/********************************************/
	/* Set packet loss rate measured by farend  */
	/********************************************/
	if (PacketLoss_perc < 0) || (PacketLoss_perc > 100) {
		ret = -5
	}
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketLoss_perc = PacketLoss_perc

	/********************************************/
	/* Set LBRR usage                           */
	/********************************************/
	ret = ret + (setup_LBRR_FIX(tls, psEnc))

	/********************************************/
	/* Set DTX mode                             */
	/********************************************/
	if (DTX_enabled < 0) || (DTX_enabled > 1) {
		ret = -8
	}
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseDTX = DTX_enabled
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fcontrolled_since_last_payload = 1

	return ret
}

/* Control low bitrate redundancy usage */
func LBRR_ctrl_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrlC uintptr) { /* control_codec_FIX.c:133:6: */
	var LBRR_usage int32

	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRR_enabled != 0 {
		/* Control LBRR */

		/* Usage Control based on sensitivity and packet loss caracteristics */
		/* For now only enable adding to next for active frames. Make more complex later */
		LBRR_usage = 0
		if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8 > FIX_CONST(tls, 0.5, 8)) && ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketLoss_perc > 1) { // nb! maybe multiply loss prob and speech activity
			LBRR_usage = 1
		}
		(*encoder_control)(unsafe.Pointer(psEncCtrlC)).FLBRR_usage = LBRR_usage
	} else {
		(*encoder_control)(unsafe.Pointer(psEncCtrlC)).FLBRR_usage = 0
	}
}

func setup_resamplers_FIX(tls *libc.TLS, psEnc uintptr, fs_kHz int32) int32 { /* control_codec_FIX.c:155:20: */
	bp := tls.Alloc(13128)
	defer tls.Free(13128)

	var ret int32 = 0

	if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz != fs_kHz) || ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fprev_API_fs_Hz != (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz) {

		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 0 {
			/* Initialize the resampler for enc_API.c preparing resampling from API_fs_Hz to fs_kHz */
			ret = ret + (resampler_init(tls, (psEnc /* &.sCmn */ + 18348 /* &.resampler_state */), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz, (fs_kHz * 1000)))
		} else {
			/* Allocate space for worst case temporary upsampling, 8 to 48 kHz, so a factor 6 */
			// var x_buf_API_fs_Hz [6480]int16 at bp+168, 12960

			var nSamples_temp int32 = ((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length) << (1)) + (5 * (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz))

			if (((int32(int16(fs_kHz))) * (int32(int16(1000)))) < (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz) && ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz != 0) {
				/* Resample buffered data in x_buf to API_fs_Hz */

				// var temp_resampler_state resampler_state_struct at bp, 168

				/* Initialize resampler for temporary resampling of x_buf data to API_fs_Hz */
				ret = ret + (resampler_init(tls, bp /* &temp_resampler_state */, ((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz))) * (int32(int16(1000)))), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz))

				/* Temporary resampling of x_buf data to API_fs_Hz */
				ret = ret + (resampler(tls, bp /* &temp_resampler_state */, bp+168 /* &x_buf_API_fs_Hz[0] */, psEnc+20748 /* &.x_buf */, nSamples_temp))

				/* Calculate number of samples that has been temporarily upsampled */
				nSamples_temp = ((nSamples_temp * (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz) / ((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz))) * (int32(int16(1000)))))

				/* Initialize the resampler for enc_API.c preparing resampling from API_fs_Hz to fs_kHz */
				ret = ret + (resampler_init(tls, (psEnc /* &.sCmn */ + 18348 /* &.resampler_state */), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz, ((int32(int16(fs_kHz))) * (int32(int16(1000))))))

			} else {
				/* Copy data */
				libc.Xmemcpy(tls, bp+168 /* &x_buf_API_fs_Hz[0] */, psEnc+20748 /* &.x_buf */, (uint32(nSamples_temp) * uint32(unsafe.Sizeof(int16(0)))))
			}

			if (1000 * fs_kHz) != (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz {
				/* Correct resampler state (unless resampling by a factor 1) by resampling buffered data from API_fs_Hz to fs_kHz */
				ret = ret + (resampler(tls, (psEnc /* &.sCmn */ + 18348 /* &.resampler_state */), psEnc+20748 /* &.x_buf */, bp+168 /* &x_buf_API_fs_Hz[0] */, nSamples_temp))
			}
		}
	}

	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fprev_API_fs_Hz = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz

	return ret
}

func setup_packetsize_FIX(tls *libc.TLS, psEnc uintptr, PacketSize_ms int32) int32 { /* control_codec_FIX.c:207:20: */
	var ret int32 = 0

	/* Set packet size */
	if ((((PacketSize_ms != 20) && (PacketSize_ms != 40)) && (PacketSize_ms != 60)) && (PacketSize_ms != 80)) && (PacketSize_ms != 100) {
		ret = -3
	} else {
		if PacketSize_ms != (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketSize_ms {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketSize_ms = PacketSize_ms

			/* Packet length changes. Reset LBRR buffer */
			LBRR_reset(tls, (psEnc /* &.sCmn */))
		}
	}
	return ret
}

func setup_fs_FIX(tls *libc.TLS, psEnc uintptr, fs_kHz int32) int32 { /* control_codec_FIX.c:232:20: */
	var ret int32 = 0

	/* Set internal sampling frequency */
	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz != fs_kHz {
		/* reset part of the state */
		libc.Xmemset(tls, (psEnc + 19540 /* &.sShape */), 0, uint32(unsafe.Sizeof(shape_state_FIX{})))
		libc.Xmemset(tls, (psEnc + 19556 /* &.sPrefilt */), 0, uint32(unsafe.Sizeof(prefilter_state_FIX{})))
		libc.Xmemset(tls, (psEnc + 20672 /* &.sPred */), 0, uint32(unsafe.Sizeof(predict_state_FIX{})))
		libc.Xmemset(tls, (psEnc /* &.sCmn */ + 2088 /* &.sNSQ */), 0, uint32(unsafe.Sizeof(nsq_state{})))
		libc.Xmemset(tls, psEnc /* &.sCmn */ +8548 /* &.sNSQ_LBRR */ /* &.xq */, 0, ((uint32(2 * (20 * 24))) * uint32(unsafe.Sizeof(int16(0)))))
		libc.Xmemset(tls, psEnc /* &.sCmn */ +16256 /* &.LBRR_buffer */, 0, (uint32(2) * uint32(unsafe.Sizeof(LBRR_struct{}))))
		libc.Xmemset(tls, psEnc /* &.sCmn */ +15016 /* &.sLP */ /* &.In_LP_State */, 0, (uint32(2) * uint32(unsafe.Sizeof(int32(0)))))
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsLP.Fmode == 1 {
			/* Begin transition phase */
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsLP.Ftransition_frame_no = 1
		} else {
			/* End transition phase */
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsLP.Ftransition_frame_no = 0
		}
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinputBufIx = 0
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf = 0
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnBytesInPayloadBuf = 0
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Foldest_LBRR_idx = 0
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FTargetRate_bps = 0 /* Ensures that psEnc->SNR_dB is recomputed */

		libc.Xmemset(tls, psEnc+20672 /* &.sPred */ +12 /* &.prev_NLSFq_Q15 */, 0, (uint32(16) * uint32(unsafe.Sizeof(int32(0)))))

		/* Initialize non-zero parameters */
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FprevLag = 100
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fprev_sigtype = 1
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffirst_frame_after_reset = 1
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsPrefilt.FlagPrev = 100
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsShape.FLastGainIndex = 1
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsNSQ.FlagPrev = 100
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsNSQ.Fprev_inv_gain_Q16 = 65536
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsNSQ_LBRR.Fprev_inv_gain_Q16 = 65536

		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz = fs_kHz
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 8 {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder = 10
			*(*uintptr)(unsafe.Pointer((psEnc /* &.sCmn */ + 16248 /* &.psNLSF_CB */))) = uintptr(unsafe.Pointer(&NLSF_CB0_10))
			*(*uintptr)(unsafe.Pointer((psEnc /* &.sCmn */ + 16248 /* &.psNLSF_CB */) + 1*4)) = uintptr(unsafe.Pointer(&NLSF_CB1_10))
		} else {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder = 16
			*(*uintptr)(unsafe.Pointer((psEnc /* &.sCmn */ + 16248 /* &.psNLSF_CB */))) = uintptr(unsafe.Pointer(&NLSF_CB0_16))
			*(*uintptr)(unsafe.Pointer((psEnc /* &.sCmn */ + 16248 /* &.psNLSF_CB */) + 1*4)) = uintptr(unsafe.Pointer(&NLSF_CB1_16))
		}
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length = ((int32(int16(20))) * (int32(int16(fs_kHz))))
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length) / (4))
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_pitch = ((int32(int16(2))) * (int32(int16(fs_kHz))))
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsPred.Fmin_pitch_lag = ((int32(int16(3))) * (int32(int16(fs_kHz))))
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsPred.Fmax_pitch_lag = ((int32(int16(18))) * (int32(int16(fs_kHz))))
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsPred.Fpitch_LPC_win_length = ((int32((int16(20 + (int32(2) << 1))))) * (int32(int16(fs_kHz))))
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 24 {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fmu_LTP_Q8 = FIX_CONST(tls, 0.016, 8)
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fbitrate_threshold_up = 0x7FFFFFFF
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fbitrate_threshold_down = 25000
		} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 16 {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fmu_LTP_Q8 = FIX_CONST(tls, 0.02, 8)
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fbitrate_threshold_up = 30000
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fbitrate_threshold_down = 14000
		} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 12 {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fmu_LTP_Q8 = FIX_CONST(tls, 0.025, 8)
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fbitrate_threshold_up = 18000
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fbitrate_threshold_down = 10000
		} else {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fmu_LTP_Q8 = FIX_CONST(tls, 0.03, 8)
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fbitrate_threshold_up = 14000
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fbitrate_threshold_down = 0
		}
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz_changed = 1

		/* Check that settings are valid */

	}
	return ret
}

func setup_rate_FIX(tls *libc.TLS, psEnc uintptr, TargetRate_bps int32) int32 { /* control_codec_FIX.c:317:20: */
	var k int32
	var ret int32 = 0
	var frac_Q6 int32
	var rateTable uintptr

	/* Set bitrate/coding quality */
	if TargetRate_bps != (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FTargetRate_bps {
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FTargetRate_bps = TargetRate_bps

		/* If new TargetRate_bps, translate to SNR_dB value */
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 8 {
			rateTable = uintptr(unsafe.Pointer(&TargetRate_table_NB))
		} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 12 {
			rateTable = uintptr(unsafe.Pointer(&TargetRate_table_MB))
		} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 16 {
			rateTable = uintptr(unsafe.Pointer(&TargetRate_table_WB))
		} else {
			rateTable = uintptr(unsafe.Pointer(&TargetRate_table_SWB))
		}
		for k = 1; k < 8; k++ {
			/* Find bitrate interval in table and interpolate */
			if TargetRate_bps <= *(*int32)(unsafe.Pointer(rateTable + uintptr(k)*4)) {
				frac_Q6 = (((TargetRate_bps - *(*int32)(unsafe.Pointer(rateTable + uintptr((k-1))*4))) << (6)) / (*(*int32)(unsafe.Pointer(rateTable + uintptr(k)*4)) - *(*int32)(unsafe.Pointer(rateTable + uintptr((k-1))*4))))
				(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FSNR_dB_Q7 = (((SNR_table_Q1[(k - 1)]) << (6)) + ((frac_Q6) * (SNR_table_Q1[k] - SNR_table_Q1[(k-1)])))
				break
			}
		}
	}
	return ret
}

func setup_LBRR_FIX(tls *libc.TLS, psEnc uintptr) int32 { /* control_codec_FIX.c:353:20: */
	var ret int32 = 0
	var LBRRRate_thres_bps int32

	if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseInBandFEC < 0) || ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseInBandFEC > 1) {
		ret = -7
	}

	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRR_enabled = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseInBandFEC
	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 8 {
		LBRRRate_thres_bps = (18000 - 9000)
	} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 12 {
		LBRRRate_thres_bps = (18000 - 6000)

	} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 16 {
		LBRRRate_thres_bps = (18000 - 3000)
	} else {
		LBRRRate_thres_bps = 18000
	}

	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FTargetRate_bps >= LBRRRate_thres_bps {
		/* Set gain increase / rate reduction for LBRR usage */
		/* Coarsely tuned with PESQ for now. */
		/* Linear regression coefs G = 8 - 0.5 * loss */
		/* Meaning that at 16% loss main rate and redundant rate is the same, -> G = 0 */
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRR_GainIncreases = max_int(tls, (8 - (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketLoss_perc) >> (1))), 0)

		/* Set main stream rate compensation */
		if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRR_enabled != 0) && ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketLoss_perc > 1) {
			/* Tuned to give approx same mean / weighted bitrate as no inband FEC */
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FinBandFEC_SNR_comp_Q8 = (FIX_CONST(tls, 6.0, 8) - (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRR_GainIncreases) << (7)))
		} else {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FinBandFEC_SNR_comp_Q8 = 0
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRR_enabled = 0
		}
	} else {
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FinBandFEC_SNR_comp_Q8 = 0
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRR_enabled = 0
	}
	return ret
}

/* Calculates correlation vector X'*t */
func corrVector_FIX(tls *libc.TLS, x uintptr, t uintptr, L int32, order int32, Xt uintptr, rshifts int32) { /* corrMatrix_FIX.c:35:6: */
	var lag int32
	var i int32
	var ptr1 uintptr
	var ptr2 uintptr
	var inner_prod int32

	ptr1 = (x + uintptr((order-1))*2) /* Points to first sample of column 0 of X: X[:,0] */
	ptr2 = t
	/* Calculate X'*t */
	if rshifts > 0 {
		/* Right shifting used */
		for lag = 0; lag < order; lag++ {
			inner_prod = 0
			for i = 0; i < L; i++ {
				inner_prod = inner_prod + (((int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr(i)*2)))) * (int32(*(*int16)(unsafe.Pointer(ptr2 + uintptr(i)*2))))) >> (rshifts))
			}
			*(*int32)(unsafe.Pointer(Xt + uintptr(lag)*4)) = inner_prod /* X[:,lag]'*t */
			ptr1 -= 2                                                   /* Go to next column of X */
		}
	} else {

		for lag = 0; lag < order; lag++ {
			*(*int32)(unsafe.Pointer(Xt + uintptr(lag)*4)) = inner_prod_aligned(tls, ptr1, ptr2, L) /* X[:,lag]'*t */
			ptr1 -= 2                                                                               /* Go to next column of X */
		}
	}
}

/* Calculates correlation matrix X'*X */
func corrMatrix_FIX(tls *libc.TLS, x uintptr, L int32, order int32, head_room int32, XX uintptr, rshifts uintptr) { /* corrMatrix_FIX.c:71:6: */
	bp := tls.Alloc(8)
	defer tls.Free(8)

	var i int32
	var j int32
	var lag int32
	// var rshifts_local int32 at bp+4, 4

	var head_room_rshifts int32
	// var energy int32 at bp, 4

	var ptr1 uintptr
	var ptr2 uintptr

	/* Calculate energy to find shift used to fit in 32 bits */
	sum_sqr_shift(tls, bp /* &energy */, bp+4 /* &rshifts_local */, x, ((L + order) - 1))

	/* Add shifts to get the desired head room */
	head_room_rshifts = func() int32 {
		if (head_room - CLZ32(tls, *(*int32)(unsafe.Pointer(bp /* energy */)))) > (0) {
			return (head_room - CLZ32(tls, *(*int32)(unsafe.Pointer(bp /* energy */))))
		}
		return 0
	}()

	*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) >> (head_room_rshifts))
	*(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */)) += head_room_rshifts

	/* Calculate energy of first column (0) of X: X[:,0]'*X[:,0] */
	/* Remove contribution of first order - 1 samples */
	for i = 0; i < (order - 1); i++ {
		*(*int32)(unsafe.Pointer(bp /* energy */)) -= (((int32(*(*int16)(unsafe.Pointer(x + uintptr(i)*2)))) * (int32(*(*int16)(unsafe.Pointer(x + uintptr(i)*2))))) >> (*(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */))))
	}
	if *(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */)) < *(*int32)(unsafe.Pointer(rshifts)) {
		/* Adjust energy */
		*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) >> (*(*int32)(unsafe.Pointer(rshifts)) - *(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */))))
		*(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */)) = *(*int32)(unsafe.Pointer(rshifts))
	}

	/* Calculate energy of remaining columns of X: X[:,j]'*X[:,j] */
	/* Fill out the diagonal of the correlation matrix */
	*(*int32)(unsafe.Pointer((XX + uintptr((((0)*(order))+(0)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
	ptr1 = (x + uintptr((order-1))*2) /* First sample of column 0 of X */
	for j = 1; j < order; j++ {
		*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) - (((int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr((L-j))*2)))) * (int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr((L-j))*2))))) >> (*(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */)))))
		*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) + (((int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr(-j)*2)))) * (int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr(-j)*2))))) >> (*(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */)))))
		*(*int32)(unsafe.Pointer((XX + uintptr((((j)*(order))+(j)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
	}

	ptr2 = (x + uintptr((order-2))*2) /* First sample of column 1 of X */
	/* Calculate the remaining elements of the correlation matrix */
	if *(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */)) > 0 {
		/* Right shifting used */
		for lag = 1; lag < order; lag++ {
			/* Inner product of column 0 and column lag: X[:,0]'*X[:,lag] */
			*(*int32)(unsafe.Pointer(bp /* energy */)) = 0
			for i = 0; i < L; i++ {
				*(*int32)(unsafe.Pointer(bp /* energy */)) += (((int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr(i)*2)))) * (int32(*(*int16)(unsafe.Pointer(ptr2 + uintptr(i)*2))))) >> (*(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */))))
			}
			/* Calculate remaining off diagonal: X[:,j]'*X[:,j + lag] */
			*(*int32)(unsafe.Pointer((XX + uintptr((((lag)*(order))+(0)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
			*(*int32)(unsafe.Pointer((XX + uintptr((((0)*(order))+(lag)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
			for j = 1; j < (order - lag); j++ {
				*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) - (((int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr((L-j))*2)))) * (int32(*(*int16)(unsafe.Pointer(ptr2 + uintptr((L-j))*2))))) >> (*(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */)))))
				*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) + (((int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr(-j)*2)))) * (int32(*(*int16)(unsafe.Pointer(ptr2 + uintptr(-j)*2))))) >> (*(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */)))))
				*(*int32)(unsafe.Pointer((XX + uintptr((((lag+j)*(order))+(j)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
				*(*int32)(unsafe.Pointer((XX + uintptr((((j)*(order))+(lag+j)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
			}
			ptr2 -= 2 /* Update pointer to first sample of next column (lag) in X */
		}
	} else {
		for lag = 1; lag < order; lag++ {
			/* Inner product of column 0 and column lag: X[:,0]'*X[:,lag] */
			*(*int32)(unsafe.Pointer(bp /* energy */)) = inner_prod_aligned(tls, ptr1, ptr2, L)
			*(*int32)(unsafe.Pointer((XX + uintptr((((lag)*(order))+(0)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
			*(*int32)(unsafe.Pointer((XX + uintptr((((0)*(order))+(lag)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
			/* Calculate remaining off diagonal: X[:,j]'*X[:,j + lag] */
			for j = 1; j < (order - lag); j++ {
				*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) - ((int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr((L-j))*2)))) * (int32(*(*int16)(unsafe.Pointer(ptr2 + uintptr((L-j))*2))))))
				*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) + ((int32(*(*int16)(unsafe.Pointer(ptr1 + uintptr(-j)*2)))) * (int32(*(*int16)(unsafe.Pointer(ptr2 + uintptr(-j)*2))))))
				*(*int32)(unsafe.Pointer((XX + uintptr((((lag+j)*(order))+(j)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
				*(*int32)(unsafe.Pointer((XX + uintptr((((j)*(order))+(lag+j)))*4))) = *(*int32)(unsafe.Pointer(bp /* energy */))
			}
			ptr2 -= 2 /* Update pointer to first sample of next column (lag) in X */
		}
	}
	*(*int32)(unsafe.Pointer(rshifts)) = *(*int32)(unsafe.Pointer(bp + 4 /* rshifts_local */))
}

/************************/
/* Init Decoder State   */
/************************/
func Init_decoder(tls *libc.TLS, psDec uintptr) int32 { /* create_init_destroy.c:34:9: */
	libc.Xmemset(tls, psDec, 0, uint32(unsafe.Sizeof(decoder_state{})))
	/* Set sampling rate to 24 kHz, and init non-zero values */
	decoder_set_fs(tls, psDec, 24)

	/* Used to deactivate e.g. LSF interpolation and fluctuation reduction */
	(*decoder_state)(unsafe.Pointer(psDec)).Ffirst_frame_after_reset = 1
	(*decoder_state)(unsafe.Pointer(psDec)).Fprev_inv_gain_Q16 = 65536

	/* Reset CNG state */
	CNG_Reset(tls, psDec)

	PLC_Reset(tls, psDec)

	return 0
}

/* Set decoder sampling rate */
func decoder_set_fs(tls *libc.TLS, psDec uintptr, fs_kHz int32) { /* decoder_set_fs.c:31:6: */
	if (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz != fs_kHz {
		(*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz = fs_kHz
		(*decoder_state)(unsafe.Pointer(psDec)).Fframe_length = ((int32(int16(20))) * (int32(int16(fs_kHz))))
		(*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length = ((int32((int16(20 / 4)))) * (int32(int16(fs_kHz))))
		if (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz == 8 {
			(*decoder_state)(unsafe.Pointer(psDec)).FLPC_order = 10
			*(*uintptr)(unsafe.Pointer((psDec + 11500 /* &.psNLSF_CB */))) = uintptr(unsafe.Pointer(&NLSF_CB0_10))
			*(*uintptr)(unsafe.Pointer((psDec + 11500 /* &.psNLSF_CB */) + 1*4)) = uintptr(unsafe.Pointer(&NLSF_CB1_10))
		} else {
			(*decoder_state)(unsafe.Pointer(psDec)).FLPC_order = 16
			*(*uintptr)(unsafe.Pointer((psDec + 11500 /* &.psNLSF_CB */))) = uintptr(unsafe.Pointer(&NLSF_CB0_16))
			*(*uintptr)(unsafe.Pointer((psDec + 11500 /* &.psNLSF_CB */) + 1*4)) = uintptr(unsafe.Pointer(&NLSF_CB1_16))
		}
		/* Reset part of the decoder state */
		libc.Xmemset(tls, psDec+4888 /* &.sLPC_Q14 */, 0, (uint32(16) * uint32(unsafe.Sizeof(int32(0)))))
		libc.Xmemset(tls, psDec+9272 /* &.outBuf */, 0, ((uint32(20 * 24)) * uint32(unsafe.Sizeof(int16(0)))))
		libc.Xmemset(tls, psDec+11244 /* &.prevNLSF_Q15 */, 0, (uint32(16) * uint32(unsafe.Sizeof(int32(0)))))

		(*decoder_state)(unsafe.Pointer(psDec)).FlagPrev = 100
		(*decoder_state)(unsafe.Pointer(psDec)).FLastGainIndex = 1
		(*decoder_state)(unsafe.Pointer(psDec)).Fprev_sigtype = 0
		(*decoder_state)(unsafe.Pointer(psDec)).Ffirst_frame_after_reset = 1

		if fs_kHz == 24 {
			(*decoder_state)(unsafe.Pointer(psDec)).FHP_A = uintptr(unsafe.Pointer(&Dec_A_HP_24))
			(*decoder_state)(unsafe.Pointer(psDec)).FHP_B = uintptr(unsafe.Pointer(&Dec_B_HP_24))
		} else if fs_kHz == 16 {
			(*decoder_state)(unsafe.Pointer(psDec)).FHP_A = uintptr(unsafe.Pointer(&Dec_A_HP_16))
			(*decoder_state)(unsafe.Pointer(psDec)).FHP_B = uintptr(unsafe.Pointer(&Dec_B_HP_16))
		} else if fs_kHz == 12 {
			(*decoder_state)(unsafe.Pointer(psDec)).FHP_A = uintptr(unsafe.Pointer(&Dec_A_HP_12))
			(*decoder_state)(unsafe.Pointer(psDec)).FHP_B = uintptr(unsafe.Pointer(&Dec_B_HP_12))
		} else if fs_kHz == 8 {
			(*decoder_state)(unsafe.Pointer(psDec)).FHP_A = uintptr(unsafe.Pointer(&Dec_A_HP_8))
			(*decoder_state)(unsafe.Pointer(psDec)).FHP_B = uintptr(unsafe.Pointer(&Dec_B_HP_8))
		} else {
			/* unsupported sampling rate */

		}
	}

	/* Check that settings are valid */

}

/**********************************************************/
/* Core decoder. Performs inverse NSQ operation LTP + LPC */
/**********************************************************/
func decode_core(tls *libc.TLS, psDec uintptr, psDecCtrl uintptr, xq uintptr, q uintptr) { /* decode_core.c:44:6: */
	bp := tls.Alloc(1536)
	defer tls.Free(1536)

	var i int32
	var k int32
	var lag int32 = 0
	var start_idx int32
	var sLTP_buf_idx int32
	var NLSF_interpolation_flag int32
	var sigtype int32
	var A_Q12 uintptr
	var B_Q14 uintptr
	var pxq uintptr
	// var A_Q12_tmp [16]int16 at bp, 32

	// var sLTP [480]int16 at bp+96, 960

	var LTP_pred_Q14 int32
	var Gain_Q16 int32
	var inv_gain_Q16 int32
	var inv_gain_Q32 int32
	var gain_adj_Q16 int32
	var rand_seed int32
	var offset_Q10 int32
	var dither int32
	var pred_lag_ptr uintptr
	var pexc_Q10 uintptr
	var pres_Q10 uintptr
	// var vec_Q10 [120]int32 at bp+1056, 480

	// var FiltState [16]int32 at bp+32, 64

	offset_Q10 = int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&Quantization_Offsets_Q10)) + uintptr((*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype)*4) + uintptr((*decoder_control)(unsafe.Pointer(psDecCtrl)).FQuantOffsetType)*2)))

	if (*decoder_control)(unsafe.Pointer(psDecCtrl)).FNLSFInterpCoef_Q2 < (int32(1) << 2) {
		NLSF_interpolation_flag = 1
	} else {
		NLSF_interpolation_flag = 0
	}

	/* Decode excitation */
	rand_seed = (*decoder_control)(unsafe.Pointer(psDecCtrl)).FSeed
	for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).Fframe_length; i++ {
		rand_seed = (int32((uint32(907633515)) + ((uint32(rand_seed)) * (uint32(196314165)))))
		/* dither = rand_seed < 0 ? 0xFFFFFFFF : 0; */
		dither = ((rand_seed) >> (31))

		*(*int32)(unsafe.Pointer((psDec + 5432 /* &.exc_Q10 */) + uintptr(i)*4)) = (((*(*int32)(unsafe.Pointer(q + uintptr(i)*4))) << (10)) + offset_Q10)
		*(*int32)(unsafe.Pointer((psDec + 5432 /* &.exc_Q10 */) + uintptr(i)*4)) = ((*(*int32)(unsafe.Pointer((psDec + 5432 /* &.exc_Q10 */) + uintptr(i)*4)) ^ dither) - dither)

		rand_seed = rand_seed + (*(*int32)(unsafe.Pointer(q + uintptr(i)*4)))
	}

	pexc_Q10 = psDec + 5432 /* &.exc_Q10 */
	pres_Q10 = psDec + 7352 /* &.res_Q10 */
	pxq = ((psDec + 9272 /* &.outBuf */) + uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length)*2)
	sLTP_buf_idx = (*decoder_state)(unsafe.Pointer(psDec)).Fframe_length
	/* Loop over subframes */
	for k = 0; k < 4; k++ {
		A_Q12 = psDecCtrl + 36 /* &.PredCoef_Q12 */ + uintptr((k>>1))*32

		/* Preload LPC coeficients to array on stack. Gives small performance gain */
		libc.Xmemcpy(tls, bp /* &A_Q12_tmp[0] */, A_Q12, (uint32((*decoder_state)(unsafe.Pointer(psDec)).FLPC_order) * uint32(unsafe.Sizeof(int16(0)))))
		B_Q14 = ((psDecCtrl + 100 /* &.LTPCoef_Q14 */) + uintptr((k*5))*2)
		Gain_Q16 = *(*int32)(unsafe.Pointer((psDecCtrl + 16 /* &.Gains_Q16 */) + uintptr(k)*4))
		sigtype = (*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype

		inv_gain_Q16 = INVERSE32_varQ(tls, func() int32 {
			if (Gain_Q16) > (1) {
				return Gain_Q16
			}
			return 1
		}(), 32)
		inv_gain_Q16 = func() int32 {
			if (inv_gain_Q16) < (0x7FFF) {
				return inv_gain_Q16
			}
			return 0x7FFF
		}()

		/* Calculate Gain adjustment factor */
		gain_adj_Q16 = (int32(1) << 16)
		if inv_gain_Q16 != (*decoder_state)(unsafe.Pointer(psDec)).Fprev_inv_gain_Q16 {
			gain_adj_Q16 = DIV32_varQ(tls, inv_gain_Q16, (*decoder_state)(unsafe.Pointer(psDec)).Fprev_inv_gain_Q16, 16)
		}

		/* Avoid abrupt transition from voiced PLC to unvoiced normal decoding */
		if ((((*decoder_state)(unsafe.Pointer(psDec)).FlossCnt != 0) && ((*decoder_state)(unsafe.Pointer(psDec)).Fprev_sigtype == 0)) && ((*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype == 1)) && (k < (int32(4) >> 1)) {

			libc.Xmemset(tls, B_Q14, 0, (uint32(5) * uint32(unsafe.Sizeof(int16(0)))))
			*(*int16)(unsafe.Pointer(B_Q14 + 2*2)) = (int16(int32(int32(int16(1))) << 12)) /* 0.25 */

			sigtype = 0
			*(*int32)(unsafe.Pointer((psDecCtrl /* &.pitchL */) + uintptr(k)*4)) = (*decoder_state)(unsafe.Pointer(psDec)).FlagPrev
		}

		if sigtype == 0 {
			/* Voiced */

			lag = *(*int32)(unsafe.Pointer((psDecCtrl /* &.pitchL */) + uintptr(k)*4))
			/* Re-whitening */
			if (k & (3 - ((NLSF_interpolation_flag) << (1)))) == 0 {
				/* Rewhiten with new A coefs */
				start_idx = ((((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length - lag) - (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order) - (5 / 2))

				libc.Xmemset(tls, bp+32 /* &FiltState[0] */, 0, (uint32((*decoder_state)(unsafe.Pointer(psDec)).FLPC_order) * uint32(unsafe.Sizeof(int32(0))))) /* Not really necessary, but Valgrind and Coverity will complain otherwise */
				MA_Prediction(tls, ((psDec + 9272 /* &.outBuf */) + uintptr((start_idx+(k*((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length>>2))))*2),
					A_Q12, bp+32 /* &FiltState[0] */, (bp + 96 /* &sLTP[0] */ + uintptr(start_idx)*2), ((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length - start_idx), (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order)

				/* After rewhitening the LTP state is unscaled */
				inv_gain_Q32 = ((inv_gain_Q16) << (16))
				if k == 0 {
					/* Do LTP downscaling */
					inv_gain_Q32 = (((((inv_gain_Q32) >> 16) * (int32(int16((*decoder_control)(unsafe.Pointer(psDecCtrl)).FLTP_scale_Q14)))) + ((((inv_gain_Q32) & 0x0000FFFF) * (int32(int16((*decoder_control)(unsafe.Pointer(psDecCtrl)).FLTP_scale_Q14)))) >> 16)) << (2))
				}
				for i = 0; i < (lag + (5 / 2)); i++ {
					*(*int32)(unsafe.Pointer((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(((sLTP_buf_idx-i)-1))*4)) = ((((inv_gain_Q32) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp + 96 /* &sLTP[0] */ + uintptr((((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length-i)-1))*2))))) + ((((inv_gain_Q32) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp + 96 /* &sLTP[0] */ + uintptr((((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length-i)-1))*2))))) >> 16))
				}
			} else {
				/* Update LTP state when Gain changes */
				if gain_adj_Q16 != (int32(1) << 16) {
					for i = 0; i < (lag + (5 / 2)); i++ {
						*(*int32)(unsafe.Pointer((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(((sLTP_buf_idx-i)-1))*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(((sLTP_buf_idx-i)-1))*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(((sLTP_buf_idx-i)-1))*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(((sLTP_buf_idx-i)-1))*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(((sLTP_buf_idx-i)-1))*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(((sLTP_buf_idx-i)-1))*4))) >> ((16) - 1)) + 1) >> 1)
						}())))
					}
				}
			}
		}

		/* Scale short term state */
		for i = 0; i < 16; i++ {
			*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}

		/* Save inv_gain */

		(*decoder_state)(unsafe.Pointer(psDec)).Fprev_inv_gain_Q16 = inv_gain_Q16

		/* Long-term prediction */
		if sigtype == 0 {
			/* Setup pointer */
			pred_lag_ptr = ((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(((sLTP_buf_idx-lag)+(5/2)))*4)
			for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length; i++ {
				/* Unrolled loop */
				LTP_pred_Q14 = ((((*(*int32)(unsafe.Pointer(pred_lag_ptr))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14))))) >> 16))
				LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-1)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 1*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-1)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 1*2))))) >> 16)))
				LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-2)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 2*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-2)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 2*2))))) >> 16)))
				LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-3)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 3*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-3)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 3*2))))) >> 16)))
				LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-4)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 4*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-4)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 4*2))))) >> 16)))
				pred_lag_ptr += 4

				/* Generate LPC residual */
				*(*int32)(unsafe.Pointer(pres_Q10 + uintptr(i)*4)) = ((*(*int32)(unsafe.Pointer(pexc_Q10 + uintptr(i)*4))) + (func() int32 {
					if (4) == 1 {
						return (((LTP_pred_Q14) >> 1) + ((LTP_pred_Q14) & 1))
					}
					return ((((LTP_pred_Q14) >> ((4) - 1)) + 1) >> 1)
				}()))

				/* Update states */
				*(*int32)(unsafe.Pointer((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(sLTP_buf_idx)*4)) = ((*(*int32)(unsafe.Pointer(pres_Q10 + uintptr(i)*4))) << (6))
				sLTP_buf_idx++
			}
		} else {
			libc.Xmemcpy(tls, pres_Q10, pexc_Q10, (uint32((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length) * uint32(unsafe.Sizeof(int32(0)))))
		}

		decode_short_term_prediction(tls, bp+1056 /* &vec_Q10[0] */, pres_Q10, psDec+4888 /* &.sLPC_Q14 */, bp /* &A_Q12_tmp[0] */, (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order, (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)

		/* Scale with Gain */
		for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length; i++ {
			*(*int16)(unsafe.Pointer(pxq + uintptr(i)*2)) = func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1))
					}
					return ((((((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
						if (16) == 1 {
							return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
						}
						return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1)
				}()) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (func() int32 {
						if (10) == 1 {
							return (((((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
								if (16) == 1 {
									return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
								}
								return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
							}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
								if (16) == 1 {
									return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
								}
								return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
							}()))) & 1))
						}
						return ((((((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) >> ((10) - 1)) + 1) >> 1)
					}()) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return func() int16 {
						if (10) == 1 {
							return (int16(((((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
								if (16) == 1 {
									return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
								}
								return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
							}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
								if (16) == 1 {
									return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
								}
								return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
							}()))) & 1)))
						}
						return (int16((((((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(Gain_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 1056 /* &vec_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) >> ((10) - 1)) + 1) >> 1))
					}()
				}()
			}()
		}

		/* Update LPC filter state */
		libc.Xmemcpy(tls, psDec+4888 /* &.sLPC_Q14 */, ((psDec + 4888 /* &.sLPC_Q14 */) + uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)*4), (uint32(16) * uint32(unsafe.Sizeof(int32(0)))))
		pexc_Q10 += 4 * (uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length))
		pres_Q10 += 4 * (uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length))
		pxq += 2 * (uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length))
	}

	/* Copy to output */
	libc.Xmemcpy(tls, xq, ((psDec + 9272 /* &.outBuf */) + uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length)*2), (uint32((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length) * uint32(unsafe.Sizeof(int16(0)))))

}

func decode_short_term_prediction(tls *libc.TLS, vec_Q10 uintptr, pres_Q10 uintptr, sLPC_Q14 uintptr, A_Q12_tmp uintptr, LPC_order int32, subfr_length int32) { /* decode_core.c:204:6: */
	var i int32
	var LPC_pred_Q10 int32
	var j int32
	for i = 0; i < subfr_length; i++ {
		/* Partially unrolled */
		LPC_pred_Q10 = ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-1))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-1))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp))))) >> 16))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-2))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 1*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-2))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 1*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-3))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 2*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-3))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 2*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-4))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 3*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-4))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 3*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-5))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 4*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-5))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 4*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-6))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 5*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-6))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 5*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-7))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 6*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-7))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 6*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-8))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 7*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-8))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 7*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-9))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 8*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-9))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 8*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-10))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 9*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr(((16+i)-10))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + 9*2))))) >> 16)))

		for j = 10; j < LPC_order; j++ {
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr((((16+i)-j)-1))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + uintptr(j)*2))))) + ((((*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr((((16+i)-j)-1))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12_tmp + uintptr(j)*2))))) >> 16)))
		}

		/* Add prediction to LPC residual */
		*(*int32)(unsafe.Pointer(vec_Q10 + uintptr(i)*4)) = ((*(*int32)(unsafe.Pointer(pres_Q10 + uintptr(i)*4))) + (LPC_pred_Q10))

		/* Update states */
		*(*int32)(unsafe.Pointer(sLPC_Q14 + uintptr((16+i))*4)) = ((*(*int32)(unsafe.Pointer(vec_Q10 + uintptr(i)*4))) << (4))
	}
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/****************/
/* Decode frame */
/****************/
func decode_frame(tls *libc.TLS, psDec uintptr, pOut uintptr, pN uintptr, pCode uintptr, nBytes int32, action int32, decBytes uintptr) int32 { /* decode_frame.c:35:9: */
	bp := tls.Alloc(2084)
	defer tls.Free(2084)

	// var sDecCtrl decoder_control at bp, 164

	var L int32
	var fs_Khz_old int32
	var ret int32 = 0
	// var Pulses [480]int32 at bp+164, 1920

	L = (*decoder_state)(unsafe.Pointer(psDec)).Fframe_length
	(*decoder_control)(unsafe.Pointer(bp /* &sDecCtrl */)).FLTP_scale_Q14 = 0

	/* Safety checks */

	/********************************************/
	/* Decode Frame if packet is not lost  */
	/********************************************/
	*(*int32)(unsafe.Pointer(decBytes)) = 0
	if action == 0 {
		/********************************************/
		/* Initialize arithmetic coder              */
		/********************************************/
		fs_Khz_old = (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz
		if (*decoder_state)(unsafe.Pointer(psDec)).FnFramesDecoded == 0 {
			/* Initialize range decoder state */
			range_dec_init(tls, (psDec /* &.sRC */), pCode, nBytes)
		}

		/********************************************/
		/* Decode parameters and pulse signal       */
		/********************************************/
		decode_parameters(tls, psDec, bp /* &sDecCtrl */, bp+164 /* &Pulses[0] */, 1)

		if (*decoder_state)(unsafe.Pointer(psDec)).FsRC.Ferror != 0 {
			(*decoder_state)(unsafe.Pointer(psDec)).FnBytesLeft = 0

			action = 1 /* PLC operation */
			/* revert fs if changed in decode_parameters */
			decoder_set_fs(tls, psDec, fs_Khz_old)

			/* Avoid crashing */
			*(*int32)(unsafe.Pointer(decBytes)) = (*decoder_state)(unsafe.Pointer(psDec)).FsRC.FbufferLength

			if (*decoder_state)(unsafe.Pointer(psDec)).FsRC.Ferror == -8 {
				ret = -11
			} else {
				ret = -12
			}
		} else {
			*(*int32)(unsafe.Pointer(decBytes)) = ((*decoder_state)(unsafe.Pointer(psDec)).FsRC.FbufferLength - (*decoder_state)(unsafe.Pointer(psDec)).FnBytesLeft)
			(*decoder_state)(unsafe.Pointer(psDec)).FnFramesDecoded++

			/* Update lengths. Sampling frequency could have changed */
			L = (*decoder_state)(unsafe.Pointer(psDec)).Fframe_length

			/********************************************************/
			/* Run inverse NSQ                                      */
			/********************************************************/
			decode_core(tls, psDec, bp /* &sDecCtrl */, pOut, bp+164 /* &Pulses[0] */)

			/********************************************************/
			/* Update PLC state                                     */
			/********************************************************/
			PLC(tls, psDec, bp /* &sDecCtrl */, pOut, L, action)

			(*decoder_state)(unsafe.Pointer(psDec)).FlossCnt = 0
			(*decoder_state)(unsafe.Pointer(psDec)).Fprev_sigtype = (*decoder_control)(unsafe.Pointer(bp /* &sDecCtrl */)).Fsigtype

			/* A frame has been decoded without errors */
			(*decoder_state)(unsafe.Pointer(psDec)).Ffirst_frame_after_reset = 0
		}
	}
	/*************************************************************/
	/* Generate Concealment frame if packet is lost, or corrupt  */
	/*************************************************************/
	if action == 1 {
		/* Handle packet loss by extrapolation */
		PLC(tls, psDec, bp /* &sDecCtrl */, pOut, L, action)
	}

	/*************************/
	/* Update output buffer. */
	/*************************/
	libc.Xmemcpy(tls, psDec+9272 /* &.outBuf */, pOut, (uint32(L) * uint32(unsafe.Sizeof(int16(0)))))

	/****************************************************************/
	/* Ensure smooth connection of extrapolated and good frames     */
	/****************************************************************/
	PLC_glue_frames(tls, psDec, bp /* &sDecCtrl */, pOut, L)

	/************************************************/
	/* Comfort noise generation / estimation        */
	/************************************************/
	CNG(tls, psDec, bp /* &sDecCtrl */, pOut, L)

	/********************************************/
	/* HP filter output                            */
	/********************************************/

	biquad(tls, pOut, (*decoder_state)(unsafe.Pointer(psDec)).FHP_B, (*decoder_state)(unsafe.Pointer(psDec)).FHP_A, psDec+11208 /* &.HPState */, pOut, L)

	/********************************************/
	/* set output frame length                    */
	/********************************************/
	*(*int16)(unsafe.Pointer(pN)) = int16(L)

	/* Update some decoder state variables */
	(*decoder_state)(unsafe.Pointer(psDec)).FlagPrev = *(*int32)(unsafe.Pointer((bp /* &sDecCtrl */ /* &.pitchL */) + 3*4))

	return ret
}

/* Decode parameters from payload */
func decode_parameters(tls *libc.TLS, psDec uintptr, psDecCtrl uintptr, q uintptr, fullDecoding int32) { /* decode_parameters.c:31:6: */
	bp := tls.Alloc(208)
	defer tls.Free(208)

	var i int32
	var k int32
	// var Ix int32 at bp, 4

	var fs_kHz_dec int32
	// var nBytesUsed int32 at bp+204, 4

	// var Ixs [4]int32 at bp+188, 16

	// var GainsIndices [4]int32 at bp+4, 16

	// var NLSFIndices [10]int32 at bp+20, 40

	// var pNLSF_Q15 [16]int32 at bp+60, 64

	// var pNLSF0_Q15 [16]int32 at bp+124, 64

	var cbk_ptr_Q14 uintptr
	var psNLSF_CB uintptr = uintptr(0)
	var psRC uintptr = (psDec /* &.sRC */)

	/************************/
	/* Decode sampling rate */
	/************************/
	/* only done for first frame of packet */
	if (*decoder_state)(unsafe.Pointer(psDec)).FnFramesDecoded == 0 {
		range_decoder(tls, bp /* &Ix */, psRC, uintptr(unsafe.Pointer(&SamplingRates_CDF)), SamplingRates_offset)

		/* check that sampling rate is supported */
		if (*(*int32)(unsafe.Pointer(bp /* Ix */)) < 0) || (*(*int32)(unsafe.Pointer(bp /* Ix */)) > 3) {
			(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -7
			return
		}
		fs_kHz_dec = SamplingRates_table[*(*int32)(unsafe.Pointer(bp /* Ix */))]
		decoder_set_fs(tls, psDec, fs_kHz_dec)
	}

	/*******************************************/
	/* Decode signal type and quantizer offset */
	/*******************************************/
	if (*decoder_state)(unsafe.Pointer(psDec)).FnFramesDecoded == 0 {
		/* first frame in packet: independent coding */
		range_decoder(tls, bp /* &Ix */, psRC, uintptr(unsafe.Pointer(&type_offset_CDF)), type_offset_CDF_offset)
	} else {
		/* condidtional coding */
		range_decoder(tls, bp /* &Ix */, psRC, (uintptr(unsafe.Pointer(&type_offset_joint_CDF)) + uintptr((*decoder_state)(unsafe.Pointer(psDec)).FtypeOffsetPrev)*10),
			type_offset_CDF_offset)
	}
	(*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype = ((*(*int32)(unsafe.Pointer(bp /* Ix */))) >> (1))
	(*decoder_control)(unsafe.Pointer(psDecCtrl)).FQuantOffsetType = (*(*int32)(unsafe.Pointer(bp /* Ix */)) & 1)
	(*decoder_state)(unsafe.Pointer(psDec)).FtypeOffsetPrev = *(*int32)(unsafe.Pointer(bp /* Ix */))

	/****************/
	/* Decode gains */
	/****************/
	/* first subframe */
	if (*decoder_state)(unsafe.Pointer(psDec)).FnFramesDecoded == 0 {
		/* first frame in packet: independent coding */
		range_decoder(tls, (bp + 4 /* &GainsIndices */), psRC, (uintptr(unsafe.Pointer(&gain_CDF)) + uintptr((*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype)*130), gain_CDF_offset)
	} else {
		/* condidtional coding */
		range_decoder(tls, (bp + 4 /* &GainsIndices */), psRC, uintptr(unsafe.Pointer(&delta_gain_CDF)), delta_gain_CDF_offset)
	}

	/* remaining subframes */
	for i = 1; i < 4; i++ {
		range_decoder(tls, (bp + 4 /* &GainsIndices */ + uintptr(i)*4), psRC, uintptr(unsafe.Pointer(&delta_gain_CDF)), delta_gain_CDF_offset)
	}

	/* Dequant Gains */
	gains_dequant(tls, psDecCtrl+16 /* &.Gains_Q16 */, bp+4 /* &GainsIndices[0] */, (psDec + 11196 /* &.LastGainIndex */), (*decoder_state)(unsafe.Pointer(psDec)).FnFramesDecoded)
	/****************/
	/* Decode NLSFs */
	/****************/
	/* Set pointer to NLSF VQ CB for the current signal type */
	psNLSF_CB = *(*uintptr)(unsafe.Pointer((psDec + 11500 /* &.psNLSF_CB */) + uintptr((*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype)*4))

	/* Range decode NLSF path */
	range_decoder_multi(tls, bp+20 /* &NLSFIndices[0] */, psRC, (*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FStartPtr, (*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FMiddleIx, (*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages)

	/* From the NLSF path, decode an NLSF vector */
	NLSF_MSVQ_decode(tls, bp+60 /* &pNLSF_Q15[0] */, psNLSF_CB, bp+20 /* &NLSFIndices[0] */, (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order)

	/************************************/
	/* Decode NLSF interpolation factor */
	/************************************/
	range_decoder(tls, (psDecCtrl + 160 /* &.NLSFInterpCoef_Q2 */), psRC, uintptr(unsafe.Pointer(&NLSF_interpolation_factor_CDF)),
		NLSF_interpolation_factor_offset)

	/* If just reset, e.g., because internal Fs changed, do not allow interpolation */
	/* improves the case of packet loss in the first frame after a switch           */
	if (*decoder_state)(unsafe.Pointer(psDec)).Ffirst_frame_after_reset == 1 {
		(*decoder_control)(unsafe.Pointer(psDecCtrl)).FNLSFInterpCoef_Q2 = 4
	}

	if fullDecoding != 0 {
		/* Convert NLSF parameters to AR prediction filter coefficients */
		NLSF2A_stable(tls, ((psDecCtrl + 36 /* &.PredCoef_Q12 */) + 1*32), bp+60 /* &pNLSF_Q15[0] */, (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order)

		if (*decoder_control)(unsafe.Pointer(psDecCtrl)).FNLSFInterpCoef_Q2 < 4 {
			/* Calculation of the interpolated NLSF0 vector from the interpolation factor, */
			/* the previous NLSF1, and the current NLSF1                                   */
			for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order; i++ {
				*(*int32)(unsafe.Pointer(bp + 124 /* &pNLSF0_Q15[0] */ + uintptr(i)*4)) = (*(*int32)(unsafe.Pointer((psDec + 11244 /* &.prevNLSF_Q15 */) + uintptr(i)*4)) + ((((*decoder_control)(unsafe.Pointer(psDecCtrl)).FNLSFInterpCoef_Q2) * (*(*int32)(unsafe.Pointer(bp + 60 /* &pNLSF_Q15[0] */ + uintptr(i)*4)) - *(*int32)(unsafe.Pointer((psDec + 11244 /* &.prevNLSF_Q15 */) + uintptr(i)*4)))) >> (2)))
			}

			/* Convert NLSF parameters to AR prediction filter coefficients */
			NLSF2A_stable(tls, (psDecCtrl + 36 /* &.PredCoef_Q12 */), bp+124 /* &pNLSF0_Q15[0] */, (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order)
		} else {
			/* Copy LPC coefficients for first half from second half */
			libc.Xmemcpy(tls, (psDecCtrl + 36 /* &.PredCoef_Q12 */), ((psDecCtrl + 36 /* &.PredCoef_Q12 */) + 1*32), (uint32((*decoder_state)(unsafe.Pointer(psDec)).FLPC_order) * uint32(unsafe.Sizeof(int16(0)))))
		}
	}

	libc.Xmemcpy(tls, psDec+11244 /* &.prevNLSF_Q15 */, bp+60 /* &pNLSF_Q15[0] */, (uint32((*decoder_state)(unsafe.Pointer(psDec)).FLPC_order) * uint32(unsafe.Sizeof(int32(0)))))

	/* After a packet loss do BWE of LPC coefs */
	if (*decoder_state)(unsafe.Pointer(psDec)).FlossCnt != 0 {
		bwexpander(tls, (psDecCtrl + 36 /* &.PredCoef_Q12 */), (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order, 63570)
		bwexpander(tls, ((psDecCtrl + 36 /* &.PredCoef_Q12 */) + 1*32), (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order, 63570)
	}

	if (*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype == 0 {
		/*********************/
		/* Decode pitch lags */
		/*********************/
		/* Get lag index */
		if (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz == 8 {
			range_decoder(tls, (bp + 188 /* &Ixs */), psRC, uintptr(unsafe.Pointer(&pitch_lag_NB_CDF)), pitch_lag_NB_CDF_offset)
		} else if (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz == 12 {
			range_decoder(tls, (bp + 188 /* &Ixs */), psRC, uintptr(unsafe.Pointer(&pitch_lag_MB_CDF)), pitch_lag_MB_CDF_offset)
		} else if (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz == 16 {
			range_decoder(tls, (bp + 188 /* &Ixs */), psRC, uintptr(unsafe.Pointer(&pitch_lag_WB_CDF)), pitch_lag_WB_CDF_offset)
		} else {
			range_decoder(tls, (bp + 188 /* &Ixs */), psRC, uintptr(unsafe.Pointer(&pitch_lag_SWB_CDF)), pitch_lag_SWB_CDF_offset)
		}

		/* Get countour index */
		if (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz == 8 {
			/* Less codevectors used in 8 khz mode */
			range_decoder(tls, (bp + 188 /* &Ixs */ + 1*4), psRC, uintptr(unsafe.Pointer(&pitch_contour_NB_CDF)), pitch_contour_NB_CDF_offset)
		} else {
			/* Joint for 12, 16, and 24 khz */
			range_decoder(tls, (bp + 188 /* &Ixs */ + 1*4), psRC, uintptr(unsafe.Pointer(&pitch_contour_CDF)), pitch_contour_CDF_offset)
		}

		/* Decode pitch values */
		decode_pitch(tls, *(*int32)(unsafe.Pointer(bp + 188 /* &Ixs[0] */)), *(*int32)(unsafe.Pointer(bp + 188 /* &Ixs[0] */ + 1*4)), psDecCtrl /* &.pitchL */, (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz)

		/********************/
		/* Decode LTP gains */
		/********************/
		/* Decode PERIndex value */
		range_decoder(tls, (psDecCtrl + 144 /* &.PERIndex */), psRC, uintptr(unsafe.Pointer(&LTP_per_index_CDF)),
			LTP_per_index_CDF_offset)

		/* Decode Codebook Index */
		cbk_ptr_Q14 = LTP_vq_ptrs_Q14[(*decoder_control)(unsafe.Pointer(psDecCtrl)).FPERIndex] /* set pointer to start of codebook */

		for k = 0; k < 4; k++ {
			range_decoder(tls, bp /* &Ix */, psRC, LTP_gain_CDF_ptrs[(*decoder_control)(unsafe.Pointer(psDecCtrl)).FPERIndex],
				LTP_gain_CDF_offsets[(*decoder_control)(unsafe.Pointer(psDecCtrl)).FPERIndex])

			for i = 0; i < 5; i++ {
				*(*int16)(unsafe.Pointer((psDecCtrl + 100 /* &.LTPCoef_Q14 */) + uintptr(((k*5)+i))*2)) = *(*int16)(unsafe.Pointer(cbk_ptr_Q14 + uintptr(((*(*int32)(unsafe.Pointer(bp /* Ix */))*5)+i))*2))
			}
		}

		/**********************/
		/* Decode LTP scaling */
		/**********************/
		range_decoder(tls, bp /* &Ix */, psRC, uintptr(unsafe.Pointer(&LTPscale_CDF)), LTPscale_offset)
		(*decoder_control)(unsafe.Pointer(psDecCtrl)).FLTP_scale_Q14 = int32(LTPScales_table_Q14[*(*int32)(unsafe.Pointer(bp /* Ix */))])
	} else {

		libc.Xmemset(tls, psDecCtrl /* &.pitchL */, 0, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))
		libc.Xmemset(tls, psDecCtrl+100 /* &.LTPCoef_Q14 */, 0, ((uint32(5 * 4)) * uint32(unsafe.Sizeof(int16(0)))))
		(*decoder_control)(unsafe.Pointer(psDecCtrl)).FPERIndex = 0
		(*decoder_control)(unsafe.Pointer(psDecCtrl)).FLTP_scale_Q14 = 0
	}

	/***************/
	/* Decode seed */
	/***************/
	range_decoder(tls, bp /* &Ix */, psRC, uintptr(unsafe.Pointer(&Seed_CDF)), Seed_offset)
	(*decoder_control)(unsafe.Pointer(psDecCtrl)).FSeed = *(*int32)(unsafe.Pointer(bp /* Ix */))
	/*********************************************/
	/* Decode quantization indices of excitation */
	/*********************************************/
	decode_pulses(tls, psRC, psDecCtrl, q, (*decoder_state)(unsafe.Pointer(psDec)).Fframe_length)

	/*********************************************/
	/* Decode VAD flag                           */
	/*********************************************/
	range_decoder(tls, (psDec + 11508 /* &.vadFlag */), psRC, uintptr(unsafe.Pointer(&vadflag_CDF)), vadflag_offset)

	/**************************************/
	/* Decode Frame termination indicator */
	/**************************************/
	range_decoder(tls, (psDec + 11328 /* &.FrameTermination */), psRC, uintptr(unsafe.Pointer(&FrameTermination_CDF)), FrameTermination_offset)

	/****************************************/
	/* get number of bytes used so far      */
	/****************************************/
	range_coder_get_length(tls, psRC, bp+204 /* &nBytesUsed */)
	(*decoder_state)(unsafe.Pointer(psDec)).FnBytesLeft = ((*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength - *(*int32)(unsafe.Pointer(bp + 204 /* nBytesUsed */)))
	if (*decoder_state)(unsafe.Pointer(psDec)).FnBytesLeft < 0 {
		(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -6
	}

	/****************************************/
	/* check remaining bits in last byte    */
	/****************************************/
	if (*decoder_state)(unsafe.Pointer(psDec)).FnBytesLeft == 0 {
		range_coder_check_after_decoding(tls, psRC)
	}
}

func decode_pitch(tls *libc.TLS, lagIndex int32, contourIndex int32, pitch_lags uintptr, Fs_kHz int32) { /* decode_pitch.c:34:6: */
	var lag int32
	var i int32
	var min_lag int32

	min_lag = ((int32(int16(2))) * (int32(int16(Fs_kHz))))

	/* Only for 24 / 16 kHz version for now */
	lag = (min_lag + lagIndex)
	if Fs_kHz == 8 {
		/* Only a small codebook for 8 khz */
		for i = 0; i < 4; i++ {
			*(*int32)(unsafe.Pointer(pitch_lags + uintptr(i)*4)) = (lag + int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage2)) + uintptr(i)*22) + uintptr(contourIndex)*2))))
		}
	} else {
		for i = 0; i < 4; i++ {
			*(*int32)(unsafe.Pointer(pitch_lags + uintptr(i)*4)) = (lag + int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage3)) + uintptr(i)*68) + uintptr(contourIndex)*2))))
		}
	}
}

/*********************************************/
/* Decode quantization indices of excitation */
/*********************************************/
func decode_pulses(tls *libc.TLS, psRC uintptr, psDecCtrl uintptr, q uintptr, frame_length int32) { /* decode_pulses.c:33:6: */
	bp := tls.Alloc(244)
	defer tls.Free(244)

	var i int32
	var j int32
	var k int32
	var iter int32
	var abs_q int32
	var nLS int32
	// var bit int32 at bp+240, 4

	// var sum_pulses [30]int32 at bp+120, 120

	// var nLshifts [30]int32 at bp, 120

	var pulses_ptr uintptr
	var cdf_ptr uintptr

	/*********************/
	/* Decode rate level */
	/*********************/
	range_decoder(tls, (psDecCtrl + 148 /* &.RateLevelIndex */), psRC,
		(uintptr(unsafe.Pointer(&rate_levels_CDF)) + uintptr((*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype)*20), rate_levels_CDF_offset)

	/* Calculate number of shell blocks */
	iter = (frame_length / 16)

	/***************************************************/
	/* Sum-Weighted-Pulses Decoding                    */
	/***************************************************/
	cdf_ptr = (uintptr(unsafe.Pointer(&pulses_per_block_CDF)) + uintptr((*decoder_control)(unsafe.Pointer(psDecCtrl)).FRateLevelIndex)*42)
	for i = 0; i < iter; i++ {
		*(*int32)(unsafe.Pointer(bp /* &nLshifts[0] */ + uintptr(i)*4)) = 0
		range_decoder(tls, (bp + 120 /* &sum_pulses */ + uintptr(i)*4), psRC, cdf_ptr, pulses_per_block_CDF_offset)

		/* LSB indication */
		for *(*int32)(unsafe.Pointer(bp + 120 /* &sum_pulses[0] */ + uintptr(i)*4)) == (18 + 1) {
			*(*int32)(unsafe.Pointer(bp /* &nLshifts[0] */ + uintptr(i)*4))++
			range_decoder(tls, (bp + 120 /* &sum_pulses */ + uintptr(i)*4), psRC,
				(uintptr(unsafe.Pointer(&pulses_per_block_CDF)) + 9*42), pulses_per_block_CDF_offset)
		}
	}

	/***************************************************/
	/* Shell decoding                                  */
	/***************************************************/
	for i = 0; i < iter; i++ {
		if *(*int32)(unsafe.Pointer(bp + 120 /* &sum_pulses[0] */ + uintptr(i)*4)) > 0 {
			shell_decoder(tls, (q + uintptr(((int32(int16(i)))*(int32(int16(16)))))*4), psRC, *(*int32)(unsafe.Pointer(bp + 120 /* &sum_pulses[0] */ + uintptr(i)*4)))
		} else {
			libc.Xmemset(tls, (q + uintptr(((int32(int16(i)))*(int32(int16(16)))))*4), 0, (uint32(16) * uint32(unsafe.Sizeof(int32(0)))))
		}
	}

	/***************************************************/
	/* LSB Decoding                                    */
	/***************************************************/
	for i = 0; i < iter; i++ {
		if *(*int32)(unsafe.Pointer(bp /* &nLshifts[0] */ + uintptr(i)*4)) > 0 {
			nLS = *(*int32)(unsafe.Pointer(bp /* &nLshifts[0] */ + uintptr(i)*4))
			pulses_ptr = (q + uintptr(((int32(int16(i)))*(int32(int16(16)))))*4)
			for k = 0; k < 16; k++ {
				abs_q = *(*int32)(unsafe.Pointer(pulses_ptr + uintptr(k)*4))
				for j = 0; j < nLS; j++ {
					abs_q = ((abs_q) << (1))
					range_decoder(tls, bp+240 /* &bit */, psRC, uintptr(unsafe.Pointer(&lsb_CDF)), 1)
					abs_q = abs_q + (*(*int32)(unsafe.Pointer(bp + 240 /* bit */)))
				}
				*(*int32)(unsafe.Pointer(pulses_ptr + uintptr(k)*4)) = abs_q
			}
		}
	}

	/****************************************/
	/* Decode and add signs to pulse signal */
	/****************************************/
	decode_signs(tls, psRC, q, frame_length, (*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype,
		(*decoder_control)(unsafe.Pointer(psDecCtrl)).FQuantOffsetType, (*decoder_control)(unsafe.Pointer(psDecCtrl)).FRateLevelIndex)
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/******************/
/* Error messages */
/******************/

/**************************/
/* Encoder error messages */
/**************************/

/* Input length is not a multiplum of 10 ms, or length is longer than the packet length */

/* Sampling frequency not 8000, 12000, 16000 or 24000 Hertz */

/* Packet size not 20, 40, 60, 80 or 100 ms */

/* Allocated payload buffer too short */

/* Loss rate not between 0 and 100 percent */

/* Complexity setting not valid, use 0, 1 or 2 */

/* Inband FEC setting not valid, use 0 or 1 */

/* DTX setting not valid, use 0 or 1 */

/* Internal encoder error */

/**************************/
/* Decoder error messages */
/**************************/

/* Output sampling frequency lower than internal decoded sampling frequency */

/* Payload size exceeded the maximum allowed 1024 bytes */

/* Payload has bit errors */

/* Struct for TOC (Table of Contents) */
type TOC_struct struct {
	FframesInPacket int32
	Ffs_kHz         int32
	FinbandLBRR     int32
	Fcorrupt        int32
	FvadFlags       [5]int32
	FsigtypeFlags   [5]int32
} /* SDK_API.h:50:3 */

/*********************/
/* Decoder functions */
/*********************/

func SDK_Get_Decoder_Size(tls *libc.TLS, decSizeBytes uintptr) int32 { /* dec_API.c:35:9: */
	var ret int32 = 0

	*(*int32)(unsafe.Pointer(decSizeBytes)) = int32(unsafe.Sizeof(decoder_state{}))

	return ret
}

/* Reset decoder state */
func SDK_InitDecoder(tls *libc.TLS, decState uintptr) int32 { /* dec_API.c:45:9: */
	var ret int32 = 0
	var struc uintptr

	struc = decState

	ret = Init_decoder(tls, struc)

	return ret
}

/* Decode a frame */
func SDK_Decode(tls *libc.TLS, decState uintptr, decControl uintptr, lostFlag int32, inData uintptr, nBytesIn int32, samplesOut uintptr, nSamplesOut uintptr) int32 { /* dec_API.c:60:9: */
	bp := tls.Alloc(3844)
	defer tls.Free(3844)

	var ret int32 = 0
	// var used_bytes int32 at bp+1920, 4

	var prev_fs_kHz int32
	var psDec uintptr
	// var samplesOutInternal [960]int16 at bp, 1920

	var pSamplesOutInternal uintptr

	psDec = decState

	/* We need this buffer to have room for an internal frame */
	pSamplesOutInternal = samplesOut
	if ((*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz * 1000) > (*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate {
		pSamplesOutInternal = bp /* &samplesOutInternal[0] */
	}

	/**********************************/
	/* Test if first frame in payload */
	/**********************************/
	if (*decoder_state)(unsafe.Pointer(psDec)).FmoreInternalDecoderFrames == 0 {
		/* First Frame in Payload */
		(*decoder_state)(unsafe.Pointer(psDec)).FnFramesDecoded = 0 /* Used to count frames in packet */
	}

	if (((*decoder_state)(unsafe.Pointer(psDec)).FmoreInternalDecoderFrames == 0) && (lostFlag == 0)) && (nBytesIn > 1024) { /* Too long payload         */
		/* Avoid trying to decode a too large packet */
		lostFlag = 1
		ret = -11
	}

	/* Save previous sample frequency */
	prev_fs_kHz = (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz

	/* Call decoder for one frame */
	ret = ret + (decode_frame(tls, psDec, pSamplesOutInternal, nSamplesOut, inData, nBytesIn,
		lostFlag, bp+1920 /* &used_bytes */))

	if *(*int32)(unsafe.Pointer(bp + 1920 /* used_bytes */)) != 0 { /* Only Call if not a packet loss */
		if (((*decoder_state)(unsafe.Pointer(psDec)).FnBytesLeft > 0) && ((*decoder_state)(unsafe.Pointer(psDec)).FFrameTermination == 1)) && ((*decoder_state)(unsafe.Pointer(psDec)).FnFramesDecoded < 5) {
			/* We have more frames in the Payload */
			(*decoder_state)(unsafe.Pointer(psDec)).FmoreInternalDecoderFrames = 1
		} else {
			/* Last frame in Payload */
			(*decoder_state)(unsafe.Pointer(psDec)).FmoreInternalDecoderFrames = 0
			(*decoder_state)(unsafe.Pointer(psDec)).FnFramesInPacket = (*decoder_state)(unsafe.Pointer(psDec)).FnFramesDecoded

			/* Track inband FEC usage */
			if (*decoder_state)(unsafe.Pointer(psDec)).FvadFlag == 1 {
				if (*decoder_state)(unsafe.Pointer(psDec)).FFrameTermination == 0 {
					(*decoder_state)(unsafe.Pointer(psDec)).Fno_FEC_counter++
					if (*decoder_state)(unsafe.Pointer(psDec)).Fno_FEC_counter > 10 {
						(*decoder_state)(unsafe.Pointer(psDec)).Finband_FEC_offset = 0
					}
				} else if (*decoder_state)(unsafe.Pointer(psDec)).FFrameTermination == 2 {
					(*decoder_state)(unsafe.Pointer(psDec)).Finband_FEC_offset = 1 /* FEC info with 1 packet delay */
					(*decoder_state)(unsafe.Pointer(psDec)).Fno_FEC_counter = 0
				} else if (*decoder_state)(unsafe.Pointer(psDec)).FFrameTermination == 3 {
					(*decoder_state)(unsafe.Pointer(psDec)).Finband_FEC_offset = 2 /* FEC info with 2 packets delay */
					(*decoder_state)(unsafe.Pointer(psDec)).Fno_FEC_counter = 0
				}
			}
		}
	}

	if ((48 * 1000) < (*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate) || (8000 > (*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate) {
		ret = -10
		return ret
	}

	/* Resample if needed */
	if ((*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz * 1000) != (*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate {
		// var samplesOut_tmp [960]int16 at bp+1924, 1920

		/* Copy to a tmp buffer as the resampling writes to samplesOut */
		libc.Xmemcpy(tls, bp+1924 /* &samplesOut_tmp[0] */, pSamplesOutInternal, (uint32(*(*int16)(unsafe.Pointer(nSamplesOut))) * uint32(unsafe.Sizeof(int16(0)))))

		/* (Re-)initialize resampler state when switching internal sampling frequency */
		if (prev_fs_kHz != (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz) || ((*decoder_state)(unsafe.Pointer(psDec)).Fprev_API_sampleRate != (*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate) {
			ret = resampler_init(tls, (psDec + 11332 /* &.resampler_state */), ((int32(int16((*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz))) * (int32(int16(1000)))), (*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate)
		}

		/* Resample the output to API_sampleRate */
		ret = ret + (resampler(tls, (psDec + 11332 /* &.resampler_state */), samplesOut, bp+1924 /* &samplesOut_tmp[0] */, int32(*(*int16)(unsafe.Pointer(nSamplesOut)))))

		/* Update the number of output samples */
		*(*int16)(unsafe.Pointer(nSamplesOut)) = int16(((int32(*(*int16)(unsafe.Pointer(nSamplesOut))) * (*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate) / ((*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz * 1000)))
	} else if (prev_fs_kHz * 1000) > (*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate {
		libc.Xmemcpy(tls, samplesOut, pSamplesOutInternal, (uint32(*(*int16)(unsafe.Pointer(nSamplesOut))) * uint32(unsafe.Sizeof(int16(0)))))
	}

	(*decoder_state)(unsafe.Pointer(psDec)).Fprev_API_sampleRate = (*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate

	/* Copy all parameters that are needed out of internal structure to the control stucture */
	(*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FframeSize = int32((uint16((*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FAPI_sampleRate / 50)))
	(*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FframesPerPacket = (*decoder_state)(unsafe.Pointer(psDec)).FnFramesInPacket
	(*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FinBandFECOffset = (*decoder_state)(unsafe.Pointer(psDec)).Finband_FEC_offset
	(*SDK_DecControlStruct)(unsafe.Pointer(decControl)).FmoreInternalDecoderFrames = (*decoder_state)(unsafe.Pointer(psDec)).FmoreInternalDecoderFrames

	return ret
}

/* Function to find LBRR information in a packet */
func SDK_search_for_LBRR(tls *libc.TLS, inData uintptr, nBytesIn int32, lost_offset int32, LBRRData uintptr, nLBRRBytes uintptr) { /* dec_API.c:173:6: */
	bp := tls.Alloc(15764)
	defer tls.Free(15764)

	// var sDec decoder_state at bp, 13680
	// Local decoder state to avoid interfering with running decoder */
	// var sDecCtrl decoder_control at bp+13680, 164

	// var TempQ [480]int32 at bp+13844, 1920

	if (lost_offset < 1) || (lost_offset > 2) {
		/* No useful FEC in this packet */
		*(*int16)(unsafe.Pointer(nLBRRBytes)) = int16(0)
		return
	}

	(*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnFramesDecoded = 0
	(*decoder_state)(unsafe.Pointer(bp /* &sDec */)).Ffs_kHz = 0  /* Force update parameters LPC_order etc */
	(*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FlossCnt = 0 /* Avoid running bw expansion of the LPC parameters when searching for LBRR data */
	libc.Xmemset(tls, bp /* &sDec */ +11244 /* &.prevNLSF_Q15 */, 0, (uint32(16) * uint32(unsafe.Sizeof(int32(0)))))
	range_dec_init(tls, (bp /* &sDec */ /* &.sRC */), inData, nBytesIn)

	for 1 != 0 {
		decode_parameters(tls, bp /* &sDec */, bp+13680 /* &sDecCtrl */, bp+13844 /* &TempQ[0] */, 0)

		if (*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FsRC.Ferror != 0 {
			/* Corrupt stream */
			*(*int16)(unsafe.Pointer(nLBRRBytes)) = int16(0)
			return
		}

		if (((((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FFrameTermination - 1) & lost_offset) != 0) && ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FFrameTermination > 0)) && ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnBytesLeft >= 0) {
			/* The wanted FEC is present in the packet */
			*(*int16)(unsafe.Pointer(nLBRRBytes)) = int16((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnBytesLeft)
			libc.Xmemcpy(tls, LBRRData, (inData + uintptr((nBytesIn - (*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnBytesLeft))), (uint32((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnBytesLeft) * uint32(unsafe.Sizeof(uint8(0)))))
			break
		}
		if ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnBytesLeft > 0) && ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FFrameTermination == 1) {
			(*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnFramesDecoded++
		} else {
			LBRRData = uintptr(0)
			*(*int16)(unsafe.Pointer(nLBRRBytes)) = int16(0)
			break
		}
	}
}

/* Getting type of content for a packet */
func SDK_get_TOC(tls *libc.TLS, inData uintptr, nBytesIn int32, Silk_TOC uintptr) { /* dec_API.c:222:6: */
	bp := tls.Alloc(15764)
	defer tls.Free(15764)

	// var sDec decoder_state at bp, 13680
	// Local Decoder state to avoid interfering with running decoder */
	// var sDecCtrl decoder_control at bp+13680, 164

	// var TempQ [480]int32 at bp+13844, 1920

	(*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnFramesDecoded = 0
	(*decoder_state)(unsafe.Pointer(bp /* &sDec */)).Ffs_kHz = 0 /* Force update parameters LPC_order etc */
	range_dec_init(tls, (bp /* &sDec */ /* &.sRC */), inData, nBytesIn)

	(*TOC_struct)(unsafe.Pointer(Silk_TOC)).Fcorrupt = 0
	for 1 != 0 {
		decode_parameters(tls, bp /* &sDec */, bp+13680 /* &sDecCtrl */, bp+13844 /* &TempQ[0] */, 0)

		*(*int32)(unsafe.Pointer((Silk_TOC + 16 /* &.vadFlags */) + uintptr((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnFramesDecoded)*4)) = (*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FvadFlag
		*(*int32)(unsafe.Pointer((Silk_TOC + 36 /* &.sigtypeFlags */) + uintptr((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnFramesDecoded)*4)) = (*decoder_control)(unsafe.Pointer(bp + 13680 /* &sDecCtrl */)).Fsigtype

		if (*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FsRC.Ferror != 0 {
			/* Corrupt stream */
			(*TOC_struct)(unsafe.Pointer(Silk_TOC)).Fcorrupt = 1
			break
		}

		if ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnBytesLeft > 0) && ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FFrameTermination == 1) {
			(*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnFramesDecoded++
		} else {
			break
		}
	}
	if (((*TOC_struct)(unsafe.Pointer(Silk_TOC)).Fcorrupt != 0) || ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FFrameTermination == 1)) || ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnFramesInPacket > 5) {
		/* Corrupt packet */
		libc.Xmemset(tls, Silk_TOC, 0, uint32(unsafe.Sizeof(TOC_struct{})))
		(*TOC_struct)(unsafe.Pointer(Silk_TOC)).Fcorrupt = 1
	} else {
		(*TOC_struct)(unsafe.Pointer(Silk_TOC)).FframesInPacket = ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FnFramesDecoded + 1)
		(*TOC_struct)(unsafe.Pointer(Silk_TOC)).Ffs_kHz = (*decoder_state)(unsafe.Pointer(bp /* &sDec */)).Ffs_kHz
		if (*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FFrameTermination == 0 {
			(*TOC_struct)(unsafe.Pointer(Silk_TOC)).FinbandLBRR = (*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FFrameTermination
		} else {
			(*TOC_struct)(unsafe.Pointer(Silk_TOC)).FinbandLBRR = ((*decoder_state)(unsafe.Pointer(bp /* &sDec */)).FFrameTermination - 1)
		}
	}
}

/**************************/
/* Get the version number */
/**************************/
/* Return a pointer to string specifying the version */
func SDK_get_version(tls *libc.TLS) uintptr { /* dec_API.c:275:12: */
	return uintptr(unsafe.Pointer(&version))
}

var version = *(*[6]int8)(unsafe.Pointer(ts /* "1.0.9" */)) /* dec_API.c:277:23 */

// 7.18.2  Limits of specified-width integer types

// 7.18.2.1  Limits of exact-width integer types

// 7.18.2.2  Limits of minimum-width integer types

// 7.18.2.3  Limits of fastest minimum-width integer types

// 7.18.2.4  Limits of integer types capable of holding
//     object pointers

// 7.18.2.5  Limits of greatest-width integer types

// 7.18.3  Limits of other integer types

// wint_t is unsigned short for compatibility with MS runtime

// 7.18.4  Macros for integer constants

// 7.18.4.1  Macros for minimum-width integer constants
//
//     Accoding to Douglas Gwyn <gwyn@arl.mil>:
// 	"This spec was changed in ISO/IEC 9899:1999 TC1; in ISO/IEC
// 	9899:1999 as initially published, the expansion was required
// 	to be an integer constant of precisely matching type, which
// 	is impossible to accomplish for the shorter types on most
// 	platforms, because C99 provides no standard way to designate
// 	an integer constant with width less than that of type int.
// 	TC1 changed this to require just an integer constant
// 	*expression* with *promoted* type."
//
// 	The trick used here is from Clive D W Feather.

//  The 'trick' doesn't work in C89 for long long because, without
//     suffix, (val) will be evaluated as int, not intmax_t

// 7.18.4.2  Macros for greatest-width integer constants

/* assertions */

/* Limits on bitrate */

/* Transition bitrates between modes */

/* Integration/hysteresis threshold for lowering internal sample frequency */
/* 30000000 -> 6 sec if bitrate is 5000 bps below limit; 3 sec if bitrate is 10000 bps below limit */

/* DTX settings                                 */

/* Amount of concecutive no FEC packets before telling JB */

/* Maximum delay between real packet and LBRR packet */

/* LBRR usage defines */

/* Frame termination indicator defines */

/* Number of Second order Sections for SWB detection HP filter */

/* Low complexity setting */

/* Activate bandwidth transition filtering for mode switching */

/* Decoder Parameters */

/* Maximum sampling frequency, should be 16 for some embedded platforms */

/* Signal Types used by silk */

/* VAD Types used by silk */

/* Number of samples per frame */

/* Milliseconds of lookahead for pitch analysis */

/* Length of LPC window used in find pitch */

/* Order of LPC used in find pitch */

/* Milliseconds of lookahead for noise shape analysis */

/* Max length of LPC window used in noise shape analysis */

/* Max number of bytes in payload output buffer (may contain multiple frames) */

/* dB level of lowest gain quantization level */
/* dB level of highest gain quantization level */
/* Number of gain quantization levels */
/* Max increase in gain quantization index */
/* Max decrease in gain quantization index */

/* Quantization offsets (multiples of 4) */

/* Maximum numbers of iterations used to stabilize a LPC vector */

/* Find Pred Coef defines */

/* LTP quantization settings */

/* Number of subframes */

/* Flag to use harmonic noise shaping */

/* Max LPC order of noise shaping filters */

/* Maximum number of delayed decision states */

/* number of subframes for excitation entropy coding */

/* number of rate levels, for entropy coding of excitation */

/* maximum sum of pulses per shell coding frame */

/***********************/
/* High pass filtering */
/***********************/

/***************************/
/* Voice activity detector */
/***************************/

/* Sigmoid settings */

/* smoothing for SNR measurement */

/******************/
/* NLSF quantizer */
/******************/

/* Based on above defines, calculate how much memory is necessary to allocate */

/* Transition filtering for mode switching */

/* Row based */

/* Column based */

/* BWE factors to apply after packet loss */

/* Defines for CN generation */

func detect_SWB_input(tls *libc.TLS, psSWBdetect uintptr, samplesIn uintptr, nSamplesIn int32) { /* detect_SWB_input.c:34:6: */
	bp := tls.Alloc(968)
	defer tls.Free(968)

	var HP_8_kHz_len int32
	var i int32
	// var shift int32 at bp+964, 4

	// var in_HP_8_kHz [480]int16 at bp, 960

	// var energy_32 int32 at bp+960, 4

	/* High pass filter with cutoff at 8 khz */
	HP_8_kHz_len = min_int(tls, nSamplesIn, (20 * 24))
	HP_8_kHz_len = max_int(tls, HP_8_kHz_len, 0)

	/* Cutoff around 9 khz */
	/* A = conv(conv([8192,14613, 6868], [8192,12883, 7337]), [8192,11586, 7911]); */
	/* B = conv(conv([575, -948, 575], [575, -221, 575]), [575, 104, 575]); */
	biquad(tls, samplesIn, (uintptr(unsafe.Pointer(&SWB_detect_B_HP_Q13))), (uintptr(unsafe.Pointer(&SWB_detect_A_HP_Q13))),
		(psSWBdetect /* &.S_HP_8_kHz */), bp /* &in_HP_8_kHz[0] */, HP_8_kHz_len)
	for i = 1; i < 3; i++ {
		biquad(tls, bp /* &in_HP_8_kHz[0] */, (uintptr(unsafe.Pointer(&SWB_detect_B_HP_Q13)) + uintptr(i)*6), (uintptr(unsafe.Pointer(&SWB_detect_A_HP_Q13)) + uintptr(i)*4),
			((psSWBdetect /* &.S_HP_8_kHz */) + uintptr(i)*8), bp /* &in_HP_8_kHz[0] */, HP_8_kHz_len)
	}

	/* Calculate energy in HP signal */
	sum_sqr_shift(tls, bp+960 /* &energy_32 */, bp+964 /* &shift */, bp /* &in_HP_8_kHz[0] */, HP_8_kHz_len)

	/* Count concecutive samples above threshold, after adjusting threshold for number of input samples and shift */
	if *(*int32)(unsafe.Pointer(bp + 960 /* energy_32 */)) > (((int32(int16(10))) * (int32(int16(HP_8_kHz_len)))) >> (*(*int32)(unsafe.Pointer(bp + 964 /* shift */)))) {
		*(*int32)(unsafe.Pointer(psSWBdetect + 24 /* &.ConsecSmplsAboveThres */)) += (nSamplesIn)
		if (*detect_SWB_state)(unsafe.Pointer(psSWBdetect)).FConsecSmplsAboveThres > (480 * 15) {
			(*detect_SWB_state)(unsafe.Pointer(psSWBdetect)).FSWB_detected = 1
		}
	} else {
		*(*int32)(unsafe.Pointer(psSWBdetect + 24 /* &.ConsecSmplsAboveThres */)) -= (nSamplesIn)
		(*detect_SWB_state)(unsafe.Pointer(psSWBdetect)).FConsecSmplsAboveThres = func() int32 {
			if ((*detect_SWB_state)(unsafe.Pointer(psSWBdetect)).FConsecSmplsAboveThres) > (0) {
				return (*detect_SWB_state)(unsafe.Pointer(psSWBdetect)).FConsecSmplsAboveThres
			}
			return 0
		}()
	}

	/* If sufficient speech activity and no SWB detected, we detect the signal as being WB */
	if ((*detect_SWB_state)(unsafe.Pointer(psSWBdetect)).FActiveSpeech_ms > 15000) && ((*detect_SWB_state)(unsafe.Pointer(psSWBdetect)).FSWB_detected == 0) {
		(*detect_SWB_state)(unsafe.Pointer(psSWBdetect)).FWB_detected = 1
	}
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*******************/
/* Pitch estimator */
/*******************/

/* Level of noise floor for whitening filter LPC analysis in pitch analysis */

/* Bandwidth expansion for whitening filter in pitch analysis */

/* Threshold used by pitch estimator for early escape */

/*********************/
/* Linear prediction */
/*********************/

/* LPC analysis defines: regularization and bandwidth expansion */

/* LTP analysis defines */

/* LTP quantization settings */

/***********************/
/* High pass filtering */
/***********************/

/* Smoothing parameters for low end of pitch frequency range estimation */

/* Min and max values for low end of pitch frequency range estimation */

/* Max absolute difference between log2 of pitch frequency and smoother state, to enter the smoother */

/***********/
/* Various */
/***********/

/* Required speech activity for counting frame as active */

/* Speech Activity LBRR enable threshold (needs tuning) */

/*************************/
/* Perceptual parameters */
/*************************/

/* reduction in coding SNR during low speech activity */

/* factor for reducing quantization noise during voiced speech */

/* factor for reducing quantization noise for unvoiced sparse signals */

/* threshold for sparseness measure above which to use lower quantization offset during unvoiced */

/* warping control */

/* fraction added to first autocorrelation value */

/* noise shaping filter chirp factor */

/* difference between chirp factors for analysis and synthesis noise shaping filters at low bitrates */

/* gain reduction for fricatives */

/* extra harmonic boosting (signal shaping) at low bitrates */

/* extra harmonic boosting (signal shaping) for noisy input signals */

/* harmonic noise shaping */

/* extra harmonic noise shaping for high bitrates or noisy input */

/* parameter for shaping noise towards higher frequencies */

/* parameter for shaping noise even more towards higher frequencies during voiced speech */

/* parameter for applying a high-pass tilt to the input signal */

/* parameter for extra high-pass tilt to the input signal at high rates */

/* parameter for reducing noise at the very low frequencies */

/* less reduction of noise at the very low frequencies for signals with low SNR at low frequencies */

/* noise floor to put a lower limit on the quantization step size */

/* noise floor relative to active speech gain level */

/* subframe smoothing coefficient for determining active speech gain level (lower -> more smoothing) */

/* subframe smoothing coefficient for HarmBoost, HarmShapeGain, Tilt (lower -> more smoothing) */

/* parameters defining the R/D tradeoff in the residual quantizer */

/****************/
/* Encode frame */
/****************/
func encode_frame_FIX(tls *libc.TLS, psEnc uintptr, pCode uintptr, pnBytesOut uintptr, pIn uintptr) int32 { /* encode_frame_FIX.c:34:9: */
	bp := tls.Alloc(5644)
	defer tls.Free(5644)

	// var sEncCtrl encoder_control_FIX at bp+2020, 672

	// var nBytes int32 at bp+5640, 4

	var ret int32 = 0
	var x_frame uintptr
	var res_pitch_frame uintptr
	// var xfw [480]int16 at bp+3652, 960

	// var pIn_HP [480]int16 at bp+2692, 960

	// var res_pitch [1008]int16 at bp, 2016

	var LBRR_idx int32
	var frame_terminator int32
	// var SNR_dB_Q7 int32 at bp+2016, 4

	var FrameTermination_CDF uintptr
	/* Low bitrate redundancy parameters */
	// var LBRRpayload [1024]uint8 at bp+4612, 1024

	// var nBytesLBRR int16 at bp+5636, 2

	(*encoder_control_FIX)(unsafe.Pointer(bp + 2020 /* &sEncCtrl */)).FsCmn.FSeed = (libc.PostIncInt32(&(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FframeCounter, 1) & 3)
	/**************************************************************/
	/* Setup Input Pointers, and insert frame in input buffer    */
	/*************************************************************/
	x_frame = ((psEnc + 20748 /* &.x_buf */) + uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)*2)  /* start of frame to encode */
	res_pitch_frame = (bp /* &res_pitch[0] */ + uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)*2) /* start of pitch LPC residual frame */

	/****************************/
	/* Voice Activity Detection */
	/****************************/
	ret = VAD_GetSA_Q8(tls, (psEnc /* &.sCmn */ + 15032 /* &.sVAD */), (psEnc + 22932 /* &.speech_activity_Q8 */), bp+2016, /* &SNR_dB_Q7 */
		bp+2020 /* &sEncCtrl */ +620 /* &.input_quality_bands_Q15 */, (bp + 2020 /* &sEncCtrl */ + 636 /* &.input_tilt_Q15 */),
		pIn, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)

	/*******************************************/
	/* High-pass filtering of the input signal */
	/*******************************************/
	/* Variable high-pass filter */
	HP_variable_cutoff_FIX(tls, psEnc, bp+2020 /* &sEncCtrl */, bp+2692 /* &pIn_HP[0] */, pIn)

	/* Ensure smooth bandwidth transitions */
	LP_variable_cutoff(tls, (psEnc /* &.sCmn */ + 15016 /* &.sLP */), (x_frame + uintptr((5*(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz))*2), bp+2692 /* &pIn_HP[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)

	/*****************************************/
	/* Find pitch lags, initial LPC analysis */
	/*****************************************/
	find_pitch_lags_FIX(tls, psEnc, bp+2020 /* &sEncCtrl */, bp /* &res_pitch[0] */, x_frame)

	/************************/
	/* Noise shape analysis */
	/************************/
	noise_shape_analysis_FIX(tls, psEnc, bp+2020 /* &sEncCtrl */, res_pitch_frame, x_frame)

	/*****************************************/
	/* Prefiltering for noise shaper         */
	/*****************************************/
	prefilter_FIX(tls, psEnc, bp+2020 /* &sEncCtrl */, bp+3652 /* &xfw[0] */, x_frame)

	/***************************************************/
	/* Find linear prediction coefficients (LPC + LTP) */
	/***************************************************/
	find_pred_coefs_FIX(tls, psEnc, bp+2020 /* &sEncCtrl */, bp /* &res_pitch[0] */)

	/****************************************/
	/* Process gains                        */
	/****************************************/
	process_gains_FIX(tls, psEnc, bp+2020 /* &sEncCtrl */)

	/****************************************/
	/* Low Bitrate Redundant Encoding       */
	/****************************************/
	*(*int16)(unsafe.Pointer(bp + 5636 /* nBytesLBRR */)) = int16(1024)
	LBRR_encode_FIX(tls, psEnc, bp+2020 /* &sEncCtrl */, bp+4612 /* &LBRRpayload[0] */, bp+5636 /* &nBytesLBRR */, bp+3652 /* &xfw[0] */)

	/*****************************************/
	/* Noise shaping quantization            */
	/*****************************************/
	if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnStatesDelayedDecision > 1) || ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fwarping_Q16 > 0) {
		NSQ_del_dec(tls, (psEnc /* &.sCmn */), (bp + 2020 /* &sEncCtrl */ /* &.sCmn */), (psEnc /* &.sCmn */ + 2088 /* &.sNSQ */), bp+3652, /* &xfw[0] */
			psEnc /* &.sCmn */ +18572 /* &.q */, (*encoder_control_FIX)(unsafe.Pointer(bp+2020 /* &sEncCtrl */)).FsCmn.FNLSFInterpCoef_Q2,
			(bp + 2020 /* &sEncCtrl */ + 144 /* &.PredCoef_Q12 */), bp+2020 /* &sEncCtrl */ +208 /* &.LTPCoef_Q14 */, bp+2020 /* &sEncCtrl */ +380 /* &.AR2_Q13 */, bp+2020 /* &sEncCtrl */ +572, /* &.HarmShapeGain_Q14 */
			bp+2020 /* &sEncCtrl */ +556 /* &.Tilt_Q14 */, bp+2020 /* &sEncCtrl */ +508 /* &.LF_shp_Q14 */, bp+2020 /* &sEncCtrl */ +128 /* &.Gains_Q16 */, (*encoder_control_FIX)(unsafe.Pointer(bp+2020 /* &sEncCtrl */)).FLambda_Q10,
			(*encoder_control_FIX)(unsafe.Pointer(bp+2020 /* &sEncCtrl */)).FLTP_scale_Q14)
	} else {
		NSQ(tls, (psEnc /* &.sCmn */), (bp + 2020 /* &sEncCtrl */ /* &.sCmn */), (psEnc /* &.sCmn */ + 2088 /* &.sNSQ */), bp+3652, /* &xfw[0] */
			psEnc /* &.sCmn */ +18572 /* &.q */, (*encoder_control_FIX)(unsafe.Pointer(bp+2020 /* &sEncCtrl */)).FsCmn.FNLSFInterpCoef_Q2,
			(bp + 2020 /* &sEncCtrl */ + 144 /* &.PredCoef_Q12 */), bp+2020 /* &sEncCtrl */ +208 /* &.LTPCoef_Q14 */, bp+2020 /* &sEncCtrl */ +380 /* &.AR2_Q13 */, bp+2020 /* &sEncCtrl */ +572, /* &.HarmShapeGain_Q14 */
			bp+2020 /* &sEncCtrl */ +556 /* &.Tilt_Q14 */, bp+2020 /* &sEncCtrl */ +508 /* &.LF_shp_Q14 */, bp+2020 /* &sEncCtrl */ +128 /* &.Gains_Q16 */, (*encoder_control_FIX)(unsafe.Pointer(bp+2020 /* &sEncCtrl */)).FLambda_Q10,
			(*encoder_control_FIX)(unsafe.Pointer(bp+2020 /* &sEncCtrl */)).FLTP_scale_Q14)
	}

	/**************************************************/
	/* Convert speech activity into VAD and DTX flags */
	/**************************************************/
	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8 < FIX_CONST(tls, 0.1, 8) {
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FvadFlag = 0
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnoSpeechCounter++
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnoSpeechCounter > 5 {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinDTX = 1
		}
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnoSpeechCounter > (20 + 5) {
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnoSpeechCounter = 5
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinDTX = 0
		}
	} else {
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnoSpeechCounter = 0
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinDTX = 0
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FvadFlag = 1
	}

	/****************************************/
	/* Initialize range coder               */
	/****************************************/
	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf == 0 {
		range_enc_init(tls, (psEnc /* &.sCmn */ /* &.sRC */))
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnBytesInPayloadBuf = 0
	}

	/****************************************/
	/* Encode Parameters                    */
	/****************************************/
	encode_parameters(tls, (psEnc /* &.sCmn */), (bp + 2020 /* &sEncCtrl */ /* &.sCmn */), (psEnc /* &.sCmn */ /* &.sRC */), psEnc /* &.sCmn */ +18572 /* &.q */)
	FrameTermination_CDF = uintptr(unsafe.Pointer(&FrameTermination_CDF))

	/****************************************/
	/* Update Buffers and State             */
	/****************************************/
	/* Update input buffer */
	libc.Xmemmove(tls, psEnc+20748 /* &.x_buf */, ((psEnc + 20748 /* &.x_buf */) + uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)*2), ((uint32((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length + (5 * (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz))) * uint32(unsafe.Sizeof(int16(0)))))

	/* Parameters needed for next frame */
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fprev_sigtype = (*encoder_control_FIX)(unsafe.Pointer(bp + 2020 /* &sEncCtrl */)).FsCmn.Fsigtype
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FprevLag = *(*int32)(unsafe.Pointer((bp + 2020 /* &sEncCtrl */ /* &.sCmn */ + 108 /* &.pitchL */) + 3*4))
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffirst_frame_after_reset = 0

	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsRC.Ferror != 0 {
		/* Encoder returned error: clear payload buffer */
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf = 0
	} else {
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf++
	}

	/****************************************/
	/* Finalize payload and copy to output  */
	/****************************************/
	if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf * 20) >= (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketSize_ms {

		LBRR_idx = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Foldest_LBRR_idx + 1) & 1)

		/* Check if FEC information should be added */
		frame_terminator = 0
		if (*LBRR_struct)(unsafe.Pointer((psEnc /* &.sCmn */ +16256 /* &.LBRR_buffer */)+uintptr(LBRR_idx)*1032)).Fusage == 1 {
			frame_terminator = 2
		}
		if (*LBRR_struct)(unsafe.Pointer((psEnc /* &.sCmn */ +16256 /* &.LBRR_buffer */)+uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Foldest_LBRR_idx)*1032)).Fusage == 2 {
			frame_terminator = 3
			LBRR_idx = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Foldest_LBRR_idx
		}

		/* Add the frame termination info to stream */
		range_encoder(tls, (psEnc /* &.sCmn */ /* &.sRC */), frame_terminator, FrameTermination_CDF)

		/* Payload length so far */
		range_coder_get_length(tls, (psEnc /* &.sCmn */ /* &.sRC */), bp+5640 /* &nBytes */)

		/* Check that there is enough space in external output buffer, and move data */
		if int32(*(*int16)(unsafe.Pointer(pnBytesOut))) >= *(*int32)(unsafe.Pointer(bp + 5640 /* nBytes */)) {
			range_enc_wrap_up(tls, (psEnc /* &.sCmn */ /* &.sRC */))
			libc.Xmemcpy(tls, pCode, psEnc /* &.sCmn */ /* &.sRC */ +20 /* &.buffer */, (uint32(*(*int32)(unsafe.Pointer(bp + 5640 /* nBytes */))) * uint32(unsafe.Sizeof(uint8(0)))))

			if (frame_terminator > 1) && (int32(*(*int16)(unsafe.Pointer(pnBytesOut))) >= (*(*int32)(unsafe.Pointer(bp + 5640 /* nBytes */)) + (*LBRR_struct)(unsafe.Pointer((psEnc /* &.sCmn */ +16256 /* &.LBRR_buffer */)+uintptr(LBRR_idx)*1032)).FnBytes)) {
				/* Get old packet and add to payload. */
				libc.Xmemcpy(tls, (pCode + uintptr(*(*int32)(unsafe.Pointer(bp + 5640 /* nBytes */)))), (psEnc /* &.sCmn */ +16256 /* &.LBRR_buffer */)+uintptr(LBRR_idx)*1032 /* &.payload */, (uint32((*LBRR_struct)(unsafe.Pointer((psEnc /* &.sCmn */ +16256 /* &.LBRR_buffer */)+uintptr(LBRR_idx)*1032)).FnBytes) * uint32(unsafe.Sizeof(uint8(0)))))
				*(*int32)(unsafe.Pointer(bp + 5640 /* nBytes */)) += (*LBRR_struct)(unsafe.Pointer((psEnc /* &.sCmn */ + 16256 /* &.LBRR_buffer */) + uintptr(LBRR_idx)*1032)).FnBytes
			}

			*(*int16)(unsafe.Pointer(pnBytesOut)) = int16(*(*int32)(unsafe.Pointer(bp + 5640 /* nBytes */)))

			/* Update FEC buffer */
			libc.Xmemcpy(tls, (psEnc /* &.sCmn */ +16256 /* &.LBRR_buffer */)+uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Foldest_LBRR_idx)*1032 /* &.payload */, bp+4612 /* &LBRRpayload[0] */, (uint32(*(*int16)(unsafe.Pointer(bp + 5636 /* nBytesLBRR */))) * uint32(unsafe.Sizeof(uint8(0)))))
			(*LBRR_struct)(unsafe.Pointer((psEnc /* &.sCmn */ + 16256 /* &.LBRR_buffer */) + uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Foldest_LBRR_idx)*1032)).FnBytes = int32(*(*int16)(unsafe.Pointer(bp + 5636 /* nBytesLBRR */)))
			/* The line below describes how FEC should be used */
			(*LBRR_struct)(unsafe.Pointer((psEnc /* &.sCmn */ + 16256 /* &.LBRR_buffer */) + uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Foldest_LBRR_idx)*1032)).Fusage = (*encoder_control_FIX)(unsafe.Pointer(bp + 2020 /* &sEncCtrl */)).FsCmn.FLBRR_usage
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Foldest_LBRR_idx = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Foldest_LBRR_idx + 1) & 1)

		} else {
			/* Not enough space: Payload will be discarded */
			*(*int16)(unsafe.Pointer(pnBytesOut)) = int16(0)
			*(*int32)(unsafe.Pointer(bp + 5640 /* nBytes */)) = 0
			ret = -4
		}

		/* Reset the number of frames in payload buffer */
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf = 0
	} else {
		/* No payload this time */
		*(*int16)(unsafe.Pointer(pnBytesOut)) = int16(0)

		/* Encode that more frames follows */
		frame_terminator = 1
		range_encoder(tls, (psEnc /* &.sCmn */ /* &.sRC */), frame_terminator, FrameTermination_CDF)

		/* Payload length so far */
		range_coder_get_length(tls, (psEnc /* &.sCmn */ /* &.sRC */), bp+5640 /* &nBytes */)

	}

	/* Check for arithmetic coder errors */
	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsRC.Ferror != 0 {
		ret = -9
	}

	/* Simulate number of ms buffered in channel because of exceeding TargetRate */

	*(*int32)(unsafe.Pointer(psEnc + 22928 /* &.BufferedInChannel_ms */)) += (((8 * 1000) * (*(*int32)(unsafe.Pointer(bp + 5640 /* nBytes */)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnBytesInPayloadBuf)) / ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FTargetRate_bps))
	*(*int32)(unsafe.Pointer(psEnc + 22928 /* &.BufferedInChannel_ms */)) -= (20)
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FBufferedInChannel_ms = func() int32 {
		if (0) > (100) {
			return func() int32 {
				if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FBufferedInChannel_ms) > (0) {
					return 0
				}
				return func() int32 {
					if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FBufferedInChannel_ms) < (100) {
						return 100
					}
					return (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FBufferedInChannel_ms
				}()
			}()
		}
		return func() int32 {
			if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FBufferedInChannel_ms) > (100) {
				return 100
			}
			return func() int32 {
				if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FBufferedInChannel_ms) < (0) {
					return 0
				}
				return (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FBufferedInChannel_ms
			}()
		}()
	}()
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnBytesInPayloadBuf = *(*int32)(unsafe.Pointer(bp + 5640 /* nBytes */))

	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8 > FIX_CONST(tls, 0.7, 8) {
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsSWBdetect.FActiveSpeech_ms = func() int32 {
			if ((uint32(((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsSWBdetect.FActiveSpeech_ms) + (20))) & 0x80000000) != 0 {
				return 0x7FFFFFFF
			}
			return (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsSWBdetect.FActiveSpeech_ms) + (20))
		}()
	}

	return ret
}

/* Low BitRate Redundancy encoding functionality. Reuse all parameters but encode residual with lower bitrate */
func LBRR_encode_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrl uintptr, pCode uintptr, pnBytesOut uintptr, xfw uintptr) { /* encode_frame_FIX.c:279:6: */
	bp := tls.Alloc(36)
	defer tls.Free(36)

	// var TempGainsIndices [4]int32 at bp, 16

	var frame_terminator int32
	// var nBytes int32 at bp+32, 4

	var nFramesInPayloadBuf int32
	// var TempGains_Q16 [4]int32 at bp+16, 16

	var typeOffset int32
	var LTP_scaleIndex int32
	var Rate_only_parameters int32 = 0
	/*******************************************/
	/* Control use of inband LBRR              */
	/*******************************************/
	LBRR_ctrl_FIX(tls, psEnc, (psEncCtrl /* &.sCmn */))

	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRR_enabled != 0 {
		/* Save original gains */
		libc.Xmemcpy(tls, bp /* &TempGainsIndices[0] */, psEncCtrl /* &.sCmn */ +72 /* &.GainsIndices */, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))
		libc.Xmemcpy(tls, bp+16 /* &TempGains_Q16[0] */, psEncCtrl+128 /* &.Gains_Q16 */, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))

		typeOffset = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FtypeOffsetPrev // Temp save as cannot be overwritten
		LTP_scaleIndex = (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FLTP_scaleIndex

		/* Set max rate where quant signal is encoded */
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 8 {
			Rate_only_parameters = 13500
		} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 12 {
			Rate_only_parameters = 15500
		} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 16 {
			Rate_only_parameters = 17500
		} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 24 {
			Rate_only_parameters = 19500
		} else {

		}

		if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FComplexity > 0) && ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FTargetRate_bps > Rate_only_parameters) {
			if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf == 0 {
				/* First frame in packet; copy everything */
				libc.Xmemcpy(tls, (psEnc /* &.sCmn */ + 8548 /* &.sNSQ_LBRR */), (psEnc /* &.sCmn */ + 2088 /* &.sNSQ */), uint32(unsafe.Sizeof(nsq_state{})))

				(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRRprevLastGainIndex = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsShape.FLastGainIndex
				/* Increase Gains to get target LBRR rate */
				*(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 72 /* &.GainsIndices */))) = (*(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 72 /* &.GainsIndices */))) + (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLBRR_GainIncreases)
				*(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 72 /* &.GainsIndices */))) = func() int32 {
					if (0) > (64 - 1) {
						return func() int32 {
							if (*(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 72 /* &.GainsIndices */)))) > (0) {
								return 0
							}
							return func() int32 {
								if (*(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 72 /* &.GainsIndices */)))) < (64 - 1) {
									return (64 - 1)
								}
								return *(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 72 /* &.GainsIndices */)))
							}()
						}()
					}
					return func() int32 {
						if (*(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 72 /* &.GainsIndices */)))) > (64 - 1) {
							return (64 - 1)
						}
						return func() int32 {
							if (*(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 72 /* &.GainsIndices */)))) < (0) {
								return 0
							}
							return *(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 72 /* &.GainsIndices */)))
						}()
					}()
				}()
			}
			/* Decode to get gains in sync with decoder         */
			/* Overwrite unquantized gains with quantized gains */
			gains_dequant(tls, psEncCtrl+128 /* &.Gains_Q16 */, psEncCtrl /* &.sCmn */ +72, /* &.GainsIndices */
				(psEnc /* &.sCmn */ + 15144 /* &.LBRRprevLastGainIndex */), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf)

			/*****************************************/
			/* Noise shaping quantization            */
			/*****************************************/
			if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnStatesDelayedDecision > 1) || ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fwarping_Q16 > 0) {
				NSQ_del_dec(tls, (psEnc /* &.sCmn */), (psEncCtrl /* &.sCmn */), (psEnc /* &.sCmn */ + 8548 /* &.sNSQ_LBRR */), xfw, psEnc /* &.sCmn */ +19052, /* &.q_LBRR */
					(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FNLSFInterpCoef_Q2, (psEncCtrl + 144 /* &.PredCoef_Q12 */), psEncCtrl+208, /* &.LTPCoef_Q14 */
					psEncCtrl+380 /* &.AR2_Q13 */, psEncCtrl+572 /* &.HarmShapeGain_Q14 */, psEncCtrl+556 /* &.Tilt_Q14 */, psEncCtrl+508, /* &.LF_shp_Q14 */
					psEncCtrl+128 /* &.Gains_Q16 */, (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLambda_Q10, (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTP_scale_Q14)
			} else {
				NSQ(tls, (psEnc /* &.sCmn */), (psEncCtrl /* &.sCmn */), (psEnc /* &.sCmn */ + 8548 /* &.sNSQ_LBRR */), xfw, psEnc /* &.sCmn */ +19052, /* &.q_LBRR */
					(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FNLSFInterpCoef_Q2, (psEncCtrl + 144 /* &.PredCoef_Q12 */), psEncCtrl+208, /* &.LTPCoef_Q14 */
					psEncCtrl+380 /* &.AR2_Q13 */, psEncCtrl+572 /* &.HarmShapeGain_Q14 */, psEncCtrl+556 /* &.Tilt_Q14 */, psEncCtrl+508, /* &.LF_shp_Q14 */
					psEncCtrl+128 /* &.Gains_Q16 */, (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLambda_Q10, (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTP_scale_Q14)
			}
		} else {
			libc.Xmemset(tls, psEnc /* &.sCmn */ +19052 /* &.q_LBRR */, 0, (uint32((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length) * uint32(unsafe.Sizeof(int8(0)))))
			(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FLTP_scaleIndex = 0
		}
		/****************************************/
		/* Initialize arithmetic coder          */
		/****************************************/
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf == 0 {
			range_enc_init(tls, (psEnc /* &.sCmn */ + 1044 /* &.sRC_LBRR */))
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnBytesInPayloadBuf = 0
		}

		/****************************************/
		/* Encode Parameters                    */
		/****************************************/
		encode_parameters(tls, (psEnc /* &.sCmn */), (psEncCtrl /* &.sCmn */),
			(psEnc /* &.sCmn */ + 1044 /* &.sRC_LBRR */), psEnc /* &.sCmn */ +19052 /* &.q_LBRR */)

		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsRC_LBRR.Ferror != 0 {
			/* Encoder returned error: clear payload buffer */
			nFramesInPayloadBuf = 0
		} else {
			nFramesInPayloadBuf = ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf + 1)
		}

		/****************************************/
		/* Finalize payload and copy to output  */
		/****************************************/
		if ((int32(int16(nFramesInPayloadBuf))) * (int32(int16(20)))) >= (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketSize_ms {

			/* Check if FEC information should be added */
			frame_terminator = 0

			/* Add the frame termination info to stream */
			range_encoder(tls, (psEnc /* &.sCmn */ + 1044 /* &.sRC_LBRR */), frame_terminator, uintptr(unsafe.Pointer(&FrameTermination_CDF)))

			/* Payload length so far */
			range_coder_get_length(tls, (psEnc /* &.sCmn */ + 1044 /* &.sRC_LBRR */), bp+32 /* &nBytes */)

			/* Check that there is enough space in external output buffer and move data */
			if int32(*(*int16)(unsafe.Pointer(pnBytesOut))) >= *(*int32)(unsafe.Pointer(bp + 32 /* nBytes */)) {
				range_enc_wrap_up(tls, (psEnc /* &.sCmn */ + 1044 /* &.sRC_LBRR */))
				libc.Xmemcpy(tls, pCode, psEnc /* &.sCmn */ +1044 /* &.sRC_LBRR */ +20 /* &.buffer */, (uint32(*(*int32)(unsafe.Pointer(bp + 32 /* nBytes */))) * uint32(unsafe.Sizeof(uint8(0)))))

				*(*int16)(unsafe.Pointer(pnBytesOut)) = int16(*(*int32)(unsafe.Pointer(bp + 32 /* nBytes */)))
			} else {
				/* Not enough space: payload will be discarded */
				*(*int16)(unsafe.Pointer(pnBytesOut)) = int16(0)

			}
		} else {
			/* No payload this time */
			*(*int16)(unsafe.Pointer(pnBytesOut)) = int16(0)

			/* Encode that more frames follows */
			frame_terminator = 1
			range_encoder(tls, (psEnc /* &.sCmn */ + 1044 /* &.sRC_LBRR */), frame_terminator, uintptr(unsafe.Pointer(&FrameTermination_CDF)))
		}

		/* Restore original Gains */
		libc.Xmemcpy(tls, psEncCtrl /* &.sCmn */ +72 /* &.GainsIndices */, bp /* &TempGainsIndices[0] */, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))
		libc.Xmemcpy(tls, psEncCtrl+128 /* &.Gains_Q16 */, bp+16 /* &TempGains_Q16[0] */, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))

		/* Restore LTP scale index and typeoffset */
		(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FLTP_scaleIndex = LTP_scaleIndex
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FtypeOffsetPrev = typeOffset
	}
}

/*******************************************/
/* Encode parameters to create the payload */
/*******************************************/
func encode_parameters(tls *libc.TLS, psEncC uintptr, psEncCtrlC uintptr, psRC uintptr, q uintptr) { /* encode_parameters.c:33:6: */
	var i int32
	var k int32
	var typeOffset int32
	var psNLSF_CB uintptr

	/************************/
	/* Encode sampling rate */
	/************************/
	/* only done for first frame in packet */
	if (*encoder_state)(unsafe.Pointer(psEncC)).FnFramesInPayloadBuf == 0 {
		/* get sampling rate index */
		for i = 0; i < 3; i++ {
			if SamplingRates_table[i] == (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz {
				break
			}
		}
		range_encoder(tls, psRC, i, uintptr(unsafe.Pointer(&SamplingRates_CDF)))
	}

	/*******************************************/
	/* Encode signal type and quantizer offset */
	/*******************************************/
	typeOffset = ((2 * (*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype) + (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FQuantOffsetType)
	if (*encoder_state)(unsafe.Pointer(psEncC)).FnFramesInPayloadBuf == 0 {
		/* first frame in packet: independent coding */
		range_encoder(tls, psRC, typeOffset, uintptr(unsafe.Pointer(&type_offset_CDF)))
	} else {
		/* condidtional coding */
		range_encoder(tls, psRC, typeOffset, (uintptr(unsafe.Pointer(&type_offset_joint_CDF)) + uintptr((*encoder_state)(unsafe.Pointer(psEncC)).FtypeOffsetPrev)*10))
	}
	(*encoder_state)(unsafe.Pointer(psEncC)).FtypeOffsetPrev = typeOffset

	/****************/
	/* Encode gains */
	/****************/
	/* first subframe */
	if (*encoder_state)(unsafe.Pointer(psEncC)).FnFramesInPayloadBuf == 0 {
		/* first frame in packet: independent coding */
		range_encoder(tls, psRC, *(*int32)(unsafe.Pointer((psEncCtrlC + 72 /* &.GainsIndices */))), (uintptr(unsafe.Pointer(&gain_CDF)) + uintptr((*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype)*130))
	} else {
		/* condidtional coding */
		range_encoder(tls, psRC, *(*int32)(unsafe.Pointer((psEncCtrlC + 72 /* &.GainsIndices */))), uintptr(unsafe.Pointer(&delta_gain_CDF)))
	}

	/* remaining subframes */
	for i = 1; i < 4; i++ {
		range_encoder(tls, psRC, *(*int32)(unsafe.Pointer((psEncCtrlC + 72 /* &.GainsIndices */) + uintptr(i)*4)), uintptr(unsafe.Pointer(&delta_gain_CDF)))
	}

	/****************/
	/* Encode NLSFs */
	/****************/
	/* Range encoding of the NLSF path */
	psNLSF_CB = *(*uintptr)(unsafe.Pointer((psEncC + 16248 /* &.psNLSF_CB */) + uintptr((*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype)*4))
	range_encoder_multi(tls, psRC, psEncCtrlC+28 /* &.NLSFIndices */, (*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FStartPtr, (*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages)

	/* Encode NLSF interpolation factor */

	range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FNLSFInterpCoef_Q2, uintptr(unsafe.Pointer(&NLSF_interpolation_factor_CDF)))

	if (*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype == 0 {
		/*********************/
		/* Encode pitch lags */
		/*********************/

		/* lag index */
		if (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 8 {
			range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FlagIndex, uintptr(unsafe.Pointer(&pitch_lag_NB_CDF)))
		} else if (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 12 {
			range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FlagIndex, uintptr(unsafe.Pointer(&pitch_lag_MB_CDF)))
		} else if (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 16 {
			range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FlagIndex, uintptr(unsafe.Pointer(&pitch_lag_WB_CDF)))
		} else {
			range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FlagIndex, uintptr(unsafe.Pointer(&pitch_lag_SWB_CDF)))
		}

		/* countour index */
		if (*encoder_state)(unsafe.Pointer(psEncC)).Ffs_kHz == 8 {
			/* Less codevectors used in 8 khz mode */
			range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FcontourIndex, uintptr(unsafe.Pointer(&pitch_contour_NB_CDF)))
		} else {
			/* Joint for 12, 16, 24 khz */
			range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FcontourIndex, uintptr(unsafe.Pointer(&pitch_contour_CDF)))
		}

		/********************/
		/* Encode LTP gains */
		/********************/

		/* PERIndex value */
		range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FPERIndex, uintptr(unsafe.Pointer(&LTP_per_index_CDF)))

		/* Codebook Indices */
		for k = 0; k < 4; k++ {
			range_encoder(tls, psRC, *(*int32)(unsafe.Pointer((psEncCtrlC + 12 /* &.LTPIndex */) + uintptr(k)*4)), LTP_gain_CDF_ptrs[(*encoder_control)(unsafe.Pointer(psEncCtrlC)).FPERIndex])
		}

		/**********************/
		/* Encode LTP scaling */
		/**********************/
		range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FLTP_scaleIndex, uintptr(unsafe.Pointer(&LTPscale_CDF)))
	}

	/***************/
	/* Encode seed */
	/***************/
	range_encoder(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FSeed, uintptr(unsafe.Pointer(&Seed_CDF)))

	/*********************************************/
	/* Encode quantization indices of excitation */
	/*********************************************/
	encode_pulses(tls, psRC, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FQuantOffsetType, q, (*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length)

	/*********************************************/
	/* Encode VAD flag                           */
	/*********************************************/
	range_encoder(tls, psRC, (*encoder_state)(unsafe.Pointer(psEncC)).FvadFlag, uintptr(unsafe.Pointer(&vadflag_CDF)))
}

/*********************************************/
/* Encode quantization indices of excitation */
/*********************************************/

func combine_and_check(tls *libc.TLS, pulses_comb uintptr, pulses_in uintptr, max_pulses int32, len int32) int32 { /* encode_pulses.c:34:20: */
	var k int32
	var sum int32

	for k = 0; k < len; k++ {
		sum = (*(*int32)(unsafe.Pointer(pulses_in + uintptr((2*k))*4)) + *(*int32)(unsafe.Pointer(pulses_in + uintptr(((2*k)+1))*4)))
		if sum > max_pulses {
			return 1
		}
		*(*int32)(unsafe.Pointer(pulses_comb + uintptr(k)*4)) = sum
	}

	return 0
}

/* Encode quantization indices of excitation */
func encode_pulses(tls *libc.TLS, psRC uintptr, sigtype int32, QuantOffsetType int32, q uintptr, frame_length int32) { /* encode_pulses.c:55:6: */
	bp := tls.Alloc(2192)
	defer tls.Free(2192)

	var i int32
	var k int32
	var j int32
	var iter int32
	var bit int32
	var nLS int32
	var scale_down int32
	var RateLevelIndex int32 = 0
	var abs_q int32
	var minSumBits_Q6 int32
	var sumBits_Q6 int32
	// var abs_pulses [480]int32 at bp+32, 1920

	// var sum_pulses [30]int32 at bp+2072, 120

	// var nRshifts [30]int32 at bp+1952, 120

	// var pulses_comb [8]int32 at bp, 32

	var abs_pulses_ptr uintptr
	var pulses_ptr uintptr
	var cdf_ptr uintptr
	var nBits_ptr uintptr

	libc.Xmemset(tls, bp /* &pulses_comb[0] */, 0, (uint32(8) * uint32(unsafe.Sizeof(int32(0))))) // Fixing Valgrind reported problem

	/****************************/
	/* Prepare for shell coding */
	/****************************/
	/* Calculate number of shell blocks */
	iter = (frame_length / 16)

	/* Take the absolute value of the pulses */
	for i = 0; i < frame_length; i = i + (4) {
		*(*int32)(unsafe.Pointer(bp + 32 /* &abs_pulses[0] */ + uintptr((i+0))*4)) = func() int32 {
			if (int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 0)))))) > 0 {
				return int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 0)))))
			}
			return -int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 0)))))
		}()
		*(*int32)(unsafe.Pointer(bp + 32 /* &abs_pulses[0] */ + uintptr((i+1))*4)) = func() int32 {
			if (int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 1)))))) > 0 {
				return int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 1)))))
			}
			return -int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 1)))))
		}()
		*(*int32)(unsafe.Pointer(bp + 32 /* &abs_pulses[0] */ + uintptr((i+2))*4)) = func() int32 {
			if (int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 2)))))) > 0 {
				return int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 2)))))
			}
			return -int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 2)))))
		}()
		*(*int32)(unsafe.Pointer(bp + 32 /* &abs_pulses[0] */ + uintptr((i+3))*4)) = func() int32 {
			if (int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 3)))))) > 0 {
				return int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 3)))))
			}
			return -int32(*(*int8)(unsafe.Pointer(q + uintptr((i + 3)))))
		}()
	}

	/* Calc sum pulses per shell code frame */
	abs_pulses_ptr = bp + 32 /* &abs_pulses[0] */
	for i = 0; i < iter; i++ {
		*(*int32)(unsafe.Pointer(bp + 1952 /* &nRshifts[0] */ + uintptr(i)*4)) = 0

		for 1 != 0 {
			/* 1+1 -> 2 */
			scale_down = combine_and_check(tls, bp /* &pulses_comb[0] */, abs_pulses_ptr, max_pulses_table[0], 8)

			/* 2+2 -> 4 */
			scale_down = scale_down + (combine_and_check(tls, bp /* &pulses_comb[0] */, bp /* &pulses_comb[0] */, max_pulses_table[1], 4))

			/* 4+4 -> 8 */
			scale_down = scale_down + (combine_and_check(tls, bp /* &pulses_comb[0] */, bp /* &pulses_comb[0] */, max_pulses_table[2], 2))

			/* 8+8 -> 16 */
			*(*int32)(unsafe.Pointer(bp + 2072 /* &sum_pulses[0] */ + uintptr(i)*4)) = (*(*int32)(unsafe.Pointer(bp /* &pulses_comb[0] */)) + *(*int32)(unsafe.Pointer(bp /* &pulses_comb[0] */ + 1*4)))
			if *(*int32)(unsafe.Pointer(bp + 2072 /* &sum_pulses[0] */ + uintptr(i)*4)) > max_pulses_table[3] {
				scale_down++
			}

			if scale_down != 0 {
				/* We need to down scale the quantization signal */
				*(*int32)(unsafe.Pointer(bp + 1952 /* &nRshifts[0] */ + uintptr(i)*4))++
				for k = 0; k < 16; k++ {
					*(*int32)(unsafe.Pointer(abs_pulses_ptr + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer(abs_pulses_ptr + uintptr(k)*4))) >> (1))
				}
			} else {
				/* Jump out of while(1) loop and go to next shell coding frame */
				break
			}
		}
		abs_pulses_ptr += 4 * (uintptr(16))
	}

	/**************/
	/* Rate level */
	/**************/
	/* find rate level that leads to fewest bits for coding of pulses per block info */
	minSumBits_Q6 = 0x7FFFFFFF
	for k = 0; k < (10 - 1); k++ {
		nBits_ptr = (uintptr(unsafe.Pointer(&pulses_per_block_BITS_Q6)) + uintptr(k)*40)
		sumBits_Q6 = int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&rate_levels_BITS_Q6)) + uintptr(sigtype)*18) + uintptr(k)*2)))
		for i = 0; i < iter; i++ {
			if *(*int32)(unsafe.Pointer(bp + 1952 /* &nRshifts[0] */ + uintptr(i)*4)) > 0 {
				sumBits_Q6 = sumBits_Q6 + (int32(*(*int16)(unsafe.Pointer(nBits_ptr + 19*2))))
			} else {
				sumBits_Q6 = sumBits_Q6 + (int32(*(*int16)(unsafe.Pointer(nBits_ptr + uintptr(*(*int32)(unsafe.Pointer(bp + 2072 /* &sum_pulses[0] */ + uintptr(i)*4)))*2))))
			}
		}
		if sumBits_Q6 < minSumBits_Q6 {
			minSumBits_Q6 = sumBits_Q6
			RateLevelIndex = k
		}
	}
	range_encoder(tls, psRC, RateLevelIndex, (uintptr(unsafe.Pointer(&rate_levels_CDF)) + uintptr(sigtype)*20))

	/***************************************************/
	/* Sum-Weighted-Pulses Encoding                    */
	/***************************************************/
	cdf_ptr = (uintptr(unsafe.Pointer(&pulses_per_block_CDF)) + uintptr(RateLevelIndex)*42)
	for i = 0; i < iter; i++ {
		if *(*int32)(unsafe.Pointer(bp + 1952 /* &nRshifts[0] */ + uintptr(i)*4)) == 0 {
			range_encoder(tls, psRC, *(*int32)(unsafe.Pointer(bp + 2072 /* &sum_pulses[0] */ + uintptr(i)*4)), cdf_ptr)
		} else {
			range_encoder(tls, psRC, (18 + 1), cdf_ptr)
			for k = 0; k < (*(*int32)(unsafe.Pointer(bp + 1952 /* &nRshifts[0] */ + uintptr(i)*4)) - 1); k++ {
				range_encoder(tls, psRC, (18 + 1), (uintptr(unsafe.Pointer(&pulses_per_block_CDF)) + 9*42))
			}
			range_encoder(tls, psRC, *(*int32)(unsafe.Pointer(bp + 2072 /* &sum_pulses[0] */ + uintptr(i)*4)), (uintptr(unsafe.Pointer(&pulses_per_block_CDF)) + 9*42))
		}
	}

	/******************/
	/* Shell Encoding */
	/******************/
	for i = 0; i < iter; i++ {
		if *(*int32)(unsafe.Pointer(bp + 2072 /* &sum_pulses[0] */ + uintptr(i)*4)) > 0 {
			shell_encoder(tls, psRC, (bp + 32 /* &abs_pulses */ + uintptr((i*16))*4))
		}
	}

	/****************/
	/* LSB Encoding */
	/****************/
	for i = 0; i < iter; i++ {
		if *(*int32)(unsafe.Pointer(bp + 1952 /* &nRshifts[0] */ + uintptr(i)*4)) > 0 {
			pulses_ptr = (q + uintptr((i * 16)))
			nLS = (*(*int32)(unsafe.Pointer(bp + 1952 /* &nRshifts[0] */ + uintptr(i)*4)) - 1)
			for k = 0; k < 16; k++ {
				abs_q = int32(func() int8 {
					if (int32(*(*int8)(unsafe.Pointer(pulses_ptr + uintptr(k))))) > 0 {
						return *(*int8)(unsafe.Pointer(pulses_ptr + uintptr(k)))
					}
					return int8(-int32(*(*int8)(unsafe.Pointer(pulses_ptr + uintptr(k)))))
				}())
				for j = nLS; j > 0; j-- {
					bit = (((abs_q) >> (j)) & 1)
					range_encoder(tls, psRC, bit, uintptr(unsafe.Pointer(&lsb_CDF)))
				}
				bit = (abs_q & 1)
				range_encoder(tls, psRC, bit, uintptr(unsafe.Pointer(&lsb_CDF)))
			}
		}
	}

	/****************/
	/* Encode signs */
	/****************/
	encode_signs(tls, psRC, q, frame_length, sigtype, QuantOffsetType, RateLevelIndex)
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/****************************************/
/* Encoder functions                    */
/****************************************/

func SDK_Get_Encoder_Size(tls *libc.TLS, encSizeBytes uintptr) int32 { /* enc_API.c:41:9: */
	var ret int32 = 0

	*(*int32)(unsafe.Pointer(encSizeBytes)) = int32(unsafe.Sizeof(encoder_state_FIX{}))

	return ret
}

/***************************************/
/* Read control structure from encoder */
/***************************************/
func SDK_QueryEncoder(tls *libc.TLS, encState uintptr, encStatus uintptr) int32 { /* enc_API.c:54:9: */
	var psEnc uintptr
	var ret int32 = 0

	psEnc = encState

	(*SDK_EncControlStruct)(unsafe.Pointer(encStatus)).FAPI_sampleRate = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz
	(*SDK_EncControlStruct)(unsafe.Pointer(encStatus)).FmaxInternalSampleRate = ((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FmaxInternal_fs_kHz))) * (int32(int16(1000))))
	(*SDK_EncControlStruct)(unsafe.Pointer(encStatus)).FpacketSize = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz * (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketSize_ms) / (1000)) /* convert samples -> ms */
	(*SDK_EncControlStruct)(unsafe.Pointer(encStatus)).FbitRate = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FTargetRate_bps
	(*SDK_EncControlStruct)(unsafe.Pointer(encStatus)).FpacketLossPercentage = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketLoss_perc
	(*SDK_EncControlStruct)(unsafe.Pointer(encStatus)).Fcomplexity = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FComplexity
	(*SDK_EncControlStruct)(unsafe.Pointer(encStatus)).FuseInBandFEC = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseInBandFEC
	(*SDK_EncControlStruct)(unsafe.Pointer(encStatus)).FuseDTX = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseDTX
	return ret
}

/*************************/
/* Init or Reset encoder */
/*************************/
func SDK_InitEncoder(tls *libc.TLS, encState uintptr, encStatus uintptr) int32 { /* enc_API.c:78:9: */
	var psEnc uintptr
	var ret int32 = 0

	psEnc = encState

	/* Reset Encoder */
	if libc.AssignAddInt32(&ret, init_encoder_FIX(tls, psEnc)) != 0 {

	}

	/* Read control structure */
	if libc.AssignAddInt32(&ret, SDK_QueryEncoder(tls, encState, encStatus)) != 0 {

	}

	return ret
}

/**************************/
/* Encode frame with Silk */
/**************************/
func SDK_Encode(tls *libc.TLS, encState uintptr, encControl uintptr, samplesIn uintptr, nSamplesIn int32, outData uintptr, nBytesOut uintptr) int32 { /* enc_API.c:106:9: */
	bp := tls.Alloc(2)
	defer tls.Free(2)

	var max_internal_fs_kHz int32
	var PacketSize_ms int32
	var PacketLoss_perc int32
	var UseInBandFEC int32
	var UseDTX int32
	var ret int32 = 0
	var nSamplesToBuffer int32
	var Complexity int32
	var input_10ms int32
	var nSamplesFromInput int32 = 0
	var TargetRate_bps int32
	var API_fs_Hz int32
	// var MaxBytesOut int16 at bp, 2

	var psEnc uintptr = encState

	/* Check sampling frequency first, to avoid divide by zero later */
	if ((((((((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FAPI_sampleRate != 8000) && ((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FAPI_sampleRate != 12000)) && ((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FAPI_sampleRate != 16000)) && ((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FAPI_sampleRate != 24000)) && ((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FAPI_sampleRate != 32000)) && ((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FAPI_sampleRate != 44100)) && ((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FAPI_sampleRate != 48000)) || (((((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FmaxInternalSampleRate != 8000) && ((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FmaxInternalSampleRate != 12000)) && ((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FmaxInternalSampleRate != 16000)) && ((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FmaxInternalSampleRate != 24000)) {
		ret = -2

		return ret
	}

	/* Set encoder parameters from control structure */
	API_fs_Hz = (*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FAPI_sampleRate
	max_internal_fs_kHz = (((*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FmaxInternalSampleRate >> 10) + 1) /* convert Hz -> kHz */
	PacketSize_ms = ((1000 * (*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FpacketSize) / (API_fs_Hz))
	TargetRate_bps = (*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FbitRate
	PacketLoss_perc = (*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FpacketLossPercentage
	UseInBandFEC = (*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FuseInBandFEC
	Complexity = (*SDK_EncControlStruct)(unsafe.Pointer(encControl)).Fcomplexity
	UseDTX = (*SDK_EncControlStruct)(unsafe.Pointer(encControl)).FuseDTX

	/* Save values in state */
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FAPI_fs_Hz = API_fs_Hz
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FmaxInternal_fs_kHz = max_internal_fs_kHz
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseInBandFEC = UseInBandFEC

	/* Only accept input lengths that are a multiple of 10 ms */
	input_10ms = ((100 * nSamplesIn) / (API_fs_Hz))
	if ((input_10ms * API_fs_Hz) != (100 * nSamplesIn)) || (nSamplesIn < 0) {
		ret = -1

		return ret
	}

	TargetRate_bps = func() int32 {
		if (5000) > (100000) {
			return func() int32 {
				if (TargetRate_bps) > (5000) {
					return 5000
				}
				return func() int32 {
					if (TargetRate_bps) < (100000) {
						return 100000
					}
					return TargetRate_bps
				}()
			}()
		}
		return func() int32 {
			if (TargetRate_bps) > (100000) {
				return 100000
			}
			return func() int32 {
				if (TargetRate_bps) < (5000) {
					return 5000
				}
				return TargetRate_bps
			}()
		}()
	}()
	if (libc.AssignInt32(&ret, control_encoder_FIX(tls, psEnc, PacketSize_ms, TargetRate_bps,
		PacketLoss_perc, UseDTX, Complexity))) != 0 {

		return ret
	}

	/* Make sure no more than one packet can be produced */
	if (1000 * nSamplesIn) > ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketSize_ms * API_fs_Hz) {
		ret = -1

		return ret
	}

	/* Detect energy above 8 kHz */
	if (((func() int32 {
		if (API_fs_Hz) < (1000 * max_internal_fs_kHz) {
			return API_fs_Hz
		}
		return (1000 * max_internal_fs_kHz)
	}()) == 24000) && ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsSWBdetect.FSWB_detected == 0)) && ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsSWBdetect.FWB_detected == 0) {
		detect_SWB_input(tls, (psEnc /* &.sCmn */ + 18532 /* &.sSWBdetect */), samplesIn, nSamplesIn)
	}

	/* Input buffering/resampling and encoding */
	*(*int16)(unsafe.Pointer(bp /* MaxBytesOut */)) = int16(0) /* return 0 output bytes if no encoder called */
	for 1 != 0 {
		nSamplesToBuffer = ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinputBufIx)
		if API_fs_Hz == ((int32(int16(1000))) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz)))) {
			nSamplesToBuffer = min_int(tls, nSamplesToBuffer, nSamplesIn)
			nSamplesFromInput = nSamplesToBuffer
			/* Copy to buffer */
			libc.Xmemcpy(tls, ((psEnc /* &.sCmn */ + 15272 /* &.inputBuf */) + uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinputBufIx)*2), samplesIn, (uint32(nSamplesFromInput) * uint32(unsafe.Sizeof(int16(0)))))
		} else {
			nSamplesToBuffer = func() int32 {
				if (nSamplesToBuffer) < ((10 * input_10ms) * (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz) {
					return nSamplesToBuffer
				}
				return ((10 * input_10ms) * (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz)
			}()
			nSamplesFromInput = ((nSamplesToBuffer * API_fs_Hz) / ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz * 1000))
			/* Resample and write to buffer */
			ret = ret + (resampler(tls, (psEnc /* &.sCmn */ + 18348 /* &.resampler_state */),
				((psEnc /* &.sCmn */ + 15272 /* &.inputBuf */) + uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinputBufIx)*2), samplesIn, nSamplesFromInput))
		}
		samplesIn += 2 * (uintptr(nSamplesFromInput))
		nSamplesIn = nSamplesIn - (nSamplesFromInput)
		*(*int32)(unsafe.Pointer(psEnc /* &.sCmn */ + 16232 /* &.inputBufIx */)) += (nSamplesToBuffer)

		/* Silk encoder */
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinputBufIx >= (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length {

			/* Enough data in input buffer, so encode */
			if int32(*(*int16)(unsafe.Pointer(bp /* MaxBytesOut */))) == 0 {
				/* No payload obtained so far */
				*(*int16)(unsafe.Pointer(bp /* MaxBytesOut */)) = *(*int16)(unsafe.Pointer(nBytesOut))
				if (libc.AssignInt32(&ret, encode_frame_FIX(tls, psEnc, outData, bp /* &MaxBytesOut */, psEnc /* &.sCmn */ +15272 /* &.inputBuf */))) != 0 {

				}
			} else {
				/* outData already contains a payload */
				if (libc.AssignInt32(&ret, encode_frame_FIX(tls, psEnc, outData, nBytesOut, psEnc /* &.sCmn */ +15272 /* &.inputBuf */))) != 0 {

				}
				/* Check that no second payload was created */

			}
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinputBufIx = 0
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fcontrolled_since_last_payload = 0

			if nSamplesIn == 0 {
				break
			}
		} else {
			break
		}
	}

	*(*int16)(unsafe.Pointer(nBytesOut)) = *(*int16)(unsafe.Pointer(bp /* MaxBytesOut */))
	if ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseDTX != 0) && ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FinDTX != 0) {
		/* DTX simulation */
		*(*int16)(unsafe.Pointer(nBytesOut)) = int16(0)
	}

	return ret
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/******************/
/* Error messages */
/******************/

/**************************/
/* Encoder error messages */
/**************************/

/* Input length is not a multiplum of 10 ms, or length is longer than the packet length */

/* Sampling frequency not 8000, 12000, 16000 or 24000 Hertz */

/* Packet size not 20, 40, 60, 80 or 100 ms */

/* Allocated payload buffer too short */

/* Loss rate not between 0 and 100 percent */

/* Complexity setting not valid, use 0, 1 or 2 */

/* Inband FEC setting not valid, use 0 or 1 */

/* DTX setting not valid, use 0 or 1 */

/* Internal encoder error */

/**************************/
/* Decoder error messages */
/**************************/

/* Output sampling frequency lower than internal decoded sampling frequency */

/* Payload size exceeded the maximum allowed 1024 bytes */

/* Payload has bit errors */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*******************/
/* Pitch estimator */
/*******************/

/* Level of noise floor for whitening filter LPC analysis in pitch analysis */

/* Bandwidth expansion for whitening filter in pitch analysis */

/* Threshold used by pitch estimator for early escape */

/*********************/
/* Linear prediction */
/*********************/

/* LPC analysis defines: regularization and bandwidth expansion */

/* LTP analysis defines */

/* LTP quantization settings */

/***********************/
/* High pass filtering */
/***********************/

/* Smoothing parameters for low end of pitch frequency range estimation */

/* Min and max values for low end of pitch frequency range estimation */

/* Max absolute difference between log2 of pitch frequency and smoother state, to enter the smoother */

/***********/
/* Various */
/***********/

/* Required speech activity for counting frame as active */

/* Speech Activity LBRR enable threshold (needs tuning) */

/*************************/
/* Perceptual parameters */
/*************************/

/* reduction in coding SNR during low speech activity */

/* factor for reducing quantization noise during voiced speech */

/* factor for reducing quantization noise for unvoiced sparse signals */

/* threshold for sparseness measure above which to use lower quantization offset during unvoiced */

/* warping control */

/* fraction added to first autocorrelation value */

/* noise shaping filter chirp factor */

/* difference between chirp factors for analysis and synthesis noise shaping filters at low bitrates */

/* gain reduction for fricatives */

/* extra harmonic boosting (signal shaping) at low bitrates */

/* extra harmonic boosting (signal shaping) for noisy input signals */

/* harmonic noise shaping */

/* extra harmonic noise shaping for high bitrates or noisy input */

/* parameter for shaping noise towards higher frequencies */

/* parameter for shaping noise even more towards higher frequencies during voiced speech */

/* parameter for applying a high-pass tilt to the input signal */

/* parameter for extra high-pass tilt to the input signal at high rates */

/* parameter for reducing noise at the very low frequencies */

/* less reduction of noise at the very low frequencies for signals with low SNR at low frequencies */

/* noise floor to put a lower limit on the quantization step size */

/* noise floor relative to active speech gain level */

/* subframe smoothing coefficient for determining active speech gain level (lower -> more smoothing) */

/* subframe smoothing coefficient for HarmBoost, HarmShapeGain, Tilt (lower -> more smoothing) */

/* parameters defining the R/D tradeoff in the residual quantizer */

/* Finds LPC vector from correlations, and converts to NLSF */
func find_LPC_FIX(tls *libc.TLS, NLSF_Q15 uintptr, interpIndex uintptr, prev_NLSFq_Q15 uintptr, useInterpolatedNLSFs int32, LPC_order int32, x uintptr, subfr_length int32) { /* find_LPC_FIX.c:32:6: */
	bp := tls.Alloc(832)
	defer tls.Free(832)

	var k int32
	// var a_Q16 [16]int32 at bp+8, 64

	var isInterpLower int32
	var shift int32
	// var S [16]int16 at bp+240, 32

	// var res_nrg0 int32 at bp+816, 4

	// var res_nrg1 int32 at bp+824, 4

	// var rshift0 int32 at bp+820, 4

	// var rshift1 int32 at bp+828, 4

	/* Used only for LSF interpolation */
	// var a_tmp_Q16 [16]int32 at bp+80, 64

	var res_nrg_interp int32
	// var res_nrg int32 at bp, 4

	// var res_tmp_nrg int32 at bp+72, 4

	var res_nrg_interp_Q int32
	// var res_nrg_Q int32 at bp+4, 4

	// var res_tmp_nrg_Q int32 at bp+76, 4

	// var a_tmp_Q12 [16]int16 at bp+208, 32

	// var NLSF0_Q15 [16]int32 at bp+144, 64

	// var LPC_res [272]int16 at bp+272, 544

	/* Default: no interpolation */
	*(*int32)(unsafe.Pointer(interpIndex)) = 4

	/* Burg AR analysis for the full frame */
	burg_modified(tls, bp /* &res_nrg */, bp+4 /* &res_nrg_Q */, bp+8 /* &a_Q16[0] */, x, subfr_length, 4, FIX_CONST(tls, 2.5e-5, 32), LPC_order)

	bwexpander_32(tls, bp+8 /* &a_Q16[0] */, LPC_order, FIX_CONST(tls, 0.99995, 16))

	if useInterpolatedNLSFs == 1 {

		/* Optimal solution for last 10 ms */
		burg_modified(tls, bp+72 /* &res_tmp_nrg */, bp+76 /* &res_tmp_nrg_Q */, bp+80 /* &a_tmp_Q16[0] */, (x + uintptr(((int32(4)>>1)*subfr_length))*2),
			subfr_length, (int32(4) >> 1), FIX_CONST(tls, 2.5e-5, 32), LPC_order)

		bwexpander_32(tls, bp+80 /* &a_tmp_Q16[0] */, LPC_order, FIX_CONST(tls, 0.99995, 16))

		/* subtract residual energy here, as that's easier than adding it to the    */
		/* residual energy of the first 10 ms in each iteration of the search below */
		shift = (*(*int32)(unsafe.Pointer(bp + 76 /* res_tmp_nrg_Q */)) - *(*int32)(unsafe.Pointer(bp + 4 /* res_nrg_Q */)))
		if shift >= 0 {
			if shift < 32 {
				*(*int32)(unsafe.Pointer(bp /* res_nrg */)) = (*(*int32)(unsafe.Pointer(bp /* res_nrg */)) - ((*(*int32)(unsafe.Pointer(bp + 72 /* res_tmp_nrg */))) >> (shift)))
			}
		} else {

			*(*int32)(unsafe.Pointer(bp /* res_nrg */)) = (((*(*int32)(unsafe.Pointer(bp /* res_nrg */))) >> (-shift)) - *(*int32)(unsafe.Pointer(bp + 72 /* res_tmp_nrg */)))
			*(*int32)(unsafe.Pointer(bp + 4 /* res_nrg_Q */)) = *(*int32)(unsafe.Pointer(bp + 76 /* res_tmp_nrg_Q */))
		}

		/* Convert to NLSFs */
		A2NLSF(tls, NLSF_Q15, bp+80 /* &a_tmp_Q16[0] */, LPC_order)

		/* Search over interpolation indices to find the one with lowest residual energy */
		for k = 3; k >= 0; k-- {
			/* Interpolate NLSFs for first half */
			interpolate(tls, bp+144 /* &NLSF0_Q15[0] */, prev_NLSFq_Q15, NLSF_Q15, k, LPC_order)

			/* Convert to LPC for residual energy evaluation */
			NLSF2A_stable(tls, bp+208 /* &a_tmp_Q12[0] */, bp+144 /* &NLSF0_Q15[0] */, LPC_order)

			/* Calculate residual energy with NLSF interpolation */
			libc.Xmemset(tls, bp+240 /* &S[0] */, 0, (uint32(LPC_order) * uint32(unsafe.Sizeof(int16(0)))))
			LPC_analysis_filter(tls, x, bp+208 /* &a_tmp_Q12[0] */, bp+240 /* &S[0] */, bp+272 /* &LPC_res[0] */, (2 * subfr_length), LPC_order)

			sum_sqr_shift(tls, bp+816 /* &res_nrg0 */, bp+820 /* &rshift0 */, (bp + 272 /* &LPC_res[0] */ + uintptr(LPC_order)*2), (subfr_length - LPC_order))
			sum_sqr_shift(tls, bp+824 /* &res_nrg1 */, bp+828 /* &rshift1 */, ((bp + 272 /* &LPC_res[0] */ + uintptr(LPC_order)*2) + uintptr(subfr_length)*2), (subfr_length - LPC_order))

			/* Add subframe energies from first half frame */
			shift = (*(*int32)(unsafe.Pointer(bp + 820 /* rshift0 */)) - *(*int32)(unsafe.Pointer(bp + 828 /* rshift1 */)))
			if shift >= 0 {
				*(*int32)(unsafe.Pointer(bp + 824 /* res_nrg1 */)) = ((*(*int32)(unsafe.Pointer(bp + 824 /* res_nrg1 */))) >> (shift))
				res_nrg_interp_Q = -*(*int32)(unsafe.Pointer(bp + 820 /* rshift0 */))
			} else {
				*(*int32)(unsafe.Pointer(bp + 816 /* res_nrg0 */)) = ((*(*int32)(unsafe.Pointer(bp + 816 /* res_nrg0 */))) >> (-shift))
				res_nrg_interp_Q = -*(*int32)(unsafe.Pointer(bp + 828 /* rshift1 */))
			}
			res_nrg_interp = ((*(*int32)(unsafe.Pointer(bp + 816 /* res_nrg0 */))) + (*(*int32)(unsafe.Pointer(bp + 824 /* res_nrg1 */))))

			/* Compare with first half energy without NLSF interpolation, or best interpolated value so far */
			shift = (res_nrg_interp_Q - *(*int32)(unsafe.Pointer(bp + 4 /* res_nrg_Q */)))
			if shift >= 0 {
				if ((res_nrg_interp) >> (shift)) < *(*int32)(unsafe.Pointer(bp /* res_nrg */)) {
					isInterpLower = 1
				} else {
					isInterpLower = 0
				}
			} else {
				if -shift < 32 {
					if res_nrg_interp < ((*(*int32)(unsafe.Pointer(bp /* res_nrg */))) >> (-shift)) {
						isInterpLower = 1
					} else {
						isInterpLower = 0
					}
				} else {
					isInterpLower = 0
				}
			}

			/* Determine whether current interpolated NLSFs are best so far */
			if isInterpLower == 1 {
				/* Interpolation has lower residual energy */
				*(*int32)(unsafe.Pointer(bp /* res_nrg */)) = res_nrg_interp
				*(*int32)(unsafe.Pointer(bp + 4 /* res_nrg_Q */)) = res_nrg_interp_Q
				*(*int32)(unsafe.Pointer(interpIndex)) = k
			}
		}
	}

	if *(*int32)(unsafe.Pointer(interpIndex)) == 4 {
		/* NLSF interpolation is currently inactive, calculate NLSFs from full frame AR coefficients */
		A2NLSF(tls, NLSF_Q15, bp+8 /* &a_Q16[0] */, LPC_order)
	}
}

func find_LTP_FIX(tls *libc.TLS, b_Q14 uintptr, WLTP uintptr, LTPredCodGain_Q7 uintptr, r_first uintptr, r_last uintptr, lag uintptr, Wght_Q15 uintptr, subfr_length int32, mem_offset int32, corr_rshifts uintptr) { /* find_LTP_FIX.c:39:6: */
	bp := tls.Alloc(128)
	defer tls.Free(128)

	var i int32
	var k int32
	var lshift int32
	var r_ptr uintptr
	var lag_ptr uintptr
	var b_Q14_ptr uintptr
	var regu int32
	var WLTP_ptr uintptr
	// var b_Q16 [5]int32 at bp+40, 20

	// var delta_b_Q14 [5]int32 at bp+108, 20

	// var d_Q14 [4]int32 at bp+92, 16

	// var nrg [4]int32 at bp+60, 16

	var g_Q26 int32
	// var w [4]int32 at bp+76, 16

	var WLTP_max int32
	var max_abs_d_Q14 int32
	var max_w_bits int32
	var temp32 int32
	var denom32 int32
	var extra_shifts int32
	// var rr_shifts int32 at bp+16, 4

	var maxRshifts int32
	var maxRshifts_wxtra int32
	var LZs int32
	var LPC_res_nrg int32
	var LPC_LTP_res_nrg int32
	var div_Q16 int32
	// var Rr [5]int32 at bp+20, 20

	// var rr [4]int32 at bp, 16

	var wd int32
	var m_Q12 int32

	b_Q14_ptr = b_Q14
	WLTP_ptr = WLTP
	r_ptr = (r_first + uintptr(mem_offset)*2)
	for k = 0; k < 4; k++ {
		if k == (int32(4) >> 1) { /* shift residual for last 10 ms */
			r_ptr = (r_last + uintptr(mem_offset)*2)
		}
		lag_ptr = (r_ptr - uintptr((*(*int32)(unsafe.Pointer(lag + uintptr(k)*4))+(5/2)))*2)

		sum_sqr_shift(tls, (bp /* &rr */ + uintptr(k)*4), bp+16 /* &rr_shifts */, r_ptr, subfr_length) /* rr[ k ] in Q( -rr_shifts ) */

		/* Assure headroom */
		LZs = CLZ32(tls, *(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4)))
		if LZs < 2 {
			*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4)) = func() int32 {
				if (2 - LZs) == 1 {
					return (((*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4))) >> ((2 - LZs) - 1)) + 1) >> 1)
			}()
			*(*int32)(unsafe.Pointer(bp + 16 /* rr_shifts */)) += (2 - LZs)
		}
		*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) = *(*int32)(unsafe.Pointer(bp + 16 /* rr_shifts */))
		corrMatrix_FIX(tls, lag_ptr, subfr_length, 5, 2, WLTP_ptr, (corr_rshifts + uintptr(k)*4)) /* WLTP_fix_ptr in Q( -corr_rshifts[ k ] ) */

		/* The correlation vector always has lower max abs value than rr and/or RR so head room is assured */
		corrVector_FIX(tls, lag_ptr, r_ptr, subfr_length, 5, bp+20 /* &Rr[0] */, *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4))) /* Rr_fix_ptr   in Q( -corr_rshifts[ k ] ) */
		if *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) > *(*int32)(unsafe.Pointer(bp + 16 /* rr_shifts */)) {
			*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4))) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - *(*int32)(unsafe.Pointer(bp + 16 /* rr_shifts */)))) /* rr[ k ] in Q( -corr_rshifts[ k ] ) */
		}

		regu = 1
		regu = ((regu) + ((((*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(FIX_CONST(tls, (float64(float32(0.01) / float32(3))), 16))))) + ((((*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, (float64(float32(0.01) / float32(3))), 16))))) >> 16)))
		regu = ((regu) + ((((*(*int32)(unsafe.Pointer((WLTP_ptr + uintptr((((0)*(5))+(0)))*4)))) >> 16) * (int32(int16(FIX_CONST(tls, (float64(float32(0.01) / float32(3))), 16))))) + ((((*(*int32)(unsafe.Pointer((WLTP_ptr + uintptr((((0)*(5))+(0)))*4)))) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, (float64(float32(0.01) / float32(3))), 16))))) >> 16)))
		regu = ((regu) + ((((*(*int32)(unsafe.Pointer((WLTP_ptr + uintptr((((5-1)*(5))+(5-1)))*4)))) >> 16) * (int32(int16(FIX_CONST(tls, (float64(float32(0.01) / float32(3))), 16))))) + ((((*(*int32)(unsafe.Pointer((WLTP_ptr + uintptr((((5-1)*(5))+(5-1)))*4)))) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, (float64(float32(0.01) / float32(3))), 16))))) >> 16)))
		regularize_correlations_FIX(tls, WLTP_ptr, (bp /* &rr */ + uintptr(k)*4), regu, 5)

		solve_LDL_FIX(tls, WLTP_ptr, 5, bp+20 /* &Rr[0] */, bp+40 /* &b_Q16[0] */) /* WLTP_fix_ptr and Rr_fix_ptr both in Q(-corr_rshifts[k]) */

		/* Limit and store in Q14 */
		fit_LTP(tls, bp+40 /* &b_Q16[0] */, b_Q14_ptr)

		/* Calculate residual energy */
		*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4)) = residual_energy16_covar_FIX(tls, b_Q14_ptr, WLTP_ptr, bp+20 /* &Rr[0] */, *(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4)), 5, 14) /* nrg_fix in Q( -corr_rshifts[ k ] ) */

		/* temp = Wght[ k ] / ( nrg[ k ] * Wght[ k ] + 0.01f * subfr_length ); */
		extra_shifts = min_int(tls, *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)), 2)
		denom32 = (((func() int32 {
			if (int32((libc.Int32FromUint32(0x80000000))) >> (1 + extra_shifts)) > (int32((0x7FFFFFFF)) >> (1 + extra_shifts)) {
				return func() int32 {
					if ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) >> 16)) > (int32((libc.Int32FromUint32(0x80000000))) >> (1 + extra_shifts)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (1 + extra_shifts))
					}
					return func() int32 {
						if ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) >> 16)) < (int32((0x7FFFFFFF)) >> (1 + extra_shifts)) {
							return (int32((0x7FFFFFFF)) >> (1 + extra_shifts))
						}
						return ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) >> 16))
					}()
				}()
			}
			return func() int32 {
				if ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) >> 16)) > (int32((0x7FFFFFFF)) >> (1 + extra_shifts)) {
					return (int32((0x7FFFFFFF)) >> (1 + extra_shifts))
				}
				return func() int32 {
					if ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) >> 16)) < (int32((libc.Int32FromUint32(0x80000000))) >> (1 + extra_shifts)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (1 + extra_shifts))
					}
					return ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) >> 16))
				}()
			}()
		}()) << (1 + extra_shifts)) + (((((subfr_length) >> 16) * (int32(int16(655)))) + ((((subfr_length) & 0x0000FFFF) * (int32(int16(655)))) >> 16)) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - extra_shifts))) /* Q( -corr_rshifts[ k ] + extra_shifts ) */
		denom32 = func() int32 {
			if (denom32) > (1) {
				return denom32
			}
			return 1
		}()
		/* Wght always < 0.5 in Q0 */
		temp32 = (((*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4))) << (16)) / (denom32))                        /* Q( 15 + 16 + corr_rshifts[k] - extra_shifts ) */
		temp32 = ((temp32) >> (((31 + *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4))) - extra_shifts) - 26)) /* Q26 */

		/* Limit temp such that the below scaling never wraps around */
		WLTP_max = 0
		for i = 0; i < (5 * 5); i++ {
			WLTP_max = func() int32 {
				if (*(*int32)(unsafe.Pointer(WLTP_ptr + uintptr(i)*4))) > (WLTP_max) {
					return *(*int32)(unsafe.Pointer(WLTP_ptr + uintptr(i)*4))
				}
				return WLTP_max
			}()
		}
		lshift = ((CLZ32(tls, WLTP_max) - 1) - 3) /* keep 3 bits free for vq_nearest_neighbor_fix */

		if ((26 - 18) + lshift) < 31 {
			temp32 = min_32(tls, temp32, (int32((1)) << ((26 - 18) + lshift)))
		}

		scale_vector32_Q26_lshift_18(tls, WLTP_ptr, temp32, (5 * 5)) /* WLTP_ptr in Q( 18 - corr_rshifts[ k ] ) */

		*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4)) = *(*int32)(unsafe.Pointer((WLTP_ptr + uintptr((((int32(5)>>1)*(5))+(int32(5)>>1)))*4))) /* w in Q( 18 - corr_rshifts[ k ] ) */

		r_ptr += 2 * (uintptr(subfr_length))
		b_Q14_ptr += 2 * (uintptr(5))
		WLTP_ptr += 4 * (uintptr(5 * 5))
	}

	maxRshifts = 0
	for k = 0; k < 4; k++ {
		maxRshifts = max_int(tls, *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)), maxRshifts)
	}

	/* Compute LTP coding gain */
	if LTPredCodGain_Q7 != (uintptr(0)) {
		LPC_LTP_res_nrg = 0
		LPC_res_nrg = 0
		/* Check that no overflow will happen when adding */
		for k = 0; k < 4; k++ {
			LPC_res_nrg = ((LPC_res_nrg) + ((((((*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp /* &rr[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) >> 16)) + (1)) >> (1 + (maxRshifts - *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4))))))                     /*  Q( -maxRshifts ) */
			LPC_LTP_res_nrg = ((LPC_LTP_res_nrg) + ((((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 60 /* &nrg[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(Wght_Q15 + uintptr(k)*4)))))) >> 16)) + (1)) >> (1 + (maxRshifts - *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)))))) /*  Q( -maxRshifts ) */
		}
		LPC_LTP_res_nrg = func() int32 {
			if (LPC_LTP_res_nrg) > (1) {
				return LPC_LTP_res_nrg
			}
			return 1
		}() /* avoid division by zero */

		div_Q16 = DIV32_varQ(tls, LPC_res_nrg, LPC_LTP_res_nrg, 16)
		*(*int32)(unsafe.Pointer(LTPredCodGain_Q7)) = ((int32(int16(3))) * (int32((int16(lin2log(tls, div_Q16) - (int32(16) << 7))))))

	}

	/* smoothing */
	/* d = sum( B, 1 ); */
	b_Q14_ptr = b_Q14
	for k = 0; k < 4; k++ {
		*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4)) = 0
		for i = 0; i < 5; i++ {
			*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14 */ + uintptr(k)*4)) += (int32(*(*int16)(unsafe.Pointer(b_Q14_ptr + uintptr(i)*2))))
		}
		b_Q14_ptr += 2 * (uintptr(5))
	}

	/* m = ( w * d' ) / ( sum( w ) + 1e-3 ); */

	/* Find maximum absolute value of d_Q14 and the bits used by w in Q0 */
	max_abs_d_Q14 = 0
	max_w_bits = 0
	for k = 0; k < 4; k++ {
		max_abs_d_Q14 = max_32(tls, max_abs_d_Q14, func() int32 {
			if (*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) > 0 {
				return *(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))
			}
			return -*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))
		}())
		/* w[ k ] is in Q( 18 - corr_rshifts[ k ] ) */
		/* Find bits needed in Q( 18 - maxRshifts ) */
		max_w_bits = max_32(tls, max_w_bits, (((32 - CLZ32(tls, *(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4)))) + *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4))) - maxRshifts))
	}

	/* max_abs_d_Q14 = (5 << 15); worst case, i.e. LTP_ORDER * -int16_MIN */

	/* How many bits is needed for w*d' in Q( 18 - maxRshifts ) in the worst case, of all d_Q14's being equal to max_abs_d_Q14 */
	extra_shifts = (((max_w_bits + 32) - CLZ32(tls, max_abs_d_Q14)) - 14)

	/* Subtract what we got available; bits in output var plus maxRshifts */
	extra_shifts = extra_shifts - (((32 - 1) - 2) + maxRshifts) /* Keep sign bit free as well as 2 bits for accumulation */
	extra_shifts = max_int(tls, extra_shifts, 0)

	maxRshifts_wxtra = (maxRshifts + extra_shifts)

	temp32 = ((int32((262)) >> (maxRshifts + extra_shifts)) + 1) /* 1e-3f in Q( 18 - (maxRshifts + extra_shifts) ) */
	wd = 0
	for k = 0; k < 4; k++ {
		/* w has at least 2 bits of headroom so no overflow should happen */
		temp32 = ((temp32) + ((*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))) >> (maxRshifts_wxtra - *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4))))) /* Q( 18 - maxRshifts_wxtra ) */
		wd = ((wd) + (((((((*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))) >> (maxRshifts_wxtra - *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4)))))) + (((((*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))) >> (maxRshifts_wxtra - *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4)))))) >> 16)) + (((*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))) >> (maxRshifts_wxtra - *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)))) * (func() int32 {
			if (16) == 1 {
				return (((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) & 1))
			}
			return ((((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> ((16) - 1)) + 1) >> 1)
		}()))) << (2))) /* Q( 18 - maxRshifts_wxtra ) */
	}
	m_Q12 = DIV32_varQ(tls, wd, temp32, 12)

	b_Q14_ptr = b_Q14
	for k = 0; k < 4; k++ {
		/* w_fix[ k ] from Q( 18 - corr_rshifts[ k ] ) to Q( 16 ) */
		if (2 - *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4))) > 0 {
			temp32 = ((*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))) >> (2 - *(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4))))
		} else {
			temp32 = ((func() int32 {
				if (int32((libc.Int32FromUint32(0x80000000))) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2)) > (int32((0x7FFFFFFF)) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2)) {
					return func() int32 {
						if (*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))) > (int32((libc.Int32FromUint32(0x80000000))) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2)) {
							return (int32((libc.Int32FromUint32(0x80000000))) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2))
						}
						return func() int32 {
							if (*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))) < (int32((0x7FFFFFFF)) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2)) {
								return (int32((0x7FFFFFFF)) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2))
							}
							return *(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))
						}()
					}()
				}
				return func() int32 {
					if (*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))) > (int32((0x7FFFFFFF)) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2)) {
						return (int32((0x7FFFFFFF)) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2))
					}
					return func() int32 {
						if (*(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))) < (int32((libc.Int32FromUint32(0x80000000))) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2)) {
							return (int32((libc.Int32FromUint32(0x80000000))) >> (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2))
						}
						return *(*int32)(unsafe.Pointer(bp + 76 /* &w[0] */ + uintptr(k)*4))
					}()
				}()
			}()) << (*(*int32)(unsafe.Pointer(corr_rshifts + uintptr(k)*4)) - 2))
		}

		g_Q26 = (((FIX_CONST(tls, 0.1, 26)) / (((FIX_CONST(tls, 0.1, 26)) >> (10)) + temp32)) * ((func() int32 {
			if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
				return func() int32 {
					if (func() int32 {
						if ((uint32((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) == uint32(0) {
							return func() int32 {
								if (((uint32(m_Q12)) & ((uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2))) ^ 0x80000000)) & 0x80000000) != 0 {
									return libc.Int32FromUint32(0x80000000)
								}
								return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
							}()
						}
						return func() int32 {
							if ((((uint32(m_Q12)) ^ 0x80000000) & (uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) != 0 {
								return 0x7FFFFFFF
							}
							return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
						}()
					}()) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
					}
					return func() int32 {
						if (func() int32 {
							if ((uint32((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) == uint32(0) {
								return func() int32 {
									if (((uint32(m_Q12)) & ((uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2))) ^ 0x80000000)) & 0x80000000) != 0 {
										return libc.Int32FromUint32(0x80000000)
									}
									return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
								}()
							}
							return func() int32 {
								if ((((uint32(m_Q12)) ^ 0x80000000) & (uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) != 0 {
									return 0x7FFFFFFF
								}
								return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
							}()
						}()) < (int32((0x7FFFFFFF)) >> (4)) {
							return (int32((0x7FFFFFFF)) >> (4))
						}
						return func() int32 {
							if ((uint32((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) == uint32(0) {
								return func() int32 {
									if (((uint32(m_Q12)) & ((uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2))) ^ 0x80000000)) & 0x80000000) != 0 {
										return libc.Int32FromUint32(0x80000000)
									}
									return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
								}()
							}
							return func() int32 {
								if ((((uint32(m_Q12)) ^ 0x80000000) & (uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) != 0 {
									return 0x7FFFFFFF
								}
								return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
							}()
						}()
					}()
				}()
			}
			return func() int32 {
				if (func() int32 {
					if ((uint32((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) == uint32(0) {
						return func() int32 {
							if (((uint32(m_Q12)) & ((uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2))) ^ 0x80000000)) & 0x80000000) != 0 {
								return libc.Int32FromUint32(0x80000000)
							}
							return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
						}()
					}
					return func() int32 {
						if ((((uint32(m_Q12)) ^ 0x80000000) & (uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) != 0 {
							return 0x7FFFFFFF
						}
						return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
					}()
				}()) > (int32((0x7FFFFFFF)) >> (4)) {
					return (int32((0x7FFFFFFF)) >> (4))
				}
				return func() int32 {
					if (func() int32 {
						if ((uint32((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) == uint32(0) {
							return func() int32 {
								if (((uint32(m_Q12)) & ((uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2))) ^ 0x80000000)) & 0x80000000) != 0 {
									return libc.Int32FromUint32(0x80000000)
								}
								return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
							}()
						}
						return func() int32 {
							if ((((uint32(m_Q12)) ^ 0x80000000) & (uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) != 0 {
								return 0x7FFFFFFF
							}
							return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
						}()
					}()) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
					}
					return func() int32 {
						if ((uint32((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) == uint32(0) {
							return func() int32 {
								if (((uint32(m_Q12)) & ((uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2))) ^ 0x80000000)) & 0x80000000) != 0 {
									return libc.Int32FromUint32(0x80000000)
								}
								return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
							}()
						}
						return func() int32 {
							if ((((uint32(m_Q12)) ^ 0x80000000) & (uint32((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))) & 0x80000000) != 0 {
								return 0x7FFFFFFF
							}
							return ((m_Q12) - ((*(*int32)(unsafe.Pointer(bp + 92 /* &d_Q14[0] */ + uintptr(k)*4))) >> (2)))
						}()
					}()
				}()
			}()
		}()) << (4))) /* Q16 */

		temp32 = 0
		for i = 0; i < 5; i++ {
			*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)) = int32(max_16(tls, *(*int16)(unsafe.Pointer(b_Q14_ptr + uintptr(i)*2)), int16(1638))) /* 1638_Q14 = 0.1_Q0 */
			temp32 = temp32 + (*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))                                                                    /* Q14 */
		}
		temp32 = ((g_Q26) / (temp32)) /* Q14->Q12 */
		for i = 0; i < 5; i++ {
			*(*int16)(unsafe.Pointer(b_Q14_ptr + uintptr(i)*2)) = func() int16 {
				if (-16000) > (28000) {
					return func() int16 {
						if (int32(*(*int16)(unsafe.Pointer(b_Q14_ptr + uintptr(i)*2))) + (((((func() int32 {
							if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
								return func() int32 {
									if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
											return (int32((0x7FFFFFFF)) >> (4))
										}
										return temp32
									}()
								}()
							}
							return func() int32 {
								if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
									return (int32((0x7FFFFFFF)) >> (4))
								}
								return func() int32 {
									if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return temp32
								}()
							}()
						}()) << (4)) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) + (((((func() int32 {
							if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
								return func() int32 {
									if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
											return (int32((0x7FFFFFFF)) >> (4))
										}
										return temp32
									}()
								}()
							}
							return func() int32 {
								if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
									return (int32((0x7FFFFFFF)) >> (4))
								}
								return func() int32 {
									if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return temp32
								}()
							}()
						}()) << (4)) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) >> 16))) > (-16000) {
							return int16(-16000)
						}
						return func() int16 {
							if (int32(*(*int16)(unsafe.Pointer(b_Q14_ptr + uintptr(i)*2))) + (((((func() int32 {
								if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
									return func() int32 {
										if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
											return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
										}
										return func() int32 {
											if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
												return (int32((0x7FFFFFFF)) >> (4))
											}
											return temp32
										}()
									}()
								}
								return func() int32 {
									if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
										return (int32((0x7FFFFFFF)) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
											return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
										}
										return temp32
									}()
								}()
							}()) << (4)) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) + (((((func() int32 {
								if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
									return func() int32 {
										if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
											return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
										}
										return func() int32 {
											if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
												return (int32((0x7FFFFFFF)) >> (4))
											}
											return temp32
										}()
									}()
								}
								return func() int32 {
									if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
										return (int32((0x7FFFFFFF)) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
											return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
										}
										return temp32
									}()
								}()
							}()) << (4)) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) >> 16))) < (28000) {
								return int16(28000)
							}
							return (int16(int32(*(*int16)(unsafe.Pointer(b_Q14_ptr + uintptr(i)*2))) + (((((func() int32 {
								if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
									return func() int32 {
										if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
											return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
										}
										return func() int32 {
											if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
												return (int32((0x7FFFFFFF)) >> (4))
											}
											return temp32
										}()
									}()
								}
								return func() int32 {
									if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
										return (int32((0x7FFFFFFF)) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
											return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
										}
										return temp32
									}()
								}()
							}()) << (4)) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) + (((((func() int32 {
								if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
									return func() int32 {
										if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
											return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
										}
										return func() int32 {
											if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
												return (int32((0x7FFFFFFF)) >> (4))
											}
											return temp32
										}()
									}()
								}
								return func() int32 {
									if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
										return (int32((0x7FFFFFFF)) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
											return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
										}
										return temp32
									}()
								}()
							}()) << (4)) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) >> 16))))
						}()
					}()
				}
				return func() int16 {
					if (int32(*(*int16)(unsafe.Pointer(b_Q14_ptr + uintptr(i)*2))) + (((((func() int32 {
						if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
							return func() int32 {
								if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
									return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
								}
								return func() int32 {
									if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
										return (int32((0x7FFFFFFF)) >> (4))
									}
									return temp32
								}()
							}()
						}
						return func() int32 {
							if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
								return (int32((0x7FFFFFFF)) >> (4))
							}
							return func() int32 {
								if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
									return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
								}
								return temp32
							}()
						}()
					}()) << (4)) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) + (((((func() int32 {
						if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
							return func() int32 {
								if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
									return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
								}
								return func() int32 {
									if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
										return (int32((0x7FFFFFFF)) >> (4))
									}
									return temp32
								}()
							}()
						}
						return func() int32 {
							if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
								return (int32((0x7FFFFFFF)) >> (4))
							}
							return func() int32 {
								if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
									return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
								}
								return temp32
							}()
						}()
					}()) << (4)) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) >> 16))) > (28000) {
						return int16(28000)
					}
					return func() int16 {
						if (int32(*(*int16)(unsafe.Pointer(b_Q14_ptr + uintptr(i)*2))) + (((((func() int32 {
							if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
								return func() int32 {
									if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
											return (int32((0x7FFFFFFF)) >> (4))
										}
										return temp32
									}()
								}()
							}
							return func() int32 {
								if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
									return (int32((0x7FFFFFFF)) >> (4))
								}
								return func() int32 {
									if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return temp32
								}()
							}()
						}()) << (4)) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) + (((((func() int32 {
							if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
								return func() int32 {
									if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
											return (int32((0x7FFFFFFF)) >> (4))
										}
										return temp32
									}()
								}()
							}
							return func() int32 {
								if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
									return (int32((0x7FFFFFFF)) >> (4))
								}
								return func() int32 {
									if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return temp32
								}()
							}()
						}()) << (4)) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) >> 16))) < (-16000) {
							return int16(-16000)
						}
						return (int16(int32(*(*int16)(unsafe.Pointer(b_Q14_ptr + uintptr(i)*2))) + (((((func() int32 {
							if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
								return func() int32 {
									if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
											return (int32((0x7FFFFFFF)) >> (4))
										}
										return temp32
									}()
								}()
							}
							return func() int32 {
								if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
									return (int32((0x7FFFFFFF)) >> (4))
								}
								return func() int32 {
									if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return temp32
								}()
							}()
						}()) << (4)) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) + (((((func() int32 {
							if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
								return func() int32 {
									if (temp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return func() int32 {
										if (temp32) < (int32((0x7FFFFFFF)) >> (4)) {
											return (int32((0x7FFFFFFF)) >> (4))
										}
										return temp32
									}()
								}()
							}
							return func() int32 {
								if (temp32) > (int32((0x7FFFFFFF)) >> (4)) {
									return (int32((0x7FFFFFFF)) >> (4))
								}
								return func() int32 {
									if (temp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
										return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
									}
									return temp32
								}()
							}()
						}()) << (4)) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp + 108 /* &delta_b_Q14[0] */ + uintptr(i)*4)))))) >> 16))))
					}()
				}()
			}()
		}
		b_Q14_ptr += 2 * (uintptr(5))
	}
}

func fit_LTP(tls *libc.TLS, LTP_coefs_Q16 uintptr, LTP_coefs_Q14 uintptr) { /* find_LTP_FIX.c:233:6: */
	var i int32

	for i = 0; i < 5; i++ {
		*(*int16)(unsafe.Pointer(LTP_coefs_Q14 + uintptr(i)*2)) = func() int16 {
			if (func() int32 {
				if (2) == 1 {
					return (((*(*int32)(unsafe.Pointer(LTP_coefs_Q16 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(LTP_coefs_Q16 + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer(LTP_coefs_Q16 + uintptr(i)*4))) >> ((2) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (2) == 1 {
						return (((*(*int32)(unsafe.Pointer(LTP_coefs_Q16 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(LTP_coefs_Q16 + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer(LTP_coefs_Q16 + uintptr(i)*4))) >> ((2) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (2) == 1 {
						return (int16(((*(*int32)(unsafe.Pointer(LTP_coefs_Q16 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(LTP_coefs_Q16 + uintptr(i)*4))) & 1)))
					}
					return (int16((((*(*int32)(unsafe.Pointer(LTP_coefs_Q16 + uintptr(i)*4))) >> ((2) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*******************/
/* Pitch estimator */
/*******************/

/* Level of noise floor for whitening filter LPC analysis in pitch analysis */

/* Bandwidth expansion for whitening filter in pitch analysis */

/* Threshold used by pitch estimator for early escape */

/*********************/
/* Linear prediction */
/*********************/

/* LPC analysis defines: regularization and bandwidth expansion */

/* LTP analysis defines */

/* LTP quantization settings */

/***********************/
/* High pass filtering */
/***********************/

/* Smoothing parameters for low end of pitch frequency range estimation */

/* Min and max values for low end of pitch frequency range estimation */

/* Max absolute difference between log2 of pitch frequency and smoother state, to enter the smoother */

/***********/
/* Various */
/***********/

/* Required speech activity for counting frame as active */

/* Speech Activity LBRR enable threshold (needs tuning) */

/*************************/
/* Perceptual parameters */
/*************************/

/* reduction in coding SNR during low speech activity */

/* factor for reducing quantization noise during voiced speech */

/* factor for reducing quantization noise for unvoiced sparse signals */

/* threshold for sparseness measure above which to use lower quantization offset during unvoiced */

/* warping control */

/* fraction added to first autocorrelation value */

/* noise shaping filter chirp factor */

/* difference between chirp factors for analysis and synthesis noise shaping filters at low bitrates */

/* gain reduction for fricatives */

/* extra harmonic boosting (signal shaping) at low bitrates */

/* extra harmonic boosting (signal shaping) for noisy input signals */

/* harmonic noise shaping */

/* extra harmonic noise shaping for high bitrates or noisy input */

/* parameter for shaping noise towards higher frequencies */

/* parameter for shaping noise even more towards higher frequencies during voiced speech */

/* parameter for applying a high-pass tilt to the input signal */

/* parameter for extra high-pass tilt to the input signal at high rates */

/* parameter for reducing noise at the very low frequencies */

/* less reduction of noise at the very low frequencies for signals with low SNR at low frequencies */

/* noise floor to put a lower limit on the quantization step size */

/* noise floor relative to active speech gain level */

/* subframe smoothing coefficient for determining active speech gain level (lower -> more smoothing) */

/* subframe smoothing coefficient for HarmBoost, HarmShapeGain, Tilt (lower -> more smoothing) */

/* parameters defining the R/D tradeoff in the residual quantizer */

/* Find pitch lags */
func find_pitch_lags_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrl uintptr, res uintptr, x uintptr) { /* find_pitch_lags_FIX.c:32:6: */
	bp := tls.Alloc(1416)
	defer tls.Free(1416)

	var psPredSt uintptr = (psEnc + 20672 /* &.sPred */)
	var buf_len int32
	var i int32
	// var scale int32 at bp+1220, 4

	var thrhld_Q15 int32
	var res_nrg int32
	var x_buf uintptr
	var x_buf_ptr uintptr
	// var Wsig [576]int16 at bp, 1152

	var Wsig_ptr uintptr
	// var auto_corr [17]int32 at bp+1152, 68

	// var rc_Q15 [16]int16 at bp+1224, 32

	// var A_Q24 [16]int32 at bp+1256, 64

	// var FiltState [16]int32 at bp+1352, 64

	// var A_Q12 [16]int16 at bp+1320, 32

	/******************************************/
	/* Setup buffer lengths etc based on Fs   */
	/******************************************/
	buf_len = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_pitch) + (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length) << (1)))

	/* Safty check */

	x_buf = (x - uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)*2)

	/*************************************/
	/* Estimate LPC AR coefficients      */
	/*************************************/

	/* Calculate windowed signal */

	/* First LA_LTP samples */
	x_buf_ptr = ((x_buf + uintptr(buf_len)*2) - uintptr((*predict_state_FIX)(unsafe.Pointer(psPredSt)).Fpitch_LPC_win_length)*2)
	Wsig_ptr = bp /* &Wsig[0] */
	apply_sine_window(tls, Wsig_ptr, x_buf_ptr, 1, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_pitch)

	/* Middle un - windowed samples */
	Wsig_ptr += 2 * (uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_pitch))
	x_buf_ptr += 2 * (uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_pitch))
	libc.Xmemcpy(tls, Wsig_ptr, x_buf_ptr, ((uint32((*predict_state_FIX)(unsafe.Pointer(psPredSt)).Fpitch_LPC_win_length - (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_pitch) << (1)))) * uint32(unsafe.Sizeof(int16(0)))))

	/* Last LA_LTP samples */
	Wsig_ptr += 2 * (uintptr((*predict_state_FIX)(unsafe.Pointer(psPredSt)).Fpitch_LPC_win_length - (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_pitch) << (1))))
	x_buf_ptr += 2 * (uintptr((*predict_state_FIX)(unsafe.Pointer(psPredSt)).Fpitch_LPC_win_length - (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_pitch) << (1))))
	apply_sine_window(tls, Wsig_ptr, x_buf_ptr, 2, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_pitch)

	/* Calculate autocorrelation sequence */
	autocorr(tls, bp+1152 /* &auto_corr[0] */, bp+1220 /* &scale */, bp /* &Wsig[0] */, (*predict_state_FIX)(unsafe.Pointer(psPredSt)).Fpitch_LPC_win_length, ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationLPCOrder + 1))

	/* Add white noise, as fraction of energy */
	*(*int32)(unsafe.Pointer(bp + 1152 /* &auto_corr[0] */)) = ((*(*int32)(unsafe.Pointer(bp + 1152 /* &auto_corr[0] */))) + ((((*(*int32)(unsafe.Pointer(bp + 1152 /* &auto_corr[0] */))) >> 16) * (int32(int16(FIX_CONST(tls, 1e-3, 16))))) + ((((*(*int32)(unsafe.Pointer(bp + 1152 /* &auto_corr[0] */))) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 1e-3, 16))))) >> 16)))

	/* Calculate the reflection coefficients using schur */
	res_nrg = schur(tls, bp+1224 /* &rc_Q15[0] */, bp+1152 /* &auto_corr[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationLPCOrder)

	/* Prediction gain */
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FpredGain_Q16 = DIV32_varQ(tls, *(*int32)(unsafe.Pointer(bp + 1152 /* &auto_corr[0] */)), max_int(tls, res_nrg, 1), 16)

	/* Convert reflection coefficients to prediction coefficients */
	k2a(tls, bp+1256 /* &A_Q24[0] */, bp+1224 /* &rc_Q15[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationLPCOrder)

	/* Convert From 32 bit Q24 to 16 bit Q12 coefs */
	for i = 0; i < (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationLPCOrder; i++ {
		*(*int16)(unsafe.Pointer(bp + 1320 /* &A_Q12[0] */ + uintptr(i)*2)) = func() int16 {
			if ((*(*int32)(unsafe.Pointer(bp + 1256 /* &A_Q24[0] */ + uintptr(i)*4))) >> (12)) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if ((*(*int32)(unsafe.Pointer(bp + 1256 /* &A_Q24[0] */ + uintptr(i)*4))) >> (12)) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return (int16((*(*int32)(unsafe.Pointer(bp + 1256 /* &A_Q24[0] */ + uintptr(i)*4))) >> (12)))
			}()
		}()
	}

	/* Do BWE */
	bwexpander(tls, bp+1320 /* &A_Q12[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationLPCOrder, FIX_CONST(tls, 0.99, 16))

	/*****************************************/
	/* LPC analysis filtering                */
	/*****************************************/
	libc.Xmemset(tls, bp+1352 /* &FiltState[0] */, 0, (uint32((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationLPCOrder) * uint32(unsafe.Sizeof(int32(0))))) /* Not really necessary, but Valgrind will complain otherwise */
	MA_Prediction(tls, x_buf, bp+1320 /* &A_Q12[0] */, bp+1352 /* &FiltState[0] */, res, buf_len, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationLPCOrder)
	libc.Xmemset(tls, res, 0, (uint32((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationLPCOrder) * uint32(unsafe.Sizeof(int16(0)))))

	/* Threshold for pitch estimator */
	thrhld_Q15 = FIX_CONST(tls, 0.45, 15)
	thrhld_Q15 = ((thrhld_Q15) + ((int32(int16(FIX_CONST(tls, -0.004, 15)))) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationLPCOrder)))))
	thrhld_Q15 = ((thrhld_Q15) + ((int32(int16(FIX_CONST(tls, -0.1, 7)))) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))))
	thrhld_Q15 = ((thrhld_Q15) + ((int32(int16(FIX_CONST(tls, 0.15, 15)))) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fprev_sigtype)))))
	thrhld_Q15 = ((thrhld_Q15) + ((((FIX_CONST(tls, -0.1, 16)) >> 16) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15)))) + ((((FIX_CONST(tls, -0.1, 16)) & 0x0000FFFF) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15)))) >> 16)))
	thrhld_Q15 = func() int32 {
		if (thrhld_Q15) > 0x7FFF {
			return 0x7FFF
		}
		return func() int32 {
			if (thrhld_Q15) < (int32(libc.Int16FromInt32(0x8000))) {
				return int32(libc.Int16FromInt32(0x8000))
			}
			return thrhld_Q15
		}()
	}()

	/*****************************************/
	/* Call pitch estimator                  */
	/*****************************************/
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype = pitch_analysis_core(tls, res, psEncCtrl /* &.sCmn */ +108 /* &.pitchL */, (psEncCtrl /* &.sCmn */ /* &.lagIndex */),
		(psEncCtrl /* &.sCmn */ + 4 /* &.contourIndex */), (psEnc + 22908 /* &.LTPCorr_Q15 */), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FprevLag, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationThreshold_Q16,
		int32(int16(thrhld_Q15)), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpitchEstimationComplexity, 0)
}

func find_pred_coefs_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrl uintptr, res_pitch uintptr) { /* find_pred_coefs_FIX.c:31:6: */
	bp := tls.Alloc(1616)
	defer tls.Free(1616)

	var i int32
	// var WLTP [100]int32 at bp+48, 400

	// var invGains_Q16 [4]int32 at bp, 16

	// var local_gains [4]int32 at bp+32, 16

	// var Wght_Q15 [4]int32 at bp+16, 16

	// var NLSF_Q15 [16]int32 at bp+1552, 64

	var x_ptr uintptr
	var x_pre_ptr uintptr
	// var LPC_in_pre [544]int16 at bp+464, 1088

	var tmp int32
	var min_gain_Q16 int32
	// var LTP_corrs_rshift [4]int32 at bp+448, 16

	/* weighting for weighted least squares */
	min_gain_Q16 = (int32(0x7FFFFFFF) >> 6)
	for i = 0; i < 4; i++ {
		min_gain_Q16 = func() int32 {
			if (min_gain_Q16) < (*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(i)*4))) {
				return min_gain_Q16
			}
			return *(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(i)*4))
		}()
	}
	for i = 0; i < 4; i++ {
		/* Divide to Q16 */

		/* Invert and normalize gains, and ensure that maximum invGains_Q16 is within range of a 16 bit int */
		*(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4)) = DIV32_varQ(tls, min_gain_Q16, *(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(i)*4)), (16 - 2))

		/* Ensure Wght_Q15 a minimum value 1 */
		*(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4)) = func() int32 {
			if (*(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4))) > (363) {
				return *(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4))
			}
			return 363
		}()

		/* Square the inverted gains */

		tmp = ((((*(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4)))))) >> 16))
		*(*int32)(unsafe.Pointer(bp + 16 /* &Wght_Q15[0] */ + uintptr(i)*4)) = ((tmp) >> (1))

		/* Invert the inverted and normalized gains */
		*(*int32)(unsafe.Pointer(bp + 32 /* &local_gains[0] */ + uintptr(i)*4)) = ((int32(1) << 16) / (*(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4))))
	}

	if (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 0 {
		/**********/
		/* VOICED */
		/**********/

		/* LTP analysis */
		find_LTP_FIX(tls, psEncCtrl+208 /* &.LTPCoef_Q14 */, bp+48 /* &WLTP[0] */, (psEncCtrl + 616 /* &.LTPredCodGain_Q7 */), res_pitch,
			(res_pitch + uintptr((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)>>(1)))*2), psEncCtrl /* &.sCmn */ +108 /* &.pitchL */, bp+16, /* &Wght_Q15[0] */
			(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length, bp+448 /* &LTP_corrs_rshift[0] */)

		/* Quantize LTP gain parameters */
		quant_LTP_gains_FIX(tls, psEncCtrl+208 /* &.LTPCoef_Q14 */, psEncCtrl /* &.sCmn */ +12 /* &.LTPIndex */, (psEncCtrl /* &.sCmn */ + 8 /* &.PERIndex */),
			bp+48 /* &WLTP[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fmu_LTP_Q8, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FLTPQuantLowComplexity)

		/* Control LTP scaling */
		LTP_scale_ctrl_FIX(tls, psEnc, psEncCtrl)

		/* Create LTP residual */
		LTP_analysis_filter_FIX(tls, bp+464 /* &LPC_in_pre[0] */, (((psEnc + 20748 /* &.x_buf */) + uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)*2) - uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)*2),
			psEncCtrl+208 /* &.LTPCoef_Q14 */, psEncCtrl /* &.sCmn */ +108 /* &.pitchL */, bp /* &invGains_Q16[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)

	} else {
		/************/
		/* UNVOICED */
		/************/
		/* Create signal with prepended subframes, scaled by inverse gains */
		x_ptr = (((psEnc + 20748 /* &.x_buf */) + uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)*2) - uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)*2)
		x_pre_ptr = bp + 464 /* &LPC_in_pre[0] */
		for i = 0; i < 4; i++ {
			scale_copy_vector16(tls, x_pre_ptr, x_ptr, *(*int32)(unsafe.Pointer(bp /* &invGains_Q16[0] */ + uintptr(i)*4)),
				((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length + (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder))
			x_pre_ptr += 2 * (uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length + (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder))
			x_ptr += 2 * (uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length))
		}

		libc.Xmemset(tls, psEncCtrl+208 /* &.LTPCoef_Q14 */, 0, ((uint32(4 * 5)) * uint32(unsafe.Sizeof(int16(0)))))
		(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7 = 0
	}

	/* LPC_in_pre contains the LTP-filtered input for voiced, and the unfiltered input for unvoiced */

	find_LPC_FIX(tls, bp+1552 /* &NLSF_Q15[0] */, (psEncCtrl /* &.sCmn */ + 68 /* &.NLSFInterpCoef_Q2 */), psEnc+20672 /* &.sPred */ +12, /* &.prev_NLSFq_Q15 */
		((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseInterpolatedNLSFs * (1 - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffirst_frame_after_reset)), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder,
		bp+464 /* &LPC_in_pre[0] */, ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length + (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder))

	/* Quantize LSFs */

	process_NLSFs_FIX(tls, psEnc, psEncCtrl, bp+1552 /* &NLSF_Q15[0] */)

	/* Calculate residual energy using quantized LPC coefficients */
	residual_energy_FIX(tls, psEncCtrl+640 /* &.ResNrg */, psEncCtrl+656 /* &.ResNrgQ */, bp+464 /* &LPC_in_pre[0] */, psEncCtrl+144 /* &.PredCoef_Q12 */, bp+32, /* &local_gains[0] */
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)

	/* Copy to prediction struct for use in next frame for fluctuation reduction */
	libc.Xmemcpy(tls, psEnc+20672 /* &.sPred */ +12 /* &.prev_NLSFq_Q15 */, bp+1552 /* &NLSF_Q15[0] */, (uint32((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder) * uint32(unsafe.Sizeof(int32(0)))))

}

/* Gain scalar quantization with hysteresis, uniform on log scale */
func gains_quant(tls *libc.TLS, ind uintptr, gain_Q16 uintptr, prev_ind uintptr, conditional int32) { /* gain_quant.c:35:6: */
	var k int32

	for k = 0; k < 4; k++ {
		/* Add half of previous quantization error, convert to log scale, scale, floor() */
		*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) = (((int32(((65536 * (64 - 1)) / (((86 - 6) * 128) / 6))) >> 16) * (int32((int16(lin2log(tls, *(*int32)(unsafe.Pointer(gain_Q16 + uintptr(k)*4))) - (((6 * 128) / 6) + (16 * 128))))))) + (((((65536 * (64 - 1)) / (((86 - 6) * 128) / 6)) & 0x0000FFFF) * (int32((int16(lin2log(tls, *(*int32)(unsafe.Pointer(gain_Q16 + uintptr(k)*4))) - (((6 * 128) / 6) + (16 * 128))))))) >> 16))

		/* Round towards previous quantized gain (hysteresis) */
		if *(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) < *(*int32)(unsafe.Pointer(prev_ind)) {
			*(*int32)(unsafe.Pointer(ind + uintptr(k)*4))++
		}

		/* Compute delta indices and limit */
		if (k == 0) && (conditional == 0) {
			/* Full index */
			*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) = func() int32 {
				if (0) > (64 - 1) {
					return func() int32 {
						if (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4))) > (0) {
							return 0
						}
						return func() int32 {
							if (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4))) < (64 - 1) {
								return (64 - 1)
							}
							return *(*int32)(unsafe.Pointer(ind + uintptr(k)*4))
						}()
					}()
				}
				return func() int32 {
					if (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4))) > (64 - 1) {
						return (64 - 1)
					}
					return func() int32 {
						if (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4))) < (0) {
							return 0
						}
						return *(*int32)(unsafe.Pointer(ind + uintptr(k)*4))
					}()
				}()
			}()
			*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) = max_int(tls, *(*int32)(unsafe.Pointer(ind + uintptr(k)*4)), (*(*int32)(unsafe.Pointer(prev_ind)) + -4))
			*(*int32)(unsafe.Pointer(prev_ind)) = *(*int32)(unsafe.Pointer(ind + uintptr(k)*4))
		} else {
			/* Delta index */
			*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) = func() int32 {
				if (-4) > (40) {
					return func() int32 {
						if (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) - *(*int32)(unsafe.Pointer(prev_ind))) > (-4) {
							return -4
						}
						return func() int32 {
							if (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) - *(*int32)(unsafe.Pointer(prev_ind))) < (40) {
								return 40
							}
							return (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) - *(*int32)(unsafe.Pointer(prev_ind)))
						}()
					}()
				}
				return func() int32 {
					if (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) - *(*int32)(unsafe.Pointer(prev_ind))) > (40) {
						return 40
					}
					return func() int32 {
						if (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) - *(*int32)(unsafe.Pointer(prev_ind))) < (-4) {
							return -4
						}
						return (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) - *(*int32)(unsafe.Pointer(prev_ind)))
					}()
				}()
			}()
			/* Accumulate deltas */
			*(*int32)(unsafe.Pointer(prev_ind)) += (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)))
			/* Shift to make non-negative */
			*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) -= (-4)
		}

		/* Convert to linear scale and scale */
		*(*int32)(unsafe.Pointer(gain_Q16 + uintptr(k)*4)) = log2lin(tls, min_32(tls, ((((int32(((65536*(((86-6)*128)/6))/(64-1)))>>16)*(int32(int16(*(*int32)(unsafe.Pointer(prev_ind))))))+(((((65536*(((86-6)*128)/6))/(64-1))&0x0000FFFF)*(int32(int16(*(*int32)(unsafe.Pointer(prev_ind))))))>>16))+(((6*128)/6)+(16*128))), 3967)) /* 3968 = 31 in Q7 */
	}
}

/* Gains scalar dequantization, uniform on log scale */
func gains_dequant(tls *libc.TLS, gain_Q16 uintptr, ind uintptr, prev_ind uintptr, conditional int32) { /* gain_quant.c:74:6: */
	var k int32

	for k = 0; k < 4; k++ {
		if (k == 0) && (conditional == 0) {
			*(*int32)(unsafe.Pointer(prev_ind)) = *(*int32)(unsafe.Pointer(ind + uintptr(k)*4))
		} else {
			/* Delta index */
			*(*int32)(unsafe.Pointer(prev_ind)) += (*(*int32)(unsafe.Pointer(ind + uintptr(k)*4)) + -4)
		}

		/* Convert to linear scale and scale */
		*(*int32)(unsafe.Pointer(gain_Q16 + uintptr(k)*4)) = log2lin(tls, min_32(tls, ((((int32(((65536*(((86-6)*128)/6))/(64-1)))>>16)*(int32(int16(*(*int32)(unsafe.Pointer(prev_ind))))))+(((((65536*(((86-6)*128)/6))/(64-1))&0x0000FFFF)*(int32(int16(*(*int32)(unsafe.Pointer(prev_ind))))))>>16))+(((6*128)/6)+(16*128))), 3967)) /* 3968 = 31 in Q7 */
	}
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*******************/
/* Pitch estimator */
/*******************/

/* Level of noise floor for whitening filter LPC analysis in pitch analysis */

/* Bandwidth expansion for whitening filter in pitch analysis */

/* Threshold used by pitch estimator for early escape */

/*********************/
/* Linear prediction */
/*********************/

/* LPC analysis defines: regularization and bandwidth expansion */

/* LTP analysis defines */

/* LTP quantization settings */

/***********************/
/* High pass filtering */
/***********************/

/* Smoothing parameters for low end of pitch frequency range estimation */

/* Min and max values for low end of pitch frequency range estimation */

/* Max absolute difference between log2 of pitch frequency and smoother state, to enter the smoother */

/***********/
/* Various */
/***********/

/* Required speech activity for counting frame as active */

/* Speech Activity LBRR enable threshold (needs tuning) */

/*************************/
/* Perceptual parameters */
/*************************/

/* reduction in coding SNR during low speech activity */

/* factor for reducing quantization noise during voiced speech */

/* factor for reducing quantization noise for unvoiced sparse signals */

/* threshold for sparseness measure above which to use lower quantization offset during unvoiced */

/* warping control */

/* fraction added to first autocorrelation value */

/* noise shaping filter chirp factor */

/* difference between chirp factors for analysis and synthesis noise shaping filters at low bitrates */

/* gain reduction for fricatives */

/* extra harmonic boosting (signal shaping) at low bitrates */

/* extra harmonic boosting (signal shaping) for noisy input signals */

/* harmonic noise shaping */

/* extra harmonic noise shaping for high bitrates or noisy input */

/* parameter for shaping noise towards higher frequencies */

/* parameter for shaping noise even more towards higher frequencies during voiced speech */

/* parameter for applying a high-pass tilt to the input signal */

/* parameter for extra high-pass tilt to the input signal at high rates */

/* parameter for reducing noise at the very low frequencies */

/* less reduction of noise at the very low frequencies for signals with low SNR at low frequencies */

/* noise floor to put a lower limit on the quantization step size */

/* noise floor relative to active speech gain level */

/* subframe smoothing coefficient for determining active speech gain level (lower -> more smoothing) */

/* subframe smoothing coefficient for HarmBoost, HarmShapeGain, Tilt (lower -> more smoothing) */

/* parameters defining the R/D tradeoff in the residual quantizer */

/* High-pass filter with cutoff frequency adaptation based on pitch lag statistics */
func HP_variable_cutoff_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrl uintptr, out uintptr, in uintptr) { /* HP_variable_cutoff_FIX.c:37:6: */
	bp := tls.Alloc(20)
	defer tls.Free(20)

	var quality_Q15 int32
	// var B_Q28 [3]int32 at bp, 12

	// var A_Q28 [2]int32 at bp+12, 8

	var Fc_Q19 int32
	var r_Q28 int32
	var r_Q22 int32
	var pitch_freq_Hz_Q16 int32
	var pitch_freq_log_Q7 int32
	var delta_freq_Q7 int32

	/*********************************************/
	/* Estimate Low End of Pitch Frequency Range */
	/*********************************************/
	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fprev_sigtype == 0 {
		/* difference, in log domain */
		pitch_freq_Hz_Q16 = (((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz) * (1000)) << (16)) / ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FprevLag))
		pitch_freq_log_Q7 = (lin2log(tls, pitch_freq_Hz_Q16) - (int32(16) << 7)) //0x70

		/* adjustment based on quality */
		quality_Q15 = *(*int32)(unsafe.Pointer((psEncCtrl + 620 /* &.input_quality_bands_Q15 */)))
		pitch_freq_log_Q7 = ((pitch_freq_log_Q7) - ((((((((quality_Q15) << (2)) >> 16) * (int32(int16(quality_Q15)))) + (((((quality_Q15) << (2)) & 0x0000FFFF) * (int32(int16(quality_Q15)))) >> 16)) >> 16) * (int32((int16(pitch_freq_log_Q7 - 809))))) + ((((((((quality_Q15) << (2)) >> 16) * (int32(int16(quality_Q15)))) + (((((quality_Q15) << (2)) & 0x0000FFFF) * (int32(int16(quality_Q15)))) >> 16)) & 0x0000FFFF) * (int32((int16(pitch_freq_log_Q7 - 809))))) >> 16)))
		pitch_freq_log_Q7 = ((pitch_freq_log_Q7) + ((FIX_CONST(tls, 0.6, 15) - quality_Q15) >> (9)))

		//delta_freq = pitch_freq_log - psEnc->variable_HP_smth1;
		delta_freq_Q7 = (pitch_freq_log_Q7 - (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth1_Q15) >> (8)))
		if delta_freq_Q7 < 0 {
			/* less smoothing for decreasing pitch frequency, to track something close to the minimum */
			delta_freq_Q7 = ((delta_freq_Q7) * (3))
		}

		/* limit delta, to reduce impact of outliers */
		delta_freq_Q7 = func() int32 {
			if (-FIX_CONST(tls, 0.4, 7)) > (FIX_CONST(tls, 0.4, 7)) {
				return func() int32 {
					if (delta_freq_Q7) > (-FIX_CONST(tls, 0.4, 7)) {
						return -FIX_CONST(tls, 0.4, 7)
					}
					return func() int32 {
						if (delta_freq_Q7) < (FIX_CONST(tls, 0.4, 7)) {
							return FIX_CONST(tls, 0.4, 7)
						}
						return delta_freq_Q7
					}()
				}()
			}
			return func() int32 {
				if (delta_freq_Q7) > (FIX_CONST(tls, 0.4, 7)) {
					return FIX_CONST(tls, 0.4, 7)
				}
				return func() int32 {
					if (delta_freq_Q7) < (-FIX_CONST(tls, 0.4, 7)) {
						return -FIX_CONST(tls, 0.4, 7)
					}
					return delta_freq_Q7
				}()
			}()
		}()

		/* update smoother */
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth1_Q15 = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth1_Q15) + (((((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8) << (1)) * (delta_freq_Q7)) >> 16) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) + (((((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8) << (1)) * (delta_freq_Q7)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) >> 16)))
	}
	/* second smoother */
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth2_Q15 = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth2_Q15) + (((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth1_Q15 - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth2_Q15) >> 16) * (int32(int16(FIX_CONST(tls, 0.015, 16))))) + (((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth1_Q15 - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth2_Q15) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.015, 16))))) >> 16)))

	/* convert from log scale to Hertz */
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fpitch_freq_low_Hz = log2lin(tls, (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth2_Q15) >> (8)))

	/* limit frequency range */
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fpitch_freq_low_Hz = func() int32 {
		if (FIX_CONST(tls, 80.0, 0)) > (FIX_CONST(tls, 150.0, 0)) {
			return func() int32 {
				if ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fpitch_freq_low_Hz) > (FIX_CONST(tls, 80.0, 0)) {
					return FIX_CONST(tls, 80.0, 0)
				}
				return func() int32 {
					if ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fpitch_freq_low_Hz) < (FIX_CONST(tls, 150.0, 0)) {
						return FIX_CONST(tls, 150.0, 0)
					}
					return (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fpitch_freq_low_Hz
				}()
			}()
		}
		return func() int32 {
			if ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fpitch_freq_low_Hz) > (FIX_CONST(tls, 150.0, 0)) {
				return FIX_CONST(tls, 150.0, 0)
			}
			return func() int32 {
				if ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fpitch_freq_low_Hz) < (FIX_CONST(tls, 80.0, 0)) {
					return FIX_CONST(tls, 80.0, 0)
				}
				return (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fpitch_freq_low_Hz
			}()
		}()
	}()

	/********************************/
	/* Compute Filter Coefficients  */
	/********************************/
	/* compute cut-off frequency, in radians */
	//Fc_num   = (float)( 0.45f * 2.0f * 3.14159265359 * psEncCtrl->pitch_freq_low_Hz );
	//Fc_denom = (float)( 1e3f * psEnc->sCmn.fs_kHz );

	Fc_Q19 = (((int32(int16(1482))) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fpitch_freq_low_Hz)))) / ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz)) // range: 3704 - 27787, 11-15 bits

	r_Q28 = (FIX_CONST(tls, 1.0, 28) - ((FIX_CONST(tls, 0.92, 9)) * (Fc_Q19)))

	/* b = r * [ 1; -2; 1 ]; */
	/* a = [ 1; -2 * r * ( 1 - 0.5 * Fc^2 ); r^2 ]; */
	*(*int32)(unsafe.Pointer(bp /* &B_Q28[0] */)) = r_Q28
	*(*int32)(unsafe.Pointer(bp /* &B_Q28[0] */ + 1*4)) = ((-r_Q28) << (1))
	*(*int32)(unsafe.Pointer(bp /* &B_Q28[0] */ + 2*4)) = r_Q28

	// -r * ( 2 - Fc * Fc );
	r_Q22 = ((r_Q28) >> (6))
	*(*int32)(unsafe.Pointer(bp + 12 /* &A_Q28[0] */)) = (((((r_Q22) >> 16) * (int32((int16((((((Fc_Q19) >> 16) * (int32(int16(Fc_Q19)))) + ((((Fc_Q19) & 0x0000FFFF) * (int32(int16(Fc_Q19)))) >> 16)) + ((Fc_Q19) * (func() int32 {
		if (16) == 1 {
			return (((Fc_Q19) >> 1) + ((Fc_Q19) & 1))
		}
		return ((((Fc_Q19) >> ((16) - 1)) + 1) >> 1)
	}()))) - FIX_CONST(tls, 2.0, 22)))))) + ((((r_Q22) & 0x0000FFFF) * (int32((int16((((((Fc_Q19) >> 16) * (int32(int16(Fc_Q19)))) + ((((Fc_Q19) & 0x0000FFFF) * (int32(int16(Fc_Q19)))) >> 16)) + ((Fc_Q19) * (func() int32 {
		if (16) == 1 {
			return (((Fc_Q19) >> 1) + ((Fc_Q19) & 1))
		}
		return ((((Fc_Q19) >> ((16) - 1)) + 1) >> 1)
	}()))) - FIX_CONST(tls, 2.0, 22)))))) >> 16)) + ((r_Q22) * (func() int32 {
		if (16) == 1 {
			return ((((((((Fc_Q19) >> 16) * (int32(int16(Fc_Q19)))) + ((((Fc_Q19) & 0x0000FFFF) * (int32(int16(Fc_Q19)))) >> 16)) + ((Fc_Q19) * (func() int32 {
				if (16) == 1 {
					return (((Fc_Q19) >> 1) + ((Fc_Q19) & 1))
				}
				return ((((Fc_Q19) >> ((16) - 1)) + 1) >> 1)
			}()))) - FIX_CONST(tls, 2.0, 22)) >> 1) + (((((((Fc_Q19) >> 16) * (int32(int16(Fc_Q19)))) + ((((Fc_Q19) & 0x0000FFFF) * (int32(int16(Fc_Q19)))) >> 16)) + ((Fc_Q19) * (func() int32 {
				if (16) == 1 {
					return (((Fc_Q19) >> 1) + ((Fc_Q19) & 1))
				}
				return ((((Fc_Q19) >> ((16) - 1)) + 1) >> 1)
			}()))) - FIX_CONST(tls, 2.0, 22)) & 1))
		}
		return (((((((((Fc_Q19) >> 16) * (int32(int16(Fc_Q19)))) + ((((Fc_Q19) & 0x0000FFFF) * (int32(int16(Fc_Q19)))) >> 16)) + ((Fc_Q19) * (func() int32 {
			if (16) == 1 {
				return (((Fc_Q19) >> 1) + ((Fc_Q19) & 1))
			}
			return ((((Fc_Q19) >> ((16) - 1)) + 1) >> 1)
		}()))) - FIX_CONST(tls, 2.0, 22)) >> ((16) - 1)) + 1) >> 1)
	}())))
	*(*int32)(unsafe.Pointer(bp + 12 /* &A_Q28[0] */ + 1*4)) = (((((r_Q22) >> 16) * (int32(int16(r_Q22)))) + ((((r_Q22) & 0x0000FFFF) * (int32(int16(r_Q22)))) >> 16)) + ((r_Q22) * (func() int32 {
		if (16) == 1 {
			return (((r_Q22) >> 1) + ((r_Q22) & 1))
		}
		return ((((r_Q22) >> ((16) - 1)) + 1) >> 1)
	}())))

	/********************************/
	/* High-Pass Filter             */
	/********************************/
	biquad_alt(tls, in, bp /* &B_Q28[0] */, bp+12 /* &A_Q28[0] */, psEnc /* &.sCmn */ +15008 /* &.In_HP_State */, out, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fframe_length)
}

/*********************************/
/* Initialize Silk Encoder state */
/*********************************/
func init_encoder_FIX(tls *libc.TLS, psEnc uintptr) int32 { /* init_encoder_FIX.c:33:9: */
	var ret int32 = 0
	/* Clear the entire encoder state */
	libc.Xmemset(tls, psEnc, 0, uint32(unsafe.Sizeof(encoder_state_FIX{})))

	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth1_Q15 = 200844 /* = log2(70)_Q0; */
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fvariable_HP_smth2_Q15 = 200844 /* = log2(70)_Q0; */

	/* Used to deactivate e.g. LSF interpolation and fluctuation reduction */
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffirst_frame_after_reset = 1

	/* Initialize Silk VAD */
	ret = ret + (VAD_Init(tls, (psEnc /* &.sCmn */ + 15032 /* &.sVAD */)))

	/* Initialize NSQ */
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsNSQ.Fprev_inv_gain_Q16 = 65536
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FsNSQ_LBRR.Fprev_inv_gain_Q16 = 65536

	return ret
}

/* sum= for(i=0;i<len;i++)inVec1[i]*inVec2[i];      ---        inner product    */
/* Note for ARM asm:                                                            */
/*        * inVec1 and inVec2 should be at least 2 byte aligned.    (Or defined as short/int16) */
/*        * len should be positive 16bit integer.                               */
/*        * only when len>6, memory access can be reduced by half.              */

func inner_prod_aligned(tls *libc.TLS, inVec1 uintptr, inVec2 uintptr, len int32) int32 { /* inner_prod_aligned.c:43:11: */
	var i int32
	var sum int32 = 0
	for i = 0; i < len; i++ {
		sum = ((sum) + ((int32(*(*int16)(unsafe.Pointer(inVec1 + uintptr(i)*2)))) * (int32(*(*int16)(unsafe.Pointer(inVec2 + uintptr(i)*2))))))
	}
	return sum
}

func inner_prod16_aligned_64(tls *libc.TLS, inVec1 uintptr, inVec2 uintptr, len int32) int64_t { /* inner_prod_aligned.c:57:11: */
	var i int32
	var sum int64_t = int64(0)
	for i = 0; i < len; i++ {
		sum = ((sum) + (int64_t((int32(*(*int16)(unsafe.Pointer(inVec1 + uintptr(i)*2)))) * (int32(*(*int16)(unsafe.Pointer(inVec2 + uintptr(i)*2)))))))
	}
	return sum
}

/* Interpolate two vectors */
func interpolate(tls *libc.TLS, xi uintptr, x0 uintptr, x1 uintptr, ifact_Q2 int32, d int32) { /* interpolate.c:31:6: */
	var i int32

	for i = 0; i < d; i++ {
		*(*int32)(unsafe.Pointer(xi + uintptr(i)*4)) = (*(*int32)(unsafe.Pointer(x0 + uintptr(i)*4)) + (((*(*int32)(unsafe.Pointer(x1 + uintptr(i)*4)) - *(*int32)(unsafe.Pointer(x0 + uintptr(i)*4))) * (ifact_Q2)) >> (2)))
	}
}

/* Step up function, converts reflection coefficients to prediction coefficients */
func k2a(tls *libc.TLS, A_Q24 uintptr, rc_Q15 uintptr, order int32) { /* k2a.c:40:6: */
	bp := tls.Alloc(64)
	defer tls.Free(64)

	var k int32
	var n int32
	// var Atmp [16]int32 at bp, 64

	for k = 0; k < order; k++ {
		for n = 0; n < k; n++ {
			*(*int32)(unsafe.Pointer(bp /* &Atmp[0] */ + uintptr(n)*4)) = *(*int32)(unsafe.Pointer(A_Q24 + uintptr(n)*4))
		}
		for n = 0; n < k; n++ {
			*(*int32)(unsafe.Pointer(A_Q24 + uintptr(n)*4)) = ((*(*int32)(unsafe.Pointer(A_Q24 + uintptr(n)*4))) + (((((*(*int32)(unsafe.Pointer(bp /* &Atmp[0] */ + uintptr(((k-n)-1))*4))) << (1)) >> 16) * (int32(*(*int16)(unsafe.Pointer(rc_Q15 + uintptr(k)*2))))) + (((((*(*int32)(unsafe.Pointer(bp /* &Atmp[0] */ + uintptr(((k-n)-1))*4))) << (1)) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(rc_Q15 + uintptr(k)*2))))) >> 16)))
		}
		*(*int32)(unsafe.Pointer(A_Q24 + uintptr(k)*4)) = -((int32(*(*int16)(unsafe.Pointer(rc_Q15 + uintptr(k)*2)))) << (9))
	}
}

/* Step up function, converts reflection coefficients to prediction coefficients */
func k2a_Q16(tls *libc.TLS, A_Q24 uintptr, rc_Q16 uintptr, order int32) { /* k2a_Q16.c:40:6: */
	bp := tls.Alloc(64)
	defer tls.Free(64)

	var k int32
	var n int32
	// var Atmp [16]int32 at bp, 64

	for k = 0; k < order; k++ {
		for n = 0; n < k; n++ {
			*(*int32)(unsafe.Pointer(bp /* &Atmp[0] */ + uintptr(n)*4)) = *(*int32)(unsafe.Pointer(A_Q24 + uintptr(n)*4))
		}
		for n = 0; n < k; n++ {
			*(*int32)(unsafe.Pointer(A_Q24 + uintptr(n)*4)) = (((*(*int32)(unsafe.Pointer(A_Q24 + uintptr(n)*4))) + ((((*(*int32)(unsafe.Pointer(bp /* &Atmp[0] */ + uintptr(((k-n)-1))*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(rc_Q16 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp /* &Atmp[0] */ + uintptr(((k-n)-1))*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(rc_Q16 + uintptr(k)*4)))))) >> 16))) + ((*(*int32)(unsafe.Pointer(bp /* &Atmp[0] */ + uintptr(((k-n)-1))*4))) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer(rc_Q16 + uintptr(k)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(rc_Q16 + uintptr(k)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer(rc_Q16 + uintptr(k)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}
		*(*int32)(unsafe.Pointer(A_Q24 + uintptr(k)*4)) = -((*(*int32)(unsafe.Pointer(rc_Q16 + uintptr(k)*4))) << (8))
	}
}

/* Resets LBRR buffer, used if packet size changes */
func LBRR_reset(tls *libc.TLS, psEncC uintptr) { /* LBRR_reset.c:31:6: */
	var i int32

	for i = 0; i < 2; i++ {
		(*LBRR_struct)(unsafe.Pointer((psEncC + 16256 /* &.LBRR_buffer */) + uintptr(i)*1032)).Fusage = 0
	}
}

/* Approximation of 128 * log2() (very close inverse of approx 2^() below) */
/* Convert input to a log scale    */
func lin2log(tls *libc.TLS, inLin int32) int32 { /* lin2log.c:40:11: */
	bp := tls.Alloc(8)
	defer tls.Free(8)

	// var lz int32 at bp, 4

	// var frac_Q7 int32 at bp+4, 4

	CLZ_FRAC(tls, inLin, bp /* &lz */, bp+4 /* &frac_Q7 */)

	/* Piece-wise parabolic approximation */
	return (((31 - *(*int32)(unsafe.Pointer(bp /* lz */))) << (7)) + ((*(*int32)(unsafe.Pointer(bp + 4 /* frac_Q7 */))) + (((((*(*int32)(unsafe.Pointer(bp + 4 /* frac_Q7 */))) * (128 - *(*int32)(unsafe.Pointer(bp + 4 /* frac_Q7 */)))) >> 16) * (int32(int16(179)))) + (((((*(*int32)(unsafe.Pointer(bp + 4 /* frac_Q7 */))) * (128 - *(*int32)(unsafe.Pointer(bp + 4 /* frac_Q7 */)))) & 0x0000FFFF) * (int32(int16(179)))) >> 16))))
}

/* Approximation of 2^() (very close inverse of lin2log()) */
/* Convert input to a linear scale    */
func log2lin(tls *libc.TLS, inLog_Q7 int32) int32 { /* log2lin.c:40:11: */
	var out int32
	var frac_Q7 int32

	if inLog_Q7 < 0 {
		return 0
	} else if inLog_Q7 >= (int32(31) << 7) {
		/* Saturate, and prevent wrap-around */
		return 0x7FFFFFFF
	}

	out = (int32((1)) << ((inLog_Q7) >> (7)))
	frac_Q7 = (inLog_Q7 & 0x7F)
	if inLog_Q7 < 2048 {
		/* Piece-wise parabolic approximation */
		out = ((out) + (((out) * ((frac_Q7) + (((((frac_Q7) * (128 - frac_Q7)) >> 16) * (int32(int16(-174)))) + (((((frac_Q7) * (128 - frac_Q7)) & 0x0000FFFF) * (int32(int16(-174)))) >> 16)))) >> (7)))
	} else {
		/* Piece-wise parabolic approximation */
		out = ((out) + (((out) >> (7)) * ((frac_Q7) + (((((frac_Q7) * (128 - frac_Q7)) >> 16) * (int32(int16(-174)))) + (((((frac_Q7) * (128 - frac_Q7)) & 0x0000FFFF) * (int32(int16(-174)))) >> 16)))))
	}
	return out
}

/* Compute inverse of LPC prediction gain, and                          */
/* test if LPC coefficients are stable (all poles within unit circle)   */
func LPC_inverse_pred_gain_QA(tls *libc.TLS, invGain_Q30 uintptr, A_QA uintptr, order int32) int32 { /* LPC_inv_pred_gain.c:43:16: */
	var k int32
	var n int32
	var headrm int32
	var rc_Q31 int32
	var rc_mult1_Q30 int32
	var rc_mult2_Q16 int32
	var tmp_QA int32
	var Aold_QA uintptr
	var Anew_QA uintptr

	Anew_QA = A_QA + uintptr((order&1))*64

	*(*int32)(unsafe.Pointer(invGain_Q30)) = (int32(1) << 30)
	for k = (order - 1); k > 0; k-- {
		/* Check for stability */
		if (*(*int32)(unsafe.Pointer(Anew_QA + uintptr(k)*4)) > FIX_CONST(tls, 0.99975, 16)) || (*(*int32)(unsafe.Pointer(Anew_QA + uintptr(k)*4)) < -FIX_CONST(tls, 0.99975, 16)) {
			return 1
		}

		/* Set RC equal to negated AR coef */
		rc_Q31 = -((*(*int32)(unsafe.Pointer(Anew_QA + uintptr(k)*4))) << (31 - 16))

		/* rc_mult1_Q30 range: [ 1 : 2^30-1 ] */
		rc_mult1_Q30 = ((int32(0x7FFFFFFF) >> 1) - (int32(((int64_t(rc_Q31)) * (int64_t(rc_Q31))) >> (32))))
		/* reduce A_LIMIT if fails */

		/* rc_mult2_Q16 range: [ 2^16 : int32_MAX ] */
		rc_mult2_Q16 = INVERSE32_varQ(tls, rc_mult1_Q30, 46) /* 16 = 46 - 30 */

		/* Update inverse gain */
		/* invGain_Q30 range: [ 0 : 2^30 ] */
		*(*int32)(unsafe.Pointer(invGain_Q30)) = ((int32(((int64_t(*(*int32)(unsafe.Pointer(invGain_Q30)))) * (int64_t(rc_mult1_Q30))) >> (32))) << (2))

		/* Swap pointers */
		Aold_QA = Anew_QA
		Anew_QA = A_QA + uintptr((k&1))*64

		/* Update AR coefficient */
		headrm = (CLZ32(tls, rc_mult2_Q16) - 1)
		rc_mult2_Q16 = ((rc_mult2_Q16) << (headrm)) /* Q: 16 + headrm */
		for n = 0; n < k; n++ {
			tmp_QA = (*(*int32)(unsafe.Pointer(Aold_QA + uintptr(n)*4)) - ((int32(((int64_t(*(*int32)(unsafe.Pointer(Aold_QA + uintptr(((k-n)-1))*4)))) * (int64_t(rc_Q31))) >> (32))) << (1)))
			*(*int32)(unsafe.Pointer(Anew_QA + uintptr(n)*4)) = ((int32(((int64_t(tmp_QA)) * (int64_t(rc_mult2_Q16))) >> (32))) << (16 - headrm))
		}
	}

	/* Check for stability */
	if (*(*int32)(unsafe.Pointer(Anew_QA)) > FIX_CONST(tls, 0.99975, 16)) || (*(*int32)(unsafe.Pointer(Anew_QA)) < -FIX_CONST(tls, 0.99975, 16)) {
		return 1
	}

	/* Set RC equal to negated AR coef */
	rc_Q31 = -((*(*int32)(unsafe.Pointer(Anew_QA))) << (31 - 16))

	/* Range: [ 1 : 2^30 ] */
	rc_mult1_Q30 = ((int32(0x7FFFFFFF) >> 1) - (int32(((int64_t(rc_Q31)) * (int64_t(rc_Q31))) >> (32))))

	/* Update inverse gain */
	/* Range: [ 0 : 2^30 ] */
	*(*int32)(unsafe.Pointer(invGain_Q30)) = ((int32(((int64_t(*(*int32)(unsafe.Pointer(invGain_Q30)))) * (int64_t(rc_mult1_Q30))) >> (32))) << (2))

	return 0
}

/* For input in Q12 domain */
func LPC_inverse_pred_gain(tls *libc.TLS, invGain_Q30 uintptr, A_Q12 uintptr, order int32) int32 { /* LPC_inv_pred_gain.c:113:9: */
	bp := tls.Alloc(128)
	defer tls.Free(128)

	var k int32
	// var Atmp_QA [2][16]int32 at bp, 128

	var Anew_QA uintptr

	Anew_QA = (bp /* &Atmp_QA[0] */ + uintptr((order&1))*64)

	/* Increase Q domain of the AR coefficients */
	for k = 0; k < order; k++ {
		*(*int32)(unsafe.Pointer(Anew_QA + uintptr(k)*4)) = ((int32(*(*int16)(unsafe.Pointer(A_Q12 + uintptr(k)*2)))) << (16 - 12))
	}

	return LPC_inverse_pred_gain_QA(tls, invGain_Q30, bp /* &Atmp_QA[0] */, order)
}

/* For input in Q24 domain */
func LPC_inverse_pred_gain_Q24(tls *libc.TLS, invGain_Q30 uintptr, A_Q24 uintptr, order int32) int32 { /* LPC_inv_pred_gain.c:134:9: */
	bp := tls.Alloc(128)
	defer tls.Free(128)

	var k int32
	// var Atmp_QA [2][16]int32 at bp, 128

	var Anew_QA uintptr

	Anew_QA = (bp /* &Atmp_QA[0] */ + uintptr((order&1))*64)

	/* Increase Q domain of the AR coefficients */
	for k = 0; k < order; k++ {
		*(*int32)(unsafe.Pointer(Anew_QA + uintptr(k)*4)) = func() int32 {
			if (24 - 16) == 1 {
				return (((*(*int32)(unsafe.Pointer(A_Q24 + uintptr(k)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(A_Q24 + uintptr(k)*4))) & 1))
			}
			return ((((*(*int32)(unsafe.Pointer(A_Q24 + uintptr(k)*4))) >> ((24 - 16) - 1)) + 1) >> 1)
		}()
	}

	return LPC_inverse_pred_gain_QA(tls, invGain_Q30, bp /* &Atmp_QA[0] */, order)
}

/* even order AR filter */
func LPC_synthesis_filter(tls *libc.TLS, in uintptr, A_Q12 uintptr, Gain_Q26 int32, S uintptr, out uintptr, len int32, Order int32) { /* LPC_synthesis_filter.c:37:6: */
	var k int32
	var j int32
	var idx int32
	var Order_half int32 = ((Order) >> (1))
	var SA int32
	var SB int32
	var out32_Q10 int32
	var out32 int32

	/* Order must be even */

	/* S[] values are in Q14 */
	for k = 0; k < len; k++ {
		SA = *(*int32)(unsafe.Pointer(S + uintptr((Order-1))*4))
		out32_Q10 = 0
		for j = 0; j < (Order_half - 1); j++ {
			idx = (((int32(int16(2))) * (int32(int16(j)))) + 1)
			SB = *(*int32)(unsafe.Pointer(S + uintptr(((Order-1)-idx))*4))
			*(*int32)(unsafe.Pointer(S + uintptr(((Order-1)-idx))*4)) = SA
			out32_Q10 = ((out32_Q10) + ((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + uintptr((j<<1))*2))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + uintptr((j<<1))*2))))) >> 16)))
			out32_Q10 = ((out32_Q10) + ((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + uintptr(((j<<1)+1))*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + uintptr(((j<<1)+1))*2))))) >> 16)))
			SA = *(*int32)(unsafe.Pointer(S + uintptr(((Order-2)-idx))*4))
			*(*int32)(unsafe.Pointer(S + uintptr(((Order-2)-idx))*4)) = SB
		}

		/* unrolled loop: epilog */
		SB = *(*int32)(unsafe.Pointer(S))
		*(*int32)(unsafe.Pointer(S)) = SA
		out32_Q10 = ((out32_Q10) + ((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + uintptr((Order-2))*2))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + uintptr((Order-2))*2))))) >> 16)))
		out32_Q10 = ((out32_Q10) + ((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + uintptr((Order-1))*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + uintptr((Order-1))*2))))) >> 16)))
		/* apply gain to excitation signal and add to prediction */
		out32_Q10 = func() int32 {
			if ((uint32((out32_Q10) + ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))) & 0x80000000) == uint32(0) {
				return func() int32 {
					if ((uint32((out32_Q10) & ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))) & 0x80000000) != uint32(0) {
						return libc.Int32FromUint32(0x80000000)
					}
					return ((out32_Q10) + ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))
				}()
			}
			return func() int32 {
				if ((uint32((out32_Q10) | ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))) & 0x80000000) == uint32(0) {
					return 0x7FFFFFFF
				}
				return ((out32_Q10) + ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))
			}()
		}()

		/* scale to Q0 */
		out32 = func() int32 {
			if (10) == 1 {
				return (((out32_Q10) >> 1) + ((out32_Q10) & 1))
			}
			return ((((out32_Q10) >> ((10) - 1)) + 1) >> 1)
		}()

		/* saturate output */
		*(*int16)(unsafe.Pointer(out + uintptr(k)*2)) = func() int16 {
			if (out32) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (out32) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return int16(out32)
			}()
		}()

		/* move result into delay line */
		*(*int32)(unsafe.Pointer(S + uintptr((Order-1))*4)) = ((func() int32 {
			if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
				return func() int32 {
					if (out32_Q10) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
					}
					return func() int32 {
						if (out32_Q10) < (int32((0x7FFFFFFF)) >> (4)) {
							return (int32((0x7FFFFFFF)) >> (4))
						}
						return out32_Q10
					}()
				}()
			}
			return func() int32 {
				if (out32_Q10) > (int32((0x7FFFFFFF)) >> (4)) {
					return (int32((0x7FFFFFFF)) >> (4))
				}
				return func() int32 {
					if (out32_Q10) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
					}
					return out32_Q10
				}()
			}()
		}()) << (4))
	}
}

/* 16th order AR filter */
func LPC_synthesis_order16(tls *libc.TLS, in uintptr, A_Q12 uintptr, Gain_Q26 int32, S uintptr, out uintptr, len int32) { /* LPC_synthesis_order16.c:37:6: */
	var k int32
	var SA int32
	var SB int32
	var out32_Q10 int32
	var out32 int32
	for k = 0; k < len; k++ {
		/* unrolled loop: prolog */
		/* multiply-add two prediction coefficients per iteration */
		SA = *(*int32)(unsafe.Pointer(S + 15*4))
		SB = *(*int32)(unsafe.Pointer(S + 14*4))
		*(*int32)(unsafe.Pointer(S + 14*4)) = SA
		out32_Q10 = ((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12))))) >> 16))
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 1*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 1*2))))) >> 16)))))
		SA = *(*int32)(unsafe.Pointer(S + 13*4))
		*(*int32)(unsafe.Pointer(S + 13*4)) = SB

		/* unrolled loop: main loop */
		SB = *(*int32)(unsafe.Pointer(S + 12*4))
		*(*int32)(unsafe.Pointer(S + 12*4)) = SA
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 2*2))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 2*2))))) >> 16)))))
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 3*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 3*2))))) >> 16)))))
		SA = *(*int32)(unsafe.Pointer(S + 11*4))
		*(*int32)(unsafe.Pointer(S + 11*4)) = SB

		SB = *(*int32)(unsafe.Pointer(S + 10*4))
		*(*int32)(unsafe.Pointer(S + 10*4)) = SA
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 4*2))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 4*2))))) >> 16)))))
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 5*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 5*2))))) >> 16)))))
		SA = *(*int32)(unsafe.Pointer(S + 9*4))
		*(*int32)(unsafe.Pointer(S + 9*4)) = SB

		SB = *(*int32)(unsafe.Pointer(S + 8*4))
		*(*int32)(unsafe.Pointer(S + 8*4)) = SA
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 6*2))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 6*2))))) >> 16)))))
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 7*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 7*2))))) >> 16)))))
		SA = *(*int32)(unsafe.Pointer(S + 7*4))
		*(*int32)(unsafe.Pointer(S + 7*4)) = SB

		SB = *(*int32)(unsafe.Pointer(S + 6*4))
		*(*int32)(unsafe.Pointer(S + 6*4)) = SA
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 8*2))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 8*2))))) >> 16)))))
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 9*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 9*2))))) >> 16)))))
		SA = *(*int32)(unsafe.Pointer(S + 5*4))
		*(*int32)(unsafe.Pointer(S + 5*4)) = SB

		SB = *(*int32)(unsafe.Pointer(S + 4*4))
		*(*int32)(unsafe.Pointer(S + 4*4)) = SA
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 10*2))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 10*2))))) >> 16)))))
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 11*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 11*2))))) >> 16)))))
		SA = *(*int32)(unsafe.Pointer(S + 3*4))
		*(*int32)(unsafe.Pointer(S + 3*4)) = SB

		SB = *(*int32)(unsafe.Pointer(S + 2*4))
		*(*int32)(unsafe.Pointer(S + 2*4)) = SA
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 12*2))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 12*2))))) >> 16)))))
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 13*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 13*2))))) >> 16)))))
		SA = *(*int32)(unsafe.Pointer(S + 1*4))
		*(*int32)(unsafe.Pointer(S + 1*4)) = SB

		/* unrolled loop: epilog */
		SB = *(*int32)(unsafe.Pointer(S))
		*(*int32)(unsafe.Pointer(S)) = SA
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SA) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 14*2))))) + ((((SA) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 14*2))))) >> 16)))))
		out32_Q10 = (int32((uint32(out32_Q10)) + (uint32((((SB) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 15*2))))) + ((((SB) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q12 + 15*2))))) >> 16)))))

		/* unrolled loop: end */
		/* apply gain to excitation signal and add to prediction */
		out32_Q10 = func() int32 {
			if ((uint32((out32_Q10) + ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))) & 0x80000000) == uint32(0) {
				return func() int32 {
					if ((uint32((out32_Q10) & ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))) & 0x80000000) != uint32(0) {
						return libc.Int32FromUint32(0x80000000)
					}
					return ((out32_Q10) + ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))
				}()
			}
			return func() int32 {
				if ((uint32((out32_Q10) | ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))) & 0x80000000) == uint32(0) {
					return 0x7FFFFFFF
				}
				return ((out32_Q10) + ((((Gain_Q26) >> 16) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) + ((((Gain_Q26) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2))))) >> 16)))
			}()
		}()

		/* scale to Q0 */
		out32 = func() int32 {
			if (10) == 1 {
				return (((out32_Q10) >> 1) + ((out32_Q10) & 1))
			}
			return ((((out32_Q10) >> ((10) - 1)) + 1) >> 1)
		}()

		/* saturate output */
		*(*int16)(unsafe.Pointer(out + uintptr(k)*2)) = func() int16 {
			if (out32) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (out32) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return int16(out32)
			}()
		}()

		/* move result into delay line */
		*(*int32)(unsafe.Pointer(S + 15*4)) = ((func() int32 {
			if (int32((libc.Int32FromUint32(0x80000000))) >> (4)) > (int32((0x7FFFFFFF)) >> (4)) {
				return func() int32 {
					if (out32_Q10) > (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
					}
					return func() int32 {
						if (out32_Q10) < (int32((0x7FFFFFFF)) >> (4)) {
							return (int32((0x7FFFFFFF)) >> (4))
						}
						return out32_Q10
					}()
				}()
			}
			return func() int32 {
				if (out32_Q10) > (int32((0x7FFFFFFF)) >> (4)) {
					return (int32((0x7FFFFFFF)) >> (4))
				}
				return func() int32 {
					if (out32_Q10) < (int32((libc.Int32FromUint32(0x80000000))) >> (4)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (4))
					}
					return out32_Q10
				}()
			}()
		}()) << (4))
	}
}

/* Helper function, that interpolates the filter taps */
func LP_interpolate_filter_taps(tls *libc.TLS, B_Q28 uintptr, A_Q28 uintptr, ind int32, fac_Q16 int32) { /* LP_variable_cutoff.c:40:17: */
	var nb int32
	var na int32

	if ind < (5 - 1) {
		if fac_Q16 > 0 {
			if fac_Q16 == (func() int32 {
				if (fac_Q16) > 0x7FFF {
					return 0x7FFF
				}
				return func() int32 {
					if (fac_Q16) < (int32(libc.Int16FromInt32(0x8000))) {
						return int32(libc.Int16FromInt32(0x8000))
					}
					return fac_Q16
				}()
			}()) { /* fac_Q16 is in range of a 16-bit int */
				/* Piece-wise linear interpolation of B and A */
				for nb = 0; nb < 3; nb++ {
					*(*int32)(unsafe.Pointer(B_Q28 + uintptr(nb)*4)) = ((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr(ind)*12) + uintptr(nb)*4))) + ((((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr((ind+1))*12) + uintptr(nb)*4)) - *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr(ind)*12) + uintptr(nb)*4))) >> 16) * (int32(int16(fac_Q16)))) + ((((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr((ind+1))*12) + uintptr(nb)*4)) - *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr(ind)*12) + uintptr(nb)*4))) & 0x0000FFFF) * (int32(int16(fac_Q16)))) >> 16)))
				}
				for na = 0; na < 2; na++ {
					*(*int32)(unsafe.Pointer(A_Q28 + uintptr(na)*4)) = ((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr(ind)*8) + uintptr(na)*4))) + ((((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr((ind+1))*8) + uintptr(na)*4)) - *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr(ind)*8) + uintptr(na)*4))) >> 16) * (int32(int16(fac_Q16)))) + ((((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr((ind+1))*8) + uintptr(na)*4)) - *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr(ind)*8) + uintptr(na)*4))) & 0x0000FFFF) * (int32(int16(fac_Q16)))) >> 16)))
				}
			} else if fac_Q16 == (int32(1) << 15) { /* Neither fac_Q16 nor ( ( 1 << 16 ) - fac_Q16 ) is in range of a 16-bit int */

				/* Piece-wise linear interpolation of B and A */
				for nb = 0; nb < 3; nb++ {
					*(*int32)(unsafe.Pointer(B_Q28 + uintptr(nb)*4)) = ((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr(ind)*12) + uintptr(nb)*4)) + *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr((ind+1))*12) + uintptr(nb)*4))) >> (1))
				}
				for na = 0; na < 2; na++ {
					*(*int32)(unsafe.Pointer(A_Q28 + uintptr(na)*4)) = ((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr(ind)*8) + uintptr(na)*4)) + *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr((ind+1))*8) + uintptr(na)*4))) >> (1))
				}
			} else { /* ( ( 1 << 16 ) - fac_Q16 ) is in range of a 16-bit int */

				/* Piece-wise linear interpolation of B and A */
				for nb = 0; nb < 3; nb++ {
					*(*int32)(unsafe.Pointer(B_Q28 + uintptr(nb)*4)) = ((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr((ind+1))*12) + uintptr(nb)*4))) + ((((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr(ind)*12) + uintptr(nb)*4)) - *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr((ind+1))*12) + uintptr(nb)*4))) >> 16) * (int32((int16((int32(1) << 16) - fac_Q16))))) + ((((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr(ind)*12) + uintptr(nb)*4)) - *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr((ind+1))*12) + uintptr(nb)*4))) & 0x0000FFFF) * (int32((int16((int32(1) << 16) - fac_Q16))))) >> 16)))
				}
				for na = 0; na < 2; na++ {
					*(*int32)(unsafe.Pointer(A_Q28 + uintptr(na)*4)) = ((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr((ind+1))*8) + uintptr(na)*4))) + ((((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr(ind)*8) + uintptr(na)*4)) - *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr((ind+1))*8) + uintptr(na)*4))) >> 16) * (int32((int16((int32(1) << 16) - fac_Q16))))) + ((((*(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr(ind)*8) + uintptr(na)*4)) - *(*int32)(unsafe.Pointer((uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr((ind+1))*8) + uintptr(na)*4))) & 0x0000FFFF) * (int32((int16((int32(1) << 16) - fac_Q16))))) >> 16)))
				}
			}
		} else {
			libc.Xmemcpy(tls, B_Q28, (uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + uintptr(ind)*12), (uint32(3) * uint32(unsafe.Sizeof(int32(0)))))
			libc.Xmemcpy(tls, A_Q28, (uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + uintptr(ind)*8), (uint32(2) * uint32(unsafe.Sizeof(int32(0)))))
		}
	} else {
		libc.Xmemcpy(tls, B_Q28, (uintptr(unsafe.Pointer(&Transition_LP_B_Q28)) + 4*12), (uint32(3) * uint32(unsafe.Sizeof(int32(0)))))
		libc.Xmemcpy(tls, A_Q28, (uintptr(unsafe.Pointer(&Transition_LP_A_Q28)) + 4*8), (uint32(2) * uint32(unsafe.Sizeof(int32(0)))))
	}
}

/* Low-pass filter with variable cutoff frequency based on  */
/* piece-wise linear interpolation between elliptic filters */
/* Start by setting psEncC->transition_frame_no = 1;            */
/* Deactivate by setting psEncC->transition_frame_no = 0;   */
func LP_variable_cutoff(tls *libc.TLS, psLP uintptr, out uintptr, in uintptr, frame_length int32) { /* LP_variable_cutoff.c:115:6: */
	bp := tls.Alloc(20)
	defer tls.Free(20)

	// var B_Q28 [3]int32 at bp, 12

	// var A_Q28 [2]int32 at bp+12, 8

	var fac_Q16 int32 = 0
	var ind int32 = 0

	/* Interpolate filter coefficients if needed */
	if (*LP_state)(unsafe.Pointer(psLP)).Ftransition_frame_no > 0 {
		if (*LP_state)(unsafe.Pointer(psLP)).Fmode == 0 {
			if (*LP_state)(unsafe.Pointer(psLP)).Ftransition_frame_no < (2560 / 20) {
				/* Calculate index and interpolation factor for interpolation */
				fac_Q16 = (((*LP_state)(unsafe.Pointer(psLP)).Ftransition_frame_no) << (16 - 5))
				ind = ((fac_Q16) >> (16))
				fac_Q16 = fac_Q16 - ((ind) << (16))

				/* Interpolate filter coefficients */
				LP_interpolate_filter_taps(tls, bp /* &B_Q28[0] */, bp+12 /* &A_Q28[0] */, ind, fac_Q16)

				/* Increment transition frame number for next frame */
				(*LP_state)(unsafe.Pointer(psLP)).Ftransition_frame_no++

			} else {

				/* End of transition phase */
				LP_interpolate_filter_taps(tls, bp /* &B_Q28[0] */, bp+12 /* &A_Q28[0] */, (5 - 1), 0)
			}
		} else {

			if (*LP_state)(unsafe.Pointer(psLP)).Ftransition_frame_no < (5120 / 20) {
				/* Calculate index and interpolation factor for interpolation */
				fac_Q16 = (((5120 / 20) - (*LP_state)(unsafe.Pointer(psLP)).Ftransition_frame_no) << (16 - 6))
				ind = ((fac_Q16) >> (16))
				fac_Q16 = fac_Q16 - ((ind) << (16))

				/* Interpolate filter coefficients */
				LP_interpolate_filter_taps(tls, bp /* &B_Q28[0] */, bp+12 /* &A_Q28[0] */, ind, fac_Q16)

				/* Increment transition frame number for next frame */
				(*LP_state)(unsafe.Pointer(psLP)).Ftransition_frame_no++

			} else {

				/* End of transition phase */
				LP_interpolate_filter_taps(tls, bp /* &B_Q28[0] */, bp+12 /* &A_Q28[0] */, 0, 0)
			}
		}
	}

	if (*LP_state)(unsafe.Pointer(psLP)).Ftransition_frame_no > 0 {
		/* ARMA low-pass filtering */

		biquad_alt(tls, in, bp /* &B_Q28[0] */, bp+12 /* &A_Q28[0] */, psLP /* &.In_LP_State */, out, frame_length)
	} else {
		/* Instead of using the filter, copy input directly to output */
		libc.Xmemcpy(tls, out, in, (uint32(frame_length) * uint32(unsafe.Sizeof(int16(0)))))
	}
}

// Q12 values (even)
var LSFCosTab_FIX_Q12 = [129]int32{
	8192, 8190, 8182, 8170,
	8152, 8130, 8104, 8072,
	8034, 7994, 7946, 7896,
	7840, 7778, 7714, 7644,
	7568, 7490, 7406, 7318,
	7226, 7128, 7026, 6922,
	6812, 6698, 6580, 6458,
	6332, 6204, 6070, 5934,
	5792, 5648, 5502, 5352,
	5198, 5040, 4880, 4718,
	4552, 4382, 4212, 4038,
	3862, 3684, 3502, 3320,
	3136, 2948, 2760, 2570,
	2378, 2186, 1990, 1794,
	1598, 1400, 1202, 1002,
	802, 602, 402, 202,
	0, -202, -402, -602,
	-802, -1002, -1202, -1400,
	-1598, -1794, -1990, -2186,
	-2378, -2570, -2760, -2948,
	-3136, -3320, -3502, -3684,
	-3862, -4038, -4212, -4382,
	-4552, -4718, -4880, -5040,
	-5198, -5352, -5502, -5648,
	-5792, -5934, -6070, -6204,
	-6332, -6458, -6580, -6698,
	-6812, -6922, -7026, -7128,
	-7226, -7318, -7406, -7490,
	-7568, -7644, -7714, -7778,
	-7840, -7896, -7946, -7994,
	-8034, -8072, -8104, -8130,
	-8152, -8170, -8182, -8190,
	-8192,
} /* LSF_cos_table.c:31:15 */

func LTP_analysis_filter_FIX(tls *libc.TLS, LTP_res uintptr, x uintptr, LTPCoef_Q14 uintptr, pitchL uintptr, invGains_Q16 uintptr, subfr_length int32, pre_length int32) { /* LTP_analysis_filter_FIX.c:30:6: */
	bp := tls.Alloc(10)
	defer tls.Free(10)

	var x_ptr uintptr
	var x_lag_ptr uintptr
	// var Btmp_Q14 [5]int16 at bp, 10

	var LTP_res_ptr uintptr
	var k int32
	var i int32
	var j int32
	var LTP_est int32

	x_ptr = x
	LTP_res_ptr = LTP_res
	for k = 0; k < 4; k++ {

		x_lag_ptr = (x_ptr - uintptr(*(*int32)(unsafe.Pointer(pitchL + uintptr(k)*4)))*2)
		for i = 0; i < 5; i++ {
			*(*int16)(unsafe.Pointer(bp /* &Btmp_Q14[0] */ + uintptr(i)*2)) = *(*int16)(unsafe.Pointer(LTPCoef_Q14 + uintptr(((k*5)+i))*2))
		}

		/* LTP analysis FIR filter */
		for i = 0; i < (subfr_length + pre_length); i++ {
			*(*int16)(unsafe.Pointer(LTP_res_ptr + uintptr(i)*2)) = *(*int16)(unsafe.Pointer(x_ptr + uintptr(i)*2))

			/* Long-term prediction */
			LTP_est = ((int32(*(*int16)(unsafe.Pointer(x_lag_ptr + 2*2)))) * (int32(*(*int16)(unsafe.Pointer(bp /* &Btmp_Q14[0] */)))))
			for j = 1; j < 5; j++ {
				LTP_est = (int32((uint32(LTP_est)) + (uint32((int32(*(*int16)(unsafe.Pointer(x_lag_ptr + uintptr(((5/2)-j))*2)))) * (int32(*(*int16)(unsafe.Pointer(bp /* &Btmp_Q14[0] */ + uintptr(j)*2))))))))
			}
			LTP_est = func() int32 {
				if (14) == 1 {
					return (((LTP_est) >> 1) + ((LTP_est) & 1))
				}
				return ((((LTP_est) >> ((14) - 1)) + 1) >> 1)
			}() // round and -> Q0

			/* Subtract long-term prediction */
			*(*int16)(unsafe.Pointer(LTP_res_ptr + uintptr(i)*2)) = func() int16 {
				if (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(i)*2))) - LTP_est) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(i)*2))) - LTP_est) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return (int16(int32(*(*int16)(unsafe.Pointer(x_ptr + uintptr(i)*2))) - LTP_est))
				}()
			}()

			/* Scale residual */
			*(*int16)(unsafe.Pointer(LTP_res_ptr + uintptr(i)*2)) = (int16((((*(*int32)(unsafe.Pointer(invGains_Q16 + uintptr(k)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(LTP_res_ptr + uintptr(i)*2))))) + ((((*(*int32)(unsafe.Pointer(invGains_Q16 + uintptr(k)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(LTP_res_ptr + uintptr(i)*2))))) >> 16)))

			x_lag_ptr += 2
		}

		/* Update pointers */
		LTP_res_ptr += 2 * (uintptr(subfr_length + pre_length))
		x_ptr += 2 * (uintptr(subfr_length))
	}
}

/* Table containing trained thresholds for LTP scaling */
var LTPScaleThresholds_Q15 = [11]int16{
	int16(31129), int16(26214), int16(16384), int16(13107), int16(9830), int16(6554),
	int16(4915), int16(3276), int16(2621), int16(2458), int16(0),
} /* LTP_scale_ctrl_FIX.c:33:24 */

func LTP_scale_ctrl_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrl uintptr) { /* LTP_scale_ctrl_FIX.c:39:6: */
	var round_loss int32
	var frames_per_packet int32
	var g_out_Q5 int32
	var g_limit_Q15 int32
	var thrld1_Q15 int32
	var thrld2_Q15 int32

	/* 1st order high-pass filter */
	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FHPLTPredCodGain_Q7 = (max_int(tls, ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7-(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FprevLTPredCodGain_Q7), 0) +
		(func() int32 {
			if (1) == 1 {
				return ((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FHPLTPredCodGain_Q7) >> 1) + (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FHPLTPredCodGain_Q7) & 1))
			}
			return (((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FHPLTPredCodGain_Q7) >> ((1) - 1)) + 1) >> 1)
		}()))

	(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FprevLTPredCodGain_Q7 = (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7

	/* combine input and filtered input */
	g_out_Q5 = func() int32 {
		if (3) == 1 {
			return ((((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7) >> (1)) + (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FHPLTPredCodGain_Q7) >> (1))) >> 1) + (((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7) >> (1)) + (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FHPLTPredCodGain_Q7) >> (1))) & 1))
		}
		return (((((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7) >> (1)) + (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FHPLTPredCodGain_Q7) >> (1))) >> ((3) - 1)) + 1) >> 1)
	}()
	g_limit_Q15 = sigm_Q15(tls, (g_out_Q5 - (int32(3) << 5)))

	/* Default is minimum scaling */
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FLTP_scaleIndex = 0

	/* Round the loss measure to whole pct */
	round_loss = (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketLoss_perc

	/* Only scale if first frame in packet 0% */
	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf == 0 {

		frames_per_packet = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FPacketSize_ms) / (20))

		round_loss = round_loss + (frames_per_packet - 1)
		thrld1_Q15 = int32(LTPScaleThresholds_Q15[min_int(tls, round_loss, (11-1))])
		thrld2_Q15 = int32(LTPScaleThresholds_Q15[min_int(tls, (round_loss+1), (11-1))])

		if g_limit_Q15 > thrld1_Q15 {
			/* Maximum scaling */
			(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FLTP_scaleIndex = 2
		} else if g_limit_Q15 > thrld2_Q15 {
			/* Medium scaling */
			(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FLTP_scaleIndex = 1
		}
	}
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTP_scale_Q14 = int32(LTPScales_table_Q14[(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FLTP_scaleIndex])
}

/* Variable order MA prediction error filter */
func MA_Prediction(tls *libc.TLS, in uintptr, B uintptr, S uintptr, out uintptr, len int32, order int32) { /* MA.c:39:6: */
	var k int32
	var d int32
	var in16 int32
	var out32 int32

	for k = 0; k < len; k++ {
		in16 = int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))
		out32 = (((in16) << (12)) - *(*int32)(unsafe.Pointer(S)))
		out32 = func() int32 {
			if (12) == 1 {
				return (((out32) >> 1) + ((out32) & 1))
			}
			return ((((out32) >> ((12) - 1)) + 1) >> 1)
		}()

		for d = 0; d < (order - 1); d++ {
			*(*int32)(unsafe.Pointer(S + uintptr(d)*4)) = (int32((uint32(*(*int32)(unsafe.Pointer(S + uintptr((d+1))*4)))) + (uint32((int32(int16(in16))) * (int32(*(*int16)(unsafe.Pointer(B + uintptr(d)*2))))))))
		}
		*(*int32)(unsafe.Pointer(S + uintptr((order-1))*4)) = ((int32(int16(in16))) * (int32(*(*int16)(unsafe.Pointer(B + uintptr((order-1))*2)))))

		/* Limit */
		*(*int16)(unsafe.Pointer(out + uintptr(k)*2)) = func() int16 {
			if (out32) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (out32) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return int16(out32)
			}()
		}()
	}
}

func LPC_analysis_filter(tls *libc.TLS, in uintptr, B uintptr, S uintptr, out uintptr, len int32, Order int32) { /* MA.c:67:6: */
	var k int32
	var j int32
	var idx int32
	var Order_half int32 = ((Order) >> (1))
	var out32_Q12 int32
	var out32 int32
	var SA int16
	var SB int16
	/* Order must be even */

	/* S[] values are in Q0 */
	for k = 0; k < len; k++ {
		SA = *(*int16)(unsafe.Pointer(S))
		out32_Q12 = 0
		for j = 0; j < (Order_half - 1); j++ {
			idx = (((int32(int16(2))) * (int32(int16(j)))) + 1)
			/* Multiply-add two prediction coefficients for each loop */
			SB = *(*int16)(unsafe.Pointer(S + uintptr(idx)*2))
			*(*int16)(unsafe.Pointer(S + uintptr(idx)*2)) = SA
			out32_Q12 = ((out32_Q12) + ((int32(SA)) * (int32(*(*int16)(unsafe.Pointer(B + uintptr((idx-1))*2))))))
			out32_Q12 = ((out32_Q12) + ((int32(SB)) * (int32(*(*int16)(unsafe.Pointer(B + uintptr(idx)*2))))))
			SA = *(*int16)(unsafe.Pointer(S + uintptr((idx+1))*2))
			*(*int16)(unsafe.Pointer(S + uintptr((idx+1))*2)) = SB
		}

		/* Unrolled loop: epilog */
		SB = *(*int16)(unsafe.Pointer(S + uintptr((Order-1))*2))
		*(*int16)(unsafe.Pointer(S + uintptr((Order-1))*2)) = SA
		out32_Q12 = ((out32_Q12) + ((int32(SA)) * (int32(*(*int16)(unsafe.Pointer(B + uintptr((Order-2))*2))))))
		out32_Q12 = ((out32_Q12) + ((int32(SB)) * (int32(*(*int16)(unsafe.Pointer(B + uintptr((Order-1))*2))))))

		/* Subtract prediction */
		out32_Q12 = func() int32 {
			if ((uint32(((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (12)) - (out32_Q12))) & 0x80000000) == uint32(0) {
				return func() int32 {
					if (((uint32((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (12))) & ((uint32(out32_Q12)) ^ 0x80000000)) & 0x80000000) != 0 {
						return libc.Int32FromUint32(0x80000000)
					}
					return (((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (12)) - (out32_Q12))
				}()
			}
			return func() int32 {
				if ((((uint32((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (12))) ^ 0x80000000) & (uint32(out32_Q12))) & 0x80000000) != 0 {
					return 0x7FFFFFFF
				}
				return (((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (12)) - (out32_Q12))
			}()
		}()

		/* Scale to Q0 */
		out32 = func() int32 {
			if (12) == 1 {
				return (((out32_Q12) >> 1) + ((out32_Q12) & 1))
			}
			return ((((out32_Q12) >> ((12) - 1)) + 1) >> 1)
		}()

		/* Saturate output */
		*(*int16)(unsafe.Pointer(out + uintptr(k)*2)) = func() int16 {
			if (out32) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (out32) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return int16(out32)
			}()
		}()

		/* Move input line */
		*(*int16)(unsafe.Pointer(S)) = *(*int16)(unsafe.Pointer(in + uintptr(k)*2))
	}
}

/* helper function for NLSF2A(..) */
func NLSF2A_find_poly(tls *libc.TLS, out uintptr, cLSF uintptr, dd int32) { /* NLSF2A.c:37:17: */
	var k int32
	var n int32
	var ftmp int32

	*(*int32)(unsafe.Pointer(out)) = (int32((1)) << (20))
	*(*int32)(unsafe.Pointer(out + 1*4)) = -*(*int32)(unsafe.Pointer(cLSF))
	for k = 1; k < dd; k++ {
		ftmp = *(*int32)(unsafe.Pointer(cLSF + uintptr((2*k))*4)) // Q20
		*(*int32)(unsafe.Pointer(out + uintptr((k+1))*4)) = (((*(*int32)(unsafe.Pointer(out + uintptr((k-1))*4))) << (1)) - (func() int32 {
			if (20) == 1 {
				return (int32((((int64_t(ftmp)) * (int64_t(*(*int32)(unsafe.Pointer(out + uintptr(k)*4))))) >> 1) + (((int64_t(ftmp)) * (int64_t(*(*int32)(unsafe.Pointer(out + uintptr(k)*4))))) & int64(1))))
			}
			return (int32(((((int64_t(ftmp)) * (int64_t(*(*int32)(unsafe.Pointer(out + uintptr(k)*4))))) >> ((20) - 1)) + int64(1)) >> 1))
		}()))
		for n = k; n > 1; n-- {
			*(*int32)(unsafe.Pointer(out + uintptr(n)*4)) += (*(*int32)(unsafe.Pointer(out + uintptr((n-2))*4)) - (func() int32 {
				if (20) == 1 {
					return (int32((((int64_t(ftmp)) * (int64_t(*(*int32)(unsafe.Pointer(out + uintptr((n-1))*4))))) >> 1) + (((int64_t(ftmp)) * (int64_t(*(*int32)(unsafe.Pointer(out + uintptr((n-1))*4))))) & int64(1))))
				}
				return (int32(((((int64_t(ftmp)) * (int64_t(*(*int32)(unsafe.Pointer(out + uintptr((n-1))*4))))) >> ((20) - 1)) + int64(1)) >> 1))
			}()))
		}
		*(*int32)(unsafe.Pointer(out + 1*4)) -= (ftmp)
	}
}

/* compute whitening filter coefficients from normalized line spectral frequencies */
func NLSF2A(tls *libc.TLS, a uintptr, NLSF uintptr, d int32) { /* NLSF2A.c:59:6: */
	bp := tls.Alloc(200)
	defer tls.Free(200)

	var k int32
	var i int32
	var dd int32
	// var cos_LSF_Q20 [16]int32 at bp, 64

	// var P [9]int32 at bp+64, 36

	// var Q [9]int32 at bp+100, 36

	var Ptmp int32
	var Qtmp int32
	var f_int int32
	var f_frac int32
	var cos_val int32
	var delta int32
	// var a_int32 [16]int32 at bp+136, 64

	var maxabs int32
	var absval int32
	var idx int32 = 0
	var sc_Q16 int32

	/* convert LSFs to 2*cos(LSF(i)), using piecewise linear curve from table */
	for k = 0; k < d; k++ {

		/* f_int on a scale 0-127 (rounded down) */
		f_int = ((*(*int32)(unsafe.Pointer(NLSF + uintptr(k)*4))) >> (15 - 7))

		/* f_frac, range: 0..255 */
		f_frac = (*(*int32)(unsafe.Pointer(NLSF + uintptr(k)*4)) - ((f_int) << (15 - 7)))

		/* Read start and end value from table */
		cos_val = LSFCosTab_FIX_Q12[f_int]               /* Q12 */
		delta = (LSFCosTab_FIX_Q12[(f_int+1)] - cos_val) /* Q12, with a range of 0..200 */

		/* Linear interpolation */
		*(*int32)(unsafe.Pointer(bp /* &cos_LSF_Q20[0] */ + uintptr(k)*4)) = (((cos_val) << (8)) + ((delta) * (f_frac))) /* Q20 */
	}

	dd = ((d) >> (1))

	/* generate even and odd polynomials using convolution */
	NLSF2A_find_poly(tls, bp+64 /* &P[0] */, (bp /* &cos_LSF_Q20 */), dd)
	NLSF2A_find_poly(tls, bp+100 /* &Q[0] */, (bp /* &cos_LSF_Q20 */ + 1*4), dd)

	/* convert even and odd polynomials to int32 Q12 filter coefs */
	for k = 0; k < dd; k++ {
		Ptmp = (*(*int32)(unsafe.Pointer(bp + 64 /* &P[0] */ + uintptr((k+1))*4)) + *(*int32)(unsafe.Pointer(bp + 64 /* &P[0] */ + uintptr(k)*4)))
		Qtmp = (*(*int32)(unsafe.Pointer(bp + 100 /* &Q[0] */ + uintptr((k+1))*4)) - *(*int32)(unsafe.Pointer(bp + 100 /* &Q[0] */ + uintptr(k)*4)))

		/* the Ptmp and Qtmp values at this stage need to fit in int32 */

		*(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(k)*4)) = -func() int32 {
			if (9) == 1 {
				return (((Ptmp + Qtmp) >> 1) + ((Ptmp + Qtmp) & 1))
			}
			return ((((Ptmp + Qtmp) >> ((9) - 1)) + 1) >> 1)
		}() /* Q20 -> Q12 */
		*(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(((d-k)-1))*4)) = func() int32 {
			if (9) == 1 {
				return (((Qtmp - Ptmp) >> 1) + ((Qtmp - Ptmp) & 1))
			}
			return ((((Qtmp - Ptmp) >> ((9) - 1)) + 1) >> 1)
		}() /* Q20 -> Q12 */
	}

	/* Limit the maximum absolute value of the prediction coefficients */
	for i = 0; i < 10; i++ {
		/* Find maximum absolute value and its index */
		maxabs = 0
		for k = 0; k < d; k++ {
			absval = func() int32 {
				if (*(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(k)*4))) > 0 {
					return *(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(k)*4))
				}
				return -*(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(k)*4))
			}()
			if absval > maxabs {
				maxabs = absval
				idx = k
			}
		}

		if maxabs > 0x7FFF {
			/* Reduce magnitude of prediction coefficients */
			maxabs = func() int32 {
				if (maxabs) < (98369) {
					return maxabs
				}
				return 98369
			}() // ( int32_MAX / ( 65470 >> 2 ) ) + int16_MAX = 98369
			sc_Q16 = (65470 - (((int32(65470) >> 2) * (maxabs - 0x7FFF)) / (((maxabs) * (idx + 1)) >> (2))))
			bwexpander_32(tls, bp+136 /* &a_int32[0] */, d, sc_Q16)
		} else {
			break
		}
	}

	/* Reached the last iteration */
	if i == 10 {

		for k = 0; k < d; k++ {
			*(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(k)*4)) = func() int32 {
				if (*(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(k)*4))) > 0x7FFF {
					return 0x7FFF
				}
				return func() int32 {
					if (*(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(k)*4))) < (int32(libc.Int16FromInt32(0x8000))) {
						return int32(libc.Int16FromInt32(0x8000))
					}
					return *(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(k)*4))
				}()
			}()
		}
	}

	/* Return as int16 Q12 coefficients */
	for k = 0; k < d; k++ {
		*(*int16)(unsafe.Pointer(a + uintptr(k)*2)) = int16(*(*int32)(unsafe.Pointer(bp + 136 /* &a_int32[0] */ + uintptr(k)*4)))
	}
}

/* Convert NLSF parameters to stable AR prediction filter coefficients */
func NLSF2A_stable(tls *libc.TLS, pAR_Q12 uintptr, pNLSF uintptr, LPC_order int32) { /* NLSF2A_stable.c:31:6: */
	bp := tls.Alloc(4)
	defer tls.Free(4)

	var i int32
	// var invGain_Q30 int32 at bp, 4

	NLSF2A(tls, pAR_Q12, pNLSF, LPC_order)

	/* Ensure stable LPCs */
	for i = 0; i < 20; i++ {
		if LPC_inverse_pred_gain(tls, bp /* &invGain_Q30 */, pAR_Q12, LPC_order) == 1 {
			bwexpander(tls, pAR_Q12, LPC_order, (65536 - ((int32((int16(10 + i)))) * (int32(int16(i)))))) /* 10_Q16 = 0.00015 */
		} else {
			break
		}
	}

	/* Reached the last iteration */
	if i == 20 {

		for i = 0; i < LPC_order; i++ {
			*(*int16)(unsafe.Pointer(pAR_Q12 + uintptr(i)*2)) = int16(0)
		}
	}
}

/* NLSF vector decoder */
func NLSF_MSVQ_decode(tls *libc.TLS, pNLSF_Q15 uintptr, psNLSF_CB uintptr, NLSFIndices uintptr, LPC_order int32) { /* NLSF_MSVQ_decode.c:31:6: */
	var pCB_element uintptr
	var s int32
	var i int32

	/* Check that each index is within valid range */

	/* Point to the first vector element */
	pCB_element = ((*NLSF_CBS)(unsafe.Pointer((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FCBStages)).FCB_NLSF_Q15 + uintptr(((*(*int32)(unsafe.Pointer(NLSFIndices)))*(LPC_order)))*2)

	/* Initialize with the codebook vector from stage 0 */
	for i = 0; i < LPC_order; i++ {
		*(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr(i)*4)) = int32(*(*int16)(unsafe.Pointer(pCB_element + uintptr(i)*2)))
	}

	for s = 1; s < (*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages; s++ {
		/* Check that each index is within valid range */

		if LPC_order == 16 {
			/* Point to the first vector element */
			pCB_element = ((*NLSF_CBS)(unsafe.Pointer((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FCBStages+uintptr(s)*12)).FCB_NLSF_Q15 + uintptr(((*(*int32)(unsafe.Pointer(NLSFIndices + uintptr(s)*4)))<<(4)))*2)

			/* Add the codebook vector from the current stage */
			*(*int32)(unsafe.Pointer(pNLSF_Q15)) += (int32(*(*int16)(unsafe.Pointer(pCB_element))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 1*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 1*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 2*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 2*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 3*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 3*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 4*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 4*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 5*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 5*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 6*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 6*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 7*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 7*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 8*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 8*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 9*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 9*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 10*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 10*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 11*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 11*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 12*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 12*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 13*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 13*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 14*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 14*2))))
			*(*int32)(unsafe.Pointer(pNLSF_Q15 + 15*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + 15*2))))
		} else {
			/* Point to the first vector element */
			pCB_element = ((*NLSF_CBS)(unsafe.Pointer((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FCBStages+uintptr(s)*12)).FCB_NLSF_Q15 + uintptr(((int32(int16(*(*int32)(unsafe.Pointer(NLSFIndices + uintptr(s)*4)))))*(int32(int16(LPC_order)))))*2)

			/* Add the codebook vector from the current stage */
			for i = 0; i < LPC_order; i++ {
				*(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr(i)*4)) += (int32(*(*int16)(unsafe.Pointer(pCB_element + uintptr(i)*2))))
			}
		}
	}

	/* NLSF stabilization */
	NLSF_stabilize(tls, pNLSF_Q15, (*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FNDeltaMin_Q15, LPC_order)
}

/***********************/
/* NLSF vector encoder */
/***********************/
func NLSF_MSVQ_encode_FIX(tls *libc.TLS, NLSFIndices uintptr, pNLSF_Q15 uintptr, psNLSF_CB uintptr, pNLSF_q_Q15_prev uintptr, pW_Q6 uintptr, NLSF_mu_Q15 int32, NLSF_mu_fluc_red_Q16 int32, NLSF_MSVQ_Survivors int32, LPC_order int32, deactivate_fluc_red int32) { /* NLSF_MSVQ_encode_FIX.c:33:6: */
	bp := tls.Alloc(4544)
	defer tls.Free(4544)

	var i int32
	var s int32
	var k int32
	var cur_survivors int32 = 0
	var prev_survivors int32
	var min_survivors int32
	var input_index int32
	var cb_index int32
	var bestIndex int32
	var rateDistThreshold_Q18 int32
	var se_Q15 int32
	var wsse_Q20 int32
	var bestRateDist_Q20 int32
	// var pRateDist_Q18 [256]int32 at bp+1088, 1024

	// var pRate_Q5 [16]int32 at bp, 64

	// var pRate_new_Q5 [16]int32 at bp+3200, 64

	// var pTempIndices [16]int32 at bp+2112, 64

	// var pPath [160]int32 at bp+3264, 640

	// var pPath_new [160]int32 at bp+3904, 640

	// var pRes_Q15 [256]int32 at bp+64, 1024

	// var pRes_new_Q15 [256]int32 at bp+2176, 1024

	var pConstInt uintptr
	var pInt uintptr
	var pCB_element uintptr
	var pCurrentCBStage uintptr

	/****************************************************/
	/* Tree search for the multi-stage vector quantizer */
	/****************************************************/

	/* Clear accumulated rates */
	libc.Xmemset(tls, bp /* &pRate_Q5[0] */, 0, (uint32(NLSF_MSVQ_Survivors) * uint32(unsafe.Sizeof(int32(0)))))

	/* Copy NLSFs into residual signal vector */
	for i = 0; i < LPC_order; i++ {
		*(*int32)(unsafe.Pointer(bp + 64 /* &pRes_Q15[0] */ + uintptr(i)*4)) = *(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr(i)*4))
	}

	/* Set first stage values */
	prev_survivors = 1

	/* Minimum number of survivors */
	min_survivors = (NLSF_MSVQ_Survivors / 2)

	/* Loop over all stages */
	for s = 0; s < (*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages; s++ {

		/* Set a pointer to the current stage codebook */
		pCurrentCBStage = ((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FCBStages + uintptr(s)*12)

		/* Calculate the number of survivors in the current stage */
		cur_survivors = min_32(tls, NLSF_MSVQ_Survivors, ((int32(int16(prev_survivors))) * (int32(int16((*NLSF_CBS)(unsafe.Pointer(pCurrentCBStage)).FnVectors)))))

		/* Nearest neighbor clustering for multiple input data vectors */
		NLSF_VQ_rate_distortion_FIX(tls, bp+1088 /* &pRateDist_Q18[0] */, pCurrentCBStage, bp+64 /* &pRes_Q15[0] */, pW_Q6,
			bp /* &pRate_Q5[0] */, NLSF_mu_Q15, prev_survivors, LPC_order)

		/* Sort the rate-distortion errors */
		insertion_sort_increasing(tls, bp+1088 /* &pRateDist_Q18[0] */, bp+2112, /* &pTempIndices[0] */
			(prev_survivors * (*NLSF_CBS)(unsafe.Pointer(pCurrentCBStage)).FnVectors), cur_survivors)

		/* Discard survivors with rate-distortion values too far above the best one */
		if *(*int32)(unsafe.Pointer(bp + 1088 /* &pRateDist_Q18[0] */)) < (0x7FFFFFFF / 16) {
			rateDistThreshold_Q18 = ((*(*int32)(unsafe.Pointer(bp + 1088 /* &pRateDist_Q18[0] */))) + (((((NLSF_MSVQ_Survivors) * (*(*int32)(unsafe.Pointer(bp + 1088 /* &pRateDist_Q18[0] */)))) >> 16) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) + (((((NLSF_MSVQ_Survivors) * (*(*int32)(unsafe.Pointer(bp + 1088 /* &pRateDist_Q18[0] */)))) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) >> 16)))
			for (*(*int32)(unsafe.Pointer(bp + 1088 /* &pRateDist_Q18[0] */ + uintptr((cur_survivors-1))*4)) > rateDistThreshold_Q18) && (cur_survivors > min_survivors) {
				cur_survivors--
			}
		}
		/* Update accumulated codebook contributions for the 'cur_survivors' best codebook indices */
		for k = 0; k < cur_survivors; k++ {
			if s > 0 {
				/* Find the indices of the input and the codebook vector */
				if (*NLSF_CBS)(unsafe.Pointer(pCurrentCBStage)).FnVectors == 8 {
					input_index = ((*(*int32)(unsafe.Pointer(bp + 2112 /* &pTempIndices[0] */ + uintptr(k)*4))) >> (3))
					cb_index = (*(*int32)(unsafe.Pointer(bp + 2112 /* &pTempIndices[0] */ + uintptr(k)*4)) & 7)
				} else {
					input_index = ((*(*int32)(unsafe.Pointer(bp + 2112 /* &pTempIndices[0] */ + uintptr(k)*4))) / ((*NLSF_CBS)(unsafe.Pointer(pCurrentCBStage)).FnVectors))
					cb_index = (*(*int32)(unsafe.Pointer(bp + 2112 /* &pTempIndices[0] */ + uintptr(k)*4)) - ((int32(int16(input_index))) * (int32(int16((*NLSF_CBS)(unsafe.Pointer(pCurrentCBStage)).FnVectors)))))
				}
			} else {
				/* Find the indices of the input and the codebook vector */
				input_index = 0
				cb_index = *(*int32)(unsafe.Pointer(bp + 2112 /* &pTempIndices[0] */ + uintptr(k)*4))
			}

			/* Subtract new contribution from the previous residual vector for each of 'cur_survivors' */
			pConstInt = (bp + 64 /* &pRes_Q15 */ + uintptr(((int32(int16(input_index)))*(int32(int16(LPC_order)))))*4)
			pCB_element = ((*NLSF_CBS)(unsafe.Pointer(pCurrentCBStage)).FCB_NLSF_Q15 + uintptr(((int32(int16(cb_index)))*(int32(int16(LPC_order)))))*2)
			pInt = (bp + 2176 /* &pRes_new_Q15 */ + uintptr(((int32(int16(k)))*(int32(int16(LPC_order)))))*4)
			for i = 0; i < LPC_order; i++ {
				*(*int32)(unsafe.Pointer(pInt + uintptr(i)*4)) = (*(*int32)(unsafe.Pointer(pConstInt + uintptr(i)*4)) - int32(*(*int16)(unsafe.Pointer(pCB_element + uintptr(i)*2))))
			}

			/* Update accumulated rate for stage 1 to the current */
			*(*int32)(unsafe.Pointer(bp + 3200 /* &pRate_new_Q5[0] */ + uintptr(k)*4)) = (*(*int32)(unsafe.Pointer(bp /* &pRate_Q5[0] */ + uintptr(input_index)*4)) + int32(*(*int16)(unsafe.Pointer((*NLSF_CBS)(unsafe.Pointer(pCurrentCBStage)).FRates_Q5 + uintptr(cb_index)*2))))

			/* Copy paths from previous matrix, starting with the best path */
			pConstInt = (bp + 3264 /* &pPath */ + uintptr(((int32(int16(input_index)))*(int32(int16((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages)))))*4)
			pInt = (bp + 3904 /* &pPath_new */ + uintptr(((int32(int16(k)))*(int32(int16((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages)))))*4)
			for i = 0; i < s; i++ {
				*(*int32)(unsafe.Pointer(pInt + uintptr(i)*4)) = *(*int32)(unsafe.Pointer(pConstInt + uintptr(i)*4))
			}
			/* Write the current stage indices for the 'cur_survivors' to the best path matrix */
			*(*int32)(unsafe.Pointer(pInt + uintptr(s)*4)) = cb_index
		}

		if s < ((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages - 1) {
			/* Copy NLSF residual matrix for next stage */
			libc.Xmemcpy(tls, bp+64 /* &pRes_Q15[0] */, bp+2176 /* &pRes_new_Q15[0] */, ((uint32((int32(int16(cur_survivors))) * (int32(int16(LPC_order))))) * uint32(unsafe.Sizeof(int32(0)))))

			/* Copy rate vector for next stage */
			libc.Xmemcpy(tls, bp /* &pRate_Q5[0] */, bp+3200 /* &pRate_new_Q5[0] */, (uint32(cur_survivors) * uint32(unsafe.Sizeof(int32(0)))))

			/* Copy best path matrix for next stage */
			libc.Xmemcpy(tls, bp+3264 /* &pPath[0] */, bp+3904 /* &pPath_new[0] */, ((uint32((int32(int16(cur_survivors))) * (int32(int16((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages))))) * uint32(unsafe.Sizeof(int32(0)))))
		}

		prev_survivors = cur_survivors
	}

	/* (Preliminary) index of the best survivor, later to be decoded */
	bestIndex = 0

	/******************************/
	/* NLSF fluctuation reduction */
	/******************************/
	if deactivate_fluc_red != 1 {

		/* Search among all survivors, now taking also weighted fluctuation errors into account */
		bestRateDist_Q20 = 0x7FFFFFFF
		for s = 0; s < cur_survivors; s++ {
			/* Decode survivor to compare with previous quantized NLSF vector */
			NLSF_MSVQ_decode(tls, pNLSF_Q15, psNLSF_CB, (bp + 3904 /* &pPath_new */ + uintptr(((int32(int16(s)))*(int32(int16((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages)))))*4), LPC_order)

			/* Compare decoded NLSF vector with the previously quantized vector */
			wsse_Q20 = 0
			for i = 0; i < LPC_order; i = i + (2) {
				/* Compute weighted squared quantization error for index i */
				se_Q15 = (*(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr(i)*4)) - *(*int32)(unsafe.Pointer(pNLSF_q_Q15_prev + uintptr(i)*4))) // range: [ -32767 : 32767 ]
				wsse_Q20 = ((wsse_Q20) + (((((int32(int16(se_Q15))) * (int32(int16(se_Q15)))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(pW_Q6 + uintptr(i)*4)))))) + (((((int32(int16(se_Q15))) * (int32(int16(se_Q15)))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(pW_Q6 + uintptr(i)*4)))))) >> 16)))

				/* Compute weighted squared quantization error for index i + 1 */
				se_Q15 = (*(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr((i+1))*4)) - *(*int32)(unsafe.Pointer(pNLSF_q_Q15_prev + uintptr((i+1))*4))) // range: [ -32767 : 32767 ]
				wsse_Q20 = ((wsse_Q20) + (((((int32(int16(se_Q15))) * (int32(int16(se_Q15)))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(pW_Q6 + uintptr((i+1))*4)))))) + (((((int32(int16(se_Q15))) * (int32(int16(se_Q15)))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(pW_Q6 + uintptr((i+1))*4)))))) >> 16)))
			}

			/* Add the fluctuation reduction penalty to the rate distortion error */
			wsse_Q20 = func() int32 {
				if ((uint32((*(*int32)(unsafe.Pointer(bp + 1088 /* &pRateDist_Q18[0] */ + uintptr(s)*4))) + ((((wsse_Q20) >> 16) * (int32(int16(NLSF_mu_fluc_red_Q16)))) + ((((wsse_Q20) & 0x0000FFFF) * (int32(int16(NLSF_mu_fluc_red_Q16)))) >> 16)))) & 0x80000000) != 0 {
					return 0x7FFFFFFF
				}
				return ((*(*int32)(unsafe.Pointer(bp + 1088 /* &pRateDist_Q18[0] */ + uintptr(s)*4))) + ((((wsse_Q20) >> 16) * (int32(int16(NLSF_mu_fluc_red_Q16)))) + ((((wsse_Q20) & 0x0000FFFF) * (int32(int16(NLSF_mu_fluc_red_Q16)))) >> 16)))
			}()

			/* Keep index of best survivor */
			if wsse_Q20 < bestRateDist_Q20 {
				bestRateDist_Q20 = wsse_Q20
				bestIndex = s
			}
		}
	}

	/* Copy best path to output argument */
	libc.Xmemcpy(tls, NLSFIndices, (bp + 3904 /* &pPath_new */ + uintptr(((int32(int16(bestIndex)))*(int32(int16((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages)))))*4), (uint32((*NLSF_CB_struct)(unsafe.Pointer(psNLSF_CB)).FnStages) * uint32(unsafe.Sizeof(int32(0)))))

	/* Decode and stabilize the best survivor */
	NLSF_MSVQ_decode(tls, pNLSF_Q15, psNLSF_CB, NLSFIndices, LPC_order)

}

/* Constant Definitions */

/* NLSF stabilizer, for a single input data vector */
func NLSF_stabilize(tls *libc.TLS, NLSF_Q15 uintptr, NDeltaMin_Q15 uintptr, L int32) { /* NLSF_stabilize.c:42:6: */
	var center_freq_Q15 int32
	var diff_Q15 int32
	var min_center_Q15 int32
	var max_center_Q15 int32
	var min_diff_Q15 int32
	var loops int32
	var i int32
	var I int32 = 0
	var k int32

	/* This is necessary to ensure an output within range of a int16 */

	for loops = 0; loops < 20; loops++ {
		/**************************/
		/* Find smallest distance */
		/**************************/
		/* First element */
		min_diff_Q15 = (*(*int32)(unsafe.Pointer(NLSF_Q15)) - *(*int32)(unsafe.Pointer(NDeltaMin_Q15)))
		I = 0
		/* Middle elements */
		for i = 1; i <= (L - 1); i++ {
			diff_Q15 = (*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(i)*4)) - (*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((i-1))*4)) + *(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(i)*4))))
			if diff_Q15 < min_diff_Q15 {
				min_diff_Q15 = diff_Q15
				I = i
			}
		}
		/* Last element */
		diff_Q15 = ((int32(1) << 15) - (*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((L-1))*4)) + *(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(L)*4))))
		if diff_Q15 < min_diff_Q15 {
			min_diff_Q15 = diff_Q15
			I = L
		}

		/***************************************************/
		/* Now check if the smallest distance non-negative */
		/***************************************************/
		if min_diff_Q15 >= 0 {
			return
		}

		if I == 0 {
			/* Move away from lower limit */
			*(*int32)(unsafe.Pointer(NLSF_Q15)) = *(*int32)(unsafe.Pointer(NDeltaMin_Q15))

		} else if I == L {
			/* Move away from higher limit */
			*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((L-1))*4)) = ((int32(1) << 15) - *(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(L)*4)))

		} else {
			/* Find the lower extreme for the location of the current center frequency */
			min_center_Q15 = 0
			for k = 0; k < I; k++ {
				min_center_Q15 = min_center_Q15 + (*(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(k)*4)))
			}
			min_center_Q15 = min_center_Q15 + ((*(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(I)*4))) >> (1))

			/* Find the upper extreme for the location of the current center frequency */
			max_center_Q15 = (int32(1) << 15)
			for k = L; k > I; k-- {
				max_center_Q15 = max_center_Q15 - (*(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(k)*4)))
			}
			max_center_Q15 = max_center_Q15 - (*(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(I)*4)) - ((*(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(I)*4))) >> (1)))

			/* Move apart, sorted by value, keeping the same center frequency */
			center_freq_Q15 = func() int32 {
				if (min_center_Q15) > (max_center_Q15) {
					return func() int32 {
						if (func() int32 {
							if (1) == 1 {
								return (((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> ((1) - 1)) + 1) >> 1)
						}()) > (min_center_Q15) {
							return min_center_Q15
						}
						return func() int32 {
							if (func() int32 {
								if (1) == 1 {
									return (((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) & 1))
								}
								return ((((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> ((1) - 1)) + 1) >> 1)
							}()) < (max_center_Q15) {
								return max_center_Q15
							}
							return func() int32 {
								if (1) == 1 {
									return (((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) & 1))
								}
								return ((((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> ((1) - 1)) + 1) >> 1)
							}()
						}()
					}()
				}
				return func() int32 {
					if (func() int32 {
						if (1) == 1 {
							return (((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> ((1) - 1)) + 1) >> 1)
					}()) > (max_center_Q15) {
						return max_center_Q15
					}
					return func() int32 {
						if (func() int32 {
							if (1) == 1 {
								return (((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> ((1) - 1)) + 1) >> 1)
						}()) < (min_center_Q15) {
							return min_center_Q15
						}
						return func() int32 {
							if (1) == 1 {
								return (((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4))) >> ((1) - 1)) + 1) >> 1)
						}()
					}()
				}()
			}()
			*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) = (center_freq_Q15 - ((*(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(I)*4))) >> (1)))
			*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(I)*4)) = (*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((I-1))*4)) + *(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(I)*4)))
		}
	}

	/* Safe and simple fall back method, which is less ideal than the above */
	if loops == 20 {
		/* Insertion sort (fast for already almost sorted arrays):   */
		/* Best case:  O(n)   for an already sorted array            */
		/* Worst case: O(n^2) for an inversely sorted array          */
		insertion_sort_increasing_all_values(tls, (NLSF_Q15), L)

		/* First NLSF should be no less than NDeltaMin[0] */
		*(*int32)(unsafe.Pointer(NLSF_Q15)) = max_int(tls, *(*int32)(unsafe.Pointer(NLSF_Q15)), *(*int32)(unsafe.Pointer(NDeltaMin_Q15)))

		/* Keep delta_min distance between the NLSFs */
		for i = 1; i < L; i++ {
			*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(i)*4)) = max_int(tls, *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(i)*4)), (*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((i-1))*4)) + *(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(i)*4))))
		}

		/* Last NLSF should be no higher than 1 - NDeltaMin[L] */
		*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((L-1))*4)) = min_int(tls, *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((L-1))*4)), ((int32(1) << 15) - *(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr(L)*4))))

		/* Keep NDeltaMin distance between the NLSFs */
		for i = (L - 2); i >= 0; i-- {
			*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(i)*4)) = min_int(tls, *(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr(i)*4)), (*(*int32)(unsafe.Pointer(NLSF_Q15 + uintptr((i+1))*4)) - *(*int32)(unsafe.Pointer(NDeltaMin_Q15 + uintptr((i+1))*4))))
		}
	}
}

/* Rate-Distortion calculations for multiple input data vectors */
func NLSF_VQ_rate_distortion_FIX(tls *libc.TLS, pRD_Q20 uintptr, psNLSF_CBS uintptr, in_Q15 uintptr, w_Q6 uintptr, rate_acc_Q5 uintptr, mu_Q15 int32, N int32, LPC_order int32) { /* NLSF_VQ_rate_distortion_FIX.c:31:6: */
	var i int32
	var n int32
	var pRD_vec_Q20 uintptr

	/* Compute weighted quantization errors for all input vectors over one codebook stage */
	NLSF_VQ_sum_error_FIX(tls, pRD_Q20, in_Q15, w_Q6, (*NLSF_CBS)(unsafe.Pointer(psNLSF_CBS)).FCB_NLSF_Q15,
		N, (*NLSF_CBS)(unsafe.Pointer(psNLSF_CBS)).FnVectors, LPC_order)

	/* Loop over input vectors */
	pRD_vec_Q20 = pRD_Q20
	for n = 0; n < N; n++ {
		/* Add rate cost to error for each codebook vector */
		for i = 0; i < (*NLSF_CBS)(unsafe.Pointer(psNLSF_CBS)).FnVectors; i++ {

			*(*int32)(unsafe.Pointer(pRD_vec_Q20 + uintptr(i)*4)) = ((*(*int32)(unsafe.Pointer(pRD_vec_Q20 + uintptr(i)*4))) + ((int32((int16(*(*int32)(unsafe.Pointer(rate_acc_Q5 + uintptr(n)*4)) + int32(*(*int16)(unsafe.Pointer((*NLSF_CBS)(unsafe.Pointer(psNLSF_CBS)).FRates_Q5 + uintptr(i)*2))))))) * (int32(int16(mu_Q15)))))

		}
		pRD_vec_Q20 += 4 * (uintptr((*NLSF_CBS)(unsafe.Pointer(psNLSF_CBS)).FnVectors))
	}
}

/* Compute weighted quantization errors for an LPC_order element input vector, over one codebook stage */
func NLSF_VQ_sum_error_FIX(tls *libc.TLS, err_Q20 uintptr, in_Q15 uintptr, w_Q6 uintptr, pCB_Q15 uintptr, N int32, K int32, LPC_order int32) { /* NLSF_VQ_sum_error_FIX.c:32:6: */
	bp := tls.Alloc(32)
	defer tls.Free(32)

	var i int32
	var n int32
	var m int32
	var diff_Q15 int32
	var sum_error int32
	var Wtmp_Q6 int32
	// var Wcpy_Q6 [8]int32 at bp, 32

	var cb_vec_Q15 uintptr

	/* Copy to local stack and pack two weights per int32 */
	for m = 0; m < ((LPC_order) >> (1)); m++ {
		*(*int32)(unsafe.Pointer(bp /* &Wcpy_Q6[0] */ + uintptr(m)*4)) = (*(*int32)(unsafe.Pointer(w_Q6 + uintptr((2*m))*4)) | ((*(*int32)(unsafe.Pointer(w_Q6 + uintptr(((2*m)+1))*4))) << (16)))
	}

	/* Loop over input vectors */
	for n = 0; n < N; n++ {
		/* Loop over codebook */
		cb_vec_Q15 = pCB_Q15
		for i = 0; i < K; i++ {
			sum_error = 0
			for m = 0; m < LPC_order; m = m + (2) {
				/* Get two weights packed in an int32 */
				Wtmp_Q6 = *(*int32)(unsafe.Pointer(bp /* &Wcpy_Q6[0] */ + uintptr(((m)>>(1)))*4))

				/* Compute weighted squared quantization error for index m */
				diff_Q15 = (*(*int32)(unsafe.Pointer(in_Q15 + uintptr(m)*4)) - int32(*(*int16)(unsafe.Pointer(libc.PostIncUintptr(&cb_vec_Q15, 2))))) // range: [ -32767 : 32767 ]
				sum_error = ((sum_error) + (((((int32(int16(diff_Q15))) * (int32(int16(diff_Q15)))) >> 16) * (int32(int16(Wtmp_Q6)))) + (((((int32(int16(diff_Q15))) * (int32(int16(diff_Q15)))) & 0x0000FFFF) * (int32(int16(Wtmp_Q6)))) >> 16)))

				/* Compute weighted squared quantization error for index m + 1 */
				diff_Q15 = (*(*int32)(unsafe.Pointer(in_Q15 + uintptr((m+1))*4)) - int32(*(*int16)(unsafe.Pointer(libc.PostIncUintptr(&cb_vec_Q15, 2))))) // range: [ -32767 : 32767 ]
				sum_error = (((sum_error) + ((((int32(int16(diff_Q15))) * (int32(int16(diff_Q15)))) >> 16) * ((Wtmp_Q6) >> 16))) + (((((int32(int16(diff_Q15))) * (int32(int16(diff_Q15)))) & 0x0000FFFF) * ((Wtmp_Q6) >> 16)) >> 16))
			}

			*(*int32)(unsafe.Pointer(err_Q20 + uintptr(i)*4)) = sum_error
		}
		err_Q20 += 4 * (uintptr(K))
		in_Q15 += 4 * (uintptr(LPC_order))
	}
}

/*
R. Laroia, N. Phamdo and N. Farvardin, "Robust and Efficient Quantization of Speech LSP
Parameters Using Structured Vector Quantization", Proc. IEEE Int. Conf. Acoust., Speech,
Signal Processing, pp. 641-644, 1991.
*/

/* Laroia low complexity NLSF weights */
func NLSF_VQ_weights_laroia(tls *libc.TLS, pNLSFW_Q6 uintptr, pNLSF_Q15 uintptr, D int32) { /* NLSF_VQ_weights_laroia.c:40:6: */
	var k int32
	var tmp1_int int32
	var tmp2_int int32

	/* Check that we are guaranteed to end up within the required range */

	/* First value */
	tmp1_int = max_int(tls, *(*int32)(unsafe.Pointer(pNLSF_Q15)), 3)
	tmp1_int = ((int32(1) << (15 + 6)) / (tmp1_int))
	tmp2_int = max_int(tls, (*(*int32)(unsafe.Pointer(pNLSF_Q15 + 1*4)) - *(*int32)(unsafe.Pointer(pNLSF_Q15))), 3)
	tmp2_int = ((int32(1) << (15 + 6)) / (tmp2_int))
	*(*int32)(unsafe.Pointer(pNLSFW_Q6)) = min_int(tls, (tmp1_int + tmp2_int), 0x7FFF)

	/* Main loop */
	for k = 1; k < (D - 1); k = k + (2) {
		tmp1_int = max_int(tls, (*(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr((k+1))*4)) - *(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr(k)*4))), 3)
		tmp1_int = ((int32(1) << (15 + 6)) / (tmp1_int))
		*(*int32)(unsafe.Pointer(pNLSFW_Q6 + uintptr(k)*4)) = min_int(tls, (tmp1_int + tmp2_int), 0x7FFF)

		tmp2_int = max_int(tls, (*(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr((k+2))*4)) - *(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr((k+1))*4))), 3)
		tmp2_int = ((int32(1) << (15 + 6)) / (tmp2_int))
		*(*int32)(unsafe.Pointer(pNLSFW_Q6 + uintptr((k+1))*4)) = min_int(tls, (tmp1_int + tmp2_int), 0x7FFF)

	}

	/* Last value */
	tmp1_int = max_int(tls, ((int32(1) << 15) - *(*int32)(unsafe.Pointer(pNLSF_Q15 + uintptr((D-1))*4))), 3)
	tmp1_int = ((int32(1) << (15 + 6)) / (tmp1_int))
	*(*int32)(unsafe.Pointer(pNLSFW_Q6 + uintptr((D-1))*4)) = min_int(tls, (tmp1_int + tmp2_int), 0x7FFF)

}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*******************/
/* Pitch estimator */
/*******************/

/* Level of noise floor for whitening filter LPC analysis in pitch analysis */

/* Bandwidth expansion for whitening filter in pitch analysis */

/* Threshold used by pitch estimator for early escape */

/*********************/
/* Linear prediction */
/*********************/

/* LPC analysis defines: regularization and bandwidth expansion */

/* LTP analysis defines */

/* LTP quantization settings */

/***********************/
/* High pass filtering */
/***********************/

/* Smoothing parameters for low end of pitch frequency range estimation */

/* Min and max values for low end of pitch frequency range estimation */

/* Max absolute difference between log2 of pitch frequency and smoother state, to enter the smoother */

/***********/
/* Various */
/***********/

/* Required speech activity for counting frame as active */

/* Speech Activity LBRR enable threshold (needs tuning) */

/*************************/
/* Perceptual parameters */
/*************************/

/* reduction in coding SNR during low speech activity */

/* factor for reducing quantization noise during voiced speech */

/* factor for reducing quantization noise for unvoiced sparse signals */

/* threshold for sparseness measure above which to use lower quantization offset during unvoiced */

/* warping control */

/* fraction added to first autocorrelation value */

/* noise shaping filter chirp factor */

/* difference between chirp factors for analysis and synthesis noise shaping filters at low bitrates */

/* gain reduction for fricatives */

/* extra harmonic boosting (signal shaping) at low bitrates */

/* extra harmonic boosting (signal shaping) for noisy input signals */

/* harmonic noise shaping */

/* extra harmonic noise shaping for high bitrates or noisy input */

/* parameter for shaping noise towards higher frequencies */

/* parameter for shaping noise even more towards higher frequencies during voiced speech */

/* parameter for applying a high-pass tilt to the input signal */

/* parameter for extra high-pass tilt to the input signal at high rates */

/* parameter for reducing noise at the very low frequencies */

/* less reduction of noise at the very low frequencies for signals with low SNR at low frequencies */

/* noise floor to put a lower limit on the quantization step size */

/* noise floor relative to active speech gain level */

/* subframe smoothing coefficient for determining active speech gain level (lower -> more smoothing) */

/* subframe smoothing coefficient for HarmBoost, HarmShapeGain, Tilt (lower -> more smoothing) */

/* parameters defining the R/D tradeoff in the residual quantizer */

/* Compute gain to make warped filter coefficients have a zero mean log frequency response on a     */
/* non-warped frequency scale. (So that it can be implemented with a minimum-phase monic filter.)   */
func warped_gain(tls *libc.TLS, coefs_Q24 uintptr, lambda_Q16 int32, order int32) int32 { /* noise_shape_analysis_FIX.c:33:22: */
	var i int32
	var gain_Q24 int32

	lambda_Q16 = -lambda_Q16
	gain_Q24 = *(*int32)(unsafe.Pointer(coefs_Q24 + uintptr((order-1))*4))
	for i = (order - 2); i >= 0; i-- {
		gain_Q24 = ((*(*int32)(unsafe.Pointer(coefs_Q24 + uintptr(i)*4))) + ((((gain_Q24) >> 16) * (int32(int16(lambda_Q16)))) + ((((gain_Q24) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
	}
	gain_Q24 = ((FIX_CONST(tls, 1.0, 24)) + ((((gain_Q24) >> 16) * (int32(int16(-lambda_Q16)))) + ((((gain_Q24) & 0x0000FFFF) * (int32(int16(-lambda_Q16)))) >> 16)))
	return INVERSE32_varQ(tls, gain_Q24, 40)
}

/* Convert warped filter coefficients to monic pseudo-warped coefficients and limit maximum     */
/* amplitude of monic warped coefficients by using bandwidth expansion on the true coefficients */
func limit_warped_coefs(tls *libc.TLS, coefs_syn_Q24 uintptr, coefs_ana_Q24 uintptr, lambda_Q16 int32, limit_Q24 int32, order int32) { /* noise_shape_analysis_FIX.c:52:17: */
	var i int32
	var iter int32
	var ind int32 = 0
	var tmp int32
	var maxabs_Q24 int32
	var chirp_Q16 int32
	var gain_syn_Q16 int32
	var gain_ana_Q16 int32
	var nom_Q16 int32
	var den_Q24 int32

	/* Convert to monic coefficients */
	lambda_Q16 = -lambda_Q16
	for i = (order - 1); i > 0; i-- {
		*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr((i-1))*4)) = ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr((i-1))*4))) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
		*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr((i-1))*4)) = ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr((i-1))*4))) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
	}
	lambda_Q16 = -lambda_Q16
	nom_Q16 = ((FIX_CONST(tls, 1.0, 16)) + ((((-lambda_Q16) >> 16) * (int32(int16(lambda_Q16)))) + ((((-lambda_Q16) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
	den_Q24 = ((FIX_CONST(tls, 1.0, 24)) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
	gain_syn_Q16 = DIV32_varQ(tls, nom_Q16, den_Q24, 24)
	den_Q24 = ((FIX_CONST(tls, 1.0, 24)) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
	gain_ana_Q16 = DIV32_varQ(tls, nom_Q16, den_Q24, 24)
	for i = 0; i < order; i++ {
		*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4)) = (((((gain_syn_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4)))))) + ((((gain_syn_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4)))))) >> 16)) + ((gain_syn_Q16) * (func() int32 {
			if (16) == 1 {
				return (((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) & 1))
			}
			return ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
		}())))
		*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4)) = (((((gain_ana_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4)))))) + ((((gain_ana_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4)))))) >> 16)) + ((gain_ana_Q16) * (func() int32 {
			if (16) == 1 {
				return (((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) & 1))
			}
			return ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
		}())))
	}

	for iter = 0; iter < 10; iter++ {
		/* Find maximum absolute value */
		maxabs_Q24 = -1
		for i = 0; i < order; i++ {
			tmp = func() int32 {
				if (((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) ^ ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 31)) - ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 31)) > (((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) ^ ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 31)) - ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 31)) {
					return (((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) ^ ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 31)) - ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 31))
				}
				return (((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) ^ ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 31)) - ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 31))
			}()
			if tmp > maxabs_Q24 {
				maxabs_Q24 = tmp
				ind = i
			}
		}
		if maxabs_Q24 <= limit_Q24 {
			/* Coefficients are within range - done */
			return
		}

		/* Convert back to true warped coefficients */
		for i = 1; i < order; i++ {
			*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr((i-1))*4)) = ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr((i-1))*4))) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
			*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr((i-1))*4)) = ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr((i-1))*4))) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
		}
		gain_syn_Q16 = INVERSE32_varQ(tls, gain_syn_Q16, 32)
		gain_ana_Q16 = INVERSE32_varQ(tls, gain_ana_Q16, 32)
		for i = 0; i < order; i++ {
			*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4)) = (((((gain_syn_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4)))))) + ((((gain_syn_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4)))))) >> 16)) + ((gain_syn_Q16) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
			*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4)) = (((((gain_ana_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4)))))) + ((((gain_ana_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4)))))) >> 16)) + ((gain_ana_Q16) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}

		/* Apply bandwidth expansion */
		chirp_Q16 = (FIX_CONST(tls, 0.99, 16) - DIV32_varQ(tls,
			((((maxabs_Q24-limit_Q24)>>16)*(int32((int16((FIX_CONST(tls, 0.8, 10)) + ((int32(int16(FIX_CONST(tls, 0.1, 10)))) * (int32(int16(iter)))))))))+((((maxabs_Q24-limit_Q24)&0x0000FFFF)*(int32((int16((FIX_CONST(tls, 0.8, 10)) + ((int32(int16(FIX_CONST(tls, 0.1, 10)))) * (int32(int16(iter)))))))))>>16)),
			((maxabs_Q24)*(ind+1)), 22))
		bwexpander_32(tls, coefs_syn_Q24, order, chirp_Q16)
		bwexpander_32(tls, coefs_ana_Q24, order, chirp_Q16)

		/* Convert to monic warped coefficients */
		lambda_Q16 = -lambda_Q16
		for i = (order - 1); i > 0; i-- {
			*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr((i-1))*4)) = ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr((i-1))*4))) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
			*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr((i-1))*4)) = ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr((i-1))*4))) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
		}
		lambda_Q16 = -lambda_Q16
		nom_Q16 = ((FIX_CONST(tls, 1.0, 16)) + ((((-lambda_Q16) >> 16) * (int32(int16(lambda_Q16)))) + ((((-lambda_Q16) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
		den_Q24 = ((FIX_CONST(tls, 1.0, 24)) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
		gain_syn_Q16 = DIV32_varQ(tls, nom_Q16, den_Q24, 24)
		den_Q24 = ((FIX_CONST(tls, 1.0, 24)) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24))) >> 16) * (int32(int16(lambda_Q16)))) + ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24))) & 0x0000FFFF) * (int32(int16(lambda_Q16)))) >> 16)))
		gain_ana_Q16 = DIV32_varQ(tls, nom_Q16, den_Q24, 24)
		for i = 0; i < order; i++ {
			*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4)) = (((((gain_syn_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4)))))) + ((((gain_syn_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4)))))) >> 16)) + ((gain_syn_Q16) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer(coefs_syn_Q24 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
			*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4)) = (((((gain_ana_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4)))))) + ((((gain_ana_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4)))))) >> 16)) + ((gain_ana_Q16) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer(coefs_ana_Q24 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}
	}

}

/**************************************************************/
/* Compute noise shaping coefficients and initial gain values */
/**************************************************************/
func noise_shape_analysis_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrl uintptr, pitch_res uintptr, x uintptr) { /* noise_shape_analysis_FIX.c:137:6: */
	bp := tls.Alloc(992)
	defer tls.Free(992)

	var psShapeSt uintptr = (psEnc + 19540 /* &.sShape */)
	var k int32
	var i int32
	var nSamples int32
	var Qnrg int32
	var b_Q14 int32
	var warping_Q16 int32
	*(*int32)(unsafe.Pointer(bp + 4 /* scale */)) = 0
	var SNR_adj_dB_Q7 int32
	var HarmBoost_Q16 int32
	var HarmShapeGain_Q16 int32
	var Tilt_Q16 int32
	var tmp32 int32
	// var nrg int32 at bp, 4

	// var pre_nrg_Q30 int32 at bp+988, 4

	var log_energy_Q7 int32
	var log_energy_prev_Q7 int32
	var energy_variation_Q7 int32
	var delta_Q16 int32
	var BWExp1_Q16 int32
	var BWExp2_Q16 int32
	var gain_mult_Q16 int32
	var gain_add_Q16 int32
	var strength_Q16 int32
	var b_Q8 int32
	// var auto_corr [17]int32 at bp+728, 68

	// var refl_coef_Q16 [16]int32 at bp+796, 64

	// var AR1_Q24 [16]int32 at bp+924, 64

	// var AR2_Q24 [16]int32 at bp+860, 64

	// var x_windowed [360]int16 at bp+8, 720

	var x_ptr uintptr
	var pitch_res_ptr uintptr

	/* Point to start of first LPC analysis block */
	x_ptr = (x - uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fla_shape)*2)

	/****************/
	/* CONTROL SNR  */
	/****************/
	/* Reduce SNR_dB values if recent bitstream has exceeded TargetRate */
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7 = ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FSNR_dB_Q7 - ((((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FBufferedInChannel_ms) << (7)) >> 16) * (int32(int16(FIX_CONST(tls, 0.05, 16))))) + ((((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FBufferedInChannel_ms) << (7)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.05, 16))))) >> 16)))

	/* Reduce SNR_dB if inband FEC used */
	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8 > FIX_CONST(tls, 0.5, 8) {
		*(*int32)(unsafe.Pointer(psEncCtrl + 604 /* &.current_SNR_dB_Q7 */)) -= (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FinBandFEC_SNR_comp_Q8) >> (1))
	}

	/****************/
	/* GAIN CONTROL */
	/****************/
	/* Input quality is the average of the quality in the lowest two VAD bands */
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14 = ((*(*int32)(unsafe.Pointer((psEncCtrl + 620 /* &.input_quality_bands_Q15 */))) + *(*int32)(unsafe.Pointer((psEncCtrl + 620 /* &.input_quality_bands_Q15 */) + 1*4))) >> (2))

	/* Coding quality level, between 0.0_Q0 and 1.0_Q0, but in Q14 */
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14 = ((sigm_Q15(tls, func() int32 {
		if (4) == 1 {
			return ((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7 - FIX_CONST(tls, 18.0, 7)) >> 1) + (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7 - FIX_CONST(tls, 18.0, 7)) & 1))
		}
		return (((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7 - FIX_CONST(tls, 18.0, 7)) >> ((4) - 1)) + 1) >> 1)
	}())) >> (1))

	/* Reduce coding SNR during low speech activity */
	b_Q8 = (FIX_CONST(tls, 1.0, 8) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)
	b_Q8 = (((((b_Q8) << (8)) >> 16) * (int32(int16(b_Q8)))) + (((((b_Q8) << (8)) & 0x0000FFFF) * (int32(int16(b_Q8)))) >> 16))
	SNR_adj_dB_Q7 = (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7) + (((((int32((int16(FIX_CONST(tls, float64(-4.0), 7) >> (4 + 1))))) * (int32(int16(b_Q8)))) >> 16) * (int32((int16((((FIX_CONST(tls, 1.0, 14) + (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14) >> 16) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14)))) + ((((FIX_CONST(tls, 1.0, 14) + (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14) & 0x0000FFFF) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14)))) >> 16)))))) + (((((int32((int16(FIX_CONST(tls, float64(-4.0), 7) >> (4 + 1))))) * (int32(int16(b_Q8)))) & 0x0000FFFF) * (int32((int16((((FIX_CONST(tls, 1.0, 14) + (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14) >> 16) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14)))) + ((((FIX_CONST(tls, 1.0, 14) + (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14) & 0x0000FFFF) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14)))) >> 16)))))) >> 16))) // Q12

	if (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 0 {
		/* Reduce gains for periodic signals */
		SNR_adj_dB_Q7 = ((SNR_adj_dB_Q7) + ((((FIX_CONST(tls, 2.0, 8)) >> 16) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FLTPCorr_Q15)))) + ((((FIX_CONST(tls, 2.0, 8)) & 0x0000FFFF) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FLTPCorr_Q15)))) >> 16)))
	} else {
		/* For unvoiced signals and low-quality input, adjust the quality slower than SNR_dB setting */
		SNR_adj_dB_Q7 = ((SNR_adj_dB_Q7) + (((((FIX_CONST(tls, 6.0, 9)) + ((((-FIX_CONST(tls, 0.4, 18)) >> 16) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7)))) + ((((-FIX_CONST(tls, 0.4, 18)) & 0x0000FFFF) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7)))) >> 16))) >> 16) * (int32((int16(FIX_CONST(tls, 1.0, 14) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14))))) + (((((FIX_CONST(tls, 6.0, 9)) + ((((-FIX_CONST(tls, 0.4, 18)) >> 16) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7)))) + ((((-FIX_CONST(tls, 0.4, 18)) & 0x0000FFFF) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7)))) >> 16))) & 0x0000FFFF) * (int32((int16(FIX_CONST(tls, 1.0, 14) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14))))) >> 16)))
	}

	/*************************/
	/* SPARSENESS PROCESSING */
	/*************************/
	/* Set quantizer offset */
	if (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 0 {
		/* Initally set to 0; may be overruled in process_gains(..) */
		(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FQuantOffsetType = 0
		(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8 = 0
	} else {
		/* Sparseness measure, based on relative fluctuations of energy per 2 milliseconds */
		nSamples = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz) << (1))
		energy_variation_Q7 = 0
		log_energy_prev_Q7 = 0
		pitch_res_ptr = pitch_res
		for k = 0; k < (20 / 2); k++ {
			sum_sqr_shift(tls, bp /* &nrg */, bp+4 /* &scale */, pitch_res_ptr, nSamples)
			*(*int32)(unsafe.Pointer(bp /* nrg */)) += ((nSamples) >> (*(*int32)(unsafe.Pointer(bp + 4 /* scale */)))) // Q(-scale)

			log_energy_Q7 = lin2log(tls, *(*int32)(unsafe.Pointer(bp /* nrg */)))
			if k > 0 {
				energy_variation_Q7 = energy_variation_Q7 + (func() int32 {
					if (log_energy_Q7 - log_energy_prev_Q7) > 0 {
						return (log_energy_Q7 - log_energy_prev_Q7)
					}
					return -(log_energy_Q7 - log_energy_prev_Q7)
				}())
			}
			log_energy_prev_Q7 = log_energy_Q7
			pitch_res_ptr += 2 * (uintptr(nSamples))
		}

		(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8 = ((sigm_Q15(tls, ((((energy_variation_Q7 - FIX_CONST(tls, 5.0, 7)) >> 16) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) + ((((energy_variation_Q7 - FIX_CONST(tls, 5.0, 7)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) >> 16)))) >> (7))

		/* Set quantization offset depending on sparseness measure */
		if (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8 > FIX_CONST(tls, 0.75, 8) {
			(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FQuantOffsetType = 0
		} else {
			(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FQuantOffsetType = 1
		}

		/* Increase coding SNR for sparse signals */
		SNR_adj_dB_Q7 = ((SNR_adj_dB_Q7) + ((((FIX_CONST(tls, 2.0, 15)) >> 16) * (int32((int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8 - FIX_CONST(tls, 0.5, 8)))))) + ((((FIX_CONST(tls, 2.0, 15)) & 0x0000FFFF) * (int32((int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8 - FIX_CONST(tls, 0.5, 8)))))) >> 16)))
	}

	/*******************************/
	/* Control bandwidth expansion */
	/*******************************/
	/* More BWE for signals with high prediction gain */
	strength_Q16 = (((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FpredGain_Q16) >> 16) * (int32(int16(FIX_CONST(tls, 1e-3, 16))))) + (((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FpredGain_Q16) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 1e-3, 16))))) >> 16))
	BWExp1_Q16 = libc.AssignInt32(&BWExp2_Q16, DIV32_varQ(tls, FIX_CONST(tls, 0.95, 16),
		(((FIX_CONST(tls, 1.0, 16))+((((strength_Q16)>>16)*(int32(int16(strength_Q16))))+((((strength_Q16)&0x0000FFFF)*(int32(int16(strength_Q16))))>>16)))+((strength_Q16)*(func() int32 {
			if (16) == 1 {
				return (((strength_Q16) >> 1) + ((strength_Q16) & 1))
			}
			return ((((strength_Q16) >> ((16) - 1)) + 1) >> 1)
		}()))), 16))
	delta_Q16 = ((((FIX_CONST(tls, 1.0, 16) - ((int32(int16(3))) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14))))) >> 16) * (int32(int16(FIX_CONST(tls, 0.01, 16))))) + ((((FIX_CONST(tls, 1.0, 16) - ((int32(int16(3))) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14))))) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.01, 16))))) >> 16))
	BWExp1_Q16 = ((BWExp1_Q16) - (delta_Q16))
	BWExp2_Q16 = ((BWExp2_Q16) + (delta_Q16))
	/* BWExp1 will be applied after BWExp2, so make it relative */
	BWExp1_Q16 = (((BWExp1_Q16) << (14)) / ((BWExp2_Q16) >> (2)))

	if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fwarping_Q16 > 0 {
		/* Slightly more warping in analysis will move quantization noise up in frequency, where it's better masked */
		warping_Q16 = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fwarping_Q16) + (((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) >> 16) * (int32(int16(FIX_CONST(tls, 0.01, 18))))) + (((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.01, 18))))) >> 16)))
	} else {
		warping_Q16 = 0
	}

	/********************************************/
	/* Compute noise shaping AR coefs and gains */
	/********************************************/
	for k = 0; k < 4; k++ {
		/* Apply window: sine slope followed by flat part followed by cosine slope */
		var shift int32
		var slope_part int32
		var flat_part int32
		flat_part = ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz * 5)
		slope_part = (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapeWinLength - flat_part) >> (1))

		apply_sine_window(tls, bp+8 /* &x_windowed[0] */, x_ptr, 1, slope_part)
		shift = slope_part
		libc.Xmemcpy(tls, (bp + 8 /* &x_windowed[0] */ + uintptr(shift)*2), (x_ptr + uintptr(shift)*2), (uint32(flat_part) * uint32(unsafe.Sizeof(int16(0)))))
		shift = shift + (flat_part)
		apply_sine_window(tls, (bp + 8 /* &x_windowed[0] */ + uintptr(shift)*2), (x_ptr + uintptr(shift)*2), 2, slope_part)

		/* Update pointer: next LPC analysis block */
		x_ptr += 2 * (uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length))

		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fwarping_Q16 > 0 {
			/* Calculate warped auto correlation */
			warped_autocorrelation_FIX(tls, bp+728 /* &auto_corr[0] */, bp+4 /* &scale */, bp+8 /* &x_windowed[0] */, int16(warping_Q16), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapeWinLength, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder)
		} else {
			/* Calculate regular auto correlation */
			autocorr(tls, bp+728 /* &auto_corr[0] */, bp+4 /* &scale */, bp+8 /* &x_windowed[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapeWinLength, ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder + 1))
		}

		/* Add white noise, as a fraction of energy */
		*(*int32)(unsafe.Pointer(bp + 728 /* &auto_corr[0] */)) = ((*(*int32)(unsafe.Pointer(bp + 728 /* &auto_corr[0] */))) + (max_32(tls, (((((*(*int32)(unsafe.Pointer(bp + 728 /* &auto_corr[0] */))) >> (4)) >> 16) * (int32(int16(FIX_CONST(tls, 1e-5, 20))))) + (((((*(*int32)(unsafe.Pointer(bp + 728 /* &auto_corr[0] */))) >> (4)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 1e-5, 20))))) >> 16)), 1)))

		/* Calculate the reflection coefficients using schur */
		*(*int32)(unsafe.Pointer(bp /* nrg */)) = schur64(tls, bp+796 /* &refl_coef_Q16[0] */, bp+728 /* &auto_corr[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder)

		/* Convert reflection coefficients to prediction coefficients */
		k2a_Q16(tls, bp+860 /* &AR2_Q24[0] */, bp+796 /* &refl_coef_Q16[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder)

		Qnrg = -*(*int32)(unsafe.Pointer(bp + 4 /* scale */)) // range: -12...30

		/* Make sure that Qnrg is an even number */
		if (Qnrg & 1) != 0 {
			Qnrg = Qnrg - (1)
			*(*int32)(unsafe.Pointer(bp /* nrg */)) >>= 1
		}

		tmp32 = SQRT_APPROX(tls, *(*int32)(unsafe.Pointer(bp /* nrg */)))
		Qnrg >>= 1 // range: -6...15

		*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) = ((func() int32 {
			if (int32((libc.Int32FromUint32(0x80000000))) >> (16 - Qnrg)) > (int32((0x7FFFFFFF)) >> (16 - Qnrg)) {
				return func() int32 {
					if (tmp32) > (int32((libc.Int32FromUint32(0x80000000))) >> (16 - Qnrg)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (16 - Qnrg))
					}
					return func() int32 {
						if (tmp32) < (int32((0x7FFFFFFF)) >> (16 - Qnrg)) {
							return (int32((0x7FFFFFFF)) >> (16 - Qnrg))
						}
						return tmp32
					}()
				}()
			}
			return func() int32 {
				if (tmp32) > (int32((0x7FFFFFFF)) >> (16 - Qnrg)) {
					return (int32((0x7FFFFFFF)) >> (16 - Qnrg))
				}
				return func() int32 {
					if (tmp32) < (int32((libc.Int32FromUint32(0x80000000))) >> (16 - Qnrg)) {
						return (int32((libc.Int32FromUint32(0x80000000))) >> (16 - Qnrg))
					}
					return tmp32
				}()
			}()
		}()) << (16 - Qnrg))

		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fwarping_Q16 > 0 {
			/* Adjust gain for warping */
			gain_mult_Q16 = warped_gain(tls, bp+860 /* &AR2_Q24[0] */, warping_Q16, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder)

			*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) = (((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) >> 16) * (int32(int16(gain_mult_Q16)))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(gain_mult_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) * (func() int32 {
				if (16) == 1 {
					return (((gain_mult_Q16) >> 1) + ((gain_mult_Q16) & 1))
				}
				return ((((gain_mult_Q16) >> ((16) - 1)) + 1) >> 1)
			}())))
			if *(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) < 0 {
				*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) = 0x7FFFFFFF
			}
		}

		/* Bandwidth expansion for synthesis filter shaping */
		bwexpander_32(tls, bp+860 /* &AR2_Q24[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder, BWExp2_Q16)

		/* Compute noise shaping filter coefficients */
		libc.Xmemcpy(tls, bp+924 /* &AR1_Q24[0] */, bp+860 /* &AR2_Q24[0] */, (uint32((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder) * uint32(unsafe.Sizeof(int32(0)))))

		/* Bandwidth expansion for analysis filter shaping */

		bwexpander_32(tls, bp+924 /* &AR1_Q24[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder, BWExp1_Q16)

		/* Ratio of prediction gains, in energy domain */
		LPC_inverse_pred_gain_Q24(tls, bp+988 /* &pre_nrg_Q30 */, bp+860 /* &AR2_Q24[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder)
		LPC_inverse_pred_gain_Q24(tls, bp /* &nrg */, bp+924 /* &AR1_Q24[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder)

		//psEncCtrl->GainsPre[ k ] = 1.0f - 0.7f * ( 1.0f - pre_nrg / nrg ) = 0.3f + 0.7f * pre_nrg / nrg;
		*(*int32)(unsafe.Pointer(bp + 988 /* pre_nrg_Q30 */)) = (((((*(*int32)(unsafe.Pointer(bp + 988 /* pre_nrg_Q30 */))) >> 16) * (int32(int16(FIX_CONST(tls, 0.7, 15))))) + ((((*(*int32)(unsafe.Pointer(bp + 988 /* pre_nrg_Q30 */))) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.7, 15))))) >> 16)) << (1))
		*(*int32)(unsafe.Pointer((psEncCtrl + 524 /* &.GainsPre_Q14 */) + uintptr(k)*4)) = (FIX_CONST(tls, 0.3, 14) + DIV32_varQ(tls, *(*int32)(unsafe.Pointer(bp + 988 /* pre_nrg_Q30 */)), *(*int32)(unsafe.Pointer(bp /* nrg */)), 14))

		/* Convert to monic warped prediction coefficients and limit absolute values */
		limit_warped_coefs(tls, bp+860 /* &AR2_Q24[0] */, bp+924 /* &AR1_Q24[0] */, warping_Q16, FIX_CONST(tls, 3.999, 24), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder)

		/* Convert from Q24 to Q13 and store in int16 */
		for i = 0; i < (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder; i++ {
			*(*int16)(unsafe.Pointer((psEncCtrl + 252 /* &.AR1_Q13 */) + uintptr(((k*16)+i))*2)) = func() int16 {
				if (func() int32 {
					if (11) == 1 {
						return (((*(*int32)(unsafe.Pointer(bp + 924 /* &AR1_Q24[0] */ + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp + 924 /* &AR1_Q24[0] */ + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer(bp + 924 /* &AR1_Q24[0] */ + uintptr(i)*4))) >> ((11) - 1)) + 1) >> 1)
				}()) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (func() int32 {
						if (11) == 1 {
							return (((*(*int32)(unsafe.Pointer(bp + 924 /* &AR1_Q24[0] */ + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp + 924 /* &AR1_Q24[0] */ + uintptr(i)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer(bp + 924 /* &AR1_Q24[0] */ + uintptr(i)*4))) >> ((11) - 1)) + 1) >> 1)
					}()) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return func() int16 {
						if (11) == 1 {
							return (int16(((*(*int32)(unsafe.Pointer(bp + 924 /* &AR1_Q24[0] */ + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp + 924 /* &AR1_Q24[0] */ + uintptr(i)*4))) & 1)))
						}
						return (int16((((*(*int32)(unsafe.Pointer(bp + 924 /* &AR1_Q24[0] */ + uintptr(i)*4))) >> ((11) - 1)) + 1) >> 1))
					}()
				}()
			}()
			*(*int16)(unsafe.Pointer((psEncCtrl + 380 /* &.AR2_Q13 */) + uintptr(((k*16)+i))*2)) = func() int16 {
				if (func() int32 {
					if (11) == 1 {
						return (((*(*int32)(unsafe.Pointer(bp + 860 /* &AR2_Q24[0] */ + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp + 860 /* &AR2_Q24[0] */ + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer(bp + 860 /* &AR2_Q24[0] */ + uintptr(i)*4))) >> ((11) - 1)) + 1) >> 1)
				}()) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (func() int32 {
						if (11) == 1 {
							return (((*(*int32)(unsafe.Pointer(bp + 860 /* &AR2_Q24[0] */ + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp + 860 /* &AR2_Q24[0] */ + uintptr(i)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer(bp + 860 /* &AR2_Q24[0] */ + uintptr(i)*4))) >> ((11) - 1)) + 1) >> 1)
					}()) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return func() int16 {
						if (11) == 1 {
							return (int16(((*(*int32)(unsafe.Pointer(bp + 860 /* &AR2_Q24[0] */ + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(bp + 860 /* &AR2_Q24[0] */ + uintptr(i)*4))) & 1)))
						}
						return (int16((((*(*int32)(unsafe.Pointer(bp + 860 /* &AR2_Q24[0] */ + uintptr(i)*4))) >> ((11) - 1)) + 1) >> 1))
					}()
				}()
			}()
		}
	}

	/*****************/
	/* Gain tweaking */
	/*****************/
	/* Increase gains during low speech activity and put lower limit on gains */
	gain_mult_Q16 = log2lin(tls, -((-FIX_CONST(tls, 16.0, 7)) + ((((SNR_adj_dB_Q7) >> 16) * (int32(int16(FIX_CONST(tls, 0.16, 16))))) + ((((SNR_adj_dB_Q7) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.16, 16))))) >> 16))))
	gain_add_Q16 = log2lin(tls, ((FIX_CONST(tls, 16.0, 7)) + ((((FIX_CONST(tls, 4.0, 7)) >> 16) * (int32(int16(FIX_CONST(tls, 0.16, 16))))) + ((((FIX_CONST(tls, 4.0, 7)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.16, 16))))) >> 16))))
	tmp32 = log2lin(tls, ((FIX_CONST(tls, 16.0, 7)) + ((((FIX_CONST(tls, float64(-50.0), 7)) >> 16) * (int32(int16(FIX_CONST(tls, 0.16, 16))))) + ((((FIX_CONST(tls, float64(-50.0), 7)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.16, 16))))) >> 16))))
	tmp32 = ((((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) >> 16) * (int32(int16(tmp32)))) + (((((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) & 0x0000FFFF) * (int32(int16(tmp32)))) >> 16)) + (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) * (func() int32 {
		if (16) == 1 {
			return (((tmp32) >> 1) + ((tmp32) & 1))
		}
		return ((((tmp32) >> ((16) - 1)) + 1) >> 1)
	}())))
	gain_add_Q16 = func() int32 {
		if ((uint32((gain_add_Q16) + (tmp32))) & 0x80000000) == uint32(0) {
			return func() int32 {
				if ((uint32((gain_add_Q16) & (tmp32))) & 0x80000000) != uint32(0) {
					return libc.Int32FromUint32(0x80000000)
				}
				return ((gain_add_Q16) + (tmp32))
			}()
		}
		return func() int32 {
			if ((uint32((gain_add_Q16) | (tmp32))) & 0x80000000) == uint32(0) {
				return 0x7FFFFFFF
			}
			return ((gain_add_Q16) + (tmp32))
		}()
	}()

	for k = 0; k < 4; k++ {
		*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) = (((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) >> 16) * (int32(int16(gain_mult_Q16)))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(gain_mult_Q16)))) >> 16)) + ((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) * (func() int32 {
			if (16) == 1 {
				return (((gain_mult_Q16) >> 1) + ((gain_mult_Q16) & 1))
			}
			return ((((gain_mult_Q16) >> ((16) - 1)) + 1) >> 1)
		}())))
		if *(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) < 0 {
			*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) = 0x7FFFFFFF
		}
	}

	for k = 0; k < 4; k++ {
		*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) = func() int32 {
			if ((uint32((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) + (gain_add_Q16))) & 0x80000000) != 0 {
				return 0x7FFFFFFF
			}
			return ((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) + (gain_add_Q16))
		}()
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16 = func() int32 {
			if ((uint32(((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) >> 16) * (int32(func() int16 {
				if (2) == 1 {
					return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
				}
				return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
			}()))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) & 0x0000FFFF) * (int32(func() int16 {
				if (2) == 1 {
					return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
				}
				return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
			}()))) >> 16)))) & 0x80000000) == uint32(0) {
				return func() int32 {
					if ((uint32(((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) & ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) >> 16) * (int32(func() int16 {
						if (2) == 1 {
							return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
						}
						return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
					}()))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) & 0x0000FFFF) * (int32(func() int16 {
						if (2) == 1 {
							return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
						}
						return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
					}()))) >> 16)))) & 0x80000000) != uint32(0) {
						return libc.Int32FromUint32(0x80000000)
					}
					return (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) >> 16) * (int32(func() int16 {
						if (2) == 1 {
							return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
						}
						return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
					}()))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) & 0x0000FFFF) * (int32(func() int16 {
						if (2) == 1 {
							return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
						}
						return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
					}()))) >> 16)))
				}()
			}
			return func() int32 {
				if ((uint32(((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) | ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) >> 16) * (int32(func() int16 {
					if (2) == 1 {
						return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
					}
					return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
				}()))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) & 0x0000FFFF) * (int32(func() int16 {
					if (2) == 1 {
						return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
					}
					return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
				}()))) >> 16)))) & 0x80000000) == uint32(0) {
					return 0x7FFFFFFF
				}
				return (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) >> 16) * (int32(func() int16 {
					if (2) == 1 {
						return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
					}
					return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
				}()))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) - (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FavgGain_Q16) & 0x0000FFFF) * (int32(func() int16 {
					if (2) == 1 {
						return (int16((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) & 1)))
					}
					return (int16(((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32(int16(FIX_CONST(tls, 1e-3, 10))))) >> ((2) - 1)) + 1) >> 1))
				}()))) >> 16)))
			}()
		}()
	}

	/************************************************/
	/* Decrease level during fricatives (de-essing) */
	/************************************************/
	gain_mult_Q16 = (FIX_CONST(tls, 1.0, 16) + (func() int32 {
		if (10) == 1 {
			return ((((FIX_CONST(tls, 0.05, 26)) + (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) * (FIX_CONST(tls, 0.1, 12)))) >> 1) + (((FIX_CONST(tls, 0.05, 26)) + (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) * (FIX_CONST(tls, 0.1, 12)))) & 1))
		}
		return (((((FIX_CONST(tls, 0.05, 26)) + (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) * (FIX_CONST(tls, 0.1, 12)))) >> ((10) - 1)) + 1) >> 1)
	}()))

	if ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15 <= 0) && ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 1) {
		if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 24 {
			var essStrength_Q15 int32 = (((((-(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15) >> 16) * (int32((int16((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))))))) + ((((-(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15) & 0x0000FFFF) * (int32((int16((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))))))) >> 16)) + ((-(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15) * (func() int32 {
				if (16) == 1 {
					return ((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))) & 1))
				}
				return (((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))) >> ((16) - 1)) + 1) >> 1)
			}())))
			tmp32 = log2lin(tls, (FIX_CONST(tls, 16.0, 7) - ((((essStrength_Q15) >> 16) * (int32((int16((((FIX_CONST(tls, 2.0, 7)) >> 16) * (int32(int16(FIX_CONST(tls, 0.16, 17))))) + ((((FIX_CONST(tls, 2.0, 7)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.16, 17))))) >> 16)))))) + ((((essStrength_Q15) & 0x0000FFFF) * (int32((int16((((FIX_CONST(tls, 2.0, 7)) >> 16) * (int32(int16(FIX_CONST(tls, 0.16, 17))))) + ((((FIX_CONST(tls, 2.0, 7)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.16, 17))))) >> 16)))))) >> 16))))
			gain_mult_Q16 = (((((gain_mult_Q16) >> 16) * (int32(int16(tmp32)))) + ((((gain_mult_Q16) & 0x0000FFFF) * (int32(int16(tmp32)))) >> 16)) + ((gain_mult_Q16) * (func() int32 {
				if (16) == 1 {
					return (((tmp32) >> 1) + ((tmp32) & 1))
				}
				return ((((tmp32) >> ((16) - 1)) + 1) >> 1)
			}())))
		} else if (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz == 16 {
			var essStrength_Q15 int32 = (((((-(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15) >> 16) * (int32((int16((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))))))) + ((((-(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15) & 0x0000FFFF) * (int32((int16((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))))))) >> 16)) + ((-(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15) * (func() int32 {
				if (16) == 1 {
					return ((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))) >> 1) + (((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))) & 1))
				}
				return (((((int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8))) * (int32((int16(FIX_CONST(tls, 1.0, 8) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))) >> ((16) - 1)) + 1) >> 1)
			}())))
			tmp32 = log2lin(tls, (FIX_CONST(tls, 16.0, 7) - ((((essStrength_Q15) >> 16) * (int32((int16((((FIX_CONST(tls, 1.0, 7)) >> 16) * (int32(int16(FIX_CONST(tls, 0.16, 17))))) + ((((FIX_CONST(tls, 1.0, 7)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.16, 17))))) >> 16)))))) + ((((essStrength_Q15) & 0x0000FFFF) * (int32((int16((((FIX_CONST(tls, 1.0, 7)) >> 16) * (int32(int16(FIX_CONST(tls, 0.16, 17))))) + ((((FIX_CONST(tls, 1.0, 7)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.16, 17))))) >> 16)))))) >> 16))))
			gain_mult_Q16 = (((((gain_mult_Q16) >> 16) * (int32(int16(tmp32)))) + ((((gain_mult_Q16) & 0x0000FFFF) * (int32(int16(tmp32)))) >> 16)) + ((gain_mult_Q16) * (func() int32 {
				if (16) == 1 {
					return (((tmp32) >> 1) + ((tmp32) & 1))
				}
				return ((((tmp32) >> ((16) - 1)) + 1) >> 1)
			}())))
		} else {

		}
	}

	for k = 0; k < 4; k++ {
		*(*int32)(unsafe.Pointer((psEncCtrl + 524 /* &.GainsPre_Q14 */) + uintptr(k)*4)) = ((((gain_mult_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psEncCtrl + 524 /* &.GainsPre_Q14 */) + uintptr(k)*4)))))) + ((((gain_mult_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psEncCtrl + 524 /* &.GainsPre_Q14 */) + uintptr(k)*4)))))) >> 16))
	}

	/************************************************/
	/* Control low-frequency shaping and noise tilt */
	/************************************************/
	/* Less low frequency shaping for noisy inputs */
	strength_Q16 = ((FIX_CONST(tls, 3.0, 0)) * (FIX_CONST(tls, 1.0, 16) + ((int32(int16(FIX_CONST(tls, 0.5, 1)))) * (int32((int16(*(*int32)(unsafe.Pointer((psEncCtrl + 620 /* &.input_quality_bands_Q15 */))) - FIX_CONST(tls, 1.0, 15))))))))
	if (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 0 {
		/* Reduce low frequencies quantization noise for periodic signals, depending on pitch lag */
		/*f = 400; freqz([1, -0.98 + 2e-4 * f], [1, -0.97 + 7e-4 * f], 2^12, Fs); axis([0, 1000, -10, 1])*/
		var fs_kHz_inv int32 = ((FIX_CONST(tls, 0.2, 14)) / ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz))
		for k = 0; k < 4; k++ {
			b_Q14 = (fs_kHz_inv + ((FIX_CONST(tls, 3.0, 14)) / (*(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 108 /* &.pitchL */) + uintptr(k)*4)))))
			/* Pack two coefficients in one int32 */
			*(*int32)(unsafe.Pointer((psEncCtrl + 508 /* &.LF_shp_Q14 */) + uintptr(k)*4)) = (((FIX_CONST(tls, 1.0, 14) - b_Q14) - ((((strength_Q16) >> 16) * (int32(int16(b_Q14)))) + ((((strength_Q16) & 0x0000FFFF) * (int32(int16(b_Q14)))) >> 16))) << (16))
			*(*int32)(unsafe.Pointer((psEncCtrl + 508 /* &.LF_shp_Q14 */) + uintptr(k)*4)) |= (int32((uint16(b_Q14 - FIX_CONST(tls, 1.0, 14)))))
		}
		// Guarantees that second argument to SMULWB() is within range of an int16
		Tilt_Q16 = (-FIX_CONST(tls, 0.3, 16) - ((((FIX_CONST(tls, 1.0, 16) - FIX_CONST(tls, 0.3, 16)) >> 16) * (int32((int16((((FIX_CONST(tls, 0.35, 24)) >> 16) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) + ((((FIX_CONST(tls, 0.35, 24)) & 0x0000FFFF) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) >> 16)))))) + ((((FIX_CONST(tls, 1.0, 16) - FIX_CONST(tls, 0.3, 16)) & 0x0000FFFF) * (int32((int16((((FIX_CONST(tls, 0.35, 24)) >> 16) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) + ((((FIX_CONST(tls, 0.35, 24)) & 0x0000FFFF) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) >> 16)))))) >> 16)))
	} else {
		b_Q14 = ((21299) / ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffs_kHz)) // 1.3_Q0 = 21299_Q14
		/* Pack two coefficients in one int32 */
		*(*int32)(unsafe.Pointer((psEncCtrl + 508 /* &.LF_shp_Q14 */))) = (((FIX_CONST(tls, 1.0, 14) - b_Q14) - ((((strength_Q16) >> 16) * (int32((int16((((FIX_CONST(tls, 0.6, 16)) >> 16) * (int32(int16(b_Q14)))) + ((((FIX_CONST(tls, 0.6, 16)) & 0x0000FFFF) * (int32(int16(b_Q14)))) >> 16)))))) + ((((strength_Q16) & 0x0000FFFF) * (int32((int16((((FIX_CONST(tls, 0.6, 16)) >> 16) * (int32(int16(b_Q14)))) + ((((FIX_CONST(tls, 0.6, 16)) & 0x0000FFFF) * (int32(int16(b_Q14)))) >> 16)))))) >> 16))) << (16))
		*(*int32)(unsafe.Pointer((psEncCtrl + 508 /* &.LF_shp_Q14 */))) |= (int32((uint16(b_Q14 - FIX_CONST(tls, 1.0, 14)))))
		for k = 1; k < 4; k++ {
			*(*int32)(unsafe.Pointer((psEncCtrl + 508 /* &.LF_shp_Q14 */) + uintptr(k)*4)) = *(*int32)(unsafe.Pointer((psEncCtrl + 508 /* &.LF_shp_Q14 */)))
		}
		Tilt_Q16 = -FIX_CONST(tls, 0.3, 16)
	}

	/****************************/
	/* HARMONIC SHAPING CONTROL */
	/****************************/
	/* Control boosting of harmonic frequencies */
	HarmBoost_Q16 = (((((((FIX_CONST(tls, 1.0, 17) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) << (3))) >> 16) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FLTPCorr_Q15)))) + ((((FIX_CONST(tls, 1.0, 17) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) << (3))) & 0x0000FFFF) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FLTPCorr_Q15)))) >> 16)) >> 16) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) + (((((((FIX_CONST(tls, 1.0, 17) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) << (3))) >> 16) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FLTPCorr_Q15)))) + ((((FIX_CONST(tls, 1.0, 17) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) << (3))) & 0x0000FFFF) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FLTPCorr_Q15)))) >> 16)) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) >> 16))

	/* More harmonic boost for noisy input signals */
	HarmBoost_Q16 = ((HarmBoost_Q16) + ((((FIX_CONST(tls, 1.0, 16) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14) << (2))) >> 16) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) + ((((FIX_CONST(tls, 1.0, 16) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14) << (2))) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.1, 16))))) >> 16)))

	if (1 != 0) && ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 0) {
		/* More harmonic noise shaping for high bitrates or noisy input */
		HarmShapeGain_Q16 = ((FIX_CONST(tls, 0.3, 16)) + ((((FIX_CONST(tls, 1.0, 16) - ((((FIX_CONST(tls, 1.0, 18) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) << (4))) >> 16) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14)))) + ((((FIX_CONST(tls, 1.0, 18) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) << (4))) & 0x0000FFFF) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14)))) >> 16))) >> 16) * (int32(int16(FIX_CONST(tls, 0.2, 16))))) + ((((FIX_CONST(tls, 1.0, 16) - ((((FIX_CONST(tls, 1.0, 18) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) << (4))) >> 16) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14)))) + ((((FIX_CONST(tls, 1.0, 18) - (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14) << (4))) & 0x0000FFFF) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14)))) >> 16))) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.2, 16))))) >> 16)))

		/* Less harmonic noise shaping for less periodic signals */
		HarmShapeGain_Q16 = (((((HarmShapeGain_Q16) << (1)) >> 16) * (int32(int16(SQRT_APPROX(tls, (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FLTPCorr_Q15) << (15))))))) + (((((HarmShapeGain_Q16) << (1)) & 0x0000FFFF) * (int32(int16(SQRT_APPROX(tls, (((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FLTPCorr_Q15) << (15))))))) >> 16))
	} else {
		HarmShapeGain_Q16 = 0
	}

	/*************************/
	/* Smooth over subframes */
	/*************************/
	for k = 0; k < 4; k++ {
		(*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmBoost_smth_Q16 = (((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmBoost_smth_Q16) + ((((HarmBoost_Q16 - (*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmBoost_smth_Q16) >> 16) * (int32(int16(FIX_CONST(tls, 0.4, 16))))) + ((((HarmBoost_Q16 - (*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmBoost_smth_Q16) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.4, 16))))) >> 16)))
		(*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmShapeGain_smth_Q16 = (((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmShapeGain_smth_Q16) + ((((HarmShapeGain_Q16 - (*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmShapeGain_smth_Q16) >> 16) * (int32(int16(FIX_CONST(tls, 0.4, 16))))) + ((((HarmShapeGain_Q16 - (*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmShapeGain_smth_Q16) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.4, 16))))) >> 16)))
		(*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FTilt_smth_Q16 = (((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FTilt_smth_Q16) + ((((Tilt_Q16 - (*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FTilt_smth_Q16) >> 16) * (int32(int16(FIX_CONST(tls, 0.4, 16))))) + ((((Tilt_Q16 - (*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FTilt_smth_Q16) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.4, 16))))) >> 16)))

		*(*int32)(unsafe.Pointer((psEncCtrl + 540 /* &.HarmBoost_Q14 */) + uintptr(k)*4)) = func() int32 {
			if (2) == 1 {
				return ((((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmBoost_smth_Q16) >> 1) + (((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmBoost_smth_Q16) & 1))
			}
			return (((((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmBoost_smth_Q16) >> ((2) - 1)) + 1) >> 1)
		}()
		*(*int32)(unsafe.Pointer((psEncCtrl + 572 /* &.HarmShapeGain_Q14 */) + uintptr(k)*4)) = func() int32 {
			if (2) == 1 {
				return ((((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmShapeGain_smth_Q16) >> 1) + (((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmShapeGain_smth_Q16) & 1))
			}
			return (((((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FHarmShapeGain_smth_Q16) >> ((2) - 1)) + 1) >> 1)
		}()
		*(*int32)(unsafe.Pointer((psEncCtrl + 556 /* &.Tilt_Q14 */) + uintptr(k)*4)) = func() int32 {
			if (2) == 1 {
				return ((((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FTilt_smth_Q16) >> 1) + (((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FTilt_smth_Q16) & 1))
			}
			return (((((*shape_state_FIX)(unsafe.Pointer(psShapeSt)).FTilt_smth_Q16) >> ((2) - 1)) + 1) >> 1)
		}()
	}
}

func NSQ(tls *libc.TLS, psEncC uintptr, psEncCtrlC uintptr, NSQ uintptr, x uintptr, q uintptr, LSFInterpFactor_Q2 int32, PredCoef_Q12 uintptr, LTPCoef_Q14 uintptr, AR2_Q13 uintptr, HarmShapeGain_Q14 uintptr, Tilt_Q14 uintptr, LF_shp_Q14 uintptr, Gains_Q16 uintptr, Lambda_Q10 int32, LTP_scale_Q14 int32) { /* NSQ.c:65:6: */
	bp := tls.Alloc(6304)
	defer tls.Free(6304)

	var k int32
	var lag int32
	var start_idx int32
	var LSF_interpolation_flag int32
	var A_Q12 uintptr
	var B_Q14 uintptr
	var AR_shp_Q13 uintptr
	var pxq uintptr
	// var sLTP_Q16 [960]int32 at bp+2464, 3840

	// var sLTP [960]int16 at bp+64, 1920

	var HarmShapeFIRPacked_Q14 int32
	var offset_Q10 int32
	// var FiltState [16]int32 at bp, 64

	// var x_sc_Q10 [120]int32 at bp+1984, 480

	(*nsq_state)(unsafe.Pointer(NSQ)).Frand_seed = (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FSeed
	/* Set unvoiced lag to the previous one, overwrite later for voiced */
	lag = (*nsq_state)(unsafe.Pointer(NSQ)).FlagPrev

	offset_Q10 = int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&Quantization_Offsets_Q10)) + uintptr((*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype)*4) + uintptr((*encoder_control)(unsafe.Pointer(psEncCtrlC)).FQuantOffsetType)*2)))

	if LSFInterpFactor_Q2 == (int32(1) << 2) {
		LSF_interpolation_flag = 0
	} else {
		LSF_interpolation_flag = 1
	}

	/* Setup pointers to start of sub frame */
	(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx = (*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length
	(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx = (*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length
	pxq = ((NSQ /* &.xq */) + uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length)*2)
	for k = 0; k < 4; k++ {
		A_Q12 = (PredCoef_Q12 + uintptr((((k>>1)|(1-LSF_interpolation_flag))*16))*2)
		B_Q14 = (LTPCoef_Q14 + uintptr((k*5))*2)
		AR_shp_Q13 = (AR2_Q13 + uintptr((k*16))*2)

		/* Noise shape parameters */

		HarmShapeFIRPacked_Q14 = ((*(*int32)(unsafe.Pointer(HarmShapeGain_Q14 + uintptr(k)*4))) >> (2))
		HarmShapeFIRPacked_Q14 = HarmShapeFIRPacked_Q14 | (((*(*int32)(unsafe.Pointer(HarmShapeGain_Q14 + uintptr(k)*4))) >> (1)) << (16))

		(*nsq_state)(unsafe.Pointer(NSQ)).Frewhite_flag = 0
		if (*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype == 0 {
			/* Voiced */
			lag = *(*int32)(unsafe.Pointer((psEncCtrlC + 108 /* &.pitchL */) + uintptr(k)*4))

			/* Re-whitening */
			if (k & (3 - ((LSF_interpolation_flag) << (1)))) == 0 {

				/* Rewhiten with new A coefs */
				start_idx = ((((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length - lag) - (*encoder_state)(unsafe.Pointer(psEncC)).FpredictLPCOrder) - (5 / 2))

				libc.Xmemset(tls, bp /* &FiltState[0] */, 0, (uint32((*encoder_state)(unsafe.Pointer(psEncC)).FpredictLPCOrder) * uint32(unsafe.Sizeof(int32(0)))))
				MA_Prediction(tls, ((NSQ /* &.xq */) + uintptr((start_idx+(k*((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length>>2))))*2),
					A_Q12, bp /* &FiltState[0] */, (bp + 64 /* &sLTP[0] */ + uintptr(start_idx)*2), ((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length - start_idx), (*encoder_state)(unsafe.Pointer(psEncC)).FpredictLPCOrder)

				(*nsq_state)(unsafe.Pointer(NSQ)).Frewhite_flag = 1
				(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx = (*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length
			}
		}

		nsq_scale_states(tls, NSQ, x, bp+1984 /* &x_sc_Q10[0] */, (*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length, bp+64, /* &sLTP[0] */
			bp+2464 /* &sLTP_Q16[0] */, k, LTP_scale_Q14, Gains_Q16, psEncCtrlC+108 /* &.pitchL */)

		noise_shape_quantizer(tls, NSQ, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype, bp+1984 /* &x_sc_Q10[0] */, q, pxq, bp+2464 /* &sLTP_Q16[0] */, A_Q12, B_Q14,
			AR_shp_Q13, lag, HarmShapeFIRPacked_Q14, *(*int32)(unsafe.Pointer(Tilt_Q14 + uintptr(k)*4)), *(*int32)(unsafe.Pointer(LF_shp_Q14 + uintptr(k)*4)), *(*int32)(unsafe.Pointer(Gains_Q16 + uintptr(k)*4)), Lambda_Q10,
			offset_Q10, (*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length, (*encoder_state)(unsafe.Pointer(psEncC)).FshapingLPCOrder, (*encoder_state)(unsafe.Pointer(psEncC)).FpredictLPCOrder)

		x += 2 * uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length)
		q += uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length)
		pxq += 2 * (uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length))
	}

	/* Update lagPrev for next frame */
	(*nsq_state)(unsafe.Pointer(NSQ)).FlagPrev = *(*int32)(unsafe.Pointer((psEncCtrlC + 108 /* &.pitchL */) + 3*4))

	/* Save quantized speech and noise shaping signals */
	libc.Xmemcpy(tls, NSQ /* &.xq */, ((NSQ /* &.xq */) + uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length)*2), (uint32((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length) * uint32(unsafe.Sizeof(int16(0)))))
	libc.Xmemcpy(tls, NSQ+1920 /* &.sLTP_shp_Q10 */, ((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length)*4), (uint32((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length) * uint32(unsafe.Sizeof(int32(0)))))

}

/***********************************/
/* noise_shape_quantizer  */
/***********************************/
func noise_shape_quantizer(tls *libc.TLS, NSQ uintptr, sigtype int32, x_sc_Q10 uintptr, q uintptr, xq uintptr, sLTP_Q16 uintptr, a_Q12 uintptr, b_Q14 uintptr, AR_shp_Q13 uintptr, lag int32, HarmShapeFIRPacked_Q14 int32, Tilt_Q14 int32, LF_shp_Q14 int32, Gain_Q16 int32, Lambda_Q10 int32, offset_Q10 int32, length int32, shapingLPCOrder int32, predictLPCOrder int32) { /* NSQ.c:172:17: */
	var i int32
	var j int32
	var LTP_pred_Q14 int32
	var LPC_pred_Q10 int32
	var n_AR_Q10 int32
	var n_LTP_Q14 int32
	var n_LF_Q10 int32
	var r_Q10 int32
	var q_Q0 int32
	var q_Q10 int32
	var thr1_Q10 int32
	var thr2_Q10 int32
	var thr3_Q10 int32
	var dither int32
	var exc_Q10 int32
	var LPC_exc_Q10 int32
	var xq_Q10 int32
	var tmp1 int32
	var tmp2 int32
	var sLF_AR_shp_Q10 int32
	var psLPC_Q14 uintptr
	var shp_lag_ptr uintptr
	var pred_lag_ptr uintptr

	shp_lag_ptr = ((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr((((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx-lag)+(3/2)))*4)
	pred_lag_ptr = (sLTP_Q16 + uintptr((((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx-lag)+(5/2)))*4)

	/* Setup short term AR state */
	psLPC_Q14 = ((NSQ + 5760 /* &.sLPC_Q14 */) + 31*4)

	/* Quantization thresholds */
	thr1_Q10 = ((-1536) - ((Lambda_Q10) >> (1)))
	thr2_Q10 = ((-512) - ((Lambda_Q10) >> (1)))
	thr2_Q10 = ((thr2_Q10) + (((int32(int16(offset_Q10))) * (int32(int16(Lambda_Q10)))) >> (10)))
	thr3_Q10 = ((512) + ((Lambda_Q10) >> (1)))

	for i = 0; i < length; i++ {
		/* Generate dither */
		(*nsq_state)(unsafe.Pointer(NSQ)).Frand_seed = (int32((uint32(907633515)) + ((uint32((*nsq_state)(unsafe.Pointer(NSQ)).Frand_seed)) * (uint32(196314165)))))

		/* dither = rand_seed < 0 ? 0xFFFFFFFF : 0; */
		dither = (((*nsq_state)(unsafe.Pointer(NSQ)).Frand_seed) >> (31))

		/* Short-term prediction */
		/* check that order is even */
		/* check that array starts at 4-byte aligned address */

		/* check that unrolling works */
		/* Partially unrolled */
		LPC_pred_Q10 = ((((*(*int32)(unsafe.Pointer(psLPC_Q14))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12))))) >> 16))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-1)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 1*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-1)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 1*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-2)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 2*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-2)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 2*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-3)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 3*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-3)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 3*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-4)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 4*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-4)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 4*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-5)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 5*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-5)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 5*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-6)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 6*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-6)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 6*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-7)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 7*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-7)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 7*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-8)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 8*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-8)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 8*2))))) >> 16)))
		LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-9)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 9*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-9)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 9*2))))) >> 16)))
		for j = 10; j < predictLPCOrder; j++ {
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + uintptr(-j)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + uintptr(j)*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + uintptr(-j)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + uintptr(j)*2))))) >> 16)))
		}
		/* Long-term prediction */
		if sigtype == 0 {
			/* Unrolled loop */
			LTP_pred_Q14 = ((((*(*int32)(unsafe.Pointer(pred_lag_ptr))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14))))) >> 16))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-1)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 1*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-1)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 1*2))))) >> 16)))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-2)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 2*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-2)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 2*2))))) >> 16)))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-3)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 3*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-3)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 3*2))))) >> 16)))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-4)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 4*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-4)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 4*2))))) >> 16)))
			pred_lag_ptr += 4
		} else {
			LTP_pred_Q14 = 0
		}

		/* Noise shape feedback */
		/* check that order is even */
		tmp2 = *(*int32)(unsafe.Pointer(psLPC_Q14))
		tmp1 = *(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */)))
		*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */))) = tmp2
		n_AR_Q10 = ((((tmp2) >> 16) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13))))) + ((((tmp2) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13))))) >> 16))
		for j = 2; j < shapingLPCOrder; j = j + (2) {
			tmp2 = *(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr((j-1))*4))
			*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr((j-1))*4)) = tmp1
			n_AR_Q10 = ((n_AR_Q10) + ((((tmp1) >> 16) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr((j-1))*2))))) + ((((tmp1) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr((j-1))*2))))) >> 16)))
			tmp1 = *(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr((j+0))*4))
			*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr((j+0))*4)) = tmp2
			n_AR_Q10 = ((n_AR_Q10) + ((((tmp2) >> 16) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr(j)*2))))) + ((((tmp2) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr(j)*2))))) >> 16)))
		}
		*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr((shapingLPCOrder-1))*4)) = tmp1
		n_AR_Q10 = ((n_AR_Q10) + ((((tmp1) >> 16) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr((shapingLPCOrder-1))*2))))) + ((((tmp1) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr((shapingLPCOrder-1))*2))))) >> 16)))

		n_AR_Q10 = ((n_AR_Q10) >> (1)) /* Q11 -> Q10 */
		n_AR_Q10 = ((n_AR_Q10) + (((((*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12) >> 16) * (int32(int16(Tilt_Q14)))) + (((((*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12) & 0x0000FFFF) * (int32(int16(Tilt_Q14)))) >> 16)))

		n_LF_Q10 = (((((*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx-1))*4))) >> 16) * (int32(int16(LF_shp_Q14)))) + ((((*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx-1))*4))) & 0x0000FFFF) * (int32(int16(LF_shp_Q14)))) >> 16)) << (2))
		n_LF_Q10 = (((n_LF_Q10) + ((((*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12) >> 16) * ((LF_shp_Q14) >> 16))) + (((((*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12) & 0x0000FFFF) * ((LF_shp_Q14) >> 16)) >> 16))

		/* Long-term shaping */
		if lag > 0 {
			/* Symmetric, packed FIR coefficients */
			n_LTP_Q14 = (((((*(*int32)(unsafe.Pointer(shp_lag_ptr))) + (*(*int32)(unsafe.Pointer(shp_lag_ptr + libc.UintptrFromInt32(-2)*4)))) >> 16) * (int32(int16(HarmShapeFIRPacked_Q14)))) + (((((*(*int32)(unsafe.Pointer(shp_lag_ptr))) + (*(*int32)(unsafe.Pointer(shp_lag_ptr + libc.UintptrFromInt32(-2)*4)))) & 0x0000FFFF) * (int32(int16(HarmShapeFIRPacked_Q14)))) >> 16))
			n_LTP_Q14 = (((n_LTP_Q14) + (((*(*int32)(unsafe.Pointer(shp_lag_ptr + libc.UintptrFromInt32(-1)*4))) >> 16) * ((HarmShapeFIRPacked_Q14) >> 16))) + ((((*(*int32)(unsafe.Pointer(shp_lag_ptr + libc.UintptrFromInt32(-1)*4))) & 0x0000FFFF) * ((HarmShapeFIRPacked_Q14) >> 16)) >> 16))
			n_LTP_Q14 = ((n_LTP_Q14) << (6))
			shp_lag_ptr += 4
		} else {
			n_LTP_Q14 = 0
		}

		/* Input minus prediction plus noise feedback  */
		//r = x[ i ] - LTP_pred - LPC_pred + n_AR + n_Tilt + n_LF + n_LTP;
		tmp1 = ((LTP_pred_Q14) - (n_LTP_Q14)) /* Add Q14 stuff */
		tmp1 = ((tmp1) >> (4))                /* convert to Q10  */
		tmp1 = ((tmp1) + (LPC_pred_Q10))      /* add Q10 stuff */
		tmp1 = ((tmp1) - (n_AR_Q10))          /* subtract Q10 stuff */
		tmp1 = ((tmp1) - (n_LF_Q10))          /* subtract Q10 stuff */
		r_Q10 = ((*(*int32)(unsafe.Pointer(x_sc_Q10 + uintptr(i)*4))) - (tmp1))

		/* Flip sign depending on dither */
		r_Q10 = ((r_Q10 ^ dither) - dither)
		r_Q10 = ((r_Q10) - (offset_Q10))
		r_Q10 = func() int32 {
			if (int32(-64) << 10) > (int32(64) << 10) {
				return func() int32 {
					if (r_Q10) > (int32(-64) << 10) {
						return (int32(-64) << 10)
					}
					return func() int32 {
						if (r_Q10) < (int32(64) << 10) {
							return (int32(64) << 10)
						}
						return r_Q10
					}()
				}()
			}
			return func() int32 {
				if (r_Q10) > (int32(64) << 10) {
					return (int32(64) << 10)
				}
				return func() int32 {
					if (r_Q10) < (int32(-64) << 10) {
						return (int32(-64) << 10)
					}
					return r_Q10
				}()
			}()
		}()

		/* Quantize */
		q_Q0 = 0
		q_Q10 = 0
		if r_Q10 < thr2_Q10 {
			if r_Q10 < thr1_Q10 {
				q_Q0 = func() int32 {
					if (10) == 1 {
						return ((((r_Q10) + ((Lambda_Q10) >> (1))) >> 1) + (((r_Q10) + ((Lambda_Q10) >> (1))) & 1))
					}
					return (((((r_Q10) + ((Lambda_Q10) >> (1))) >> ((10) - 1)) + 1) >> 1)
				}()
				q_Q10 = ((q_Q0) << (10))
			} else {
				q_Q0 = -1
				q_Q10 = -1024
			}
		} else {
			if r_Q10 > thr3_Q10 {
				q_Q0 = func() int32 {
					if (10) == 1 {
						return ((((r_Q10) - ((Lambda_Q10) >> (1))) >> 1) + (((r_Q10) - ((Lambda_Q10) >> (1))) & 1))
					}
					return (((((r_Q10) - ((Lambda_Q10) >> (1))) >> ((10) - 1)) + 1) >> 1)
				}()
				q_Q10 = ((q_Q0) << (10))
			}
		}
		*(*int8)(unsafe.Pointer(q + uintptr(i))) = int8(q_Q0) /* No saturation needed because max is 64 */

		/* Excitation */
		exc_Q10 = ((q_Q10) + (offset_Q10))
		exc_Q10 = ((exc_Q10 ^ dither) - dither)

		/* Add predictions */
		LPC_exc_Q10 = ((exc_Q10) + (func() int32 {
			if (4) == 1 {
				return (((LTP_pred_Q14) >> 1) + ((LTP_pred_Q14) & 1))
			}
			return ((((LTP_pred_Q14) >> ((4) - 1)) + 1) >> 1)
		}()))
		xq_Q10 = ((LPC_exc_Q10) + (LPC_pred_Q10))

		/* Scale XQ back to normal level before saving */
		*(*int16)(unsafe.Pointer(xq + uintptr(i)*2)) = func() int16 {
			if (func() int32 {
				if (10) == 1 {
					return (((((((xq_Q10) >> 16) * (int32(int16(Gain_Q16)))) + ((((xq_Q10) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((xq_Q10) * (func() int32 {
						if (16) == 1 {
							return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
						}
						return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
					}()))) >> 1) + ((((((xq_Q10) >> 16) * (int32(int16(Gain_Q16)))) + ((((xq_Q10) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((xq_Q10) * (func() int32 {
						if (16) == 1 {
							return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
						}
						return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
					}()))) & 1))
				}
				return ((((((((xq_Q10) >> 16) * (int32(int16(Gain_Q16)))) + ((((xq_Q10) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((xq_Q10) * (func() int32 {
					if (16) == 1 {
						return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
					}
					return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
				}()))) >> ((10) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((((((xq_Q10) >> 16) * (int32(int16(Gain_Q16)))) + ((((xq_Q10) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((xq_Q10) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((xq_Q10) >> 16) * (int32(int16(Gain_Q16)))) + ((((xq_Q10) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((xq_Q10) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1))
					}
					return ((((((((xq_Q10) >> 16) * (int32(int16(Gain_Q16)))) + ((((xq_Q10) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((xq_Q10) * (func() int32 {
						if (16) == 1 {
							return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
						}
						return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (10) == 1 {
						return (int16(((((((xq_Q10) >> 16) * (int32(int16(Gain_Q16)))) + ((((xq_Q10) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((xq_Q10) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((xq_Q10) >> 16) * (int32(int16(Gain_Q16)))) + ((((xq_Q10) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((xq_Q10) * (func() int32 {
							if (16) == 1 {
								return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
							}
							return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1)))
					}
					return (int16((((((((xq_Q10) >> 16) * (int32(int16(Gain_Q16)))) + ((((xq_Q10) & 0x0000FFFF) * (int32(int16(Gain_Q16)))) >> 16)) + ((xq_Q10) * (func() int32 {
						if (16) == 1 {
							return (((Gain_Q16) >> 1) + ((Gain_Q16) & 1))
						}
						return ((((Gain_Q16) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1))
				}()
			}()
		}()

		/* Update states */
		psLPC_Q14 += 4
		*(*int32)(unsafe.Pointer(psLPC_Q14)) = ((xq_Q10) << (4))
		sLF_AR_shp_Q10 = ((xq_Q10) - (n_AR_Q10))
		(*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12 = ((sLF_AR_shp_Q10) << (2))

		*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx)*4)) = ((sLF_AR_shp_Q10) - (n_LF_Q10))
		*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx)*4)) = ((LPC_exc_Q10) << (6))
		(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx++
		(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx++

		/* Make dither dependent on quantized signal */
		*(*int32)(unsafe.Pointer(NSQ + 6448 /* &.rand_seed */)) += (int32(*(*int8)(unsafe.Pointer(q + uintptr(i)))))
	}

	/* Update LPC synth buffer */
	libc.Xmemcpy(tls, NSQ+5760 /* &.sLPC_Q14 */, ((NSQ + 5760 /* &.sLPC_Q14 */) + uintptr(length)*4), (uint32(32) * uint32(unsafe.Sizeof(int32(0)))))
}

func nsq_scale_states(tls *libc.TLS, NSQ uintptr, x uintptr, x_sc_Q10 uintptr, subfr_length int32, sLTP uintptr, sLTP_Q16 uintptr, subfr int32, LTP_scale_Q14 int32, Gains_Q16 uintptr, pitchL uintptr) { /* NSQ.c:353:17: */
	var i int32
	var lag int32
	var inv_gain_Q16 int32
	var gain_adj_Q16 int32
	var inv_gain_Q32 int32

	inv_gain_Q16 = INVERSE32_varQ(tls, func() int32 {
		if (*(*int32)(unsafe.Pointer(Gains_Q16 + uintptr(subfr)*4))) > (1) {
			return *(*int32)(unsafe.Pointer(Gains_Q16 + uintptr(subfr)*4))
		}
		return 1
	}(), 32)
	inv_gain_Q16 = func() int32 {
		if (inv_gain_Q16) < (0x7FFF) {
			return inv_gain_Q16
		}
		return 0x7FFF
	}()
	lag = *(*int32)(unsafe.Pointer(pitchL + uintptr(subfr)*4))

	/* After rewhitening the LTP state is un-scaled, so scale with inv_gain_Q16 */
	if (*nsq_state)(unsafe.Pointer(NSQ)).Frewhite_flag != 0 {
		inv_gain_Q32 = ((inv_gain_Q16) << (16))
		if subfr == 0 {
			/* Do LTP downscaling */
			inv_gain_Q32 = (((((inv_gain_Q32) >> 16) * (int32(int16(LTP_scale_Q14)))) + ((((inv_gain_Q32) & 0x0000FFFF) * (int32(int16(LTP_scale_Q14)))) >> 16)) << (2))
		}
		for i = (((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx - lag) - (5 / 2)); i < (*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx; i++ {

			*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4)) = ((((inv_gain_Q32) >> 16) * (int32(*(*int16)(unsafe.Pointer(sLTP + uintptr(i)*2))))) + ((((inv_gain_Q32) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(sLTP + uintptr(i)*2))))) >> 16))
		}
	}

	/* Adjust for changing gain */
	if inv_gain_Q16 != (*nsq_state)(unsafe.Pointer(NSQ)).Fprev_inv_gain_Q16 {
		gain_adj_Q16 = DIV32_varQ(tls, inv_gain_Q16, (*nsq_state)(unsafe.Pointer(NSQ)).Fprev_inv_gain_Q16, 16)

		/* Scale long-term shaping state */
		for i = ((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx - (subfr_length * 4)); i < (*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx; i++ {
			*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}

		/* Scale long-term prediction state */
		if (*nsq_state)(unsafe.Pointer(NSQ)).Frewhite_flag == 0 {
			for i = (((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx - lag) - (5 / 2)); i < (*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx; i++ {
				*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
				}())))
			}
		}

		(*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12 = (((((gain_adj_Q16) >> 16) * (int32(int16((*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12)))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16((*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12)))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
			if (16) == 1 {
				return ((((*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12) >> 1) + (((*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12) & 1))
			}
			return (((((*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12) >> ((16) - 1)) + 1) >> 1)
		}())))

		/* Scale short-term prediction and shaping states */
		for i = 0; i < 32; i++ {
			*(*int32)(unsafe.Pointer((NSQ + 5760 /* &.sLPC_Q14 */) + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((NSQ + 5760 /* &.sLPC_Q14 */) + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((NSQ + 5760 /* &.sLPC_Q14 */) + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer((NSQ + 5760 /* &.sLPC_Q14 */) + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((NSQ + 5760 /* &.sLPC_Q14 */) + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer((NSQ + 5760 /* &.sLPC_Q14 */) + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}
		for i = 0; i < 16; i++ {
			*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer((NSQ + 6368 /* &.sAR2_Q14 */) + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}
	}

	/* Scale input */
	for i = 0; i < subfr_length; i++ {
		*(*int32)(unsafe.Pointer(x_sc_Q10 + uintptr(i)*4)) = (((int32(*(*int16)(unsafe.Pointer(x + uintptr(i)*2)))) * (int32(int16(inv_gain_Q16)))) >> (6))
	}

	/* save inv_gain */

	(*nsq_state)(unsafe.Pointer(NSQ)).Fprev_inv_gain_Q16 = inv_gain_Q16
}

type NSQ_del_dec_struct struct {
	FRandState [32]int32
	FQ_Q10     [32]int32
	FXq_Q10    [32]int32
	FPred_Q16  [32]int32
	FShape_Q10 [32]int32
	FGain_Q16  [32]int32
	FsAR2_Q14  [16]int32
	FsLPC_Q14  [152]int32
	FLF_AR_Q12 int32
	FSeed      int32
	FSeedInit  int32
	FRD_Q10    int32
} /* NSQ_del_dec.c:43:3 */

type NSQ_sample_struct struct {
	FQ_Q10        int32
	FRD_Q10       int32
	Fxq_Q14       int32
	FLF_AR_Q12    int32
	FsLTP_shp_Q10 int32
	FLPC_exc_Q16  int32
} /* NSQ_del_dec.c:52:3 */

func NSQ_del_dec(tls *libc.TLS, psEncC uintptr, psEncCtrlC uintptr, NSQ uintptr, x uintptr, q uintptr, LSFInterpFactor_Q2 int32, PredCoef_Q12 uintptr, LTPCoef_Q14 uintptr, AR2_Q13 uintptr, HarmShapeGain_Q14 uintptr, Tilt_Q14 uintptr, LF_shp_Q14 uintptr, Gains_Q16 uintptr, Lambda_Q10 int32, LTP_scale_Q14 int32) { /* NSQ_del_dec.c:107:6: */
	bp := tls.Alloc(12132)
	defer tls.Free(12132)

	var i int32
	var k int32
	var lag int32
	var start_idx int32
	var LSF_interpolation_flag int32
	var Winner_ind int32
	var subfr int32
	var last_smple_idx int32
	// var smpl_buf_idx int32 at bp+12128, 4

	var decisionDelay int32
	var subfr_length int32
	var A_Q12 uintptr
	var B_Q14 uintptr
	var AR_shp_Q13 uintptr
	var pxq uintptr
	// var sLTP_Q16 [960]int32 at bp+8288, 3840

	// var sLTP [960]int16 at bp+5888, 1920

	var HarmShapeFIRPacked_Q14 int32
	var offset_Q10 int32
	// var FiltState [16]int32 at bp+5824, 64

	var RDmin_Q10 int32
	// var x_sc_Q10 [120]int32 at bp+7808, 480

	// var psDelDec [4]NSQ_del_dec_struct at bp, 5824

	var psDD uintptr

	subfr_length = ((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length / 4)

	/* Set unvoiced lag to the previous one, overwrite later for voiced */
	lag = (*nsq_state)(unsafe.Pointer(NSQ)).FlagPrev

	/* Initialize delayed decision states */
	libc.Xmemset(tls, bp /* &psDelDec[0] */, 0, (uint32((*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision) * uint32(unsafe.Sizeof(NSQ_del_dec_struct{}))))
	for k = 0; k < (*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision; k++ {
		psDD = (bp /* &psDelDec */ + uintptr(k)*1456)
		(*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeed = ((k + (*encoder_control)(unsafe.Pointer(psEncCtrlC)).FSeed) & 3)
		(*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeedInit = (*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeed
		(*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FRD_Q10 = 0
		(*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12 = (*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12
		*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */))) = *(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length-1))*4))
		libc.Xmemcpy(tls, psDD+832 /* &.sLPC_Q14 */, NSQ+5760 /* &.sLPC_Q14 */, (uint32(32) * uint32(unsafe.Sizeof(int32(0)))))
		libc.Xmemcpy(tls, psDD+768 /* &.sAR2_Q14 */, NSQ+6368 /* &.sAR2_Q14 */, uint32(unsafe.Sizeof([16]int32{})))
	}

	offset_Q10 = int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&Quantization_Offsets_Q10)) + uintptr((*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype)*4) + uintptr((*encoder_control)(unsafe.Pointer(psEncCtrlC)).FQuantOffsetType)*2)))
	*(*int32)(unsafe.Pointer(bp + 12128 /* smpl_buf_idx */)) = 0 /* index of oldest samples */

	decisionDelay = min_int(tls, 32, subfr_length)

	/* For voiced frames limit the decision delay to lower than the pitch lag */
	if (*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype == 0 {
		for k = 0; k < 4; k++ {
			decisionDelay = min_int(tls, decisionDelay, ((*(*int32)(unsafe.Pointer((psEncCtrlC + 108 /* &.pitchL */) + uintptr(k)*4)) - (5 / 2)) - 1))
		}
	} else {
		if lag > 0 {
			decisionDelay = min_int(tls, decisionDelay, ((lag - (5 / 2)) - 1))
		}
	}

	if LSFInterpFactor_Q2 == (int32(1) << 2) {
		LSF_interpolation_flag = 0
	} else {
		LSF_interpolation_flag = 1
	}

	/* Setup pointers to start of sub frame */
	pxq = ((NSQ /* &.xq */) + uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length)*2)
	(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx = (*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length
	(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx = (*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length
	subfr = 0
	for k = 0; k < 4; k++ {
		A_Q12 = (PredCoef_Q12 + uintptr((((k>>1)|(1-LSF_interpolation_flag))*16))*2)
		B_Q14 = (LTPCoef_Q14 + uintptr((k*5))*2)
		AR_shp_Q13 = (AR2_Q13 + uintptr((k*16))*2)

		/* Noise shape parameters */

		HarmShapeFIRPacked_Q14 = ((*(*int32)(unsafe.Pointer(HarmShapeGain_Q14 + uintptr(k)*4))) >> (2))
		HarmShapeFIRPacked_Q14 = HarmShapeFIRPacked_Q14 | (((*(*int32)(unsafe.Pointer(HarmShapeGain_Q14 + uintptr(k)*4))) >> (1)) << (16))

		(*nsq_state)(unsafe.Pointer(NSQ)).Frewhite_flag = 0
		if (*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype == 0 {
			/* Voiced */
			lag = *(*int32)(unsafe.Pointer((psEncCtrlC + 108 /* &.pitchL */) + uintptr(k)*4))

			/* Re-whitening */
			if (k & (3 - ((LSF_interpolation_flag) << (1)))) == 0 {
				if k == 2 {
					/* RESET DELAYED DECISIONS */
					/* Find winner */
					RDmin_Q10 = (*NSQ_del_dec_struct)(unsafe.Pointer(bp /* &psDelDec */)).FRD_Q10
					Winner_ind = 0
					for i = 1; i < (*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision; i++ {
						if (*NSQ_del_dec_struct)(unsafe.Pointer(bp /* &psDelDec */ +uintptr(i)*1456)).FRD_Q10 < RDmin_Q10 {
							RDmin_Q10 = (*NSQ_del_dec_struct)(unsafe.Pointer(bp /* &psDelDec */ + uintptr(i)*1456)).FRD_Q10
							Winner_ind = i
						}
					}
					for i = 0; i < (*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision; i++ {
						if i != Winner_ind {
							*(*int32)(unsafe.Pointer(bp /* &psDelDec */ + uintptr(i)*1456 + 1452 /* &.RD_Q10 */)) += (int32(0x7FFFFFFF) >> 4)

						}
					}

					/* Copy final part of signals from winner state to output and long-term filter states */
					psDD = (bp /* &psDelDec */ + uintptr(Winner_ind)*1456)
					last_smple_idx = (*(*int32)(unsafe.Pointer(bp + 12128 /* smpl_buf_idx */)) + decisionDelay)
					for i = 0; i < decisionDelay; i++ {
						last_smple_idx = ((last_smple_idx - 1) & (32 - 1))
						*(*int8)(unsafe.Pointer(q + uintptr((i - decisionDelay)))) = (int8((*(*int32)(unsafe.Pointer((psDD + 128 /* &.Q_Q10 */) + uintptr(last_smple_idx)*4))) >> (10)))
						*(*int16)(unsafe.Pointer(pxq + uintptr((i-decisionDelay))*2)) = func() int16 {
							if (func() int32 {
								if (10) == 1 {
									return (((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
										if (16) == 1 {
											return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
										}
										return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
									}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
										if (16) == 1 {
											return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
										}
										return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
									}()))) & 1))
								}
								return ((((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
									if (16) == 1 {
										return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
									}
									return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
								}()))) >> ((10) - 1)) + 1) >> 1)
							}()) > 0x7FFF {
								return int16(0x7FFF)
							}
							return func() int16 {
								if (func() int32 {
									if (10) == 1 {
										return (((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
											if (16) == 1 {
												return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
											}
											return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
										}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
											if (16) == 1 {
												return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
											}
											return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
										}()))) & 1))
									}
									return ((((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
										if (16) == 1 {
											return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
										}
										return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
									}()))) >> ((10) - 1)) + 1) >> 1)
								}()) < (int32(libc.Int16FromInt32(0x8000))) {
									return libc.Int16FromInt32(0x8000)
								}
								return func() int16 {
									if (10) == 1 {
										return (int16(((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
											if (16) == 1 {
												return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
											}
											return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
										}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
											if (16) == 1 {
												return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
											}
											return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
										}()))) & 1)))
									}
									return (int16((((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
										if (16) == 1 {
											return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
										}
										return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
									}()))) >> ((10) - 1)) + 1) >> 1))
								}()
							}()
						}()
						*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr((((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx-decisionDelay)+i))*4)) = *(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(last_smple_idx)*4))
					}

					subfr = 0
				}

				/* Rewhiten with new A coefs */
				start_idx = ((((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length - lag) - (*encoder_state)(unsafe.Pointer(psEncC)).FpredictLPCOrder) - (5 / 2))

				libc.Xmemset(tls, bp+5824 /* &FiltState[0] */, 0, (uint32((*encoder_state)(unsafe.Pointer(psEncC)).FpredictLPCOrder) * uint32(unsafe.Sizeof(int32(0)))))
				MA_Prediction(tls, ((NSQ /* &.xq */) + uintptr((start_idx+(k*(*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length)))*2),
					A_Q12, bp+5824 /* &FiltState[0] */, (bp + 5888 /* &sLTP[0] */ + uintptr(start_idx)*2), ((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length - start_idx), (*encoder_state)(unsafe.Pointer(psEncC)).FpredictLPCOrder)

				(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx = (*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length
				(*nsq_state)(unsafe.Pointer(NSQ)).Frewhite_flag = 1
			}
		}

		nsq_del_dec_scale_states(tls, NSQ, bp /* &psDelDec[0] */, x, bp+7808, /* &x_sc_Q10[0] */
			subfr_length, bp+5888 /* &sLTP[0] */, bp+8288 /* &sLTP_Q16[0] */, k, (*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision, *(*int32)(unsafe.Pointer(bp + 12128 /* smpl_buf_idx */)),
			LTP_scale_Q14, Gains_Q16, psEncCtrlC+108 /* &.pitchL */)

		noise_shape_quantizer_del_dec(tls, NSQ, bp /* &psDelDec[0] */, (*encoder_control)(unsafe.Pointer(psEncCtrlC)).Fsigtype, bp+7808 /* &x_sc_Q10[0] */, q, pxq, bp+8288, /* &sLTP_Q16[0] */
			A_Q12, B_Q14, AR_shp_Q13, lag, HarmShapeFIRPacked_Q14, *(*int32)(unsafe.Pointer(Tilt_Q14 + uintptr(k)*4)), *(*int32)(unsafe.Pointer(LF_shp_Q14 + uintptr(k)*4)), *(*int32)(unsafe.Pointer(Gains_Q16 + uintptr(k)*4)),
			Lambda_Q10, offset_Q10, (*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length, libc.PostIncInt32(&subfr, 1), (*encoder_state)(unsafe.Pointer(psEncC)).FshapingLPCOrder, (*encoder_state)(unsafe.Pointer(psEncC)).FpredictLPCOrder,
			(*encoder_state)(unsafe.Pointer(psEncC)).Fwarping_Q16, (*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision, bp+12128 /* &smpl_buf_idx */, decisionDelay)

		x += 2 * uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length)
		q += uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length)
		pxq += 2 * (uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length))
	}

	/* Find winner */
	RDmin_Q10 = (*NSQ_del_dec_struct)(unsafe.Pointer(bp /* &psDelDec */)).FRD_Q10
	Winner_ind = 0
	for k = 1; k < (*encoder_state)(unsafe.Pointer(psEncC)).FnStatesDelayedDecision; k++ {
		if (*NSQ_del_dec_struct)(unsafe.Pointer(bp /* &psDelDec */ +uintptr(k)*1456)).FRD_Q10 < RDmin_Q10 {
			RDmin_Q10 = (*NSQ_del_dec_struct)(unsafe.Pointer(bp /* &psDelDec */ + uintptr(k)*1456)).FRD_Q10
			Winner_ind = k
		}
	}

	/* Copy final part of signals from winner state to output and long-term filter states */
	psDD = (bp /* &psDelDec */ + uintptr(Winner_ind)*1456)
	(*encoder_control)(unsafe.Pointer(psEncCtrlC)).FSeed = (*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeedInit
	last_smple_idx = (*(*int32)(unsafe.Pointer(bp + 12128 /* smpl_buf_idx */)) + decisionDelay)
	for i = 0; i < decisionDelay; i++ {
		last_smple_idx = ((last_smple_idx - 1) & (32 - 1))
		*(*int8)(unsafe.Pointer(q + uintptr((i - decisionDelay)))) = (int8((*(*int32)(unsafe.Pointer((psDD + 128 /* &.Q_Q10 */) + uintptr(last_smple_idx)*4))) >> (10)))
		*(*int16)(unsafe.Pointer(pxq + uintptr((i-decisionDelay))*2)) = func() int16 {
			if (func() int32 {
				if (10) == 1 {
					return (((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) & 1))
				}
				return ((((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
				}()))) >> ((10) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1))
					}
					return ((((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (10) == 1 {
						return (int16(((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1)))
					}
					return (int16((((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1))
				}()
			}()
		}()
		*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr((((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx-decisionDelay)+i))*4)) = *(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(last_smple_idx)*4))
		*(*int32)(unsafe.Pointer(bp + 8288 /* &sLTP_Q16[0] */ + uintptr((((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx-decisionDelay)+i))*4)) = *(*int32)(unsafe.Pointer((psDD + 384 /* &.Pred_Q16 */) + uintptr(last_smple_idx)*4))
	}
	libc.Xmemcpy(tls, NSQ+5760 /* &.sLPC_Q14 */, ((psDD + 832 /* &.sLPC_Q14 */) + uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fsubfr_length)*4), (uint32(32) * uint32(unsafe.Sizeof(int32(0)))))
	libc.Xmemcpy(tls, NSQ+6368 /* &.sAR2_Q14 */, psDD+768 /* &.sAR2_Q14 */, uint32(unsafe.Sizeof([16]int32{})))

	/* Update states */
	(*nsq_state)(unsafe.Pointer(NSQ)).FsLF_AR_shp_Q12 = (*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12
	(*nsq_state)(unsafe.Pointer(NSQ)).FlagPrev = *(*int32)(unsafe.Pointer((psEncCtrlC + 108 /* &.pitchL */) + 3*4))

	/* Save quantized speech and noise shaping signals */
	libc.Xmemcpy(tls, NSQ /* &.xq */, ((NSQ /* &.xq */) + uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length)*2), (uint32((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length) * uint32(unsafe.Sizeof(int16(0)))))
	libc.Xmemcpy(tls, NSQ+1920 /* &.sLTP_shp_Q10 */, ((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length)*4), (uint32((*encoder_state)(unsafe.Pointer(psEncC)).Fframe_length) * uint32(unsafe.Sizeof(int32(0)))))

}

/******************************************/
/* Noise shape quantizer for one subframe */
/******************************************/
func noise_shape_quantizer_del_dec(tls *libc.TLS, NSQ uintptr, psDelDec uintptr, sigtype int32, x_Q10 uintptr, q uintptr, xq uintptr, sLTP_Q16 uintptr, a_Q12 uintptr, b_Q14 uintptr, AR_shp_Q13 uintptr, lag int32, HarmShapeFIRPacked_Q14 int32, Tilt_Q14 int32, LF_shp_Q14 int32, Gain_Q16 int32, Lambda_Q10 int32, offset_Q10 int32, length int32, subfr int32, shapingLPCOrder int32, predictLPCOrder int32, warping_Q16 int32, nStatesDelayedDecision int32, smpl_buf_idx uintptr, decisionDelay int32) { /* NSQ_del_dec.c:305:17: */
	bp := tls.Alloc(192)
	defer tls.Free(192)

	var i int32
	var j int32
	var k int32
	var Winner_ind int32
	var RDmin_ind int32
	var RDmax_ind int32
	var last_smple_idx int32
	var Winner_rand_state int32
	var LTP_pred_Q14 int32
	var LPC_pred_Q10 int32
	var n_AR_Q10 int32
	var n_LTP_Q14 int32
	var n_LF_Q10 int32
	var r_Q10 int32
	var rr_Q20 int32
	var rd1_Q10 int32
	var rd2_Q10 int32
	var RDmin_Q10 int32
	var RDmax_Q10 int32
	var q1_Q10 int32
	var q2_Q10 int32
	var dither int32
	var exc_Q10 int32
	var LPC_exc_Q10 int32
	var xq_Q10 int32
	var tmp1 int32
	var tmp2 int32
	var sLF_AR_shp_Q10 int32
	var pred_lag_ptr uintptr
	var shp_lag_ptr uintptr
	var psLPC_Q14 uintptr
	// var psSampleState [4][2]NSQ_sample_struct at bp, 192

	var psDD uintptr
	var psSS uintptr

	shp_lag_ptr = ((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr((((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx-lag)+(3/2)))*4)
	pred_lag_ptr = (sLTP_Q16 + uintptr((((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx-lag)+(5/2)))*4)

	for i = 0; i < length; i++ {
		/* Perform common calculations used in all states */

		/* Long-term prediction */
		if sigtype == 0 {
			/* Unrolled loop */
			LTP_pred_Q14 = ((((*(*int32)(unsafe.Pointer(pred_lag_ptr))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14))))) >> 16))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-1)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 1*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-1)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 1*2))))) >> 16)))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-2)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 2*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-2)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 2*2))))) >> 16)))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-3)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 3*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-3)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 3*2))))) >> 16)))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-4)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 4*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-4)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(b_Q14 + 4*2))))) >> 16)))
			pred_lag_ptr += 4
		} else {
			LTP_pred_Q14 = 0
		}

		/* Long-term shaping */
		if lag > 0 {
			/* Symmetric, packed FIR coefficients */
			n_LTP_Q14 = (((((*(*int32)(unsafe.Pointer(shp_lag_ptr))) + (*(*int32)(unsafe.Pointer(shp_lag_ptr + libc.UintptrFromInt32(-2)*4)))) >> 16) * (int32(int16(HarmShapeFIRPacked_Q14)))) + (((((*(*int32)(unsafe.Pointer(shp_lag_ptr))) + (*(*int32)(unsafe.Pointer(shp_lag_ptr + libc.UintptrFromInt32(-2)*4)))) & 0x0000FFFF) * (int32(int16(HarmShapeFIRPacked_Q14)))) >> 16))
			n_LTP_Q14 = (((n_LTP_Q14) + (((*(*int32)(unsafe.Pointer(shp_lag_ptr + libc.UintptrFromInt32(-1)*4))) >> 16) * ((HarmShapeFIRPacked_Q14) >> 16))) + ((((*(*int32)(unsafe.Pointer(shp_lag_ptr + libc.UintptrFromInt32(-1)*4))) & 0x0000FFFF) * ((HarmShapeFIRPacked_Q14) >> 16)) >> 16))
			n_LTP_Q14 = ((n_LTP_Q14) << (6))
			shp_lag_ptr += 4
		} else {
			n_LTP_Q14 = 0
		}

		for k = 0; k < nStatesDelayedDecision; k++ {
			/* Delayed decision state */
			psDD = (psDelDec + uintptr(k)*1456)

			/* Sample state */
			psSS = (bp /* &psSampleState[0] */ + uintptr(k)*48)

			/* Generate dither */
			(*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeed = (int32((uint32(907633515)) + ((uint32((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeed)) * (uint32(196314165)))))

			/* dither = rand_seed < 0 ? 0xFFFFFFFF : 0; */
			dither = (((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeed) >> (31))

			/* Pointer used in short term prediction and shaping */
			psLPC_Q14 = ((psDD + 832 /* &.sLPC_Q14 */) + uintptr(((32-1)+i))*4)
			/* Short-term prediction */
			/* check that unrolling works */
			/* check that order is even */
			/* check that array starts at 4-byte aligned address */
			/* Partially unrolled */
			LPC_pred_Q10 = ((((*(*int32)(unsafe.Pointer(psLPC_Q14))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12))))) >> 16))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-1)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 1*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-1)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 1*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-2)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 2*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-2)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 2*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-3)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 3*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-3)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 3*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-4)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 4*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-4)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 4*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-5)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 5*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-5)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 5*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-6)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 6*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-6)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 6*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-7)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 7*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-7)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 7*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-8)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 8*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-8)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 8*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-9)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 9*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + libc.UintptrFromInt32(-9)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + 9*2))))) >> 16)))
			for j = 10; j < predictLPCOrder; j++ {
				LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + uintptr(-j)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + uintptr(j)*2))))) + ((((*(*int32)(unsafe.Pointer(psLPC_Q14 + uintptr(-j)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(a_Q12 + uintptr(j)*2))))) >> 16)))
			}

			/* Noise shape feedback */
			/* check that order is even */
			/* Output of lowpass section */
			tmp2 = ((*(*int32)(unsafe.Pointer(psLPC_Q14))) + ((((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */)))) >> 16) * (int32(int16(warping_Q16)))) + ((((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */)))) & 0x0000FFFF) * (int32(int16(warping_Q16)))) >> 16)))
			/* Output of allpass section */
			tmp1 = ((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */)))) + ((((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + 1*4)) - tmp2) >> 16) * (int32(int16(warping_Q16)))) + ((((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + 1*4)) - tmp2) & 0x0000FFFF) * (int32(int16(warping_Q16)))) >> 16)))
			*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */))) = tmp2
			n_AR_Q10 = ((((tmp2) >> 16) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13))))) + ((((tmp2) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13))))) >> 16))
			/* Loop over allpass sections */
			for j = 2; j < shapingLPCOrder; j = j + (2) {
				/* Output of allpass section */
				tmp2 = ((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr((j-1))*4))) + ((((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr((j+0))*4)) - tmp1) >> 16) * (int32(int16(warping_Q16)))) + ((((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr((j+0))*4)) - tmp1) & 0x0000FFFF) * (int32(int16(warping_Q16)))) >> 16)))
				*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr((j-1))*4)) = tmp1
				n_AR_Q10 = ((n_AR_Q10) + ((((tmp1) >> 16) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr((j-1))*2))))) + ((((tmp1) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr((j-1))*2))))) >> 16)))
				/* Output of allpass section */
				tmp1 = ((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr((j+0))*4))) + ((((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr((j+1))*4)) - tmp2) >> 16) * (int32(int16(warping_Q16)))) + ((((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr((j+1))*4)) - tmp2) & 0x0000FFFF) * (int32(int16(warping_Q16)))) >> 16)))
				*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr((j+0))*4)) = tmp2
				n_AR_Q10 = ((n_AR_Q10) + ((((tmp2) >> 16) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr(j)*2))))) + ((((tmp2) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr(j)*2))))) >> 16)))
			}
			*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr((shapingLPCOrder-1))*4)) = tmp1
			n_AR_Q10 = ((n_AR_Q10) + ((((tmp1) >> 16) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr((shapingLPCOrder-1))*2))))) + ((((tmp1) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(AR_shp_Q13 + uintptr((shapingLPCOrder-1))*2))))) >> 16)))

			n_AR_Q10 = ((n_AR_Q10) >> (1)) /* Q11 -> Q10 */
			n_AR_Q10 = ((n_AR_Q10) + (((((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12) >> 16) * (int32(int16(Tilt_Q14)))) + (((((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12) & 0x0000FFFF) * (int32(int16(Tilt_Q14)))) >> 16)))

			n_LF_Q10 = (((((*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(*(*int32)(unsafe.Pointer(smpl_buf_idx)))*4))) >> 16) * (int32(int16(LF_shp_Q14)))) + ((((*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(*(*int32)(unsafe.Pointer(smpl_buf_idx)))*4))) & 0x0000FFFF) * (int32(int16(LF_shp_Q14)))) >> 16)) << (2))
			n_LF_Q10 = (((n_LF_Q10) + ((((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12) >> 16) * ((LF_shp_Q14) >> 16))) + (((((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12) & 0x0000FFFF) * ((LF_shp_Q14) >> 16)) >> 16))

			/* Input minus prediction plus noise feedback                       */
			/* r = x[ i ] - LTP_pred - LPC_pred + n_AR + n_Tilt + n_LF + n_LTP  */
			tmp1 = ((LTP_pred_Q14) - (n_LTP_Q14))                                /* Add Q14 stuff */
			tmp1 = ((tmp1) >> (4))                                               /* convert to Q10 */
			tmp1 = ((tmp1) + (LPC_pred_Q10))                                     /* add Q10 stuff */
			tmp1 = ((tmp1) - (n_AR_Q10))                                         /* subtract Q10 stuff */
			tmp1 = ((tmp1) - (n_LF_Q10))                                         /* subtract Q10 stuff */
			r_Q10 = ((*(*int32)(unsafe.Pointer(x_Q10 + uintptr(i)*4))) - (tmp1)) /* residual error Q10 */

			/* Flip sign depending on dither */
			r_Q10 = ((r_Q10 ^ dither) - dither)
			r_Q10 = ((r_Q10) - (offset_Q10))
			r_Q10 = func() int32 {
				if (int32(-64) << 10) > (int32(64) << 10) {
					return func() int32 {
						if (r_Q10) > (int32(-64) << 10) {
							return (int32(-64) << 10)
						}
						return func() int32 {
							if (r_Q10) < (int32(64) << 10) {
								return (int32(64) << 10)
							}
							return r_Q10
						}()
					}()
				}
				return func() int32 {
					if (r_Q10) > (int32(64) << 10) {
						return (int32(64) << 10)
					}
					return func() int32 {
						if (r_Q10) < (int32(-64) << 10) {
							return (int32(-64) << 10)
						}
						return r_Q10
					}()
				}()
			}()

			/* Find two quantization level candidates and measure their rate-distortion */
			if r_Q10 < -1536 {
				q1_Q10 = ((func() int32 {
					if (10) == 1 {
						return (((r_Q10) >> 1) + ((r_Q10) & 1))
					}
					return ((((r_Q10) >> ((10) - 1)) + 1) >> 1)
				}()) << (10))
				r_Q10 = ((r_Q10) - (q1_Q10))
				rd1_Q10 = ((((-((q1_Q10) + (offset_Q10))) * (Lambda_Q10)) + ((int32(int16(r_Q10))) * (int32(int16(r_Q10))))) >> (10))
				rd2_Q10 = ((rd1_Q10) + (1024))
				rd2_Q10 = ((rd2_Q10) - ((Lambda_Q10) + ((r_Q10) << (1))))
				q2_Q10 = ((q1_Q10) + (1024))
			} else if r_Q10 > 512 {
				q1_Q10 = ((func() int32 {
					if (10) == 1 {
						return (((r_Q10) >> 1) + ((r_Q10) & 1))
					}
					return ((((r_Q10) >> ((10) - 1)) + 1) >> 1)
				}()) << (10))
				r_Q10 = ((r_Q10) - (q1_Q10))
				rd1_Q10 = (((((q1_Q10) + (offset_Q10)) * (Lambda_Q10)) + ((int32(int16(r_Q10))) * (int32(int16(r_Q10))))) >> (10))
				rd2_Q10 = ((rd1_Q10) + (1024))
				rd2_Q10 = ((rd2_Q10) - ((Lambda_Q10) - ((r_Q10) << (1))))
				q2_Q10 = ((q1_Q10) - (1024))
			} else { /* r_Q10 >= -1536 && q1_Q10 <= 512 */
				rr_Q20 = ((int32(int16(offset_Q10))) * (int32(int16(Lambda_Q10))))
				rd2_Q10 = (((rr_Q20) + ((int32(int16(r_Q10))) * (int32(int16(r_Q10))))) >> (10))
				rd1_Q10 = ((rd2_Q10) + (1024))
				rd1_Q10 = ((rd1_Q10) + (((Lambda_Q10) + ((r_Q10) << (1))) - ((rr_Q20) >> (9))))
				q1_Q10 = -1024
				q2_Q10 = 0
			}

			if rd1_Q10 < rd2_Q10 {
				(*NSQ_sample_struct)(unsafe.Pointer(psSS)).FRD_Q10 = (((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FRD_Q10) + (rd1_Q10))
				(*NSQ_sample_struct)(unsafe.Pointer(psSS + 1*24)).FRD_Q10 = (((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FRD_Q10) + (rd2_Q10))
				(*NSQ_sample_struct)(unsafe.Pointer(psSS)).FQ_Q10 = q1_Q10
				(*NSQ_sample_struct)(unsafe.Pointer(psSS + 1*24)).FQ_Q10 = q2_Q10
			} else {
				(*NSQ_sample_struct)(unsafe.Pointer(psSS)).FRD_Q10 = (((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FRD_Q10) + (rd2_Q10))
				(*NSQ_sample_struct)(unsafe.Pointer(psSS + 1*24)).FRD_Q10 = (((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FRD_Q10) + (rd1_Q10))
				(*NSQ_sample_struct)(unsafe.Pointer(psSS)).FQ_Q10 = q2_Q10
				(*NSQ_sample_struct)(unsafe.Pointer(psSS + 1*24)).FQ_Q10 = q1_Q10
			}

			/* Update states for best quantization */

			/* Quantized excitation */
			exc_Q10 = ((offset_Q10) + ((*NSQ_sample_struct)(unsafe.Pointer(psSS)).FQ_Q10))
			exc_Q10 = ((exc_Q10 ^ dither) - dither)

			/* Add predictions */
			LPC_exc_Q10 = (exc_Q10 + (func() int32 {
				if (4) == 1 {
					return (((LTP_pred_Q14) >> 1) + ((LTP_pred_Q14) & 1))
				}
				return ((((LTP_pred_Q14) >> ((4) - 1)) + 1) >> 1)
			}()))
			xq_Q10 = ((LPC_exc_Q10) + (LPC_pred_Q10))

			/* Update states */
			sLF_AR_shp_Q10 = ((xq_Q10) - (n_AR_Q10))
			(*NSQ_sample_struct)(unsafe.Pointer(psSS)).FsLTP_shp_Q10 = ((sLF_AR_shp_Q10) - (n_LF_Q10))
			(*NSQ_sample_struct)(unsafe.Pointer(psSS)).FLF_AR_Q12 = ((sLF_AR_shp_Q10) << (2))
			(*NSQ_sample_struct)(unsafe.Pointer(psSS)).Fxq_Q14 = ((xq_Q10) << (4))
			(*NSQ_sample_struct)(unsafe.Pointer(psSS)).FLPC_exc_Q16 = ((LPC_exc_Q10) << (6))

			/* Update states for second best quantization */

			/* Quantized excitation */
			exc_Q10 = ((offset_Q10) + ((*NSQ_sample_struct)(unsafe.Pointer(psSS + 1*24)).FQ_Q10))
			exc_Q10 = ((exc_Q10 ^ dither) - dither)

			/* Add predictions */
			LPC_exc_Q10 = (exc_Q10 + (func() int32 {
				if (4) == 1 {
					return (((LTP_pred_Q14) >> 1) + ((LTP_pred_Q14) & 1))
				}
				return ((((LTP_pred_Q14) >> ((4) - 1)) + 1) >> 1)
			}()))
			xq_Q10 = ((LPC_exc_Q10) + (LPC_pred_Q10))

			/* Update states */
			sLF_AR_shp_Q10 = ((xq_Q10) - (n_AR_Q10))
			(*NSQ_sample_struct)(unsafe.Pointer(psSS + 1*24)).FsLTP_shp_Q10 = ((sLF_AR_shp_Q10) - (n_LF_Q10))
			(*NSQ_sample_struct)(unsafe.Pointer(psSS + 1*24)).FLF_AR_Q12 = ((sLF_AR_shp_Q10) << (2))
			(*NSQ_sample_struct)(unsafe.Pointer(psSS + 1*24)).Fxq_Q14 = ((xq_Q10) << (4))
			(*NSQ_sample_struct)(unsafe.Pointer(psSS + 1*24)).FLPC_exc_Q16 = ((LPC_exc_Q10) << (6))
		}

		*(*int32)(unsafe.Pointer(smpl_buf_idx)) = ((*(*int32)(unsafe.Pointer(smpl_buf_idx)) - 1) & (32 - 1)) /* Index to newest samples              */
		last_smple_idx = ((*(*int32)(unsafe.Pointer(smpl_buf_idx)) + decisionDelay) & (32 - 1))              /* Index to decisionDelay old samples   */

		/* Find winner */
		RDmin_Q10 = (*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */))).FRD_Q10
		Winner_ind = 0
		for k = 1; k < nStatesDelayedDecision; k++ {
			if (*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ + uintptr(k)*48))).FRD_Q10 < RDmin_Q10 {
				RDmin_Q10 = (*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ + uintptr(k)*48))).FRD_Q10
				Winner_ind = k
			}
		}

		/* Increase RD values of expired states */
		Winner_rand_state = *(*int32)(unsafe.Pointer((psDelDec + uintptr(Winner_ind)*1456 /* &.RandState */) + uintptr(last_smple_idx)*4))
		for k = 0; k < nStatesDelayedDecision; k++ {
			if *(*int32)(unsafe.Pointer((psDelDec + uintptr(k)*1456 /* &.RandState */) + uintptr(last_smple_idx)*4)) != Winner_rand_state {
				(*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ + uintptr(k)*48))).FRD_Q10 = (((*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ + uintptr(k)*48))).FRD_Q10) + (int32(0x7FFFFFFF) >> 4))
				(*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ + uintptr(k)*48) + 1*24)).FRD_Q10 = (((*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ + uintptr(k)*48) + 1*24)).FRD_Q10) + (int32(0x7FFFFFFF) >> 4))

			}
		}

		/* Find worst in first set and best in second set */
		RDmax_Q10 = (*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */))).FRD_Q10
		RDmin_Q10 = (*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */) + 1*24)).FRD_Q10
		RDmax_ind = 0
		RDmin_ind = 0
		for k = 1; k < nStatesDelayedDecision; k++ {
			/* find worst in first set */
			if (*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ + uintptr(k)*48))).FRD_Q10 > RDmax_Q10 {
				RDmax_Q10 = (*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ + uintptr(k)*48))).FRD_Q10
				RDmax_ind = k
			}
			/* find best in second set */
			if (*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ +uintptr(k)*48)+1*24)).FRD_Q10 < RDmin_Q10 {
				RDmin_Q10 = (*NSQ_sample_struct)(unsafe.Pointer((bp /* &psSampleState */ + uintptr(k)*48) + 1*24)).FRD_Q10
				RDmin_ind = k
			}
		}

		/* Replace a state if best from second set outperforms worst in first set */
		if RDmin_Q10 < RDmax_Q10 {
			copy_del_dec_state(tls, (psDelDec + uintptr(RDmax_ind)*1456), (psDelDec + uintptr(RDmin_ind)*1456), i)
			libc.Xmemcpy(tls, (bp /* &psSampleState */ + uintptr(RDmax_ind)*48), ((bp /* &psSampleState */ + uintptr(RDmin_ind)*48) + 1*24), uint32(unsafe.Sizeof(NSQ_sample_struct{})))
		}

		/* Write samples from winner to output and long-term filter states */
		psDD = (psDelDec + uintptr(Winner_ind)*1456)
		if (subfr > 0) || (i >= decisionDelay) {
			*(*int8)(unsafe.Pointer(q + uintptr((i - decisionDelay)))) = (int8((*(*int32)(unsafe.Pointer((psDD + 128 /* &.Q_Q10 */) + uintptr(last_smple_idx)*4))) >> (10)))
			*(*int16)(unsafe.Pointer(xq + uintptr((i-decisionDelay))*2)) = func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1))
					}
					return ((((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1)
				}()) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (func() int32 {
						if (10) == 1 {
							return (((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
								if (16) == 1 {
									return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
								}
								return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
							}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
								if (16) == 1 {
									return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
								}
								return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
							}()))) & 1))
						}
						return ((((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) >> ((10) - 1)) + 1) >> 1)
					}()) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return func() int16 {
						if (10) == 1 {
							return (int16(((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
								if (16) == 1 {
									return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
								}
								return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
							}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
								if (16) == 1 {
									return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
								}
								return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
							}()))) & 1)))
						}
						return (int16((((((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(last_smple_idx)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(last_smple_idx)*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) >> ((10) - 1)) + 1) >> 1))
					}()
				}()
			}()
			*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx-decisionDelay))*4)) = *(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(last_smple_idx)*4))
			*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx-decisionDelay))*4)) = *(*int32)(unsafe.Pointer((psDD + 384 /* &.Pred_Q16 */) + uintptr(last_smple_idx)*4))
		}
		(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx++
		(*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx++

		/* Update states */
		for k = 0; k < nStatesDelayedDecision; k++ {
			psDD = (psDelDec + uintptr(k)*1456)
			psSS = (bp /* &psSampleState */ + uintptr(k)*48)
			(*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12 = (*NSQ_sample_struct)(unsafe.Pointer(psSS)).FLF_AR_Q12
			*(*int32)(unsafe.Pointer((psDD + 832 /* &.sLPC_Q14 */) + uintptr((32+i))*4)) = (*NSQ_sample_struct)(unsafe.Pointer(psSS)).Fxq_Q14
			*(*int32)(unsafe.Pointer((psDD + 256 /* &.Xq_Q10 */) + uintptr(*(*int32)(unsafe.Pointer(smpl_buf_idx)))*4)) = (((*NSQ_sample_struct)(unsafe.Pointer(psSS)).Fxq_Q14) >> (4))
			*(*int32)(unsafe.Pointer((psDD + 128 /* &.Q_Q10 */) + uintptr(*(*int32)(unsafe.Pointer(smpl_buf_idx)))*4)) = (*NSQ_sample_struct)(unsafe.Pointer(psSS)).FQ_Q10
			*(*int32)(unsafe.Pointer((psDD + 384 /* &.Pred_Q16 */) + uintptr(*(*int32)(unsafe.Pointer(smpl_buf_idx)))*4)) = (*NSQ_sample_struct)(unsafe.Pointer(psSS)).FLPC_exc_Q16
			*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(*(*int32)(unsafe.Pointer(smpl_buf_idx)))*4)) = (*NSQ_sample_struct)(unsafe.Pointer(psSS)).FsLTP_shp_Q10
			(*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeed = (((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeed) + (((*NSQ_sample_struct)(unsafe.Pointer(psSS)).FQ_Q10) >> (10)))
			*(*int32)(unsafe.Pointer((psDD /* &.RandState */) + uintptr(*(*int32)(unsafe.Pointer(smpl_buf_idx)))*4)) = (*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FSeed
			(*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FRD_Q10 = (*NSQ_sample_struct)(unsafe.Pointer(psSS)).FRD_Q10
			*(*int32)(unsafe.Pointer((psDD + 640 /* &.Gain_Q16 */) + uintptr(*(*int32)(unsafe.Pointer(smpl_buf_idx)))*4)) = Gain_Q16
		}
	}
	/* Update LPC states */
	for k = 0; k < nStatesDelayedDecision; k++ {
		psDD = (psDelDec + uintptr(k)*1456)
		libc.Xmemcpy(tls, psDD+832 /* &.sLPC_Q14 */, ((psDD + 832 /* &.sLPC_Q14 */) + uintptr(length)*4), (uint32(32) * uint32(unsafe.Sizeof(int32(0)))))
	}
}

func nsq_del_dec_scale_states(tls *libc.TLS, NSQ uintptr, psDelDec uintptr, x uintptr, x_sc_Q10 uintptr, subfr_length int32, sLTP uintptr, sLTP_Q16 uintptr, subfr int32, nStatesDelayedDecision int32, smpl_buf_idx int32, LTP_scale_Q14 int32, Gains_Q16 uintptr, pitchL uintptr) { /* NSQ_del_dec.c:603:17: */
	var i int32
	var k int32
	var lag int32
	var inv_gain_Q16 int32
	var gain_adj_Q16 int32
	var inv_gain_Q32 int32
	var psDD uintptr

	inv_gain_Q16 = INVERSE32_varQ(tls, func() int32 {
		if (*(*int32)(unsafe.Pointer(Gains_Q16 + uintptr(subfr)*4))) > (1) {
			return *(*int32)(unsafe.Pointer(Gains_Q16 + uintptr(subfr)*4))
		}
		return 1
	}(), 32)
	inv_gain_Q16 = func() int32 {
		if (inv_gain_Q16) < (0x7FFF) {
			return inv_gain_Q16
		}
		return 0x7FFF
	}()
	lag = *(*int32)(unsafe.Pointer(pitchL + uintptr(subfr)*4))

	/* After rewhitening the LTP state is un-scaled, so scale with inv_gain_Q16 */
	if (*nsq_state)(unsafe.Pointer(NSQ)).Frewhite_flag != 0 {
		inv_gain_Q32 = ((inv_gain_Q16) << (16))
		if subfr == 0 {
			/* Do LTP downscaling */
			inv_gain_Q32 = (((((inv_gain_Q32) >> 16) * (int32(int16(LTP_scale_Q14)))) + ((((inv_gain_Q32) & 0x0000FFFF) * (int32(int16(LTP_scale_Q14)))) >> 16)) << (2))
		}
		for i = (((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx - lag) - (5 / 2)); i < (*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx; i++ {

			*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4)) = ((((inv_gain_Q32) >> 16) * (int32(*(*int16)(unsafe.Pointer(sLTP + uintptr(i)*2))))) + ((((inv_gain_Q32) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(sLTP + uintptr(i)*2))))) >> 16))
		}
	}

	/* Adjust for changing gain */
	if inv_gain_Q16 != (*nsq_state)(unsafe.Pointer(NSQ)).Fprev_inv_gain_Q16 {
		gain_adj_Q16 = DIV32_varQ(tls, inv_gain_Q16, (*nsq_state)(unsafe.Pointer(NSQ)).Fprev_inv_gain_Q16, 16)

		/* Scale long-term shaping state */
		for i = ((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx - (subfr_length * 4)); i < (*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_shp_buf_idx; i++ {
			*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer((NSQ + 1920 /* &.sLTP_shp_Q10 */) + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}

		/* Scale long-term prediction state */
		if (*nsq_state)(unsafe.Pointer(NSQ)).Frewhite_flag == 0 {
			for i = (((*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx - lag) - (5 / 2)); i < (*nsq_state)(unsafe.Pointer(NSQ)).FsLTP_buf_idx; i++ {
				*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer(sLTP_Q16 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
				}())))
			}
		}

		for k = 0; k < nStatesDelayedDecision; k++ {
			psDD = (psDelDec + uintptr(k)*1456)

			/* Scale scalar states */
			(*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12 = (((((gain_adj_Q16) >> 16) * (int32(int16((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12)))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12)))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
				if (16) == 1 {
					return ((((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12) >> 1) + (((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12) & 1))
				}
				return (((((*NSQ_del_dec_struct)(unsafe.Pointer(psDD)).FLF_AR_Q12) >> ((16) - 1)) + 1) >> 1)
			}())))

			/* Scale short-term prediction and shaping states */
			for i = 0; i < 32; i++ {
				*(*int32)(unsafe.Pointer((psDD + 832 /* &.sLPC_Q14 */) + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 832 /* &.sLPC_Q14 */) + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 832 /* &.sLPC_Q14 */) + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer((psDD + 832 /* &.sLPC_Q14 */) + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 832 /* &.sLPC_Q14 */) + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer((psDD + 832 /* &.sLPC_Q14 */) + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
				}())))
			}
			for i = 0; i < 16; i++ {
				*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer((psDD + 768 /* &.sAR2_Q14 */) + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
				}())))
			}
			for i = 0; i < 32; i++ {
				*(*int32)(unsafe.Pointer((psDD + 384 /* &.Pred_Q16 */) + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 384 /* &.Pred_Q16 */) + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 384 /* &.Pred_Q16 */) + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer((psDD + 384 /* &.Pred_Q16 */) + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 384 /* &.Pred_Q16 */) + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer((psDD + 384 /* &.Pred_Q16 */) + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
				}())))
				*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(i)*4)) = (((((gain_adj_Q16) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(i)*4)))))) + ((((gain_adj_Q16) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(i)*4)))))) >> 16)) + ((gain_adj_Q16) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer((psDD + 512 /* &.Shape_Q10 */) + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
				}())))
			}
		}
	}

	/* Scale input */
	for i = 0; i < subfr_length; i++ {
		*(*int32)(unsafe.Pointer(x_sc_Q10 + uintptr(i)*4)) = (((int32(*(*int16)(unsafe.Pointer(x + uintptr(i)*2)))) * (int32(int16(inv_gain_Q16)))) >> (6))
	}

	/* save inv_gain */

	(*nsq_state)(unsafe.Pointer(NSQ)).Fprev_inv_gain_Q16 = inv_gain_Q16
}

func copy_del_dec_state(tls *libc.TLS, DD_dst uintptr, DD_src uintptr, LPC_state_idx int32) { /* NSQ_del_dec.c:686:17: */
	libc.Xmemcpy(tls, DD_dst /* &.RandState */, DD_src /* &.RandState */, uint32(unsafe.Sizeof([32]int32{})))
	libc.Xmemcpy(tls, DD_dst+128 /* &.Q_Q10 */, DD_src+128 /* &.Q_Q10 */, uint32(unsafe.Sizeof([32]int32{})))
	libc.Xmemcpy(tls, DD_dst+384 /* &.Pred_Q16 */, DD_src+384 /* &.Pred_Q16 */, uint32(unsafe.Sizeof([32]int32{})))
	libc.Xmemcpy(tls, DD_dst+512 /* &.Shape_Q10 */, DD_src+512 /* &.Shape_Q10 */, uint32(unsafe.Sizeof([32]int32{})))
	libc.Xmemcpy(tls, DD_dst+256 /* &.Xq_Q10 */, DD_src+256 /* &.Xq_Q10 */, uint32(unsafe.Sizeof([32]int32{})))
	libc.Xmemcpy(tls, DD_dst+768 /* &.sAR2_Q14 */, DD_src+768 /* &.sAR2_Q14 */, uint32(unsafe.Sizeof([16]int32{})))
	libc.Xmemcpy(tls, ((DD_dst + 832 /* &.sLPC_Q14 */) + uintptr(LPC_state_idx)*4), ((DD_src + 832 /* &.sLPC_Q14 */) + uintptr(LPC_state_idx)*4), (uint32(32) * uint32(unsafe.Sizeof(int32(0)))))
	(*NSQ_del_dec_struct)(unsafe.Pointer(DD_dst)).FLF_AR_Q12 = (*NSQ_del_dec_struct)(unsafe.Pointer(DD_src)).FLF_AR_Q12
	(*NSQ_del_dec_struct)(unsafe.Pointer(DD_dst)).FSeed = (*NSQ_del_dec_struct)(unsafe.Pointer(DD_src)).FSeed
	(*NSQ_del_dec_struct)(unsafe.Pointer(DD_dst)).FSeedInit = (*NSQ_del_dec_struct)(unsafe.Pointer(DD_src)).FSeedInit
	(*NSQ_del_dec_struct)(unsafe.Pointer(DD_dst)).FRD_Q10 = (*NSQ_del_dec_struct)(unsafe.Pointer(DD_src)).FRD_Q10
}

/*************************************************************/
/*      FIXED POINT CORE PITCH ANALYSIS FUNCTION             */
/*************************************************************/
func pitch_analysis_core(tls *libc.TLS, signal uintptr, pitch_out uintptr, lagIndex uintptr, contourIndex uintptr, LTPCorr_Q15 uintptr, prevLag int32, search_thres1_Q16 int32, search_thres2_Q15 int32, Fs_kHz int32, complexity int32, forLJC int32) int32 { /* pitch_analysis_core.c:65:9: */
	bp := tls.Alloc(20836)
	defer tls.Free(20836)

	// var signal_8kHz [480]int16 at bp+1796, 960

	// var signal_4kHz [240]int16 at bp+2812, 480

	// var scratch_mem [2880]int32 at bp+3876, 11520

	var input_signal_ptr uintptr
	// var filt_state [7]int32 at bp+1768, 28

	var i int32
	var k int32
	var d int32
	var j int32
	// var C [4][221]int16 at bp, 1768

	var target_ptr uintptr
	var basis_ptr uintptr
	var cross_corr int32
	var normalizer int32
	var energy int32
	var shift int32
	var energy_basis int32
	var energy_target int32
	// var d_srch [24]int32 at bp+3292, 96

	// var d_comp [221]int16 at bp+3388, 442

	var Cmax int32
	var length_d_srch int32
	var length_d_comp int32
	var sum int32
	var threshold int32
	var temp32 int32
	var CBimax int32
	var CBimax_new int32
	var CBimax_old int32
	var lag int32
	var start_lag int32
	var end_lag int32
	var lag_new int32
	// var CC [11]int32 at bp+3832, 44

	var CCmax int32
	var CCmax_b int32
	var CCmax_new_b int32
	var CCmax_new int32
	// var energies_st3 [4][34][5]int32 at bp+18116, 2720

	// var crosscorr_st3 [4][34][5]int32 at bp+15396, 2720

	var lag_counter int32
	var frame_length int32
	var frame_length_8kHz int32
	var frame_length_4kHz int32
	var max_sum_sq_length int32
	var sf_length int32
	var sf_length_8kHz int32
	var min_lag int32
	var min_lag_8kHz int32
	var min_lag_4kHz int32
	var max_lag int32
	var max_lag_8kHz int32
	var max_lag_4kHz int32
	var contour_bias int32
	var diff int32
	var lz int32
	var lshift int32
	var cbk_offset int32
	var cbk_size int32
	var nb_cbks_stage2 int32
	var delta_lag_log2_sqr_Q7 int32
	var lag_log2_Q7 int32
	var prevLag_log2_Q7 int32
	var prev_lag_bias_Q15 int32
	var corr_thres_Q15 int32

	/* Check for valid sampling frequency */

	/* Check for valid complexity setting */

	/* Setup frame lengths max / min lag for the sampling frequency */
	frame_length = (40 * Fs_kHz)
	frame_length_4kHz = (40 * 4)
	frame_length_8kHz = (40 * 8)
	sf_length = ((frame_length) >> (3))
	sf_length_8kHz = ((frame_length_8kHz) >> (3))
	min_lag = (2 * Fs_kHz)
	min_lag_4kHz = (2 * 4)
	min_lag_8kHz = (2 * 8)
	max_lag = (18 * Fs_kHz)
	max_lag_4kHz = (18 * 4)
	max_lag_8kHz = (18 * 8)

	libc.Xmemset(tls, bp /* &C[0] */, 0, ((uint32(unsafe.Sizeof(int16(0))) * uint32(4)) * (uint32((int32((18 * 24)) >> 1) + 5))))

	/* Resample from input sampled at Fs_kHz to 8 kHz */
	if Fs_kHz == 16 {
		libc.Xmemset(tls, bp+1768 /* &filt_state[0] */, 0, (uint32(2) * uint32(unsafe.Sizeof(int32(0)))))
		resampler_down2(tls, bp+1768 /* &filt_state[0] */, bp+1796 /* &signal_8kHz[0] */, signal, frame_length)
	} else if Fs_kHz == 12 {
		// var R23 [6]int32 at bp+2756, 24

		libc.Xmemset(tls, bp+2756 /* &R23[0] */, 0, (uint32(6) * uint32(unsafe.Sizeof(int32(0)))))
		resampler_down2_3(tls, bp+2756 /* &R23[0] */, bp+1796 /* &signal_8kHz[0] */, signal, (40 * 12))
	} else if Fs_kHz == 24 {
		// var filt_state_fix [8]int32 at bp+2780, 32

		libc.Xmemset(tls, bp+2780 /* &filt_state_fix[0] */, 0, (uint32(8) * uint32(unsafe.Sizeof(int32(0)))))
		resampler_down3(tls, bp+2780 /* &filt_state_fix[0] */, bp+1796 /* &signal_8kHz[0] */, signal, (24 * 40))
	} else {

		libc.Xmemcpy(tls, bp+1796 /* &signal_8kHz[0] */, signal, (uint32(frame_length_8kHz) * uint32(unsafe.Sizeof(int16(0)))))
	}
	/* Decimate again to 4 kHz */
	libc.Xmemset(tls, bp+1768 /* &filt_state[0] */, 0, (uint32(2) * uint32(unsafe.Sizeof(int32(0))))) /* Set state to zero */
	resampler_down2(tls, bp+1768 /* &filt_state[0] */, bp+2812 /* &signal_4kHz[0] */, bp+1796 /* &signal_8kHz[0] */, frame_length_8kHz)

	/* Low-pass filter */
	for i = (frame_length_4kHz - 1); i > 0; i-- {
		*(*int16)(unsafe.Pointer(bp + 2812 /* &signal_4kHz[0] */ + uintptr(i)*2)) = func() int16 {
			if ((int32(*(*int16)(unsafe.Pointer(bp + 2812 /* &signal_4kHz[0] */ + uintptr(i)*2)))) + (int32(*(*int16)(unsafe.Pointer(bp + 2812 /* &signal_4kHz[0] */ + uintptr((i-1))*2))))) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if ((int32(*(*int16)(unsafe.Pointer(bp + 2812 /* &signal_4kHz[0] */ + uintptr(i)*2)))) + (int32(*(*int16)(unsafe.Pointer(bp + 2812 /* &signal_4kHz[0] */ + uintptr((i-1))*2))))) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return (int16((int32(*(*int16)(unsafe.Pointer(bp + 2812 /* &signal_4kHz[0] */ + uintptr(i)*2)))) + (int32(*(*int16)(unsafe.Pointer(bp + 2812 /* &signal_4kHz[0] */ + uintptr((i-1))*2))))))
			}()
		}()
	}

	/*******************************************************************************
	 ** Scale 4 kHz signal down to prevent correlations measures from overflowing
	 ** find scaling as max scaling for each 8kHz(?) subframe
	 *******************************************************************************/

	/* Inner product is calculated with different lengths, so scale for the worst case */
	max_sum_sq_length = max_32(tls, sf_length_8kHz, ((frame_length_4kHz) >> (1)))
	shift = FIX_P_Ana_find_scaling(tls, bp+2812 /* &signal_4kHz[0] */, frame_length_4kHz, max_sum_sq_length)
	if shift > 0 {
		for i = 0; i < frame_length_4kHz; i++ {
			*(*int16)(unsafe.Pointer(bp + 2812 /* &signal_4kHz[0] */ + uintptr(i)*2)) = (int16((int32(*(*int16)(unsafe.Pointer(bp + 2812 /* &signal_4kHz[0] */ + uintptr(i)*2)))) >> (shift)))
		}
	}

	/******************************************************************************
	 * FIRST STAGE, operating in 4 khz
	 ******************************************************************************/
	target_ptr = (bp + 2812 /* &signal_4kHz */ + uintptr(((frame_length_4kHz)>>(1)))*2)
	for k = 0; k < 2; k++ {
		/* Check that we are within range of the array */

		basis_ptr = (target_ptr - uintptr(min_lag_4kHz)*2)

		/* Check that we are within range of the array */

		normalizer = 0
		cross_corr = 0
		/* Calculate first vector products before loop */
		cross_corr = inner_prod_aligned(tls, target_ptr, basis_ptr, sf_length_8kHz)
		normalizer = inner_prod_aligned(tls, basis_ptr, basis_ptr, sf_length_8kHz)
		normalizer = func() int32 {
			if ((uint32((normalizer) + ((int32(int16(sf_length_8kHz))) * (int32(int16(4000)))))) & 0x80000000) == uint32(0) {
				return func() int32 {
					if ((uint32((normalizer) & ((int32(int16(sf_length_8kHz))) * (int32(int16(4000)))))) & 0x80000000) != uint32(0) {
						return libc.Int32FromUint32(0x80000000)
					}
					return ((normalizer) + ((int32(int16(sf_length_8kHz))) * (int32(int16(4000)))))
				}()
			}
			return func() int32 {
				if ((uint32((normalizer) | ((int32(int16(sf_length_8kHz))) * (int32(int16(4000)))))) & 0x80000000) == uint32(0) {
					return 0x7FFFFFFF
				}
				return ((normalizer) + ((int32(int16(sf_length_8kHz))) * (int32(int16(4000)))))
			}()
		}()

		temp32 = ((cross_corr) / (SQRT_APPROX(tls, normalizer) + 1))
		*(*int16)(unsafe.Pointer((bp /* &C[0] */ + uintptr(k)*442) + uintptr(min_lag_4kHz)*2)) = func() int16 {
			if (temp32) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (temp32) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return int16(temp32)
			}()
		}() /* Q0 */

		/* From now on normalizer is computed recursively */
		for d = (min_lag_4kHz + 1); d <= max_lag_4kHz; d++ {
			basis_ptr -= 2

			/* Check that we are within range of the array */

			cross_corr = inner_prod_aligned(tls, target_ptr, basis_ptr, sf_length_8kHz)

			/* Add contribution of new sample and remove contribution from oldest sample */
			normalizer = normalizer + (((int32(*(*int16)(unsafe.Pointer(basis_ptr)))) * (int32(*(*int16)(unsafe.Pointer(basis_ptr))))) - ((int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(sf_length_8kHz)*2)))) * (int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(sf_length_8kHz)*2))))))

			temp32 = ((cross_corr) / (SQRT_APPROX(tls, normalizer) + 1))
			*(*int16)(unsafe.Pointer((bp /* &C[0] */ + uintptr(k)*442) + uintptr(d)*2)) = func() int16 {
				if (temp32) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (temp32) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return int16(temp32)
				}()
			}() /* Q0 */
		}
		/* Update target pointer */
		target_ptr += 2 * (uintptr(sf_length_8kHz))
	}

	/* Combine two subframes into single correlation measure and apply short-lag bias */
	for i = max_lag_4kHz; i >= min_lag_4kHz; i-- {
		sum = (int32(*(*int16)(unsafe.Pointer((bp /* &C[0] */) + uintptr(i)*2))) + int32(*(*int16)(unsafe.Pointer((bp /* &C[0] */ + 1*442) + uintptr(i)*2)))) /* Q0 */

		sum = ((sum) >> (1)) /* Q-1 */

		sum = ((sum) + ((((sum) >> 16) * (int32((int16((-i) << (4)))))) + ((((sum) & 0x0000FFFF) * (int32((int16((-i) << (4)))))) >> 16))) /* Q-1 */

		*(*int16)(unsafe.Pointer((bp /* &C[0] */) + uintptr(i)*2)) = int16(sum) /* Q-1 */
	}

	/* Sort */
	length_d_srch = (4 + (2 * complexity))

	insertion_sort_decreasing_int16(tls, ((bp /* &C */) + uintptr(min_lag_4kHz)*2), bp+3292 /* &d_srch[0] */, ((max_lag_4kHz - min_lag_4kHz) + 1), length_d_srch)

	/* Escape if correlation is very low already here */
	target_ptr = (bp + 2812 /* &signal_4kHz */ + uintptr(((frame_length_4kHz)>>(1)))*2)
	energy = inner_prod_aligned(tls, target_ptr, target_ptr, ((frame_length_4kHz) >> (1)))
	energy = func() int32 {
		if ((uint32((energy) + (1000))) & 0x80000000) != 0 {
			return 0x7FFFFFFF
		}
		return ((energy) + (1000))
	}() /* Q0 */
	Cmax = int32(*(*int16)(unsafe.Pointer((bp /* &C[0] */) + uintptr(min_lag_4kHz)*2))) /* Q-1 */
	threshold = ((int32(int16(Cmax))) * (int32(int16(Cmax))))                           /* Q-2 */
	/* Compare in Q-2 domain */
	if ((energy) >> (4 + 2)) > threshold {
		libc.Xmemset(tls, pitch_out, 0, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))
		*(*int32)(unsafe.Pointer(LTPCorr_Q15)) = 0
		*(*int32)(unsafe.Pointer(lagIndex)) = 0
		*(*int32)(unsafe.Pointer(contourIndex)) = 0
		return 1
	}

	threshold = ((((search_thres1_Q16) >> 16) * (int32(int16(Cmax)))) + ((((search_thres1_Q16) & 0x0000FFFF) * (int32(int16(Cmax)))) >> 16))
	for i = 0; i < length_d_srch; i++ {
		/* Convert to 8 kHz indices for the sorted correlation that exceeds the threshold */
		if int32(*(*int16)(unsafe.Pointer((bp /* &C[0] */) + uintptr((min_lag_4kHz+i))*2))) > threshold {
			*(*int32)(unsafe.Pointer(bp + 3292 /* &d_srch[0] */ + uintptr(i)*4)) = ((*(*int32)(unsafe.Pointer(bp + 3292 /* &d_srch[0] */ + uintptr(i)*4)) + min_lag_4kHz) << 1)
		} else {
			length_d_srch = i
			break
		}
	}

	for i = (min_lag_8kHz - 5); i < (max_lag_8kHz + 5); i++ {
		*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr(i)*2)) = int16(0)
	}
	for i = 0; i < length_d_srch; i++ {
		*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr(*(*int32)(unsafe.Pointer(bp + 3292 /* &d_srch[0] */ + uintptr(i)*4)))*2)) = int16(1)
	}

	/* Convolution */
	for i = (max_lag_8kHz + 3); i >= min_lag_8kHz; i-- {
		*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp */ + uintptr(i)*2)) += int16((int32(*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr((i-1))*2))) + int32(*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr((i-2))*2)))))
	}

	length_d_srch = 0
	for i = min_lag_8kHz; i < (max_lag_8kHz + 1); i++ {
		if int32(*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr((i+1))*2))) > 0 {
			*(*int32)(unsafe.Pointer(bp + 3292 /* &d_srch[0] */ + uintptr(length_d_srch)*4)) = i
			length_d_srch++
		}
	}

	/* Convolution */
	for i = (max_lag_8kHz + 3); i >= min_lag_8kHz; i-- {
		*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp */ + uintptr(i)*2)) += int16(((int32(*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr((i-1))*2))) + int32(*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr((i-2))*2)))) + int32(*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr((i-3))*2)))))
	}

	length_d_comp = 0
	for i = min_lag_8kHz; i < (max_lag_8kHz + 4); i++ {
		if int32(*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr(i)*2))) > 0 {
			*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr(length_d_comp)*2)) = (int16(i - 2))
			length_d_comp++
		}
	}

	/**********************************************************************************
	 ** SECOND STAGE, operating at 8 kHz, on lag sections with high correlation
	 *************************************************************************************/

	/******************************************************************************
	 ** Scale signal down to avoid correlations measures from overflowing
	 *******************************************************************************/
	/* find scaling as max scaling for each subframe */
	shift = FIX_P_Ana_find_scaling(tls, bp+1796 /* &signal_8kHz[0] */, frame_length_8kHz, sf_length_8kHz)
	if shift > 0 {
		for i = 0; i < frame_length_8kHz; i++ {
			*(*int16)(unsafe.Pointer(bp + 1796 /* &signal_8kHz[0] */ + uintptr(i)*2)) = (int16((int32(*(*int16)(unsafe.Pointer(bp + 1796 /* &signal_8kHz[0] */ + uintptr(i)*2)))) >> (shift)))
		}
	}

	/*********************************************************************************
	 * Find energy of each subframe projected onto its history, for a range of delays
	 *********************************************************************************/
	libc.Xmemset(tls, bp /* &C[0] */, 0, ((uint32(4 * ((int32((18 * 24)) >> 1) + 5))) * uint32(unsafe.Sizeof(int16(0)))))

	target_ptr = (bp + 1796 /* &signal_8kHz */ + uintptr(frame_length_4kHz)*2) /* point to middle of frame */
	for k = 0; k < 4; k++ {

		/* Check that we are within range of the array */

		energy_target = inner_prod_aligned(tls, target_ptr, target_ptr, sf_length_8kHz)
		// ToDo: Calculate 1 / energy_target here and save one division inside next for loop
		for j = 0; j < length_d_comp; j++ {
			d = int32(*(*int16)(unsafe.Pointer(bp + 3388 /* &d_comp[0] */ + uintptr(j)*2)))
			basis_ptr = (target_ptr - uintptr(d)*2)

			/* Check that we are within range of the array */

			cross_corr = inner_prod_aligned(tls, target_ptr, basis_ptr, sf_length_8kHz)
			energy_basis = inner_prod_aligned(tls, basis_ptr, basis_ptr, sf_length_8kHz)
			if cross_corr > 0 {
				energy = func() int32 {
					if (energy_target) > (energy_basis) {
						return energy_target
					}
					return energy_basis
				}() /* Find max to make sure first division < 1.0 */
				lz = CLZ32(tls, cross_corr)
				lshift = func() int32 {
					if (0) > (15) {
						return func() int32 {
							if (lz - 1) > (0) {
								return 0
							}
							return func() int32 {
								if (lz - 1) < (15) {
									return 15
								}
								return (lz - 1)
							}()
						}()
					}
					return func() int32 {
						if (lz - 1) > (15) {
							return 15
						}
						return func() int32 {
							if (lz - 1) < (0) {
								return 0
							}
							return (lz - 1)
						}()
					}()
				}()
				temp32 = (((cross_corr) << (lshift)) / (((energy) >> (15 - lshift)) + 1)) /* Q15 */

				temp32 = ((((cross_corr) >> 16) * (int32(int16(temp32)))) + ((((cross_corr) & 0x0000FFFF) * (int32(int16(temp32)))) >> 16)) /* Q(-1), cc * ( cc / max(b, t) ) */
				temp32 = func() int32 {
					if ((uint32((temp32) + (temp32))) & 0x80000000) == uint32(0) {
						return func() int32 {
							if ((uint32((temp32) & (temp32))) & 0x80000000) != uint32(0) {
								return libc.Int32FromUint32(0x80000000)
							}
							return ((temp32) + (temp32))
						}()
					}
					return func() int32 {
						if ((uint32((temp32) | (temp32))) & 0x80000000) == uint32(0) {
							return 0x7FFFFFFF
						}
						return ((temp32) + (temp32))
					}()
				}() /* Q(0) */
				lz = CLZ32(tls, temp32)
				lshift = func() int32 {
					if (0) > (15) {
						return func() int32 {
							if (lz - 1) > (0) {
								return 0
							}
							return func() int32 {
								if (lz - 1) < (15) {
									return 15
								}
								return (lz - 1)
							}()
						}()
					}
					return func() int32 {
						if (lz - 1) > (15) {
							return 15
						}
						return func() int32 {
							if (lz - 1) < (0) {
								return 0
							}
							return (lz - 1)
						}()
					}()
				}()
				energy = func() int32 {
					if (energy_target) < (energy_basis) {
						return energy_target
					}
					return energy_basis
				}()
				*(*int16)(unsafe.Pointer((bp /* &C[0] */ + uintptr(k)*442) + uintptr(d)*2)) = int16((((temp32) << (lshift)) / (((energy) >> (15 - lshift)) + 1))) // Q15
			} else {
				*(*int16)(unsafe.Pointer((bp /* &C[0] */ + uintptr(k)*442) + uintptr(d)*2)) = int16(0)
			}
		}
		target_ptr += 2 * (uintptr(sf_length_8kHz))
	}

	/* search over lag range and lags codebook */
	/* scale factor for lag codebook, as a function of center lag */

	CCmax = libc.Int32FromUint32(0x80000000)
	CCmax_b = libc.Int32FromUint32(0x80000000)

	CBimax = 0 /* To avoid returning undefined lag values */
	lag = -1   /* To check if lag with strong enough correlation has been found */

	if prevLag > 0 {
		if Fs_kHz == 12 {
			prevLag = (((prevLag) << (1)) / (3))
		} else if Fs_kHz == 16 {
			prevLag = ((prevLag) >> (1))
		} else if Fs_kHz == 24 {
			prevLag = ((prevLag) / (3))
		}
		prevLag_log2_Q7 = lin2log(tls, prevLag)
	} else {
		prevLag_log2_Q7 = 0
	}

	corr_thres_Q15 = (((int32(int16(search_thres2_Q15))) * (int32(int16(search_thres2_Q15)))) >> (13))

	/* If input is 8 khz use a larger codebook here because it is last stage */
	if (Fs_kHz == 8) && (complexity > 0) {
		nb_cbks_stage2 = 11
	} else {
		nb_cbks_stage2 = 3
	}

	for k = 0; k < length_d_srch; k++ {
		d = *(*int32)(unsafe.Pointer(bp + 3292 /* &d_srch[0] */ + uintptr(k)*4))
		for j = 0; j < nb_cbks_stage2; j++ {
			*(*int32)(unsafe.Pointer(bp + 3832 /* &CC[0] */ + uintptr(j)*4)) = 0
			for i = 0; i < 4; i++ {
				/* Try all codebooks */
				*(*int32)(unsafe.Pointer(bp + 3832 /* &CC[0] */ + uintptr(j)*4)) = (*(*int32)(unsafe.Pointer(bp + 3832 /* &CC[0] */ + uintptr(j)*4)) + int32(*(*int16)(unsafe.Pointer((bp /* &C[0] */ + uintptr(i)*442) + uintptr((d+int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage2)) + uintptr(i)*22) + uintptr(j)*2)))))*2))))
			}
		}
		/* Find best codebook */
		CCmax_new = libc.Int32FromUint32(0x80000000)
		CBimax_new = 0
		for i = 0; i < nb_cbks_stage2; i++ {
			if *(*int32)(unsafe.Pointer(bp + 3832 /* &CC[0] */ + uintptr(i)*4)) > CCmax_new {
				CCmax_new = *(*int32)(unsafe.Pointer(bp + 3832 /* &CC[0] */ + uintptr(i)*4))
				CBimax_new = i
			}
		}

		/* Bias towards shorter lags */
		lag_log2_Q7 = lin2log(tls, d) /* Q7 */

		if forLJC != 0 {
			CCmax_new_b = CCmax_new
		} else {
			CCmax_new_b = (CCmax_new - (((int32((int16(4 * 6554)))) * (int32(int16(lag_log2_Q7)))) >> (7))) /* Q15 */
		}

		/* Bias towards previous lag */

		if prevLag > 0 {
			delta_lag_log2_sqr_Q7 = (lag_log2_Q7 - prevLag_log2_Q7)

			delta_lag_log2_sqr_Q7 = (((int32(int16(delta_lag_log2_sqr_Q7))) * (int32(int16(delta_lag_log2_sqr_Q7)))) >> (7))
			prev_lag_bias_Q15 = (((int32((int16(4 * 6554)))) * (int32(int16(*(*int32)(unsafe.Pointer(LTPCorr_Q15)))))) >> (15)) /* Q15 */
			prev_lag_bias_Q15 = (((prev_lag_bias_Q15) * (delta_lag_log2_sqr_Q7)) / (delta_lag_log2_sqr_Q7 + (int32(1) << 6)))
			CCmax_new_b = CCmax_new_b - (prev_lag_bias_Q15) /* Q15 */
		}

		if ((CCmax_new_b > CCmax_b) && (CCmax_new > corr_thres_Q15)) && (int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage2))) + uintptr(CBimax_new)*2))) <= min_lag_8kHz) {
			CCmax_b = CCmax_new_b
			CCmax = CCmax_new
			lag = d
			CBimax = CBimax_new
		}
	}

	if lag == -1 {
		/* No suitable candidate found */
		libc.Xmemset(tls, pitch_out, 0, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))
		*(*int32)(unsafe.Pointer(LTPCorr_Q15)) = 0
		*(*int32)(unsafe.Pointer(lagIndex)) = 0
		*(*int32)(unsafe.Pointer(contourIndex)) = 0
		return 1
	}

	if Fs_kHz > 8 {

		/******************************************************************************
		 ** Scale input signal down to avoid correlations measures from overflowing
		 *******************************************************************************/
		/* find scaling as max scaling for each subframe */
		shift = FIX_P_Ana_find_scaling(tls, signal, frame_length, sf_length)
		if shift > 0 {
			/* Move signal to scratch mem because the input signal should be unchanged */
			/* Reuse the 32 bit scratch mem vector, use a 16 bit pointer from now */
			input_signal_ptr = bp + 3876 /* scratch_mem */
			for i = 0; i < frame_length; i++ {
				*(*int16)(unsafe.Pointer(input_signal_ptr + uintptr(i)*2)) = (int16((int32(*(*int16)(unsafe.Pointer(signal + uintptr(i)*2)))) >> (shift)))
			}
		} else {
			input_signal_ptr = signal
		}
		/*********************************************************************************/

		/* Search in original signal */

		CBimax_old = CBimax
		/* Compensate for decimation */

		if Fs_kHz == 12 {
			lag = (((int32(int16(lag))) * (int32(int16(3)))) >> (1))
		} else if Fs_kHz == 16 {
			lag = ((lag) << (1))
		} else {
			lag = ((int32(int16(lag))) * (int32(int16(3))))
		}

		lag = func() int32 {
			if (min_lag) > (max_lag) {
				return func() int32 {
					if (lag) > (min_lag) {
						return min_lag
					}
					return func() int32 {
						if (lag) < (max_lag) {
							return max_lag
						}
						return lag
					}()
				}()
			}
			return func() int32 {
				if (lag) > (max_lag) {
					return max_lag
				}
				return func() int32 {
					if (lag) < (min_lag) {
						return min_lag
					}
					return lag
				}()
			}()
		}()
		start_lag = max_int(tls, (lag - 2), min_lag)
		end_lag = min_int(tls, (lag + 2), max_lag)
		lag_new = lag /* to avoid undefined lag */
		CBimax = 0    /* to avoid undefined lag */

		*(*int32)(unsafe.Pointer(LTPCorr_Q15)) = SQRT_APPROX(tls, ((CCmax) << (13))) /* Output normalized correlation */

		CCmax = libc.Int32FromUint32(0x80000000)
		/* pitch lags according to second stage */
		for k = 0; k < 4; k++ {
			*(*int32)(unsafe.Pointer(pitch_out + uintptr(k)*4)) = (lag + (2 * int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage2)) + uintptr(k)*22) + uintptr(CBimax_old)*2)))))
		}
		/* Calculate the correlations and energies needed in stage 3 */
		FIX_P_Ana_calc_corr_st3(tls, bp+15396 /* &crosscorr_st3[0] */, input_signal_ptr, start_lag, sf_length, complexity)
		FIX_P_Ana_calc_energy_st3(tls, bp+18116 /* &energies_st3[0] */, input_signal_ptr, start_lag, sf_length, complexity)

		lag_counter = 0

		contour_bias = ((52429) / (lag))

		/* Setup cbk parameters acording to complexity setting */
		cbk_size = int32(cbk_sizes_stage3[complexity])
		cbk_offset = int32(cbk_offsets_stage3[complexity])

		for d = start_lag; d <= end_lag; d++ {
			for j = cbk_offset; j < (cbk_offset + cbk_size); j++ {
				cross_corr = 0
				energy = 0
				for k = 0; k < 4; k++ {

					energy = energy + ((*(*int32)(unsafe.Pointer(((bp + 18116 /* &energies_st3[0] */ + uintptr(k)*680) + uintptr(j)*20) + uintptr(lag_counter)*4))) >> (2)) /* use mean, to avoid overflow */

					cross_corr = cross_corr + ((*(*int32)(unsafe.Pointer(((bp + 15396 /* &crosscorr_st3[0] */ + uintptr(k)*680) + uintptr(j)*20) + uintptr(lag_counter)*4))) >> (2)) /* use mean, to avoid overflow */
				}
				if cross_corr > 0 {
					/* Divide cross_corr / energy and get result in Q15 */
					lz = CLZ32(tls, cross_corr)
					/* Divide with result in Q13, cross_corr could be larger than energy */
					lshift = func() int32 {
						if (0) > (13) {
							return func() int32 {
								if (lz - 1) > (0) {
									return 0
								}
								return func() int32 {
									if (lz - 1) < (13) {
										return 13
									}
									return (lz - 1)
								}()
							}()
						}
						return func() int32 {
							if (lz - 1) > (13) {
								return 13
							}
							return func() int32 {
								if (lz - 1) < (0) {
									return 0
								}
								return (lz - 1)
							}()
						}()
					}()
					CCmax_new = (((cross_corr) << (lshift)) / (((energy) >> (13 - lshift)) + 1))
					CCmax_new = func() int32 {
						if (CCmax_new) > 0x7FFF {
							return 0x7FFF
						}
						return func() int32 {
							if (CCmax_new) < (int32(libc.Int16FromInt32(0x8000))) {
								return int32(libc.Int16FromInt32(0x8000))
							}
							return CCmax_new
						}()
					}()
					CCmax_new = ((((cross_corr) >> 16) * (int32(int16(CCmax_new)))) + ((((cross_corr) & 0x0000FFFF) * (int32(int16(CCmax_new)))) >> 16))
					/* Saturate */
					if CCmax_new > (int32((0x7FFFFFFF)) >> (3)) {
						CCmax_new = 0x7FFFFFFF
					} else {
						CCmax_new = ((CCmax_new) << (3))
					}
					/* Reduce depending on flatness of contour */
					diff = (j - (int32((34)) >> (1)))
					diff = ((diff) * (diff))
					diff = (0x7FFF - (((contour_bias) * (diff)) >> (5))) /* Q20 -> Q15 */

					CCmax_new = (((((CCmax_new) >> 16) * (int32(int16(diff)))) + ((((CCmax_new) & 0x0000FFFF) * (int32(int16(diff)))) >> 16)) << (1))
				} else {
					CCmax_new = 0
				}

				if (CCmax_new > CCmax) && ((d + int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage3))) + uintptr(j)*2)))) <= max_lag) {
					CCmax = CCmax_new
					lag_new = d
					CBimax = j
				}
			}
			lag_counter++
		}

		for k = 0; k < 4; k++ {
			*(*int32)(unsafe.Pointer(pitch_out + uintptr(k)*4)) = (lag_new + int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage3)) + uintptr(k)*68) + uintptr(CBimax)*2))))
		}
		*(*int32)(unsafe.Pointer(lagIndex)) = (lag_new - min_lag)
		*(*int32)(unsafe.Pointer(contourIndex)) = CBimax
	} else {
		/* Save Lags and correlation */
		CCmax = func() int32 {
			if (CCmax) > (0) {
				return CCmax
			}
			return 0
		}()
		*(*int32)(unsafe.Pointer(LTPCorr_Q15)) = SQRT_APPROX(tls, ((CCmax) << (13))) /* Output normalized correlation */
		for k = 0; k < 4; k++ {
			*(*int32)(unsafe.Pointer(pitch_out + uintptr(k)*4)) = (lag + int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage2)) + uintptr(k)*22) + uintptr(CBimax)*2))))
		}
		*(*int32)(unsafe.Pointer(lagIndex)) = (lag - min_lag_8kHz)
		*(*int32)(unsafe.Pointer(contourIndex)) = CBimax
	}

	/* return as voiced */
	return 0
}

/*************************************************************************/
/* Calculates the correlations used in stage 3 search. In order to cover */
/* the whole lag codebook for all the searched offset lags (lag +- 2),   */
/*************************************************************************/
func FIX_P_Ana_calc_corr_st3(tls *libc.TLS, cross_corr_st3 uintptr, signal uintptr, start_lag int32, sf_length int32, complexity int32) { /* pitch_analysis_core.c:569:6: */
	bp := tls.Alloc(88)
	defer tls.Free(88)

	var target_ptr uintptr
	var basis_ptr uintptr
	var cross_corr int32
	var i int32
	var j int32
	var k int32
	var lag_counter int32
	var cbk_offset int32
	var cbk_size int32
	var delta int32
	var idx int32
	// var scratch_mem [22]int32 at bp, 88

	cbk_offset = int32(cbk_offsets_stage3[complexity])
	cbk_size = int32(cbk_sizes_stage3[complexity])

	target_ptr = (signal + uintptr(((sf_length)<<(2)))*2) /* Pointer to middle of frame */
	for k = 0; k < 4; k++ {
		lag_counter = 0

		/* Calculate the correlations for each subframe */
		for j = int32(*(*int16)(unsafe.Pointer(((uintptr(unsafe.Pointer(&Lag_range_stage3)) + uintptr(complexity)*16) + uintptr(k)*4)))); j <= int32(*(*int16)(unsafe.Pointer(((uintptr(unsafe.Pointer(&Lag_range_stage3)) + uintptr(complexity)*16) + uintptr(k)*4) + 1*2))); j++ {
			basis_ptr = (target_ptr - uintptr((start_lag+j))*2)
			cross_corr = inner_prod_aligned(tls, target_ptr, basis_ptr, sf_length)

			*(*int32)(unsafe.Pointer(bp /* &scratch_mem[0] */ + uintptr(lag_counter)*4)) = cross_corr
			lag_counter++
		}

		delta = int32(*(*int16)(unsafe.Pointer(((uintptr(unsafe.Pointer(&Lag_range_stage3)) + uintptr(complexity)*16) + uintptr(k)*4))))
		for i = cbk_offset; i < (cbk_offset + cbk_size); i++ {
			/* Fill out the 3 dim array that stores the correlations for */
			/* each code_book vector for each start lag */
			idx = (int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage3)) + uintptr(k)*68) + uintptr(i)*2))) - delta)
			for j = 0; j < 5; j++ {

				*(*int32)(unsafe.Pointer(((cross_corr_st3 + uintptr(k)*680) + uintptr(i)*20) + uintptr(j)*4)) = *(*int32)(unsafe.Pointer(bp /* &scratch_mem[0] */ + uintptr((idx+j))*4))
			}
		}
		target_ptr += 2 * (uintptr(sf_length))
	}
}

/********************************************************************/
/* Calculate the energies for first two subframes. The energies are */
/* calculated recursively.                                          */
/********************************************************************/
func FIX_P_Ana_calc_energy_st3(tls *libc.TLS, energies_st3 uintptr, signal uintptr, start_lag int32, sf_length int32, complexity int32) { /* pitch_analysis_core.c:621:6: */
	bp := tls.Alloc(88)
	defer tls.Free(88)

	var target_ptr uintptr
	var basis_ptr uintptr
	var energy int32
	var k int32
	var i int32
	var j int32
	var lag_counter int32
	var cbk_offset int32
	var cbk_size int32
	var delta int32
	var idx int32
	// var scratch_mem [22]int32 at bp, 88

	cbk_offset = int32(cbk_offsets_stage3[complexity])
	cbk_size = int32(cbk_sizes_stage3[complexity])

	target_ptr = (signal + uintptr(((sf_length)<<(2)))*2)
	for k = 0; k < 4; k++ {
		lag_counter = 0

		/* Calculate the energy for first lag */
		basis_ptr = (target_ptr - uintptr((start_lag+int32(*(*int16)(unsafe.Pointer(((uintptr(unsafe.Pointer(&Lag_range_stage3)) + uintptr(complexity)*16) + uintptr(k)*4))))))*2)
		energy = inner_prod_aligned(tls, basis_ptr, basis_ptr, sf_length)

		*(*int32)(unsafe.Pointer(bp /* &scratch_mem[0] */ + uintptr(lag_counter)*4)) = energy
		lag_counter++

		for i = 1; i < ((int32(*(*int16)(unsafe.Pointer(((uintptr(unsafe.Pointer(&Lag_range_stage3)) + uintptr(complexity)*16) + uintptr(k)*4) + 1*2))) - int32(*(*int16)(unsafe.Pointer(((uintptr(unsafe.Pointer(&Lag_range_stage3)) + uintptr(complexity)*16) + uintptr(k)*4))))) + 1); i++ {
			/* remove part outside new window */
			energy = energy - ((int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr((sf_length-i))*2)))) * (int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr((sf_length-i))*2)))))

			/* add part that comes into window */
			energy = func() int32 {
				if ((uint32((energy) + ((int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2)))) * (int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2))))))) & 0x80000000) == uint32(0) {
					return func() int32 {
						if ((uint32((energy) & ((int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2)))) * (int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2))))))) & 0x80000000) != uint32(0) {
							return libc.Int32FromUint32(0x80000000)
						}
						return ((energy) + ((int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2)))) * (int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2))))))
					}()
				}
				return func() int32 {
					if ((uint32((energy) | ((int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2)))) * (int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2))))))) & 0x80000000) == uint32(0) {
						return 0x7FFFFFFF
					}
					return ((energy) + ((int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2)))) * (int32(*(*int16)(unsafe.Pointer(basis_ptr + uintptr(-i)*2))))))
				}()
			}()

			*(*int32)(unsafe.Pointer(bp /* &scratch_mem[0] */ + uintptr(lag_counter)*4)) = energy
			lag_counter++
		}

		delta = int32(*(*int16)(unsafe.Pointer(((uintptr(unsafe.Pointer(&Lag_range_stage3)) + uintptr(complexity)*16) + uintptr(k)*4))))
		for i = cbk_offset; i < (cbk_offset + cbk_size); i++ {
			/* Fill out the 3 dim array that stores the correlations for    */
			/* each code_book vector for each start lag                        */
			idx = (int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&CB_lags_stage3)) + uintptr(k)*68) + uintptr(i)*2))) - delta)
			for j = 0; j < 5; j++ {

				*(*int32)(unsafe.Pointer(((energies_st3 + uintptr(k)*680) + uintptr(i)*20) + uintptr(j)*4)) = *(*int32)(unsafe.Pointer(bp /* &scratch_mem[0] */ + uintptr((idx+j))*4))

			}
		}
		target_ptr += 2 * (uintptr(sf_length))
	}
}

func FIX_P_Ana_find_scaling(tls *libc.TLS, signal uintptr, signal_length int32, sum_sqr_len int32) int32 { /* pitch_analysis_core.c:681:11: */
	var nbits int32
	var x_max int32

	x_max = int32(int16_array_maxabs(tls, signal, signal_length))

	if x_max < 0x7FFF {
		/* Number of bits needed for the sum of the squares */
		nbits = (32 - CLZ32(tls, ((int32(int16(x_max)))*(int32(int16(x_max))))))
	} else {
		/* Here we don't know if x_max should have been int16_MAX + 1, so we expect the worst case */
		nbits = 30
	}
	nbits = nbits + (17 - CLZ16(tls, int16(sum_sqr_len)))

	/* Without a guarantee of saturation, we need to keep the 31st bit free */
	if nbits < 31 {
		return 0
	} else {
		return (nbits - 30)
	}
	return int32(0)
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/************************************************************/
/* Definitions For Fix pitch estimator                      */
/************************************************************/

/********************************************************/
/* Auto Generated File from generate_pitch_est_tables.m */
/********************************************************/

var CB_lags_stage2 = [4][11]int16{
	{int16(0), int16(2), int16(-1), int16(-1), int16(-1), int16(0), int16(0), int16(1), int16(1), int16(0), int16(1)},
	{int16(0), int16(1), int16(0), int16(0), int16(0), int16(0), int16(0), int16(1), int16(0), int16(0), int16(0)},
	{int16(0), int16(0), int16(1), int16(0), int16(0), int16(0), int16(1), int16(0), int16(0), int16(0), int16(0)},
	{int16(0), int16(-1), int16(2), int16(1), int16(0), int16(1), int16(1), int16(0), int16(0), int16(-1), int16(-1)},
} /* pitch_est_tables.c:35:17 */

var CB_lags_stage3 = [4][34]int16{
	{int16(-9), int16(-7), int16(-6), int16(-5), int16(-5), int16(-4), int16(-4), int16(-3), int16(-3), int16(-2), int16(-2), int16(-2), int16(-1), int16(-1), int16(-1), int16(0), int16(0), int16(0), int16(1), int16(1), int16(0), int16(1), int16(2), int16(2), int16(2), int16(3), int16(3), int16(4), int16(4), int16(5), int16(6), int16(5), int16(6), int16(8)},
	{int16(-3), int16(-2), int16(-2), int16(-2), int16(-1), int16(-1), int16(-1), int16(-1), int16(-1), int16(0), int16(0), int16(-1), int16(0), int16(0), int16(0), int16(0), int16(0), int16(0), int16(1), int16(0), int16(0), int16(0), int16(1), int16(1), int16(0), int16(1), int16(1), int16(2), int16(1), int16(2), int16(2), int16(2), int16(2), int16(3)},
	{int16(3), int16(3), int16(2), int16(2), int16(2), int16(2), int16(1), int16(2), int16(1), int16(1), int16(0), int16(1), int16(1), int16(0), int16(0), int16(0), int16(1), int16(0), int16(0), int16(0), int16(0), int16(0), int16(0), int16(-1), int16(0), int16(0), int16(-1), int16(-1), int16(-1), int16(-1), int16(-1), int16(-2), int16(-2), int16(-2)},
	{int16(9), int16(8), int16(6), int16(5), int16(6), int16(5), int16(4), int16(4), int16(3), int16(3), int16(2), int16(2), int16(2), int16(1), int16(0), int16(1), int16(1), int16(0), int16(0), int16(0), int16(-1), int16(-1), int16(-1), int16(-2), int16(-2), int16(-2), int16(-3), int16(-3), int16(-4), int16(-4), int16(-5), int16(-5), int16(-6), int16(-7)},
} /* pitch_est_tables.c:43:17 */

var Lag_range_stage3 = [3][4][2]int16{
	{
		/* Lags to search for low number of stage3 cbks */
		{int16(-2), int16(6)},
		{int16(-1), int16(5)},
		{int16(-1), int16(5)},
		{int16(-2), int16(7)},
	},
	/* Lags to search for middle number of stage3 cbks */
	{
		{int16(-4), int16(8)},
		{int16(-1), int16(6)},
		{int16(-1), int16(6)},
		{int16(-4), int16(9)},
	},
	/* Lags to search for max number of stage3 cbks */
	{
		{int16(-9), int16(12)},
		{int16(-3), int16(7)},
		{int16(-2), int16(7)},
		{int16(-7), int16(13)},
	},
} /* pitch_est_tables.c:51:17 */

var cbk_sizes_stage3 = [3]int16{
	int16(16),
	int16(24),
	int16(34),
} /* pitch_est_tables.c:76:17 */

var cbk_offsets_stage3 = [3]int16{
	(int16(int32((34 - 16)) >> 1)),
	(int16(int32((34 - 24)) >> 1)),
	int16(0),
} /* pitch_est_tables.c:83:17 */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

var HARM_ATT_Q15 = [2]int16{int16(32440), int16(31130)}              /* PLC.c:32:24 */ /* 0.99, 0.95 */
var PLC_RAND_ATTENUATE_V_Q15 = [2]int16{int16(31130), int16(26214)}  /* PLC.c:33:24 */ /* 0.95, 0.8 */
var PLC_RAND_ATTENUATE_UV_Q15 = [2]int16{int16(32440), int16(29491)} /* PLC.c:34:24 */

/* 0.99, 0.9 */

func PLC_Reset(tls *libc.TLS, psDec uintptr) { /* PLC.c:36:6: */
	(*decoder_state)(unsafe.Pointer(psDec)).FsPLC.FpitchL_Q8 = (((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length) >> (1))
}

func PLC(tls *libc.TLS, psDec uintptr, psDecCtrl uintptr, signal uintptr, length int32, lost int32) { /* PLC.c:43:6: */
	/* PLC control function */
	if (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz != (*decoder_state)(unsafe.Pointer(psDec)).FsPLC.Ffs_kHz {
		PLC_Reset(tls, psDec)
		(*decoder_state)(unsafe.Pointer(psDec)).FsPLC.Ffs_kHz = (*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz
	}

	if lost != 0 {
		/****************************/
		/* Generate Signal          */
		/****************************/
		PLC_conceal(tls, psDec, psDecCtrl, signal, length)

		(*decoder_state)(unsafe.Pointer(psDec)).FlossCnt++
	} else {
		/****************************/
		/* Update state             */
		/****************************/
		PLC_update(tls, psDec, psDecCtrl, signal, length)
	}
}

/**************************************************/
/* Update state of PLC                            */
/**************************************************/
func PLC_update(tls *libc.TLS, psDec uintptr, psDecCtrl uintptr, signal uintptr, length int32) { /* PLC.c:75:6: */
	var LTP_Gain_Q14 int32
	var temp_LTP_Gain_Q14 int32
	var i int32
	var j int32
	var psPLC uintptr

	psPLC = (psDec + 13588 /* &.sPLC */)

	/* Update parameters used in case of packet loss */
	(*decoder_state)(unsafe.Pointer(psDec)).Fprev_sigtype = (*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype
	LTP_Gain_Q14 = 0
	if (*decoder_control)(unsafe.Pointer(psDecCtrl)).Fsigtype == 0 {
		/* Find the parameters for the last subframe which contains a pitch pulse */
		for j = 0; (j * (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length) < *(*int32)(unsafe.Pointer((psDecCtrl /* &.pitchL */) + 3*4)); j++ {
			temp_LTP_Gain_Q14 = 0
			for i = 0; i < 5; i++ {
				temp_LTP_Gain_Q14 = temp_LTP_Gain_Q14 + (int32(*(*int16)(unsafe.Pointer((psDecCtrl + 100 /* &.LTPCoef_Q14 */) + uintptr(((((4-1)-j)*5)+i))*2))))
			}
			if temp_LTP_Gain_Q14 > LTP_Gain_Q14 {
				LTP_Gain_Q14 = temp_LTP_Gain_Q14
				libc.Xmemcpy(tls, psPLC+4 /* &.LTPCoef_Q14 */, ((psDecCtrl + 100 /* &.LTPCoef_Q14 */) + uintptr(((int32((int16((4 - 1) - j))))*(int32(int16(5)))))*2), (uint32(5) * uint32(unsafe.Sizeof(int16(0)))))

				(*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8 = ((*(*int32)(unsafe.Pointer((psDecCtrl /* &.pitchL */) + uintptr(((4-1)-j))*4))) << (8))
			}
		}

		libc.Xmemset(tls, psPLC+4 /* &.LTPCoef_Q14 */, 0, (uint32(5) * uint32(unsafe.Sizeof(int16(0)))))
		*(*int16)(unsafe.Pointer((psPLC + 4 /* &.LTPCoef_Q14 */) + 2*2)) = int16(LTP_Gain_Q14)

		/* Limit LT coefs */
		if LTP_Gain_Q14 < 11469 {
			var scale_Q10 int32
			var tmp int32

			tmp = (int32((11469)) << (10))
			scale_Q10 = ((tmp) / (func() int32 {
				if (LTP_Gain_Q14) > (1) {
					return LTP_Gain_Q14
				}
				return 1
			}()))
			for i = 0; i < 5; i++ {
				*(*int16)(unsafe.Pointer((psPLC + 4 /* &.LTPCoef_Q14 */) + uintptr(i)*2)) = (int16(((int32(*(*int16)(unsafe.Pointer((psPLC + 4 /* &.LTPCoef_Q14 */) + uintptr(i)*2)))) * (int32(int16(scale_Q10)))) >> (10)))
			}
		} else if LTP_Gain_Q14 > 15565 {
			var scale_Q14 int32
			var tmp int32

			tmp = (int32((15565)) << (14))
			scale_Q14 = ((tmp) / (func() int32 {
				if (LTP_Gain_Q14) > (1) {
					return LTP_Gain_Q14
				}
				return 1
			}()))
			for i = 0; i < 5; i++ {
				*(*int16)(unsafe.Pointer((psPLC + 4 /* &.LTPCoef_Q14 */) + uintptr(i)*2)) = (int16(((int32(*(*int16)(unsafe.Pointer((psPLC + 4 /* &.LTPCoef_Q14 */) + uintptr(i)*2)))) * (int32(int16(scale_Q14)))) >> (14)))
			}
		}
	} else {
		(*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8 = (((int32(int16((*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz))) * (int32(int16(18)))) << (8))
		libc.Xmemset(tls, psPLC+4 /* &.LTPCoef_Q14 */, 0, (uint32(5) * uint32(unsafe.Sizeof(int16(0)))))
	}

	/* Save LPC coeficients */
	libc.Xmemcpy(tls, psPLC+14 /* &.prevLPC_Q12 */, ((psDecCtrl + 36 /* &.PredCoef_Q12 */) + 1*32), (uint32((*decoder_state)(unsafe.Pointer(psDec)).FLPC_order) * uint32(unsafe.Sizeof(int16(0)))))
	(*PLC_struct)(unsafe.Pointer(psPLC)).FprevLTP_scale_Q14 = int16((*decoder_control)(unsafe.Pointer(psDecCtrl)).FLTP_scale_Q14)

	/* Save Gains */
	libc.Xmemcpy(tls, psPLC+72 /* &.prevGain_Q16 */, psDecCtrl+16 /* &.Gains_Q16 */, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))
}

func PLC_conceal(tls *libc.TLS, psDec uintptr, psDecCtrl uintptr, signal uintptr, length int32) { /* PLC.c:146:6: */
	bp := tls.Alloc(2932)
	defer tls.Free(2932)

	var i int32
	var j int32
	var k int32
	var B_Q14 uintptr
	// var exc_buf [480]int16 at bp, 960

	var exc_buf_ptr uintptr
	var rand_scale_Q14 int16
	// var A_Q12_tmp struct {_ [0]uint32;Fas_int16 [16]int16;} at bp+2900, 32

	var rand_seed int32
	var harm_Gain_Q15 int32
	var rand_Gain_Q15 int32
	var lag int32
	var idx int32
	var sLTP_buf_idx int32
	// var shift1 int32 at bp+964, 4

	// var shift2 int32 at bp+972, 4

	// var energy1 int32 at bp+960, 4

	// var energy2 int32 at bp+968, 4

	var rand_ptr uintptr
	var pred_lag_ptr uintptr
	// var sig_Q10 [480]int32 at bp+980, 1920

	var sig_Q10_ptr uintptr
	var LPC_exc_Q10 int32
	var LPC_pred_Q10 int32
	var LTP_pred_Q14 int32
	var psPLC uintptr
	psPLC = (psDec + 13588 /* &.sPLC */)

	/* Update LTP buffer */
	libc.Xmemcpy(tls, psDec+1048 /* &.sLTP_Q16 */, ((psDec + 1048 /* &.sLTP_Q16 */) + uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length)*4), (uint32((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length) * uint32(unsafe.Sizeof(int32(0)))))

	/* LPC concealment. Apply BWE to previous LPC */
	bwexpander(tls, psPLC+14 /* &.prevLPC_Q12 */, (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order, 64880)

	/* Find random noise component */
	/* Scale previous excitation signal */
	exc_buf_ptr = bp /* &exc_buf[0] */
	for k = (int32(4) >> 1); k < 4; k++ {
		for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length; i++ {
			*(*int16)(unsafe.Pointer(exc_buf_ptr + uintptr(i)*2)) = (int16((((((*(*int32)(unsafe.Pointer((psDec + 5432 /* &.exc_Q10 */) + uintptr((i+(k*(*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)))*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer((psDec + 5432 /* &.exc_Q10 */) + uintptr((i+(k*(*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)))*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + uintptr(k)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer((psDec + 5432 /* &.exc_Q10 */) + uintptr((i+(k*(*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)))*4))) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + uintptr(k)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + uintptr(k)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + uintptr(k)*4))) >> ((16) - 1)) + 1) >> 1)
			}()))) >> (10)))
		}
		exc_buf_ptr += 2 * (uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length))
	}
	/* Find the subframe with lowest energy of the last two and use that as random noise generator */
	sum_sqr_shift(tls, bp+960 /* &energy1 */, bp+964 /* &shift1 */, bp /* &exc_buf[0] */, (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)
	sum_sqr_shift(tls, bp+968 /* &energy2 */, bp+972 /* &shift2 */, (bp /* &exc_buf */ + uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)*2), (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)

	if ((*(*int32)(unsafe.Pointer(bp + 960 /* energy1 */))) >> (*(*int32)(unsafe.Pointer(bp + 972 /* shift2 */)))) < ((*(*int32)(unsafe.Pointer(bp + 968 /* energy2 */))) >> (*(*int32)(unsafe.Pointer(bp + 964 /* shift1 */)))) {
		/* First sub-frame has lowest energy */
		rand_ptr = ((psDec + 5432 /* &.exc_Q10 */) + uintptr(max_int(tls, 0, ((3*(*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)-128)))*4)
	} else {
		/* Second sub-frame has lowest energy */
		rand_ptr = ((psDec + 5432 /* &.exc_Q10 */) + uintptr(max_int(tls, 0, ((*decoder_state)(unsafe.Pointer(psDec)).Fframe_length-128)))*4)
	}

	/* Setup Gain to random noise component */
	B_Q14 = psPLC + 4 /* &.LTPCoef_Q14 */
	rand_scale_Q14 = (*PLC_struct)(unsafe.Pointer(psPLC)).FrandScale_Q14

	/* Setup attenuation gains */
	harm_Gain_Q15 = int32(HARM_ATT_Q15[min_int(tls, (2-1), (*decoder_state)(unsafe.Pointer(psDec)).FlossCnt)])
	if (*decoder_state)(unsafe.Pointer(psDec)).Fprev_sigtype == 0 {
		rand_Gain_Q15 = int32(PLC_RAND_ATTENUATE_V_Q15[min_int(tls, (2-1), (*decoder_state)(unsafe.Pointer(psDec)).FlossCnt)])
	} else {
		rand_Gain_Q15 = int32(PLC_RAND_ATTENUATE_UV_Q15[min_int(tls, (2-1), (*decoder_state)(unsafe.Pointer(psDec)).FlossCnt)])
	}

	/* First Lost frame */
	if (*decoder_state)(unsafe.Pointer(psDec)).FlossCnt == 0 {
		rand_scale_Q14 = (int16(int32(1) << 14))

		/* Reduce random noise Gain for voiced frames */
		if (*decoder_state)(unsafe.Pointer(psDec)).Fprev_sigtype == 0 {
			for i = 0; i < 5; i++ {
				rand_scale_Q14 = int16(int32(rand_scale_Q14) - (int32(*(*int16)(unsafe.Pointer(B_Q14 + uintptr(i)*2)))))
			}
			rand_scale_Q14 = max_16(tls, int16(3277), rand_scale_Q14) /* 0.2 */
			rand_scale_Q14 = (int16(((int32(rand_scale_Q14)) * (int32((*PLC_struct)(unsafe.Pointer(psPLC)).FprevLTP_scale_Q14))) >> (14)))
		}

		/* Reduce random noise for unvoiced frames with high LPC gain */
		if (*decoder_state)(unsafe.Pointer(psDec)).Fprev_sigtype == 1 {
			// var invGain_Q30 int32 at bp+976, 4

			var down_scale_Q30 int32

			LPC_inverse_pred_gain(tls, bp+976 /* &invGain_Q30 */, psPLC+14 /* &.prevLPC_Q12 */, (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order)

			down_scale_Q30 = min_32(tls, (int32((int32(1) << 30)) >> (3)), *(*int32)(unsafe.Pointer(bp + 976 /* invGain_Q30 */)))
			down_scale_Q30 = max_32(tls, (int32((int32(1) << 30)) >> (8)), down_scale_Q30)
			down_scale_Q30 = ((down_scale_Q30) << (3))

			rand_Gain_Q15 = (((((down_scale_Q30) >> 16) * (int32(int16(rand_Gain_Q15)))) + ((((down_scale_Q30) & 0x0000FFFF) * (int32(int16(rand_Gain_Q15)))) >> 16)) >> (14))
		}
	}

	rand_seed = (*PLC_struct)(unsafe.Pointer(psPLC)).Frand_seed
	lag = func() int32 {
		if (8) == 1 {
			return ((((*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8) >> 1) + (((*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8) & 1))
		}
		return (((((*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8) >> ((8) - 1)) + 1) >> 1)
	}()
	sLTP_buf_idx = (*decoder_state)(unsafe.Pointer(psDec)).Fframe_length

	/***************************/
	/* LTP synthesis filtering */
	/***************************/
	sig_Q10_ptr = bp + 980 /* &sig_Q10[0] */
	for k = 0; k < 4; k++ {
		/* Setup pointer */
		pred_lag_ptr = ((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(((sLTP_buf_idx-lag)+(5/2)))*4)
		for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length; i++ {
			rand_seed = (int32((uint32(907633515)) + ((uint32(rand_seed)) * (uint32(196314165)))))
			idx = (((rand_seed) >> (25)) & (128 - 1))

			/* Unrolled loop */
			LTP_pred_Q14 = ((((*(*int32)(unsafe.Pointer(pred_lag_ptr))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14))))) >> 16))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-1)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 1*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-1)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 1*2))))) >> 16)))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-2)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 2*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-2)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 2*2))))) >> 16)))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-3)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 3*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-3)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 3*2))))) >> 16)))
			LTP_pred_Q14 = ((LTP_pred_Q14) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-4)*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 4*2))))) + ((((*(*int32)(unsafe.Pointer(pred_lag_ptr + libc.UintptrFromInt32(-4)*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + 4*2))))) >> 16)))
			pred_lag_ptr += 4

			/* Generate LPC residual */
			LPC_exc_Q10 = (((((*(*int32)(unsafe.Pointer(rand_ptr + uintptr(idx)*4))) >> 16) * (int32(rand_scale_Q14))) + ((((*(*int32)(unsafe.Pointer(rand_ptr + uintptr(idx)*4))) & 0x0000FFFF) * (int32(rand_scale_Q14))) >> 16)) << (2)) /* Random noise part */
			LPC_exc_Q10 = ((LPC_exc_Q10) + (func() int32 {
				if (4) == 1 {
					return (((LTP_pred_Q14) >> 1) + ((LTP_pred_Q14) & 1))
				}
				return ((((LTP_pred_Q14) >> ((4) - 1)) + 1) >> 1)
			}())) /* Harmonic part */

			/* Update states */
			*(*int32)(unsafe.Pointer((psDec + 1048 /* &.sLTP_Q16 */) + uintptr(sLTP_buf_idx)*4)) = ((LPC_exc_Q10) << (6))
			sLTP_buf_idx++

			/* Save LPC residual */
			*(*int32)(unsafe.Pointer(sig_Q10_ptr + uintptr(i)*4)) = LPC_exc_Q10
		}
		sig_Q10_ptr += 4 * (uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length))
		/* Gradually reduce LTP gain */
		for j = 0; j < 5; j++ {
			*(*int16)(unsafe.Pointer(B_Q14 + uintptr(j)*2)) = (int16(((int32(int16(harm_Gain_Q15))) * (int32(*(*int16)(unsafe.Pointer(B_Q14 + uintptr(j)*2))))) >> (15)))
		}
		/* Gradually reduce excitation gain */
		rand_scale_Q14 = (int16(((int32(rand_scale_Q14)) * (int32(int16(rand_Gain_Q15)))) >> (15)))

		/* Slowly increase pitch lag */
		*(*int32)(unsafe.Pointer(psPLC /* &.pitchL_Q8 */)) += (((((*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8) >> 16) * (int32(int16(655)))) + (((((*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8) & 0x0000FFFF) * (int32(int16(655)))) >> 16))
		(*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8 = min_32(tls, (*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8, (((int32(int16(18))) * (int32(int16((*decoder_state)(unsafe.Pointer(psDec)).Ffs_kHz)))) << (8)))
		lag = func() int32 {
			if (8) == 1 {
				return ((((*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8) >> 1) + (((*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8) & 1))
			}
			return (((((*PLC_struct)(unsafe.Pointer(psPLC)).FpitchL_Q8) >> ((8) - 1)) + 1) >> 1)
		}()
	}

	/***************************/
	/* LPC synthesis filtering */
	/***************************/
	sig_Q10_ptr = bp + 980 /* &sig_Q10[0] */
	/* Preload LPC coeficients to array on stack. Gives small performance gain */
	libc.Xmemcpy(tls, bp+2900 /* &A_Q12_tmp */ /* &.as_int16 */, psPLC+14 /* &.prevLPC_Q12 */, (uint32((*decoder_state)(unsafe.Pointer(psDec)).FLPC_order) * uint32(unsafe.Sizeof(int16(0)))))
	/* check that unrolling works */
	for k = 0; k < 4; k++ {
		for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length; i++ {
			/* partly unrolled */
			LPC_pred_Q10 = ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-1))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */)))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-1))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */)))))) >> 16))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-2))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 1*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-2))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 1*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-3))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 2*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-3))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 2*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-4))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 3*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-4))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 3*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-5))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 4*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-5))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 4*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-6))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 5*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-6))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 5*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-7))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 6*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-7))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 6*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-8))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 7*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-8))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 7*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-9))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 8*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-9))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 8*2))))) >> 16)))
			LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-10))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 9*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr(((16+i)-10))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + 9*2))))) >> 16)))

			for j = 10; j < (*decoder_state)(unsafe.Pointer(psDec)).FLPC_order; j++ {
				LPC_pred_Q10 = ((LPC_pred_Q10) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr((((16+i)-j)-1))*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + uintptr(j)*2))))) + ((((*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr((((16+i)-j)-1))*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer((bp + 2900 /* &A_Q12_tmp */ /* &.as_int16 */) + uintptr(j)*2))))) >> 16)))
			}
			/* Add prediction to LPC residual */
			*(*int32)(unsafe.Pointer(sig_Q10_ptr + uintptr(i)*4)) = ((*(*int32)(unsafe.Pointer(sig_Q10_ptr + uintptr(i)*4))) + (LPC_pred_Q10))

			/* Update states */
			*(*int32)(unsafe.Pointer((psDec + 4888 /* &.sLPC_Q14 */) + uintptr((16+i))*4)) = ((*(*int32)(unsafe.Pointer(sig_Q10_ptr + uintptr(i)*4))) << (4))
		}
		sig_Q10_ptr += 4 * (uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length))
		/* Update LPC filter state */
		libc.Xmemcpy(tls, psDec+4888 /* &.sLPC_Q14 */, ((psDec + 4888 /* &.sLPC_Q14 */) + uintptr((*decoder_state)(unsafe.Pointer(psDec)).Fsubfr_length)*4), (uint32(16) * uint32(unsafe.Sizeof(int32(0)))))
	}

	/* Scale with Gain */
	for i = 0; i < (*decoder_state)(unsafe.Pointer(psDec)).Fframe_length; i++ {
		*(*int16)(unsafe.Pointer(signal + uintptr(i)*2)) = func() int16 {
			if (func() int32 {
				if (10) == 1 {
					return (((((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) & 1))
				}
				return ((((((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> ((16) - 1)) + 1) >> 1)
				}()))) >> ((10) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1))
					}
					return ((((((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (10) == 1 {
						return (int16(((((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) >> 1) + ((((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
							if (16) == 1 {
								return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) & 1))
							}
							return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> ((16) - 1)) + 1) >> 1)
						}()))) & 1)))
					}
					return (int16((((((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 980 /* &sig_Q10[0] */ + uintptr(i)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer((psPLC + 72 /* &.prevGain_Q16 */) + 3*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) >> ((10) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}

	/**************************************/
	/* Update states                      */
	/**************************************/
	(*PLC_struct)(unsafe.Pointer(psPLC)).Frand_seed = rand_seed
	(*PLC_struct)(unsafe.Pointer(psPLC)).FrandScale_Q14 = rand_scale_Q14
	for i = 0; i < 4; i++ {
		*(*int32)(unsafe.Pointer((psDecCtrl /* &.pitchL */) + uintptr(i)*4)) = lag
	}
}

/* Glues concealed frames with new good recieved frames             */
func PLC_glue_frames(tls *libc.TLS, psDec uintptr, psDecCtrl uintptr, signal uintptr, length int32) { /* PLC.c:333:6: */
	bp := tls.Alloc(8)
	defer tls.Free(8)

	var i int32
	// var energy_shift int32 at bp+4, 4

	// var energy int32 at bp, 4

	var psPLC uintptr
	psPLC = (psDec + 13588 /* &.sPLC */)

	if (*decoder_state)(unsafe.Pointer(psDec)).FlossCnt != 0 {
		/* Calculate energy in concealed residual */
		sum_sqr_shift(tls, (psPLC + 60 /* &.conc_energy */), (psPLC + 64 /* &.conc_energy_shift */), signal, length)

		(*PLC_struct)(unsafe.Pointer(psPLC)).Flast_frame_lost = 1
	} else {
		if (*decoder_state)(unsafe.Pointer(psDec)).FsPLC.Flast_frame_lost != 0 {
			/* Calculate residual in decoded signal if last frame was lost */
			sum_sqr_shift(tls, bp /* &energy */, bp+4 /* &energy_shift */, signal, length)

			/* Normalize energies */
			if *(*int32)(unsafe.Pointer(bp + 4 /* energy_shift */)) > (*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy_shift {
				(*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy = (((*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy) >> (*(*int32)(unsafe.Pointer(bp + 4 /* energy_shift */)) - (*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy_shift))
			} else if *(*int32)(unsafe.Pointer(bp + 4 /* energy_shift */)) < (*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy_shift {
				*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) >> ((*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy_shift - *(*int32)(unsafe.Pointer(bp + 4 /* energy_shift */))))
			}

			/* Fade in the energy difference */
			if *(*int32)(unsafe.Pointer(bp /* energy */)) > (*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy {
				var frac_Q24 int32
				var LZ int32
				var gain_Q12 int32
				var slope_Q12 int32

				LZ = CLZ32(tls, (*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy)
				LZ = (LZ - 1)
				(*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy = (((*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy) << (LZ))
				*(*int32)(unsafe.Pointer(bp /* energy */)) = ((*(*int32)(unsafe.Pointer(bp /* energy */))) >> (max_32(tls, (24 - LZ), 0)))

				frac_Q24 = (((*PLC_struct)(unsafe.Pointer(psPLC)).Fconc_energy) / (func() int32 {
					if (*(*int32)(unsafe.Pointer(bp /* energy */))) > (1) {
						return *(*int32)(unsafe.Pointer(bp /* energy */))
					}
					return 1
				}()))

				gain_Q12 = SQRT_APPROX(tls, frac_Q24)
				slope_Q12 = (((int32(1) << 12) - gain_Q12) / (length))

				for i = 0; i < length; i++ {
					*(*int16)(unsafe.Pointer(signal + uintptr(i)*2)) = (int16(((gain_Q12) * (int32(*(*int16)(unsafe.Pointer(signal + uintptr(i)*2))))) >> (12)))
					gain_Q12 = gain_Q12 + (slope_Q12)
					gain_Q12 = func() int32 {
						if (gain_Q12) < (int32(1) << 12) {
							return gain_Q12
						}
						return (int32(1) << 12)
					}()
				}
			}
		}
		(*PLC_struct)(unsafe.Pointer(psPLC)).Flast_frame_lost = 0

	}
}

func warped_LPC_analysis_filter_FIX(tls *libc.TLS, state uintptr, res uintptr, coef_Q13 uintptr, input uintptr, lambda_Q16 int16, length int32, order int32) { /* prefilter_FIX.c:42:6: */
	var n int32
	var i int32
	var acc_Q11 int32
	var tmp1 int32
	var tmp2 int32

	/* Order must be even */

	for n = 0; n < length; n++ {
		/* Output of lowpass section */
		tmp2 = ((*(*int32)(unsafe.Pointer(state))) + ((((*(*int32)(unsafe.Pointer(state + 1*4))) >> 16) * (int32(lambda_Q16))) + ((((*(*int32)(unsafe.Pointer(state + 1*4))) & 0x0000FFFF) * (int32(lambda_Q16))) >> 16)))
		*(*int32)(unsafe.Pointer(state)) = ((int32(*(*int16)(unsafe.Pointer(input + uintptr(n)*2)))) << (14))
		/* Output of allpass section */
		tmp1 = ((*(*int32)(unsafe.Pointer(state + 1*4))) + ((((*(*int32)(unsafe.Pointer(state + 2*4)) - tmp2) >> 16) * (int32(lambda_Q16))) + ((((*(*int32)(unsafe.Pointer(state + 2*4)) - tmp2) & 0x0000FFFF) * (int32(lambda_Q16))) >> 16)))
		*(*int32)(unsafe.Pointer(state + 1*4)) = tmp2
		acc_Q11 = ((((tmp2) >> 16) * (int32(*(*int16)(unsafe.Pointer(coef_Q13))))) + ((((tmp2) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(coef_Q13))))) >> 16))
		/* Loop over allpass sections */
		for i = 2; i < order; i = i + (2) {
			/* Output of allpass section */
			tmp2 = ((*(*int32)(unsafe.Pointer(state + uintptr(i)*4))) + ((((*(*int32)(unsafe.Pointer(state + uintptr((i+1))*4)) - tmp1) >> 16) * (int32(lambda_Q16))) + ((((*(*int32)(unsafe.Pointer(state + uintptr((i+1))*4)) - tmp1) & 0x0000FFFF) * (int32(lambda_Q16))) >> 16)))
			*(*int32)(unsafe.Pointer(state + uintptr(i)*4)) = tmp1
			acc_Q11 = ((acc_Q11) + ((((tmp1) >> 16) * (int32(*(*int16)(unsafe.Pointer(coef_Q13 + uintptr((i-1))*2))))) + ((((tmp1) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(coef_Q13 + uintptr((i-1))*2))))) >> 16)))
			/* Output of allpass section */
			tmp1 = ((*(*int32)(unsafe.Pointer(state + uintptr((i+1))*4))) + ((((*(*int32)(unsafe.Pointer(state + uintptr((i+2))*4)) - tmp2) >> 16) * (int32(lambda_Q16))) + ((((*(*int32)(unsafe.Pointer(state + uintptr((i+2))*4)) - tmp2) & 0x0000FFFF) * (int32(lambda_Q16))) >> 16)))
			*(*int32)(unsafe.Pointer(state + uintptr((i+1))*4)) = tmp2
			acc_Q11 = ((acc_Q11) + ((((tmp2) >> 16) * (int32(*(*int16)(unsafe.Pointer(coef_Q13 + uintptr(i)*2))))) + ((((tmp2) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(coef_Q13 + uintptr(i)*2))))) >> 16)))
		}
		*(*int32)(unsafe.Pointer(state + uintptr(order)*4)) = tmp1
		acc_Q11 = ((acc_Q11) + ((((tmp1) >> 16) * (int32(*(*int16)(unsafe.Pointer(coef_Q13 + uintptr((order-1))*2))))) + ((((tmp1) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(coef_Q13 + uintptr((order-1))*2))))) >> 16)))
		*(*int16)(unsafe.Pointer(res + uintptr(n)*2)) = func() int16 {
			if (int32(*(*int16)(unsafe.Pointer(input + uintptr(n)*2))) - (func() int32 {
				if (11) == 1 {
					return (((acc_Q11) >> 1) + ((acc_Q11) & 1))
				}
				return ((((acc_Q11) >> ((11) - 1)) + 1) >> 1)
			}())) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (int32(*(*int16)(unsafe.Pointer(input + uintptr(n)*2))) - (func() int32 {
					if (11) == 1 {
						return (((acc_Q11) >> 1) + ((acc_Q11) & 1))
					}
					return ((((acc_Q11) >> ((11) - 1)) + 1) >> 1)
				}())) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return (int16(int32(*(*int16)(unsafe.Pointer(input + uintptr(n)*2))) - (func() int32 {
					if (11) == 1 {
						return (((acc_Q11) >> 1) + ((acc_Q11) & 1))
					}
					return ((((acc_Q11) >> ((11) - 1)) + 1) >> 1)
				}())))
			}()
		}()
	}
}

func prefilter_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrl uintptr, xw uintptr, x uintptr) { /* prefilter_FIX.c:83:6: */
	bp := tls.Alloc(756)
	defer tls.Free(756)

	var P uintptr = (psEnc + 19556 /* &.sPrefilt */)
	var j int32
	var k int32
	var lag int32
	var tmp_32 int32
	var AR1_shp_Q13 uintptr
	var px uintptr
	var pxw uintptr
	var HarmShapeGain_Q12 int32
	var Tilt_Q14 int32
	var HarmShapeFIRPacked_Q12 int32
	var LF_shp_Q14 int32
	// var x_filt_Q12 [120]int32 at bp+276, 480

	// var st_res [136]int16 at bp, 272

	// var B_Q12 [2]int16 at bp+272, 4

	/* Setup pointers */
	px = x
	pxw = xw
	lag = (*prefilter_state_FIX)(unsafe.Pointer(P)).FlagPrev
	for k = 0; k < 4; k++ {
		/* Update Variables that change per sub frame */
		if (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 0 {
			lag = *(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 108 /* &.pitchL */) + uintptr(k)*4))
		}

		/* Noise shape parameters */
		HarmShapeGain_Q12 = ((((*(*int32)(unsafe.Pointer((psEncCtrl + 572 /* &.HarmShapeGain_Q14 */) + uintptr(k)*4))) >> 16) * (int32((int16(16384 - *(*int32)(unsafe.Pointer((psEncCtrl + 540 /* &.HarmBoost_Q14 */) + uintptr(k)*4))))))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 572 /* &.HarmShapeGain_Q14 */) + uintptr(k)*4))) & 0x0000FFFF) * (int32((int16(16384 - *(*int32)(unsafe.Pointer((psEncCtrl + 540 /* &.HarmBoost_Q14 */) + uintptr(k)*4))))))) >> 16))

		HarmShapeFIRPacked_Q12 = ((HarmShapeGain_Q12) >> (2))
		HarmShapeFIRPacked_Q12 = HarmShapeFIRPacked_Q12 | (((HarmShapeGain_Q12) >> (1)) << (16))
		Tilt_Q14 = *(*int32)(unsafe.Pointer((psEncCtrl + 556 /* &.Tilt_Q14 */) + uintptr(k)*4))
		LF_shp_Q14 = *(*int32)(unsafe.Pointer((psEncCtrl + 508 /* &.LF_shp_Q14 */) + uintptr(k)*4))
		AR1_shp_Q13 = ((psEncCtrl + 252 /* &.AR1_Q13 */) + uintptr((k*16))*2)

		/* Short term FIR filtering*/
		warped_LPC_analysis_filter_FIX(tls, P+1024 /* &.sAR_shp */, bp /* &st_res[0] */, AR1_shp_Q13, px,
			int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fwarping_Q16), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FshapingLPCOrder)

		/* reduce (mainly) low frequencies during harmonic emphasis */
		*(*int16)(unsafe.Pointer(bp + 272 /* &B_Q12[0] */)) = func() int16 {
			if (2) == 1 {
				return (int16(((*(*int32)(unsafe.Pointer((psEncCtrl + 524 /* &.GainsPre_Q14 */) + uintptr(k)*4))) >> 1) + ((*(*int32)(unsafe.Pointer((psEncCtrl + 524 /* &.GainsPre_Q14 */) + uintptr(k)*4))) & 1)))
			}
			return (int16((((*(*int32)(unsafe.Pointer((psEncCtrl + 524 /* &.GainsPre_Q14 */) + uintptr(k)*4))) >> ((2) - 1)) + 1) >> 1))
		}()
		tmp_32 = ((FIX_CONST(tls, 0.05, 26)) + ((int32(int16(*(*int32)(unsafe.Pointer((psEncCtrl + 540 /* &.HarmBoost_Q14 */) + uintptr(k)*4))))) * (int32(int16(HarmShapeGain_Q12)))))                                                                                           /* Q26 */
		tmp_32 = ((tmp_32) + ((int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14))) * (int32(int16(FIX_CONST(tls, 0.1, 12))))))                                                                                                                   /* Q26 */
		tmp_32 = ((((tmp_32) >> 16) * (int32(int16(-*(*int32)(unsafe.Pointer((psEncCtrl + 524 /* &.GainsPre_Q14 */) + uintptr(k)*4)))))) + ((((tmp_32) & 0x0000FFFF) * (int32(int16(-*(*int32)(unsafe.Pointer((psEncCtrl + 524 /* &.GainsPre_Q14 */) + uintptr(k)*4)))))) >> 16)) /* Q24 */
		tmp_32 = func() int32 {
			if (12) == 1 {
				return (((tmp_32) >> 1) + ((tmp_32) & 1))
			}
			return ((((tmp_32) >> ((12) - 1)) + 1) >> 1)
		}() /* Q12 */
		*(*int16)(unsafe.Pointer(bp + 272 /* &B_Q12[0] */ + 1*2)) = func() int16 {
			if (tmp_32) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (tmp_32) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return int16(tmp_32)
			}()
		}()

		*(*int32)(unsafe.Pointer(bp + 276 /* &x_filt_Q12[0] */)) = (((int32(*(*int16)(unsafe.Pointer(bp /* &st_res[0] */)))) * (int32(*(*int16)(unsafe.Pointer(bp + 272 /* &B_Q12[0] */))))) + ((int32(int16((*prefilter_state_FIX)(unsafe.Pointer(P)).FsHarmHP))) * (int32(*(*int16)(unsafe.Pointer(bp + 272 /* &B_Q12[0] */ + 1*2))))))
		for j = 1; j < (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length; j++ {
			*(*int32)(unsafe.Pointer(bp + 276 /* &x_filt_Q12[0] */ + uintptr(j)*4)) = (((int32(*(*int16)(unsafe.Pointer(bp /* &st_res[0] */ + uintptr(j)*2)))) * (int32(*(*int16)(unsafe.Pointer(bp + 272 /* &B_Q12[0] */))))) + ((int32(*(*int16)(unsafe.Pointer(bp /* &st_res[0] */ + uintptr((j-1))*2)))) * (int32(*(*int16)(unsafe.Pointer(bp + 272 /* &B_Q12[0] */ + 1*2))))))
		}
		(*prefilter_state_FIX)(unsafe.Pointer(P)).FsHarmHP = int32(*(*int16)(unsafe.Pointer(bp /* &st_res[0] */ + uintptr(((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length-1))*2)))

		prefilt_FIX(tls, P, bp+276 /* &x_filt_Q12[0] */, pxw, HarmShapeFIRPacked_Q12, Tilt_Q14,
			LF_shp_Q14, lag, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length)

		px += 2 * (uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length))
		pxw += 2 * (uintptr((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length))
	}

	(*prefilter_state_FIX)(unsafe.Pointer(P)).FlagPrev = *(*int32)(unsafe.Pointer((psEncCtrl /* &.sCmn */ + 108 /* &.pitchL */) + 3*4))
}

/* prefilter. Prefilter for finding Quantizer input signal                           */
func prefilt_FIX(tls *libc.TLS, P uintptr, st_res_Q12 uintptr, xw uintptr, HarmShapeFIRPacked_Q12 int32, Tilt_Q14 int32, LF_shp_Q14 int32, lag int32, length int32) { /* prefilter_FIX.c:150:17: */
	var i int32
	var idx int32
	var LTP_shp_buf_idx int32
	var n_LTP_Q12 int32
	var n_Tilt_Q10 int32
	var n_LF_Q10 int32
	var sLF_MA_shp_Q12 int32
	var sLF_AR_shp_Q12 int32
	var LTP_shp_buf uintptr

	/* To speed up use temp variables instead of using the struct */
	LTP_shp_buf = P /* &.sLTP_shp */
	LTP_shp_buf_idx = (*prefilter_state_FIX)(unsafe.Pointer(P)).FsLTP_shp_buf_idx
	sLF_AR_shp_Q12 = (*prefilter_state_FIX)(unsafe.Pointer(P)).FsLF_AR_shp_Q12
	sLF_MA_shp_Q12 = (*prefilter_state_FIX)(unsafe.Pointer(P)).FsLF_MA_shp_Q12

	for i = 0; i < length; i++ {
		if lag > 0 {
			/* unrolled loop */

			idx = (lag + LTP_shp_buf_idx)
			n_LTP_Q12 = ((int32(*(*int16)(unsafe.Pointer(LTP_shp_buf + uintptr((((idx-(3/2))-1)&(512-1)))*2)))) * (int32(int16(HarmShapeFIRPacked_Q12))))
			n_LTP_Q12 = ((n_LTP_Q12) + ((int32(*(*int16)(unsafe.Pointer(LTP_shp_buf + uintptr(((idx-(3/2))&(512-1)))*2)))) * ((HarmShapeFIRPacked_Q12) >> 16)))
			n_LTP_Q12 = ((n_LTP_Q12) + ((int32(*(*int16)(unsafe.Pointer(LTP_shp_buf + uintptr((((idx-(3/2))+1)&(512-1)))*2)))) * (int32(int16(HarmShapeFIRPacked_Q12)))))
		} else {
			n_LTP_Q12 = 0
		}

		n_Tilt_Q10 = ((((sLF_AR_shp_Q12) >> 16) * (int32(int16(Tilt_Q14)))) + ((((sLF_AR_shp_Q12) & 0x0000FFFF) * (int32(int16(Tilt_Q14)))) >> 16))
		n_LF_Q10 = (((((sLF_AR_shp_Q12) >> 16) * ((LF_shp_Q14) >> 16)) + ((((sLF_AR_shp_Q12) & 0x0000FFFF) * ((LF_shp_Q14) >> 16)) >> 16)) + ((((sLF_MA_shp_Q12) >> 16) * (int32(int16(LF_shp_Q14)))) + ((((sLF_MA_shp_Q12) & 0x0000FFFF) * (int32(int16(LF_shp_Q14)))) >> 16)))

		sLF_AR_shp_Q12 = ((*(*int32)(unsafe.Pointer(st_res_Q12 + uintptr(i)*4))) - ((n_Tilt_Q10) << (2)))
		sLF_MA_shp_Q12 = ((sLF_AR_shp_Q12) - ((n_LF_Q10) << (2)))

		LTP_shp_buf_idx = ((LTP_shp_buf_idx - 1) & (512 - 1))
		*(*int16)(unsafe.Pointer(LTP_shp_buf + uintptr(LTP_shp_buf_idx)*2)) = func() int16 {
			if (func() int32 {
				if (12) == 1 {
					return (((sLF_MA_shp_Q12) >> 1) + ((sLF_MA_shp_Q12) & 1))
				}
				return ((((sLF_MA_shp_Q12) >> ((12) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (12) == 1 {
						return (((sLF_MA_shp_Q12) >> 1) + ((sLF_MA_shp_Q12) & 1))
					}
					return ((((sLF_MA_shp_Q12) >> ((12) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (12) == 1 {
						return (int16(((sLF_MA_shp_Q12) >> 1) + ((sLF_MA_shp_Q12) & 1)))
					}
					return (int16((((sLF_MA_shp_Q12) >> ((12) - 1)) + 1) >> 1))
				}()
			}()
		}()

		*(*int16)(unsafe.Pointer(xw + uintptr(i)*2)) = func() int16 {
			if (func() int32 {
				if (12) == 1 {
					return ((((sLF_MA_shp_Q12) - (n_LTP_Q12)) >> 1) + (((sLF_MA_shp_Q12) - (n_LTP_Q12)) & 1))
				}
				return (((((sLF_MA_shp_Q12) - (n_LTP_Q12)) >> ((12) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (12) == 1 {
						return ((((sLF_MA_shp_Q12) - (n_LTP_Q12)) >> 1) + (((sLF_MA_shp_Q12) - (n_LTP_Q12)) & 1))
					}
					return (((((sLF_MA_shp_Q12) - (n_LTP_Q12)) >> ((12) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (12) == 1 {
						return (int16((((sLF_MA_shp_Q12) - (n_LTP_Q12)) >> 1) + (((sLF_MA_shp_Q12) - (n_LTP_Q12)) & 1)))
					}
					return (int16(((((sLF_MA_shp_Q12) - (n_LTP_Q12)) >> ((12) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}

	/* Copy temp variable back to state */
	(*prefilter_state_FIX)(unsafe.Pointer(P)).FsLF_AR_shp_Q12 = sLF_AR_shp_Q12
	(*prefilter_state_FIX)(unsafe.Pointer(P)).FsLF_MA_shp_Q12 = sLF_MA_shp_Q12
	(*prefilter_state_FIX)(unsafe.Pointer(P)).FsLTP_shp_buf_idx = LTP_shp_buf_idx
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*******************/
/* Pitch estimator */
/*******************/

/* Level of noise floor for whitening filter LPC analysis in pitch analysis */

/* Bandwidth expansion for whitening filter in pitch analysis */

/* Threshold used by pitch estimator for early escape */

/*********************/
/* Linear prediction */
/*********************/

/* LPC analysis defines: regularization and bandwidth expansion */

/* LTP analysis defines */

/* LTP quantization settings */

/***********************/
/* High pass filtering */
/***********************/

/* Smoothing parameters for low end of pitch frequency range estimation */

/* Min and max values for low end of pitch frequency range estimation */

/* Max absolute difference between log2 of pitch frequency and smoother state, to enter the smoother */

/***********/
/* Various */
/***********/

/* Required speech activity for counting frame as active */

/* Speech Activity LBRR enable threshold (needs tuning) */

/*************************/
/* Perceptual parameters */
/*************************/

/* reduction in coding SNR during low speech activity */

/* factor for reducing quantization noise during voiced speech */

/* factor for reducing quantization noise for unvoiced sparse signals */

/* threshold for sparseness measure above which to use lower quantization offset during unvoiced */

/* warping control */

/* fraction added to first autocorrelation value */

/* noise shaping filter chirp factor */

/* difference between chirp factors for analysis and synthesis noise shaping filters at low bitrates */

/* gain reduction for fricatives */

/* extra harmonic boosting (signal shaping) at low bitrates */

/* extra harmonic boosting (signal shaping) for noisy input signals */

/* harmonic noise shaping */

/* extra harmonic noise shaping for high bitrates or noisy input */

/* parameter for shaping noise towards higher frequencies */

/* parameter for shaping noise even more towards higher frequencies during voiced speech */

/* parameter for applying a high-pass tilt to the input signal */

/* parameter for extra high-pass tilt to the input signal at high rates */

/* parameter for reducing noise at the very low frequencies */

/* less reduction of noise at the very low frequencies for signals with low SNR at low frequencies */

/* noise floor to put a lower limit on the quantization step size */

/* noise floor relative to active speech gain level */

/* subframe smoothing coefficient for determining active speech gain level (lower -> more smoothing) */

/* subframe smoothing coefficient for HarmBoost, HarmShapeGain, Tilt (lower -> more smoothing) */

/* parameters defining the R/D tradeoff in the residual quantizer */

/* Processing of gains */
func process_gains_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrl uintptr) { /* process_gains_FIX.c:32:6: */
	var psShapeSt uintptr = (psEnc + 19540 /* &.sShape */)
	var k int32
	var s_Q16 int32
	var InvMaxSqrVal_Q16 int32
	var gain int32
	var gain_squared int32
	var ResNrg int32
	var ResNrgPart int32
	var quant_offset_Q10 int32

	/* Gain reduction when LTP coding gain is high */
	if (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 0 {
		/*s = -0.5f * sigmoid( 0.25f * ( psEncCtrl->LTPredCodGain - 12.0f ) ); */
		s_Q16 = -sigm_Q15(tls, func() int32 {
			if (4) == 1 {
				return ((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7 - FIX_CONST(tls, 12.0, 7)) >> 1) + (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7 - FIX_CONST(tls, 12.0, 7)) & 1))
			}
			return (((((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7 - FIX_CONST(tls, 12.0, 7)) >> ((4) - 1)) + 1) >> 1)
		}())
		for k = 0; k < 4; k++ {
			*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) >> 16) * (int32(int16(s_Q16)))) + ((((*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(s_Q16)))) >> 16)))
		}
	}

	/* Limit the quantized signal */
	InvMaxSqrVal_Q16 = ((log2lin(tls, ((((FIX_CONST(tls, 70.0, 7) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7) >> 16) * (int32(int16(FIX_CONST(tls, 0.33, 16))))) + ((((FIX_CONST(tls, 70.0, 7) - (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcurrent_SNR_dB_Q7) & 0x0000FFFF) * (int32(int16(FIX_CONST(tls, 0.33, 16))))) >> 16)))) / ((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Fsubfr_length))

	for k = 0; k < 4; k++ {
		/* Soft limit on ratio residual energy and squared gains */
		ResNrg = *(*int32)(unsafe.Pointer((psEncCtrl + 640 /* &.ResNrg */) + uintptr(k)*4))
		ResNrgPart = (((((ResNrg) >> 16) * (int32(int16(InvMaxSqrVal_Q16)))) + ((((ResNrg) & 0x0000FFFF) * (int32(int16(InvMaxSqrVal_Q16)))) >> 16)) + ((ResNrg) * (func() int32 {
			if (16) == 1 {
				return (((InvMaxSqrVal_Q16) >> 1) + ((InvMaxSqrVal_Q16) & 1))
			}
			return ((((InvMaxSqrVal_Q16) >> ((16) - 1)) + 1) >> 1)
		}())))
		if *(*int32)(unsafe.Pointer((psEncCtrl + 656 /* &.ResNrgQ */) + uintptr(k)*4)) > 0 {
			if *(*int32)(unsafe.Pointer((psEncCtrl + 656 /* &.ResNrgQ */) + uintptr(k)*4)) < 32 {
				ResNrgPart = func() int32 {
					if (*(*int32)(unsafe.Pointer((psEncCtrl + 656 /* &.ResNrgQ */) + uintptr(k)*4))) == 1 {
						return (((ResNrgPart) >> 1) + ((ResNrgPart) & 1))
					}
					return ((((ResNrgPart) >> ((*(*int32)(unsafe.Pointer((psEncCtrl + 656 /* &.ResNrgQ */) + uintptr(k)*4))) - 1)) + 1) >> 1)
				}()
			} else {
				ResNrgPart = 0
			}
		} else if *(*int32)(unsafe.Pointer((psEncCtrl + 656 /* &.ResNrgQ */) + uintptr(k)*4)) != 0 {
			if ResNrgPart > (int32((0x7FFFFFFF)) >> (-*(*int32)(unsafe.Pointer((psEncCtrl + 656 /* &.ResNrgQ */) + uintptr(k)*4)))) {
				ResNrgPart = 0x7FFFFFFF
			} else {
				ResNrgPart = ((ResNrgPart) << (-*(*int32)(unsafe.Pointer((psEncCtrl + 656 /* &.ResNrgQ */) + uintptr(k)*4))))
			}
		}
		gain = *(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4))
		gain_squared = func() int32 {
			if ((uint32((ResNrgPart) + (int32(((int64_t(gain)) * (int64_t(gain))) >> (32))))) & 0x80000000) == uint32(0) {
				return func() int32 {
					if ((uint32((ResNrgPart) & (int32(((int64_t(gain)) * (int64_t(gain))) >> (32))))) & 0x80000000) != uint32(0) {
						return libc.Int32FromUint32(0x80000000)
					}
					return ((ResNrgPart) + (int32(((int64_t(gain)) * (int64_t(gain))) >> (32))))
				}()
			}
			return func() int32 {
				if ((uint32((ResNrgPart) | (int32(((int64_t(gain)) * (int64_t(gain))) >> (32))))) & 0x80000000) == uint32(0) {
					return 0x7FFFFFFF
				}
				return ((ResNrgPart) + (int32(((int64_t(gain)) * (int64_t(gain))) >> (32))))
			}()
		}()
		if gain_squared < 0x7FFF {
			/* recalculate with higher precision */
			gain_squared = ((((ResNrgPart) << (16)) + ((((gain) >> 16) * (int32(int16(gain)))) + ((((gain) & 0x0000FFFF) * (int32(int16(gain)))) >> 16))) + ((gain) * (func() int32 {
				if (16) == 1 {
					return (((gain) >> 1) + ((gain) & 1))
				}
				return ((((gain) >> ((16) - 1)) + 1) >> 1)
			}())))

			gain = SQRT_APPROX(tls, gain_squared) /* Q8   */
			*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) = ((func() int32 {
				if (int32((libc.Int32FromUint32(0x80000000))) >> (8)) > (int32((0x7FFFFFFF)) >> (8)) {
					return func() int32 {
						if (gain) > (int32((libc.Int32FromUint32(0x80000000))) >> (8)) {
							return (int32((libc.Int32FromUint32(0x80000000))) >> (8))
						}
						return func() int32 {
							if (gain) < (int32((0x7FFFFFFF)) >> (8)) {
								return (int32((0x7FFFFFFF)) >> (8))
							}
							return gain
						}()
					}()
				}
				return func() int32 {
					if (gain) > (int32((0x7FFFFFFF)) >> (8)) {
						return (int32((0x7FFFFFFF)) >> (8))
					}
					return func() int32 {
						if (gain) < (int32((libc.Int32FromUint32(0x80000000))) >> (8)) {
							return (int32((libc.Int32FromUint32(0x80000000))) >> (8))
						}
						return gain
					}()
				}()
			}()) << (8)) /* Q16  */
		} else {
			gain = SQRT_APPROX(tls, gain_squared) /* Q0   */
			*(*int32)(unsafe.Pointer((psEncCtrl + 128 /* &.Gains_Q16 */) + uintptr(k)*4)) = ((func() int32 {
				if (int32((libc.Int32FromUint32(0x80000000))) >> (16)) > (int32((0x7FFFFFFF)) >> (16)) {
					return func() int32 {
						if (gain) > (int32((libc.Int32FromUint32(0x80000000))) >> (16)) {
							return (int32((libc.Int32FromUint32(0x80000000))) >> (16))
						}
						return func() int32 {
							if (gain) < (int32((0x7FFFFFFF)) >> (16)) {
								return (int32((0x7FFFFFFF)) >> (16))
							}
							return gain
						}()
					}()
				}
				return func() int32 {
					if (gain) > (int32((0x7FFFFFFF)) >> (16)) {
						return (int32((0x7FFFFFFF)) >> (16))
					}
					return func() int32 {
						if (gain) < (int32((libc.Int32FromUint32(0x80000000))) >> (16)) {
							return (int32((libc.Int32FromUint32(0x80000000))) >> (16))
						}
						return gain
					}()
				}()
			}()) << (16)) /* Q16  */
		}
	}

	/* Noise shaping quantization */
	gains_quant(tls, psEncCtrl /* &.sCmn */ +72 /* &.GainsIndices */, psEncCtrl+128, /* &.Gains_Q16 */
		(psShapeSt /* &.LastGainIndex */), (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnFramesInPayloadBuf)
	/* Set quantizer offset for voiced signals. Larger offset when LTP coding gain is low or tilt is high (ie low-pass) */
	if (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 0 {
		if ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLTPredCodGain_Q7 + (((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_tilt_Q15) >> (8))) > FIX_CONST(tls, 1.0, 7) {
			(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FQuantOffsetType = 0
		} else {
			(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FQuantOffsetType = 1
		}
	}

	/* Quantizer boundary adjustment */
	quant_offset_Q10 = int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&Quantization_Offsets_Q10)) + uintptr((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype)*4) + uintptr((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FQuantOffsetType)*2)))
	(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FLambda_Q10 = (((((FIX_CONST(tls, 1.2, 10) +
		((int32(int16(FIX_CONST(tls, float64(-0.05), 10)))) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FnStatesDelayedDecision))))) +
		((((FIX_CONST(tls, float64(-0.3), 18)) >> 16) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) + ((((FIX_CONST(tls, float64(-0.3), 18)) & 0x0000FFFF) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) >> 16))) +
		((((FIX_CONST(tls, float64(-0.2), 12)) >> 16) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14)))) + ((((FIX_CONST(tls, float64(-0.2), 12)) & 0x0000FFFF) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Finput_quality_Q14)))) >> 16))) +
		((((FIX_CONST(tls, float64(-0.1), 12)) >> 16) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14)))) + ((((FIX_CONST(tls, float64(-0.1), 12)) & 0x0000FFFF) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fcoding_quality_Q14)))) >> 16))) +
		((((FIX_CONST(tls, 1.5, 16)) >> 16) * (int32(int16(quant_offset_Q10)))) + ((((FIX_CONST(tls, 1.5, 16)) & 0x0000FFFF) * (int32(int16(quant_offset_Q10)))) >> 16)))

}

/* Limit, stabilize, convert and quantize NLSFs.    */
func process_NLSFs_FIX(tls *libc.TLS, psEnc uintptr, psEncCtrl uintptr, pNLSF_Q15 uintptr) { /* process_NLSFs_FIX.c:31:6: */
	bp := tls.Alloc(192)
	defer tls.Free(192)

	var doInterpolate int32
	// var pNLSFW_Q6 [16]int32 at bp, 64

	var NLSF_mu_Q15 int32
	var NLSF_mu_fluc_red_Q16 int32
	var i_sqr_Q15 int32
	var psNLSF_CB uintptr

	/* Used only for NLSF interpolation */
	// var pNLSF0_temp_Q15 [16]int32 at bp+64, 64

	// var pNLSFW0_temp_Q6 [16]int32 at bp+128, 64

	var i int32

	/***********************/
	/* Calculate mu values */
	/***********************/
	if (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype == 0 {
		/* NLSF_mu           = 0.002f - 0.001f * psEnc->speech_activity; */
		/* NLSF_mu_fluc_red  = 0.1f   - 0.05f  * psEnc->speech_activity; */
		NLSF_mu_Q15 = ((66) + (((int32((-8388)) >> 16) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) + ((((-8388) & 0x0000FFFF) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) >> 16)))
		NLSF_mu_fluc_red_Q16 = ((6554) + (((int32((-838848)) >> 16) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) + ((((-838848) & 0x0000FFFF) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) >> 16)))
	} else {
		/* NLSF_mu           = 0.005f - 0.004f * psEnc->speech_activity; */
		/* NLSF_mu_fluc_red  = 0.2f   - 0.1f   * psEnc->speech_activity - 0.1f * psEncCtrl->sparseness; */
		NLSF_mu_Q15 = ((164) + (((int32((-33554)) >> 16) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) + ((((-33554) & 0x0000FFFF) * (int32(int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8)))) >> 16)))
		NLSF_mu_fluc_red_Q16 = ((13107) + (((int32((-1677696)) >> 16) * (int32((int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8 + (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))) + ((((-1677696) & 0x0000FFFF) * (int32((int16((*encoder_state_FIX)(unsafe.Pointer(psEnc)).Fspeech_activity_Q8 + (*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).Fsparseness_Q8))))) >> 16)))
	}

	NLSF_mu_Q15 = func() int32 {
		if (NLSF_mu_Q15) > (1) {
			return NLSF_mu_Q15
		}
		return 1
	}()

	/* Calculate NLSF weights */

	NLSF_VQ_weights_laroia(tls, bp /* &pNLSFW_Q6[0] */, pNLSF_Q15, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)

	/* Update NLSF weights for interpolated NLSFs */
	doInterpolate = (libc.Bool32(((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FuseInterpolatedNLSFs == 1) && ((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FNLSFInterpCoef_Q2 < (int32(1) << 2))))
	if doInterpolate != 0 {

		/* Calculate the interpolated NLSF vector for the first half */
		interpolate(tls, bp+64 /* &pNLSF0_temp_Q15[0] */, psEnc+20672 /* &.sPred */ +12 /* &.prev_NLSFq_Q15 */, pNLSF_Q15,
			(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FNLSFInterpCoef_Q2, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)

		/* Calculate first half NLSF weights for the interpolated NLSFs */

		NLSF_VQ_weights_laroia(tls, bp+128 /* &pNLSFW0_temp_Q6[0] */, bp+64 /* &pNLSF0_temp_Q15[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)

		/* Update NLSF weights with contribution from first half */
		i_sqr_Q15 = (((int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FNLSFInterpCoef_Q2))) * (int32(int16((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FNLSFInterpCoef_Q2)))) << (11))
		for i = 0; i < (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder; i++ {
			*(*int32)(unsafe.Pointer(bp /* &pNLSFW_Q6[0] */ + uintptr(i)*4)) = (((*(*int32)(unsafe.Pointer(bp /* &pNLSFW_Q6[0] */ + uintptr(i)*4))) >> (1)) + ((((*(*int32)(unsafe.Pointer(bp + 128 /* &pNLSFW0_temp_Q6[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(i_sqr_Q15)))) + ((((*(*int32)(unsafe.Pointer(bp + 128 /* &pNLSFW0_temp_Q6[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(i_sqr_Q15)))) >> 16)))

		}
	}

	/* Set pointer to the NLSF codebook for the current signal type and LPC order */
	psNLSF_CB = *(*uintptr)(unsafe.Pointer((psEnc /* &.sCmn */ + 16248 /* &.psNLSF_CB */) + uintptr((*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.Fsigtype)*4))

	/* Quantize NLSF parameters given the trained NLSF codebooks */

	NLSF_MSVQ_encode_FIX(tls, psEncCtrl /* &.sCmn */ +28 /* &.NLSFIndices */, pNLSF_Q15, psNLSF_CB,
		psEnc+20672 /* &.sPred */ +12 /* &.prev_NLSFq_Q15 */, bp /* &pNLSFW_Q6[0] */, NLSF_mu_Q15, NLSF_mu_fluc_red_Q16,
		(*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FNLSF_MSVQ_Survivors, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.Ffirst_frame_after_reset)

	/* Convert quantized NLSFs back to LPC coefficients */
	NLSF2A_stable(tls, ((psEncCtrl + 144 /* &.PredCoef_Q12 */) + 1*32), pNLSF_Q15, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)

	if doInterpolate != 0 {
		/* Calculate the interpolated, quantized LSF vector for the first half */
		interpolate(tls, bp+64 /* &pNLSF0_temp_Q15[0] */, psEnc+20672 /* &.sPred */ +12 /* &.prev_NLSFq_Q15 */, pNLSF_Q15,
			(*encoder_control_FIX)(unsafe.Pointer(psEncCtrl)).FsCmn.FNLSFInterpCoef_Q2, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)

		/* Convert back to LPC coefficients */
		NLSF2A_stable(tls, (psEncCtrl + 144 /* &.PredCoef_Q12 */), bp+64 /* &pNLSF0_temp_Q15[0] */, (*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder)

	} else {
		/* Copy LPC coefficients for first half from second half */
		libc.Xmemcpy(tls, (psEncCtrl + 144 /* &.PredCoef_Q12 */), ((psEncCtrl + 144 /* &.PredCoef_Q12 */) + 1*32), (uint32((*encoder_state_FIX)(unsafe.Pointer(psEnc)).FsCmn.FpredictLPCOrder) * uint32(unsafe.Sizeof(int16(0)))))
	}
}

func quant_LTP_gains_FIX(tls *libc.TLS, B_Q14 uintptr, cbk_index uintptr, periodicity_index uintptr, W_Q18 uintptr, mu_Q8 int32, lowComplexity int32) { /* quant_LTP_gains_FIX.c:30:6: */
	bp := tls.Alloc(20)
	defer tls.Free(20)

	var j int32
	var k int32
	// var temp_idx [4]int32 at bp, 16

	var cbk_size int32
	var cl_ptr uintptr
	var cbk_ptr_Q14 uintptr
	var b_Q14_ptr uintptr
	var W_Q18_ptr uintptr
	// var rate_dist_subfr int32 at bp+16, 4

	var rate_dist int32
	var min_rate_dist int32

	/***************************************************/
	/* iterate over different codebooks with different */
	/* rates/distortions, and choose best */
	/***************************************************/
	min_rate_dist = 0x7FFFFFFF
	for k = 0; k < 3; k++ {
		cl_ptr = LTP_gain_BITS_Q6_ptrs[k]
		cbk_ptr_Q14 = LTP_vq_ptrs_Q14[k]
		cbk_size = LTP_vq_sizes[k]

		/* Setup pointer to first subframe */
		W_Q18_ptr = W_Q18
		b_Q14_ptr = B_Q14

		rate_dist = 0
		for j = 0; j < 4; j++ {

			VQ_WMat_EC_FIX(tls,
				(bp /* &temp_idx */ + uintptr(j)*4), /* O    index of best codebook vector                           */
				bp+16,                               /* &rate_dist_subfr */ /* O    best weighted quantization error + mu * rate            */
				b_Q14_ptr,                           /* I    input vector to be quantized                            */
				W_Q18_ptr,                           /* I    weighting matrix                                        */
				cbk_ptr_Q14,                         /* I    codebook                                                */
				cl_ptr,                              /* I    code length for each codebook vector                    */
				mu_Q8,                               /* I    tradeoff between weighted error and rate                */
				cbk_size)

			rate_dist = func() int32 {
				if ((uint32((rate_dist) + (*(*int32)(unsafe.Pointer(bp + 16 /* rate_dist_subfr */))))) & 0x80000000) != 0 {
					return 0x7FFFFFFF
				}
				return ((rate_dist) + (*(*int32)(unsafe.Pointer(bp + 16 /* rate_dist_subfr */))))
			}()

			b_Q14_ptr += 2 * (uintptr(5))
			W_Q18_ptr += 4 * (uintptr(5 * 5))
		}

		/* Avoid never finding a codebook */
		rate_dist = func() int32 {
			if (0x7FFFFFFF - 1) < (rate_dist) {
				return (0x7FFFFFFF - 1)
			}
			return rate_dist
		}()

		if rate_dist < min_rate_dist {
			min_rate_dist = rate_dist
			libc.Xmemcpy(tls, cbk_index, bp /* &temp_idx[0] */, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))
			*(*int32)(unsafe.Pointer(periodicity_index)) = k
		}

		/* Break early in low-complexity mode if rate distortion is below threshold */
		if (lowComplexity != 0) && (rate_dist < LTP_gain_middle_avg_RD_Q14) {
			break
		}
	}

	cbk_ptr_Q14 = LTP_vq_ptrs_Q14[*(*int32)(unsafe.Pointer(periodicity_index))]
	for j = 0; j < 4; j++ {
		for k = 0; k < 5; k++ {
			*(*int16)(unsafe.Pointer(B_Q14 + uintptr(((j*5)+k))*2)) = *(*int16)(unsafe.Pointer(cbk_ptr_Q14 + uintptr(((k)+((*(*int32)(unsafe.Pointer(cbk_index + uintptr(j)*4)))*(5))))*2))
		}
	}
}

/* Range encoder for one symbol */
func range_encoder(tls *libc.TLS, psRC uintptr, data int32, prob uintptr) { /* range_coder.c:31:6: */
	var low_Q16 uint32
	var high_Q16 uint32
	var base_tmp uint32
	var range_Q32 uint32

	/* Copy structure data */
	var base_Q32 uint32 = (*range_coder_state)(unsafe.Pointer(psRC)).Fbase_Q32
	var range_Q16 uint32 = (*range_coder_state)(unsafe.Pointer(psRC)).Frange_Q16
	var bufferIx int32 = (*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx
	var buffer uintptr = psRC + 20 /* &.buffer */

	if (*range_coder_state)(unsafe.Pointer(psRC)).Ferror != 0 {
		return
	}

	/* Update interval */
	low_Q16 = uint32(*(*uint16)(unsafe.Pointer(prob + uintptr(data)*2)))
	high_Q16 = uint32(*(*uint16)(unsafe.Pointer(prob + uintptr((data+1))*2)))
	base_tmp = base_Q32 /* save current base, to test for carry */
	base_Q32 = base_Q32 + ((range_Q16) * (low_Q16))
	range_Q32 = ((range_Q16) * (high_Q16 - low_Q16))

	/* Check for carry */
	if base_Q32 < base_tmp {
		/* Propagate carry in buffer */
		var bufferIx_tmp int32 = bufferIx
		for (int32(libc.PreIncUint8(&*(*uint8)(unsafe.Pointer(buffer + uintptr(libc.PreDecInt32(&bufferIx_tmp, 1)))), 1))) == 0 {
		}
	}

	/* Check normalization */
	if (range_Q32 & 0xFF000000) != 0 {
		/* No normalization */
		range_Q16 = ((range_Q32) >> (16))
	} else {
		if (range_Q32 & 0xFFFF0000) != 0 {
			/* Normalization of 8 bits shift */
			range_Q16 = ((range_Q32) >> (8))
		} else {
			/* Normalization of 16 bits shift */
			range_Q16 = range_Q32
			/* Make sure not to write beyond buffer */
			if bufferIx >= (*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength {
				(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -1
				return
			}
			/* Write one byte to buffer */
			*(*uint8)(unsafe.Pointer(buffer + uintptr(libc.PostIncInt32(&bufferIx, 1)))) = (uint8((base_Q32) >> (24)))
			base_Q32 = ((base_Q32) << (8))
		}
		/* Make sure not to write beyond buffer */
		if bufferIx >= (*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength {
			(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -1
			return
		}
		/* Write one byte to buffer */
		*(*uint8)(unsafe.Pointer(buffer + uintptr(libc.PostIncInt32(&bufferIx, 1)))) = (uint8((base_Q32) >> (24)))
		base_Q32 = ((base_Q32) << (8))
	}

	/* Copy structure data back */
	(*range_coder_state)(unsafe.Pointer(psRC)).Fbase_Q32 = base_Q32
	(*range_coder_state)(unsafe.Pointer(psRC)).Frange_Q16 = range_Q16
	(*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx = bufferIx
}

/* Range encoder for multiple symbols */
func range_encoder_multi(tls *libc.TLS, psRC uintptr, data uintptr, prob uintptr, nSymbols int32) { /* range_coder.c:101:6: */
	var k int32
	for k = 0; k < nSymbols; k++ {
		range_encoder(tls, psRC, *(*int32)(unsafe.Pointer(data + uintptr(k)*4)), *(*uintptr)(unsafe.Pointer(prob + uintptr(k)*4)))
	}
}

/* Range decoder for one symbol */
func range_decoder(tls *libc.TLS, data uintptr, psRC uintptr, prob uintptr, probIx int32) { /* range_coder.c:115:6: */
	var low_Q16 uint32
	var high_Q16 uint32
	var base_tmp uint32
	var range_Q32 uint32

	/* Copy structure data */
	var base_Q32 uint32 = (*range_coder_state)(unsafe.Pointer(psRC)).Fbase_Q32
	var range_Q16 uint32 = (*range_coder_state)(unsafe.Pointer(psRC)).Frange_Q16
	var bufferIx int32 = (*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx
	var buffer uintptr = ((psRC + 20 /* &.buffer */) + 4)

	if (*range_coder_state)(unsafe.Pointer(psRC)).Ferror != 0 {
		/* Set output to zero */
		*(*int32)(unsafe.Pointer(data)) = 0
		return
	}

	high_Q16 = uint32(*(*uint16)(unsafe.Pointer(prob + uintptr(probIx)*2)))
	base_tmp = ((range_Q16) * (high_Q16))
	if base_tmp > base_Q32 {
		for 1 != 0 {
			low_Q16 = uint32(*(*uint16)(unsafe.Pointer(prob + uintptr(libc.PreDecInt32(&probIx, 1))*2)))
			base_tmp = ((range_Q16) * (low_Q16))
			if base_tmp <= base_Q32 {
				break
			}
			high_Q16 = low_Q16
			/* Test for out of range */
			if high_Q16 == uint32(0) {
				(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -2
				/* Set output to zero */
				*(*int32)(unsafe.Pointer(data)) = 0
				return
			}
		}
	} else {
		for 1 != 0 {
			low_Q16 = high_Q16
			high_Q16 = uint32(*(*uint16)(unsafe.Pointer(prob + uintptr(libc.PreIncInt32(&probIx, 1))*2)))
			base_tmp = ((range_Q16) * (high_Q16))
			if base_tmp > base_Q32 {
				probIx--
				break
			}
			/* Test for out of range */
			if high_Q16 == uint32(0xFFFF) {
				(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -2
				/* Set output to zero */
				*(*int32)(unsafe.Pointer(data)) = 0
				return
			}
		}
	}
	*(*int32)(unsafe.Pointer(data)) = probIx
	base_Q32 = base_Q32 - ((range_Q16) * (low_Q16))
	range_Q32 = ((range_Q16) * (high_Q16 - low_Q16))

	/* Check normalization */
	if (range_Q32 & 0xFF000000) != 0 {
		/* No normalization */
		range_Q16 = ((range_Q32) >> (16))
	} else {
		if (range_Q32 & 0xFFFF0000) != 0 {
			/* Normalization of 8 bits shift */
			range_Q16 = ((range_Q32) >> (8))
			/* Check for errors */
			if ((base_Q32) >> (24)) != 0 {
				(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -3
				/* Set output to zero */
				*(*int32)(unsafe.Pointer(data)) = 0
				return
			}
		} else {
			/* Normalization of 16 bits shift */
			range_Q16 = range_Q32
			/* Check for errors */
			if ((base_Q32) >> (16)) != 0 {
				(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -3
				/* Set output to zero */
				*(*int32)(unsafe.Pointer(data)) = 0
				return
			}
			/* Update base */
			base_Q32 = ((base_Q32) << (8))
			/* Make sure not to read beyond buffer */
			if bufferIx < (*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength {
				/* Read one byte from buffer */
				base_Q32 = base_Q32 | (uint32(*(*uint8)(unsafe.Pointer(buffer + uintptr(libc.PostIncInt32(&bufferIx, 1))))))
			}
		}
		/* Update base */
		base_Q32 = ((base_Q32) << (8))
		/* Make sure not to read beyond buffer */
		if bufferIx < (*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength {
			/* Read one byte from buffer */
			base_Q32 = base_Q32 | (uint32(*(*uint8)(unsafe.Pointer(buffer + uintptr(libc.PostIncInt32(&bufferIx, 1))))))
		}
	}

	/* Check for zero interval length */
	if range_Q16 == uint32(0) {
		(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -4
		/* Set output to zero */
		*(*int32)(unsafe.Pointer(data)) = 0
		return
	}

	/* Copy structure data back */
	(*range_coder_state)(unsafe.Pointer(psRC)).Fbase_Q32 = base_Q32
	(*range_coder_state)(unsafe.Pointer(psRC)).Frange_Q16 = range_Q16
	(*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx = bufferIx
}

/* Range decoder for multiple symbols */
func range_decoder_multi(tls *libc.TLS, data uintptr, psRC uintptr, prob uintptr, probStartIx uintptr, nSymbols int32) { /* range_coder.c:234:6: */
	var k int32
	for k = 0; k < nSymbols; k++ {
		range_decoder(tls, (data + uintptr(k)*4), psRC, *(*uintptr)(unsafe.Pointer(prob + uintptr(k)*4)), *(*int32)(unsafe.Pointer(probStartIx + uintptr(k)*4)))
	}
}

/* Initialize range encoder */
func range_enc_init(tls *libc.TLS, psRC uintptr) { /* range_coder.c:249:6: */
	/* Initialize structure */
	(*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength = 1024
	(*range_coder_state)(unsafe.Pointer(psRC)).Frange_Q16 = uint32(0x0000FFFF)
	(*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx = 0
	(*range_coder_state)(unsafe.Pointer(psRC)).Fbase_Q32 = uint32(0)
	(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = 0
}

/* Initialize range decoder */
func range_dec_init(tls *libc.TLS, psRC uintptr, buffer uintptr, bufferLength int32) { /* range_coder.c:262:6: */
	/* check input */
	if (bufferLength > 1024) || (bufferLength < 0) {
		(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -8
		return
	}
	/* Initialize structure */
	/* Copy to internal buffer */
	libc.Xmemcpy(tls, psRC+20 /* &.buffer */, buffer, (uint32(bufferLength) * uint32(unsafe.Sizeof(uint8(0)))))
	(*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength = bufferLength
	(*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx = 0
	(*range_coder_state)(unsafe.Pointer(psRC)).Fbase_Q32 = (((((uint32(*(*uint8)(unsafe.Pointer(buffer)))) << (24)) | ((uint32(*(*uint8)(unsafe.Pointer(buffer + 1)))) << (16))) | ((uint32(*(*uint8)(unsafe.Pointer(buffer + 2)))) << (8))) | uint32(*(*uint8)(unsafe.Pointer(buffer + 3))))
	(*range_coder_state)(unsafe.Pointer(psRC)).Frange_Q16 = uint32(0x0000FFFF)
	(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = 0
}

/* Determine length of bitstream */
func range_coder_get_length(tls *libc.TLS, psRC uintptr, nBytes uintptr) int32 { /* range_coder.c:288:9: */
	var nBits int32

	/* Number of bits in stream */
	nBits = (((((*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx) << (3)) + CLZ32(tls, (int32((*range_coder_state)(unsafe.Pointer(psRC)).Frange_Q16-uint32(1))))) - 14)

	*(*int32)(unsafe.Pointer(nBytes)) = ((nBits + 7) >> (3))

	/* Return number of bits in bitstream */
	return nBits
}

/* Write shortest uniquely decodable stream to buffer, and determine its length */
func range_enc_wrap_up(tls *libc.TLS, psRC uintptr) { /* range_coder.c:305:6: */
	bp := tls.Alloc(4)
	defer tls.Free(4)

	var bufferIx_tmp int32
	var bits_to_store int32
	var bits_in_stream int32
	// var nBytes int32 at bp, 4

	var mask int32
	var base_Q24 uint32

	/* Lower limit of interval, shifted 8 bits to the right */
	base_Q24 = (((*range_coder_state)(unsafe.Pointer(psRC)).Fbase_Q32) >> (8))

	bits_in_stream = range_coder_get_length(tls, psRC, bp /* &nBytes */)

	/* Number of additional bits (1..9) required to be stored to stream */
	bits_to_store = (bits_in_stream - (((*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx) << (3)))
	/* Round up to required resolution */
	base_Q24 = base_Q24 + (uint32(int32((0x00800000)) >> (bits_to_store - 1)))
	base_Q24 = base_Q24 & (uint32((0xFFFFFFFF)) << (24 - bits_to_store))

	/* Check for carry */
	if (base_Q24 & uint32(0x01000000)) != 0 {
		/* Propagate carry in buffer */
		bufferIx_tmp = (*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx
		for (int32(libc.PreIncUint8(&(*(*uint8)(unsafe.Pointer((psRC + 20 /* &.buffer */) + uintptr(libc.PreDecInt32(&bufferIx_tmp, 1))))), 1))) == 0 {
		}
	}

	/* Store to stream, making sure not to write beyond buffer */
	if (*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx < (*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength {
		*(*uint8)(unsafe.Pointer((psRC + 20 /* &.buffer */) + uintptr(libc.PostIncInt32(&(*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx, 1)))) = (uint8((base_Q24) >> (16)))
		if bits_to_store > 8 {
			if (*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx < (*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength {
				*(*uint8)(unsafe.Pointer((psRC + 20 /* &.buffer */) + uintptr(libc.PostIncInt32(&(*range_coder_state)(unsafe.Pointer(psRC)).FbufferIx, 1)))) = (uint8((base_Q24) >> (8)))
			}
		}
	}

	/* Fill up any remaining bits in the last byte with 1s */
	if (bits_in_stream & 7) != 0 {
		mask = (int32((0xFF)) >> (bits_in_stream & 7))
		if (*(*int32)(unsafe.Pointer(bp /* nBytes */)) - 1) < (*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength {
			*(*uint8)(unsafe.Pointer((psRC + 20 /* &.buffer */) + uintptr((*(*int32)(unsafe.Pointer(bp /* nBytes */)) - 1)))) |= uint8((mask))
		}
	}
}

/* Check that any remaining bits in the last byte are set to 1 */
func range_coder_check_after_decoding(tls *libc.TLS, psRC uintptr) { /* range_coder.c:350:6: */
	bp := tls.Alloc(4)
	defer tls.Free(4)

	var bits_in_stream int32
	// var nBytes int32 at bp, 4

	var mask int32

	bits_in_stream = range_coder_get_length(tls, psRC, bp /* &nBytes */)

	/* Make sure not to read beyond buffer */
	if (*(*int32)(unsafe.Pointer(bp /* nBytes */)) - 1) >= (*range_coder_state)(unsafe.Pointer(psRC)).FbufferLength {
		(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -5
		return
	}

	/* Test any remaining bits in last byte */
	if (bits_in_stream & 7) != 0 {
		mask = (int32((0xFF)) >> (bits_in_stream & 7))
		if (int32(*(*uint8)(unsafe.Pointer((psRC + 20 /* &.buffer */) + uintptr((*(*int32)(unsafe.Pointer(bp /* nBytes */)) - 1))))) & mask) != mask {
			(*range_coder_state)(unsafe.Pointer(psRC)).Ferror = -5
			return
		}
	}
}

/* Add noise to matrix diagonal */
func regularize_correlations_FIX(tls *libc.TLS, XX uintptr, xx uintptr, noise int32, D int32) { /* regularize_correlations_FIX.c:31:6: */
	var i int32
	for i = 0; i < D; i++ {
		*(*int32)(unsafe.Pointer(((XX) + uintptr((((i)*(D))+(i)))*4))) = ((*(*int32)(unsafe.Pointer(((XX) + uintptr((((i)*(D))+(i)))*4)))) + (noise))
	}
	*(*int32)(unsafe.Pointer(xx)) += (noise)
}

/* Greatest common divisor */
func gcd(tls *libc.TLS, a int32, b int32) int32 { /* resampler.c:66:18: */
	var tmp int32
	for b > 0 {
		tmp = (a - (b * ((a) / (b))))
		a = b
		b = tmp
	}
	return a
}

/* Initialize/reset the resampler state for a given pair of input/output sampling rates */
func resampler_init(tls *libc.TLS, S uintptr, Fs_Hz_in int32, Fs_Hz_out int32) int32 { /* resampler.c:81:9: */
	var cycleLen int32
	var cyclesPerBatch int32
	var up2 int32 = 0
	var down2 int32 = 0

	/* Clear state */
	libc.Xmemset(tls, S, 0, uint32(unsafe.Sizeof(resampler_state_struct{})))

	/* Input checking */
	if (((Fs_Hz_in < 8000) || (Fs_Hz_in > 192000)) || (Fs_Hz_out < 8000)) || (Fs_Hz_out > 192000) {

		return -1
	}

	/* Determine pre downsampling and post upsampling */
	if Fs_Hz_in > 96000 {
		(*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers = 2
		(*resampler_state_struct)(unsafe.Pointer(S)).Fdown_pre_function = *(*uintptr)(unsafe.Pointer(&struct {
			f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
		}{resampler_private_down4}))
	} else if Fs_Hz_in > 48000 {
		(*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers = 1
		(*resampler_state_struct)(unsafe.Pointer(S)).Fdown_pre_function = *(*uintptr)(unsafe.Pointer(&struct {
			f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
		}{resampler_down2}))
	} else {
		(*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers = 0
		(*resampler_state_struct)(unsafe.Pointer(S)).Fdown_pre_function = uintptr(0)
	}

	if Fs_Hz_out > 96000 {
		(*resampler_state_struct)(unsafe.Pointer(S)).FnPostUpsamplers = 2
		(*resampler_state_struct)(unsafe.Pointer(S)).Fup_post_function = *(*uintptr)(unsafe.Pointer(&struct {
			f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
		}{resampler_private_up4}))
	} else if Fs_Hz_out > 48000 {
		(*resampler_state_struct)(unsafe.Pointer(S)).FnPostUpsamplers = 1
		(*resampler_state_struct)(unsafe.Pointer(S)).Fup_post_function = *(*uintptr)(unsafe.Pointer(&struct {
			f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
		}{resampler_up2}))
	} else {
		(*resampler_state_struct)(unsafe.Pointer(S)).FnPostUpsamplers = 0
		(*resampler_state_struct)(unsafe.Pointer(S)).Fup_post_function = uintptr(0)
	}

	if ((*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers + (*resampler_state_struct)(unsafe.Pointer(S)).FnPostUpsamplers) > 0 {
		/* Ratio of output/input samples */
		(*resampler_state_struct)(unsafe.Pointer(S)).Fratio_Q16 = ((((Fs_Hz_out) << (13)) / (Fs_Hz_in)) << (3))
		/* Make sure the ratio is rounded up */
		for ((((((*resampler_state_struct)(unsafe.Pointer(S)).Fratio_Q16) >> 16) * (int32(int16(Fs_Hz_in)))) + (((((*resampler_state_struct)(unsafe.Pointer(S)).Fratio_Q16) & 0x0000FFFF) * (int32(int16(Fs_Hz_in)))) >> 16)) + (((*resampler_state_struct)(unsafe.Pointer(S)).Fratio_Q16) * (func() int32 {
			if (16) == 1 {
				return (((Fs_Hz_in) >> 1) + ((Fs_Hz_in) & 1))
			}
			return ((((Fs_Hz_in) >> ((16) - 1)) + 1) >> 1)
		}()))) < Fs_Hz_out {
			(*resampler_state_struct)(unsafe.Pointer(S)).Fratio_Q16++
		}

		/* Batch size is 10 ms */
		(*resampler_state_struct)(unsafe.Pointer(S)).FbatchSizePrePost = ((Fs_Hz_in) / (100))

		/* Convert sampling rate to those after pre-downsampling and before post-upsampling */
		Fs_Hz_in = ((Fs_Hz_in) >> ((*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers))
		Fs_Hz_out = ((Fs_Hz_out) >> ((*resampler_state_struct)(unsafe.Pointer(S)).FnPostUpsamplers))
	}

	/* Number of samples processed per batch */
	/* First, try 10 ms frames */
	(*resampler_state_struct)(unsafe.Pointer(S)).FbatchSize = ((Fs_Hz_in) / (100))
	if ((((*resampler_state_struct)(unsafe.Pointer(S)).FbatchSize) * (100)) != Fs_Hz_in) || ((Fs_Hz_in % 100) != 0) {
		/* No integer number of input or output samples with 10 ms frames, use greatest common divisor */
		cycleLen = ((Fs_Hz_in) / (gcd(tls, Fs_Hz_in, Fs_Hz_out)))
		cyclesPerBatch = ((480) / (cycleLen))
		if cyclesPerBatch == 0 {
			/* cycleLen too big, let's just use the maximum batch size. Some distortion will result. */
			(*resampler_state_struct)(unsafe.Pointer(S)).FbatchSize = 480

		} else {
			(*resampler_state_struct)(unsafe.Pointer(S)).FbatchSize = ((cyclesPerBatch) * (cycleLen))
		}
	}

	/* Find resampler with the right sampling ratio */
	if Fs_Hz_out > Fs_Hz_in {
		/* Upsample */
		if Fs_Hz_out == ((Fs_Hz_in) * (2)) { /* Fs_out : Fs_in = 2 : 1 */
			/* Special case: directly use 2x upsampler */
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_up2_HQ_wrapper}))
		} else {
			/* Default resampler */
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_IIR_FIR}))
			up2 = 1
			if Fs_Hz_in > 24000 {
				/* Low-quality all-pass upsampler */
				(*resampler_state_struct)(unsafe.Pointer(S)).Fup2_function = *(*uintptr)(unsafe.Pointer(&struct {
					f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
				}{resampler_up2}))
			} else {
				/* High-quality all-pass upsampler */
				(*resampler_state_struct)(unsafe.Pointer(S)).Fup2_function = *(*uintptr)(unsafe.Pointer(&struct {
					f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
				}{resampler_private_up2_HQ}))
			}
		}
	} else if Fs_Hz_out < Fs_Hz_in {
		/* Downsample */
		if ((Fs_Hz_out) * (4)) == ((Fs_Hz_in) * (3)) { /* Fs_out : Fs_in = 3 : 4 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FFIR_Fracs = 3
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_3_4_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_down_FIR}))
		} else if ((Fs_Hz_out) * (3)) == ((Fs_Hz_in) * (2)) { /* Fs_out : Fs_in = 2 : 3 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FFIR_Fracs = 2
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_2_3_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_down_FIR}))
		} else if ((Fs_Hz_out) * (2)) == Fs_Hz_in { /* Fs_out : Fs_in = 1 : 2 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FFIR_Fracs = 1
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_1_2_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_down_FIR}))
		} else if ((Fs_Hz_out) * (8)) == ((Fs_Hz_in) * (3)) { /* Fs_out : Fs_in = 3 : 8 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FFIR_Fracs = 3
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_3_8_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_down_FIR}))
		} else if ((Fs_Hz_out) * (3)) == Fs_Hz_in { /* Fs_out : Fs_in = 1 : 3 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FFIR_Fracs = 1
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_1_3_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_down_FIR}))
		} else if ((Fs_Hz_out) * (4)) == Fs_Hz_in { /* Fs_out : Fs_in = 1 : 4 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FFIR_Fracs = 1
			down2 = 1
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_1_2_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_down_FIR}))
		} else if ((Fs_Hz_out) * (6)) == Fs_Hz_in { /* Fs_out : Fs_in = 1 : 6 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FFIR_Fracs = 1
			down2 = 1
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_1_3_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_down_FIR}))
		} else if ((Fs_Hz_out) * (441)) == ((Fs_Hz_in) * (80)) { /* Fs_out : Fs_in = 80 : 441 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_80_441_ARMA4_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_IIR_FIR}))
		} else if ((Fs_Hz_out) * (441)) == ((Fs_Hz_in) * (120)) { /* Fs_out : Fs_in = 120 : 441 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_120_441_ARMA4_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_IIR_FIR}))
		} else if ((Fs_Hz_out) * (441)) == ((Fs_Hz_in) * (160)) { /* Fs_out : Fs_in = 160 : 441 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_160_441_ARMA4_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_IIR_FIR}))
		} else if ((Fs_Hz_out) * (441)) == ((Fs_Hz_in) * (240)) { /* Fs_out : Fs_in = 240 : 441 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_240_441_ARMA4_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_IIR_FIR}))
		} else if ((Fs_Hz_out) * (441)) == ((Fs_Hz_in) * (320)) { /* Fs_out : Fs_in = 320 : 441 */
			(*resampler_state_struct)(unsafe.Pointer(S)).FCoefs = uintptr(unsafe.Pointer(&Resampler_320_441_ARMA4_COEFS))
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_IIR_FIR}))
		} else {
			/* Default resampler */
			(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
				f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
			}{resampler_private_IIR_FIR}))
			up2 = 1
			if Fs_Hz_in > 24000 {
				/* Low-quality all-pass upsampler */
				(*resampler_state_struct)(unsafe.Pointer(S)).Fup2_function = *(*uintptr)(unsafe.Pointer(&struct {
					f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
				}{resampler_up2}))
			} else {
				/* High-quality all-pass upsampler */
				(*resampler_state_struct)(unsafe.Pointer(S)).Fup2_function = *(*uintptr)(unsafe.Pointer(&struct {
					f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
				}{resampler_private_up2_HQ}))
			}
		}
	} else {
		/* Input and output sampling rates are equal: copy */
		(*resampler_state_struct)(unsafe.Pointer(S)).Fresampler_function = *(*uintptr)(unsafe.Pointer(&struct {
			f func(*libc.TLS, uintptr, uintptr, uintptr, int32)
		}{resampler_private_copy}))
	}

	(*resampler_state_struct)(unsafe.Pointer(S)).Finput2x = (up2 | down2)

	/* Ratio of input/output samples */
	(*resampler_state_struct)(unsafe.Pointer(S)).FinvRatio_Q16 = ((((Fs_Hz_in) << ((14 + up2) - down2)) / (Fs_Hz_out)) << (2))
	/* Make sure the ratio is rounded up */
	for ((((((*resampler_state_struct)(unsafe.Pointer(S)).FinvRatio_Q16) >> 16) * (int32((int16((Fs_Hz_out) << (down2)))))) + (((((*resampler_state_struct)(unsafe.Pointer(S)).FinvRatio_Q16) & 0x0000FFFF) * (int32((int16((Fs_Hz_out) << (down2)))))) >> 16)) + (((*resampler_state_struct)(unsafe.Pointer(S)).FinvRatio_Q16) * (func() int32 {
		if (16) == 1 {
			return ((((Fs_Hz_out) << (down2)) >> 1) + (((Fs_Hz_out) << (down2)) & 1))
		}
		return (((((Fs_Hz_out) << (down2)) >> ((16) - 1)) + 1) >> 1)
	}()))) < ((Fs_Hz_in) << (up2)) {
		(*resampler_state_struct)(unsafe.Pointer(S)).FinvRatio_Q16++
	}

	(*resampler_state_struct)(unsafe.Pointer(S)).Fmagic_number = 123456789

	return 0
}

/* Clear the states of all resampling filters, without resetting sampling rate ratio */
func resampler_clear(tls *libc.TLS, S uintptr) int32 { /* resampler.c:255:9: */
	/* Clear state */
	libc.Xmemset(tls, S+88 /* &.sDown2 */, 0, uint32(unsafe.Sizeof([2]int32{})))
	libc.Xmemset(tls, S /* &.sIIR */, 0, uint32(unsafe.Sizeof([6]int32{})))
	libc.Xmemset(tls, S+24 /* &.sFIR */, 0, uint32(unsafe.Sizeof([16]int32{})))
	libc.Xmemset(tls, S+124 /* &.sDownPre */, 0, uint32(unsafe.Sizeof([2]int32{})))
	libc.Xmemset(tls, S+132 /* &.sUpPost */, 0, uint32(unsafe.Sizeof([2]int32{})))
	return 0
}

/* Resampler: convert from one sampling rate to another                                 */
func resampler(tls *libc.TLS, S uintptr, out uintptr, in uintptr, inLen int32) int32 { /* resampler.c:271:9: */
	bp := tls.Alloc(1920)
	defer tls.Free(1920)

	/* Verify that state was initialized and has not been corrupted */
	if (*resampler_state_struct)(unsafe.Pointer(S)).Fmagic_number != 123456789 {

		return -1
	}

	if ((*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers + (*resampler_state_struct)(unsafe.Pointer(S)).FnPostUpsamplers) > 0 {
		/* The input and/or output sampling rate is above 48000 Hz */
		var nSamplesIn int32
		var nSamplesOut int32
		// var in_buf [480]int16 at bp, 960

		// var out_buf [480]int16 at bp+960, 960

		for inLen > 0 {
			/* Number of input and output samples to process */
			nSamplesIn = func() int32 {
				if (inLen) < ((*resampler_state_struct)(unsafe.Pointer(S)).FbatchSizePrePost) {
					return inLen
				}
				return (*resampler_state_struct)(unsafe.Pointer(S)).FbatchSizePrePost
			}()
			nSamplesOut = (((((*resampler_state_struct)(unsafe.Pointer(S)).Fratio_Q16) >> 16) * (int32(int16(nSamplesIn)))) + (((((*resampler_state_struct)(unsafe.Pointer(S)).Fratio_Q16) & 0x0000FFFF) * (int32(int16(nSamplesIn)))) >> 16))

			if (*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers > 0 {
				(*(*func(*libc.TLS, uintptr, uintptr, uintptr, int32))(unsafe.Pointer((S + 140 /* &.down_pre_function */))))(tls, S+124 /* &.sDownPre */, bp /* &in_buf[0] */, in, nSamplesIn)
				if (*resampler_state_struct)(unsafe.Pointer(S)).FnPostUpsamplers > 0 {
					(*(*func(*libc.TLS, uintptr, uintptr, uintptr, int32))(unsafe.Pointer((S + 96 /* &.resampler_function */))))(tls, S, bp+960 /* &out_buf[0] */, bp /* &in_buf[0] */, ((nSamplesIn) >> ((*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers)))
					(*(*func(*libc.TLS, uintptr, uintptr, uintptr, int32))(unsafe.Pointer((S + 144 /* &.up_post_function */))))(tls, S+132 /* &.sUpPost */, out, bp+960 /* &out_buf[0] */, ((nSamplesOut) >> ((*resampler_state_struct)(unsafe.Pointer(S)).FnPostUpsamplers)))
				} else {
					(*(*func(*libc.TLS, uintptr, uintptr, uintptr, int32))(unsafe.Pointer((S + 96 /* &.resampler_function */))))(tls, S, out, bp /* &in_buf[0] */, ((nSamplesIn) >> ((*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers)))
				}
			} else {
				(*(*func(*libc.TLS, uintptr, uintptr, uintptr, int32))(unsafe.Pointer((S + 96 /* &.resampler_function */))))(tls, S, bp+960 /* &out_buf[0] */, in, ((nSamplesIn) >> ((*resampler_state_struct)(unsafe.Pointer(S)).FnPreDownsamplers)))
				(*(*func(*libc.TLS, uintptr, uintptr, uintptr, int32))(unsafe.Pointer((S + 144 /* &.up_post_function */))))(tls, S+132 /* &.sUpPost */, out, bp+960 /* &out_buf[0] */, ((nSamplesOut) >> ((*resampler_state_struct)(unsafe.Pointer(S)).FnPostUpsamplers)))
			}

			in += 2 * uintptr(nSamplesIn)
			out += 2 * uintptr(nSamplesOut)
			inLen = inLen - (nSamplesIn)
		}
	} else {
		/* Input and output sampling rate are at most 48000 Hz */
		(*(*func(*libc.TLS, uintptr, uintptr, uintptr, int32))(unsafe.Pointer((S + 96 /* &.resampler_function */))))(tls, S, out, in, inLen)
	}

	return 0
}

/* Downsample by a factor 2, mediocre quality */
func resampler_down2(tls *libc.TLS, S uintptr, out uintptr, in uintptr, inLen int32) { /* resampler_down2.c:40:6: */
	var k int32
	var len2 int32 = ((inLen) >> (1))
	var in32 int32
	var out32 int32
	var Y int32
	var X int32

	/* Internal variables and state are in Q10 format */
	for k = 0; k < len2; k++ {
		/* Convert to Q10 */
		in32 = ((int32(*(*int16)(unsafe.Pointer(in + uintptr((2*k))*2)))) << (10))

		/* All-pass section for even input sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S))))
		X = ((Y) + ((((Y) >> 16) * (int32(resampler_down2_1))) + ((((Y) & 0x0000FFFF) * (int32(resampler_down2_1))) >> 16)))
		out32 = ((*(*int32)(unsafe.Pointer(S))) + (X))
		*(*int32)(unsafe.Pointer(S)) = ((in32) + (X))

		/* Convert to Q10 */
		in32 = ((int32(*(*int16)(unsafe.Pointer(in + uintptr(((2*k)+1))*2)))) << (10))

		/* All-pass section for odd input sample, and add to output of previous section */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S + 1*4))))
		X = ((((Y) >> 16) * (int32(resampler_down2_0))) + ((((Y) & 0x0000FFFF) * (int32(resampler_down2_0))) >> 16))
		out32 = ((out32) + (*(*int32)(unsafe.Pointer(S + 1*4))))
		out32 = ((out32) + (X))
		*(*int32)(unsafe.Pointer(S + 1*4)) = ((in32) + (X))

		/* Add, convert back to int16 and store to output */
		*(*int16)(unsafe.Pointer(out + uintptr(k)*2)) = func() int16 {
			if (func() int32 {
				if (11) == 1 {
					return (((out32) >> 1) + ((out32) & 1))
				}
				return ((((out32) >> ((11) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (11) == 1 {
						return (((out32) >> 1) + ((out32) & 1))
					}
					return ((((out32) >> ((11) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (11) == 1 {
						return (int16(((out32) >> 1) + ((out32) & 1)))
					}
					return (int16((((out32) >> ((11) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}
}

/* Downsample by a factor 2/3, low quality */
func resampler_down2_3(tls *libc.TLS, S uintptr, out uintptr, in uintptr, inLen int32) { /* resampler_down2_3.c:42:6: */
	bp := tls.Alloc(1936)
	defer tls.Free(1936)

	var nSamplesIn int32
	var counter int32
	var res_Q6 int32
	// var buf [484]int32 at bp, 1936

	var buf_ptr uintptr

	/* Copy buffered samples to start of buffer */
	libc.Xmemcpy(tls, bp /* &buf[0] */, S, (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))

	/* Iterate over blocks of frameSizeIn input samples */
	for 1 != 0 {
		nSamplesIn = func() int32 {
			if (inLen) < (480) {
				return inLen
			}
			return 480
		}()

		/* Second-order AR filter (output in Q8) */
		resampler_private_AR2(tls, (S + 4*4), (bp /* &buf */ + 4*4), in,
			uintptr(unsafe.Pointer(&Resampler_2_3_COEFS_LQ)), nSamplesIn)

		/* Interpolate filtered signal */
		buf_ptr = bp /* &buf[0] */
		counter = nSamplesIn
		for counter > 2 {
			/* Inner product */
			res_Q6 = ((((*(*int32)(unsafe.Pointer(buf_ptr))) >> 16) * (int32(Resampler_2_3_COEFS_LQ[2]))) + ((((*(*int32)(unsafe.Pointer(buf_ptr))) & 0x0000FFFF) * (int32(Resampler_2_3_COEFS_LQ[2]))) >> 16))
			res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) >> 16) * (int32(Resampler_2_3_COEFS_LQ[3]))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) & 0x0000FFFF) * (int32(Resampler_2_3_COEFS_LQ[3]))) >> 16)))
			res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) >> 16) * (int32(Resampler_2_3_COEFS_LQ[5]))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) & 0x0000FFFF) * (int32(Resampler_2_3_COEFS_LQ[5]))) >> 16)))
			res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 3*4))) >> 16) * (int32(Resampler_2_3_COEFS_LQ[4]))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 3*4))) & 0x0000FFFF) * (int32(Resampler_2_3_COEFS_LQ[4]))) >> 16)))

			/* Scale down, saturate and store in output array */
			*(*int16)(unsafe.Pointer(libc.PostIncUintptr(&out, 2))) = func() int16 {
				if (func() int32 {
					if (6) == 1 {
						return (((res_Q6) >> 1) + ((res_Q6) & 1))
					}
					return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
				}()) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (func() int32 {
						if (6) == 1 {
							return (((res_Q6) >> 1) + ((res_Q6) & 1))
						}
						return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
					}()) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return func() int16 {
						if (6) == 1 {
							return (int16(((res_Q6) >> 1) + ((res_Q6) & 1)))
						}
						return (int16((((res_Q6) >> ((6) - 1)) + 1) >> 1))
					}()
				}()
			}()

			res_Q6 = ((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) >> 16) * (int32(Resampler_2_3_COEFS_LQ[4]))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) & 0x0000FFFF) * (int32(Resampler_2_3_COEFS_LQ[4]))) >> 16))
			res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) >> 16) * (int32(Resampler_2_3_COEFS_LQ[5]))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) & 0x0000FFFF) * (int32(Resampler_2_3_COEFS_LQ[5]))) >> 16)))
			res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 3*4))) >> 16) * (int32(Resampler_2_3_COEFS_LQ[3]))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 3*4))) & 0x0000FFFF) * (int32(Resampler_2_3_COEFS_LQ[3]))) >> 16)))
			res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 4*4))) >> 16) * (int32(Resampler_2_3_COEFS_LQ[2]))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 4*4))) & 0x0000FFFF) * (int32(Resampler_2_3_COEFS_LQ[2]))) >> 16)))

			/* Scale down, saturate and store in output array */
			*(*int16)(unsafe.Pointer(libc.PostIncUintptr(&out, 2))) = func() int16 {
				if (func() int32 {
					if (6) == 1 {
						return (((res_Q6) >> 1) + ((res_Q6) & 1))
					}
					return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
				}()) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (func() int32 {
						if (6) == 1 {
							return (((res_Q6) >> 1) + ((res_Q6) & 1))
						}
						return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
					}()) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return func() int16 {
						if (6) == 1 {
							return (int16(((res_Q6) >> 1) + ((res_Q6) & 1)))
						}
						return (int16((((res_Q6) >> ((6) - 1)) + 1) >> 1))
					}()
				}()
			}()

			buf_ptr += 4 * (uintptr(3))
			counter = counter - (3)
		}

		in += 2 * (uintptr(nSamplesIn))
		inLen = inLen - (nSamplesIn)

		if inLen > 0 {
			/* More iterations to do; copy last part of filtered signal to beginning of buffer */
			libc.Xmemcpy(tls, bp /* &buf[0] */, (bp /* &buf */ + uintptr(nSamplesIn)*4), (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))
		} else {
			break
		}
	}

	/* Copy last part of filtered signal to the state for the next call */
	libc.Xmemcpy(tls, S, (bp /* &buf */ + uintptr(nSamplesIn)*4), (uint32(4) * uint32(unsafe.Sizeof(int32(0)))))
}

/* Downsample by a factor 3, low quality */
func resampler_down3(tls *libc.TLS, S uintptr, out uintptr, in uintptr, inLen int32) { /* resampler_down3.c:42:6: */
	bp := tls.Alloc(1944)
	defer tls.Free(1944)

	var nSamplesIn int32
	var counter int32
	var res_Q6 int32
	// var buf [486]int32 at bp, 1944

	var buf_ptr uintptr

	/* Copy buffered samples to start of buffer */
	libc.Xmemcpy(tls, bp /* &buf[0] */, S, (uint32(6) * uint32(unsafe.Sizeof(int32(0)))))

	/* Iterate over blocks of frameSizeIn input samples */
	for 1 != 0 {
		nSamplesIn = func() int32 {
			if (inLen) < (480) {
				return inLen
			}
			return 480
		}()

		/* Second-order AR filter (output in Q8) */
		resampler_private_AR2(tls, (S + 6*4), (bp /* &buf */ + 6*4), in,
			uintptr(unsafe.Pointer(&Resampler_1_3_COEFS_LQ)), nSamplesIn)

		/* Interpolate filtered signal */
		buf_ptr = bp /* &buf[0] */
		counter = nSamplesIn
		for counter > 2 {
			/* Inner product */
			res_Q6 = (((((*(*int32)(unsafe.Pointer(buf_ptr))) + (*(*int32)(unsafe.Pointer(buf_ptr + 5*4)))) >> 16) * (int32(Resampler_1_3_COEFS_LQ[2]))) + (((((*(*int32)(unsafe.Pointer(buf_ptr))) + (*(*int32)(unsafe.Pointer(buf_ptr + 5*4)))) & 0x0000FFFF) * (int32(Resampler_1_3_COEFS_LQ[2]))) >> 16))
			res_Q6 = ((res_Q6) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 4*4)))) >> 16) * (int32(Resampler_1_3_COEFS_LQ[3]))) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 4*4)))) & 0x0000FFFF) * (int32(Resampler_1_3_COEFS_LQ[3]))) >> 16)))
			res_Q6 = ((res_Q6) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 3*4)))) >> 16) * (int32(Resampler_1_3_COEFS_LQ[4]))) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 3*4)))) & 0x0000FFFF) * (int32(Resampler_1_3_COEFS_LQ[4]))) >> 16)))

			/* Scale down, saturate and store in output array */
			*(*int16)(unsafe.Pointer(libc.PostIncUintptr(&out, 2))) = func() int16 {
				if (func() int32 {
					if (6) == 1 {
						return (((res_Q6) >> 1) + ((res_Q6) & 1))
					}
					return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
				}()) > 0x7FFF {
					return int16(0x7FFF)
				}
				return func() int16 {
					if (func() int32 {
						if (6) == 1 {
							return (((res_Q6) >> 1) + ((res_Q6) & 1))
						}
						return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
					}()) < (int32(libc.Int16FromInt32(0x8000))) {
						return libc.Int16FromInt32(0x8000)
					}
					return func() int16 {
						if (6) == 1 {
							return (int16(((res_Q6) >> 1) + ((res_Q6) & 1)))
						}
						return (int16((((res_Q6) >> ((6) - 1)) + 1) >> 1))
					}()
				}()
			}()

			buf_ptr += 4 * (uintptr(3))
			counter = counter - (3)
		}

		in += 2 * (uintptr(nSamplesIn))
		inLen = inLen - (nSamplesIn)

		if inLen > 0 {
			/* More iterations to do; copy last part of filtered signal to beginning of buffer */
			libc.Xmemcpy(tls, bp /* &buf[0] */, (bp /* &buf */ + uintptr(nSamplesIn)*4), (uint32(6) * uint32(unsafe.Sizeof(int32(0)))))
		} else {
			break
		}
	}

	/* Copy last part of filtered signal to the state for the next call */
	libc.Xmemcpy(tls, S, (bp /* &buf */ + uintptr(nSamplesIn)*4), (uint32(6) * uint32(unsafe.Sizeof(int32(0)))))
}

/* Second order AR filter with single delay elements */
func resampler_private_AR2(tls *libc.TLS, S uintptr, out_Q8 uintptr, in uintptr, A_Q14 uintptr, len int32) { /* resampler_private_AR2.c:40:6: */
	var k int32
	var out32 int32

	for k = 0; k < len; k++ {
		out32 = ((*(*int32)(unsafe.Pointer(S))) + ((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (8)))
		*(*int32)(unsafe.Pointer(out_Q8 + uintptr(k)*4)) = out32
		out32 = ((out32) << (2))
		*(*int32)(unsafe.Pointer(S)) = ((*(*int32)(unsafe.Pointer(S + 1*4))) + ((((out32) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q14))))) + ((((out32) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q14))))) >> 16)))
		*(*int32)(unsafe.Pointer(S + 1*4)) = ((((out32) >> 16) * (int32(*(*int16)(unsafe.Pointer(A_Q14 + 1*2))))) + ((((out32) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(A_Q14 + 1*2))))) >> 16))
	}
}

/* Fourth order ARMA filter                                             */
/* Internally operates as two biquad filters in sequence.               */

/* Coeffients are stored in a packed format:                                                        */
/*    { B1_Q14[1], B2_Q14[1], -A1_Q14[1], -A1_Q14[2], -A2_Q14[1], -A2_Q14[2], gain_Q16 }            */
/* where it is assumed that B*_Q14[0], B*_Q14[2], A*_Q14[0] are all 16384                           */
func resampler_private_ARMA4(tls *libc.TLS, S uintptr, out uintptr, in uintptr, Coef uintptr, len int32) { /* resampler_private_ARMA4.c:45:6: */
	var k int32
	var in_Q8 int32
	var out1_Q8 int32
	var out2_Q8 int32
	var X int32

	for k = 0; k < len; k++ {
		in_Q8 = ((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (8))

		/* Outputs of first and second biquad */
		out1_Q8 = ((in_Q8) + ((*(*int32)(unsafe.Pointer(S))) << (2)))
		out2_Q8 = ((out1_Q8) + ((*(*int32)(unsafe.Pointer(S + 2*4))) << (2)))

		/* Update states, which are stored in Q6. Coefficients are in Q14 here */
		X = ((*(*int32)(unsafe.Pointer(S + 1*4))) + ((((in_Q8) >> 16) * (int32(*(*int16)(unsafe.Pointer(Coef))))) + ((((in_Q8) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(Coef))))) >> 16)))
		*(*int32)(unsafe.Pointer(S)) = ((X) + ((((out1_Q8) >> 16) * (int32(*(*int16)(unsafe.Pointer(Coef + 2*2))))) + ((((out1_Q8) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(Coef + 2*2))))) >> 16)))

		X = ((*(*int32)(unsafe.Pointer(S + 3*4))) + ((((out1_Q8) >> 16) * (int32(*(*int16)(unsafe.Pointer(Coef + 1*2))))) + ((((out1_Q8) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(Coef + 1*2))))) >> 16)))
		*(*int32)(unsafe.Pointer(S + 2*4)) = ((X) + ((((out2_Q8) >> 16) * (int32(*(*int16)(unsafe.Pointer(Coef + 4*2))))) + ((((out2_Q8) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(Coef + 4*2))))) >> 16)))

		*(*int32)(unsafe.Pointer(S + 1*4)) = (((in_Q8) >> (2)) + ((((out1_Q8) >> 16) * (int32(*(*int16)(unsafe.Pointer(Coef + 3*2))))) + ((((out1_Q8) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(Coef + 3*2))))) >> 16)))
		*(*int32)(unsafe.Pointer(S + 3*4)) = (((out1_Q8) >> (2)) + ((((out2_Q8) >> 16) * (int32(*(*int16)(unsafe.Pointer(Coef + 5*2))))) + ((((out2_Q8) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(Coef + 5*2))))) >> 16)))

		/* Apply gain and store to output. The coefficient is in Q16 */
		*(*int16)(unsafe.Pointer(out + uintptr(k)*2)) = func() int16 {
			if (((128) + ((((out2_Q8) >> 16) * (int32(*(*int16)(unsafe.Pointer(Coef + 6*2))))) + ((((out2_Q8) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(Coef + 6*2))))) >> 16))) >> (8)) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (((128) + ((((out2_Q8) >> 16) * (int32(*(*int16)(unsafe.Pointer(Coef + 6*2))))) + ((((out2_Q8) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(Coef + 6*2))))) >> 16))) >> (8)) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return (int16(((128) + ((((out2_Q8) >> 16) * (int32(*(*int16)(unsafe.Pointer(Coef + 6*2))))) + ((((out2_Q8) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(Coef + 6*2))))) >> 16))) >> (8)))
			}()
		}()
	}
}

/* Copy */
func resampler_private_copy(tls *libc.TLS, SS uintptr, out uintptr, in uintptr, inLen int32) { /* resampler_private_copy.c:41:6: */
	libc.Xmemcpy(tls, out, in, (uint32(inLen) * uint32(unsafe.Sizeof(int16(0)))))
}

/* Downsample by a factor 4. Note: very low quality, only use with input sampling rates above 96 kHz. */
func resampler_private_down4(tls *libc.TLS, S uintptr, out uintptr, in uintptr, inLen int32) { /* resampler_private_down4.c:40:6: */
	var k int32
	var len4 int32 = ((inLen) >> (2))
	var in32 int32
	var out32 int32
	var Y int32
	var X int32

	/* Internal variables and state are in Q10 format */
	for k = 0; k < len4; k++ {
		/* Add two input samples and convert to Q10 */
		in32 = (((int32(*(*int16)(unsafe.Pointer(in + uintptr((4*k))*2)))) + (int32(*(*int16)(unsafe.Pointer(in + uintptr(((4*k)+1))*2))))) << (9))

		/* All-pass section for even input sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S))))
		X = ((Y) + ((((Y) >> 16) * (int32(resampler_down2_1))) + ((((Y) & 0x0000FFFF) * (int32(resampler_down2_1))) >> 16)))
		out32 = ((*(*int32)(unsafe.Pointer(S))) + (X))
		*(*int32)(unsafe.Pointer(S)) = ((in32) + (X))

		/* Add two input samples and convert to Q10 */
		in32 = (((int32(*(*int16)(unsafe.Pointer(in + uintptr(((4*k)+2))*2)))) + (int32(*(*int16)(unsafe.Pointer(in + uintptr(((4*k)+3))*2))))) << (9))

		/* All-pass section for odd input sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S + 1*4))))
		X = ((((Y) >> 16) * (int32(resampler_down2_0))) + ((((Y) & 0x0000FFFF) * (int32(resampler_down2_0))) >> 16))
		out32 = ((out32) + (*(*int32)(unsafe.Pointer(S + 1*4))))
		out32 = ((out32) + (X))
		*(*int32)(unsafe.Pointer(S + 1*4)) = ((in32) + (X))

		/* Add, convert back to int16 and store to output */
		*(*int16)(unsafe.Pointer(out + uintptr(k)*2)) = func() int16 {
			if (func() int32 {
				if (11) == 1 {
					return (((out32) >> 1) + ((out32) & 1))
				}
				return ((((out32) >> ((11) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (11) == 1 {
						return (((out32) >> 1) + ((out32) & 1))
					}
					return ((((out32) >> ((11) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (11) == 1 {
						return (int16(((out32) >> 1) + ((out32) & 1)))
					}
					return (int16((((out32) >> ((11) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}
}

func resampler_private_down_FIR_INTERPOL0(tls *libc.TLS, out uintptr, buf2 uintptr, FIR_Coefs uintptr, max_index_Q16 int32, index_increment_Q16 int32) uintptr { /* resampler_private_down_FIR.c:39:22: */
	var index_Q16 int32
	var res_Q6 int32
	var buf_ptr uintptr
	for index_Q16 = 0; index_Q16 < max_index_Q16; index_Q16 = index_Q16 + (index_increment_Q16) {
		/* Integer part gives pointer to buffered input */
		buf_ptr = (buf2 + uintptr(((index_Q16)>>(16)))*4)

		/* Inner product */
		res_Q6 = (((((*(*int32)(unsafe.Pointer(buf_ptr))) + (*(*int32)(unsafe.Pointer(buf_ptr + 11*4)))) >> 16) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs))))) + (((((*(*int32)(unsafe.Pointer(buf_ptr))) + (*(*int32)(unsafe.Pointer(buf_ptr + 11*4)))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs))))) >> 16))
		res_Q6 = ((res_Q6) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 10*4)))) >> 16) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 1*2))))) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 10*4)))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 1*2))))) >> 16)))
		res_Q6 = ((res_Q6) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 9*4)))) >> 16) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 2*2))))) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 9*4)))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 2*2))))) >> 16)))
		res_Q6 = ((res_Q6) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 3*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 8*4)))) >> 16) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 3*2))))) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 3*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 8*4)))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 3*2))))) >> 16)))
		res_Q6 = ((res_Q6) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 4*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 7*4)))) >> 16) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 4*2))))) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 4*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 7*4)))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 4*2))))) >> 16)))
		res_Q6 = ((res_Q6) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 5*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 6*4)))) >> 16) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 5*2))))) + (((((*(*int32)(unsafe.Pointer(buf_ptr + 5*4))) + (*(*int32)(unsafe.Pointer(buf_ptr + 6*4)))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(FIR_Coefs + 5*2))))) >> 16)))

		/* Scale down, saturate and store in output array */
		*(*int16)(unsafe.Pointer(libc.PostIncUintptr(&out, 2))) = func() int16 {
			if (func() int32 {
				if (6) == 1 {
					return (((res_Q6) >> 1) + ((res_Q6) & 1))
				}
				return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (6) == 1 {
						return (((res_Q6) >> 1) + ((res_Q6) & 1))
					}
					return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (6) == 1 {
						return (int16(((res_Q6) >> 1) + ((res_Q6) & 1)))
					}
					return (int16((((res_Q6) >> ((6) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}
	return out
}

func resampler_private_down_FIR_INTERPOL1(tls *libc.TLS, out uintptr, buf2 uintptr, FIR_Coefs uintptr, max_index_Q16 int32, index_increment_Q16 int32, FIR_Fracs int32) uintptr { /* resampler_private_down_FIR.c:62:22: */
	var index_Q16 int32
	var res_Q6 int32
	var buf_ptr uintptr
	var interpol_ind int32
	var interpol_ptr uintptr
	for index_Q16 = 0; index_Q16 < max_index_Q16; index_Q16 = index_Q16 + (index_increment_Q16) {
		/* Integer part gives pointer to buffered input */
		buf_ptr = (buf2 + uintptr(((index_Q16)>>(16)))*4)

		/* Fractional part gives interpolation coefficients */
		interpol_ind = ((((index_Q16 & 0xFFFF) >> 16) * (int32(int16(FIR_Fracs)))) + ((((index_Q16 & 0xFFFF) & 0x0000FFFF) * (int32(int16(FIR_Fracs)))) >> 16))

		/* Inner product */
		interpol_ptr = (FIR_Coefs + uintptr(((12/2)*interpol_ind))*2)
		res_Q6 = ((((*(*int32)(unsafe.Pointer(buf_ptr))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr))))) >> 16))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 1*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 1*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 1*2))))) >> 16)))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 2*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 2*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 2*2))))) >> 16)))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 3*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 3*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 3*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 3*2))))) >> 16)))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 4*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 4*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 4*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 4*2))))) >> 16)))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 5*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 5*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 5*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 5*2))))) >> 16)))
		interpol_ptr = (FIR_Coefs + uintptr(((12/2)*((FIR_Fracs-1)-interpol_ind)))*2)
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 11*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 11*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr))))) >> 16)))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 10*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 1*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 10*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 1*2))))) >> 16)))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 9*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 2*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 9*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 2*2))))) >> 16)))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 8*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 3*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 8*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 3*2))))) >> 16)))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 7*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 4*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 7*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 4*2))))) >> 16)))
		res_Q6 = ((res_Q6) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 6*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 5*2))))) + ((((*(*int32)(unsafe.Pointer(buf_ptr + 6*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(interpol_ptr + 5*2))))) >> 16)))

		/* Scale down, saturate and store in output array */
		*(*int16)(unsafe.Pointer(libc.PostIncUintptr(&out, 2))) = func() int16 {
			if (func() int32 {
				if (6) == 1 {
					return (((res_Q6) >> 1) + ((res_Q6) & 1))
				}
				return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (6) == 1 {
						return (((res_Q6) >> 1) + ((res_Q6) & 1))
					}
					return ((((res_Q6) >> ((6) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (6) == 1 {
						return (int16(((res_Q6) >> 1) + ((res_Q6) & 1)))
					}
					return (int16((((res_Q6) >> ((6) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}
	return out
}

/* Resample with a 2x downsampler (optional), a 2nd order AR filter followed by FIR interpolation */
func resampler_private_down_FIR(tls *libc.TLS, SS uintptr, out uintptr, in uintptr, inLen int32) { /* resampler_private_down_FIR.c:100:6: */
	bp := tls.Alloc(2448)
	defer tls.Free(2448)

	var S uintptr = SS
	var nSamplesIn int32
	var max_index_Q16 int32
	var index_increment_Q16 int32
	// var buf1 [240]int16 at bp+1968, 480

	// var buf2 [492]int32 at bp, 1968

	var FIR_Coefs uintptr

	/* Copy buffered samples to start of buffer */
	libc.Xmemcpy(tls, bp /* &buf2[0] */, S+24 /* &.sFIR */, (uint32(12) * uint32(unsafe.Sizeof(int32(0)))))

	FIR_Coefs = ((*resampler_state_struct)(unsafe.Pointer(S)).FCoefs + 2*2)

	/* Iterate over blocks of frameSizeIn input samples */
	index_increment_Q16 = (*resampler_state_struct)(unsafe.Pointer(S)).FinvRatio_Q16
	for 1 != 0 {
		nSamplesIn = func() int32 {
			if (inLen) < ((*resampler_state_struct)(unsafe.Pointer(S)).FbatchSize) {
				return inLen
			}
			return (*resampler_state_struct)(unsafe.Pointer(S)).FbatchSize
		}()

		if (*resampler_state_struct)(unsafe.Pointer(S)).Finput2x == 1 {
			/* Downsample 2x */
			resampler_down2(tls, S+88 /* &.sDown2 */, bp+1968 /* &buf1[0] */, in, nSamplesIn)

			nSamplesIn = ((nSamplesIn) >> (1))

			/* Second-order AR filter (output in Q8) */
			resampler_private_AR2(tls, S /* &.sIIR */, (bp /* &buf2 */ + 12*4), bp+1968 /* &buf1[0] */, (*resampler_state_struct)(unsafe.Pointer(S)).FCoefs, nSamplesIn)
		} else {
			/* Second-order AR filter (output in Q8) */
			resampler_private_AR2(tls, S /* &.sIIR */, (bp /* &buf2 */ + 12*4), in, (*resampler_state_struct)(unsafe.Pointer(S)).FCoefs, nSamplesIn)
		}

		max_index_Q16 = ((nSamplesIn) << (16))

		/* Interpolate filtered signal */
		if (*resampler_state_struct)(unsafe.Pointer(S)).FFIR_Fracs == 1 {
			out = resampler_private_down_FIR_INTERPOL0(tls, out, bp /* &buf2[0] */, FIR_Coefs, max_index_Q16, index_increment_Q16)
		} else {
			out = resampler_private_down_FIR_INTERPOL1(tls, out, bp /* &buf2[0] */, FIR_Coefs, max_index_Q16, index_increment_Q16, (*resampler_state_struct)(unsafe.Pointer(S)).FFIR_Fracs)
		}

		in += 2 * uintptr((nSamplesIn << (*resampler_state_struct)(unsafe.Pointer(S)).Finput2x))
		inLen = inLen - (nSamplesIn << (*resampler_state_struct)(unsafe.Pointer(S)).Finput2x)

		if inLen > (*resampler_state_struct)(unsafe.Pointer(S)).Finput2x {
			/* More iterations to do; copy last part of filtered signal to beginning of buffer */
			libc.Xmemcpy(tls, bp /* &buf2[0] */, (bp /* &buf2 */ + uintptr(nSamplesIn)*4), (uint32(12) * uint32(unsafe.Sizeof(int32(0)))))
		} else {
			break
		}
	}

	/* Copy last part of filtered signal to the state for the next call */
	libc.Xmemcpy(tls, S+24 /* &.sFIR */, (bp /* &buf2 */ + uintptr(nSamplesIn)*4), (uint32(12) * uint32(unsafe.Sizeof(int32(0)))))
}

func resampler_private_IIR_FIR_INTERPOL(tls *libc.TLS, out uintptr, buf uintptr, max_index_Q16 int32, index_increment_Q16 int32) uintptr { /* resampler_private_IIR_FIR.c:39:22: */
	var index_Q16 int32
	var res_Q15 int32
	var buf_ptr uintptr
	var table_index int32
	/* Interpolate upsampled signal and store in output array */
	for index_Q16 = 0; index_Q16 < max_index_Q16; index_Q16 = index_Q16 + (index_increment_Q16) {
		table_index = ((((index_Q16 & 0xFFFF) >> 16) * (int32(int16(144)))) + ((((index_Q16 & 0xFFFF) & 0x0000FFFF) * (int32(int16(144)))) >> 16))
		buf_ptr = (buf + uintptr((index_Q16>>16))*2)

		res_Q15 = ((int32(*(*int16)(unsafe.Pointer(buf_ptr)))) * (int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&resampler_frac_FIR_144)) + uintptr(table_index)*6))))))
		res_Q15 = ((res_Q15) + ((int32(*(*int16)(unsafe.Pointer(buf_ptr + 1*2)))) * (int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&resampler_frac_FIR_144)) + uintptr(table_index)*6) + 1*2))))))
		res_Q15 = ((res_Q15) + ((int32(*(*int16)(unsafe.Pointer(buf_ptr + 2*2)))) * (int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&resampler_frac_FIR_144)) + uintptr(table_index)*6) + 2*2))))))
		res_Q15 = ((res_Q15) + ((int32(*(*int16)(unsafe.Pointer(buf_ptr + 3*2)))) * (int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&resampler_frac_FIR_144)) + uintptr((143-table_index))*6) + 2*2))))))
		res_Q15 = ((res_Q15) + ((int32(*(*int16)(unsafe.Pointer(buf_ptr + 4*2)))) * (int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&resampler_frac_FIR_144)) + uintptr((143-table_index))*6) + 1*2))))))
		res_Q15 = ((res_Q15) + ((int32(*(*int16)(unsafe.Pointer(buf_ptr + 5*2)))) * (int32(*(*int16)(unsafe.Pointer((uintptr(unsafe.Pointer(&resampler_frac_FIR_144)) + uintptr((143-table_index))*6)))))))
		*(*int16)(unsafe.Pointer(libc.PostIncUintptr(&out, 2))) = func() int16 {
			if (func() int32 {
				if (15) == 1 {
					return (((res_Q15) >> 1) + ((res_Q15) & 1))
				}
				return ((((res_Q15) >> ((15) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (15) == 1 {
						return (((res_Q15) >> 1) + ((res_Q15) & 1))
					}
					return ((((res_Q15) >> ((15) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (15) == 1 {
						return (int16(((res_Q15) >> 1) + ((res_Q15) & 1)))
					}
					return (int16((((res_Q15) >> ((15) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}
	return out
}

/* Upsample using a combination of allpass-based 2x upsampling and FIR interpolation */
func resampler_private_IIR_FIR(tls *libc.TLS, SS uintptr, out uintptr, in uintptr, inLen int32) { /* resampler_private_IIR_FIR.c:60:6: */
	bp := tls.Alloc(1932)
	defer tls.Free(1932)

	var S uintptr = SS
	var nSamplesIn int32
	var max_index_Q16 int32
	var index_increment_Q16 int32
	// var buf [966]int16 at bp, 1932

	/* Copy buffered samples to start of buffer */
	libc.Xmemcpy(tls, bp /* &buf[0] */, S+24 /* &.sFIR */, (uint32(6) * uint32(unsafe.Sizeof(int32(0)))))

	/* Iterate over blocks of frameSizeIn input samples */
	index_increment_Q16 = (*resampler_state_struct)(unsafe.Pointer(S)).FinvRatio_Q16
	for 1 != 0 {
		nSamplesIn = func() int32 {
			if (inLen) < ((*resampler_state_struct)(unsafe.Pointer(S)).FbatchSize) {
				return inLen
			}
			return (*resampler_state_struct)(unsafe.Pointer(S)).FbatchSize
		}()

		if (*resampler_state_struct)(unsafe.Pointer(S)).Finput2x == 1 {
			/* Upsample 2x */
			(*(*func(*libc.TLS, uintptr, uintptr, uintptr, int32))(unsafe.Pointer((S + 100 /* &.up2_function */))))(tls, S /* &.sIIR */, (bp /* &buf */ + 6*2), in, nSamplesIn)
		} else {
			/* Fourth-order ARMA filter */
			resampler_private_ARMA4(tls, S /* &.sIIR */, (bp /* &buf */ + 6*2), in, (*resampler_state_struct)(unsafe.Pointer(S)).FCoefs, nSamplesIn)
		}

		max_index_Q16 = ((nSamplesIn) << (16 + (*resampler_state_struct)(unsafe.Pointer(S)).Finput2x)) /* +1 if 2x upsampling */
		out = resampler_private_IIR_FIR_INTERPOL(tls, out, bp /* &buf[0] */, max_index_Q16, index_increment_Q16)
		in += 2 * uintptr(nSamplesIn)
		inLen = inLen - (nSamplesIn)

		if inLen > 0 {
			/* More iterations to do; copy last part of filtered signal to beginning of buffer */
			libc.Xmemcpy(tls, bp /* &buf[0] */, (bp /* &buf */ + uintptr((nSamplesIn<<(*resampler_state_struct)(unsafe.Pointer(S)).Finput2x))*2), (uint32(6) * uint32(unsafe.Sizeof(int32(0)))))
		} else {
			break
		}
	}

	/* Copy last part of filtered signal to the state for the next call */
	libc.Xmemcpy(tls, S+24 /* &.sFIR */, (bp /* &buf */ + uintptr((nSamplesIn<<(*resampler_state_struct)(unsafe.Pointer(S)).Finput2x))*2), (uint32(6) * uint32(unsafe.Sizeof(int32(0)))))
}

/* Upsample by a factor 2, high quality */
/* Uses 2nd order allpass filters for the 2x upsampling, followed by a      */
/* notch filter just above Nyquist.                                         */
func resampler_private_up2_HQ(tls *libc.TLS, S uintptr, out uintptr, in uintptr, len int32) { /* resampler_private_up2_HQ.c:42:6: */
	var k int32
	var in32 int32
	var out32_1 int32
	var out32_2 int32
	var Y int32
	var X int32

	/* Internal variables and state are in Q10 format */
	for k = 0; k < len; k++ {
		/* Convert to Q10 */
		in32 = ((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (10))

		/* First all-pass section for even output sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S))))
		X = ((((Y) >> 16) * (int32(resampler_up2_hq_0[0]))) + ((((Y) & 0x0000FFFF) * (int32(resampler_up2_hq_0[0]))) >> 16))
		out32_1 = ((*(*int32)(unsafe.Pointer(S))) + (X))
		*(*int32)(unsafe.Pointer(S)) = ((in32) + (X))

		/* Second all-pass section for even output sample */
		Y = ((out32_1) - (*(*int32)(unsafe.Pointer(S + 1*4))))
		X = ((Y) + ((((Y) >> 16) * (int32(resampler_up2_hq_0[1]))) + ((((Y) & 0x0000FFFF) * (int32(resampler_up2_hq_0[1]))) >> 16)))
		out32_2 = ((*(*int32)(unsafe.Pointer(S + 1*4))) + (X))
		*(*int32)(unsafe.Pointer(S + 1*4)) = ((out32_1) + (X))

		/* Biquad notch filter */
		out32_2 = ((out32_2) + ((((*(*int32)(unsafe.Pointer(S + 5*4))) >> 16) * (int32(resampler_up2_hq_notch[2]))) + ((((*(*int32)(unsafe.Pointer(S + 5*4))) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[2]))) >> 16)))
		out32_2 = ((out32_2) + ((((*(*int32)(unsafe.Pointer(S + 4*4))) >> 16) * (int32(resampler_up2_hq_notch[1]))) + ((((*(*int32)(unsafe.Pointer(S + 4*4))) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[1]))) >> 16)))
		out32_1 = ((out32_2) + ((((*(*int32)(unsafe.Pointer(S + 4*4))) >> 16) * (int32(resampler_up2_hq_notch[0]))) + ((((*(*int32)(unsafe.Pointer(S + 4*4))) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[0]))) >> 16)))
		*(*int32)(unsafe.Pointer(S + 5*4)) = ((out32_2) - (*(*int32)(unsafe.Pointer(S + 5*4))))

		/* Apply gain in Q15, convert back to int16 and store to output */
		*(*int16)(unsafe.Pointer(out + uintptr((2*k))*2)) = func() int16 {
			if (((256) + ((((out32_1) >> 16) * (int32(resampler_up2_hq_notch[3]))) + ((((out32_1) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[3]))) >> 16))) >> (9)) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (((256) + ((((out32_1) >> 16) * (int32(resampler_up2_hq_notch[3]))) + ((((out32_1) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[3]))) >> 16))) >> (9)) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return (int16(((256) + ((((out32_1) >> 16) * (int32(resampler_up2_hq_notch[3]))) + ((((out32_1) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[3]))) >> 16))) >> (9)))
			}()
		}()

		/* First all-pass section for odd output sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S + 2*4))))
		X = ((((Y) >> 16) * (int32(resampler_up2_hq_1[0]))) + ((((Y) & 0x0000FFFF) * (int32(resampler_up2_hq_1[0]))) >> 16))
		out32_1 = ((*(*int32)(unsafe.Pointer(S + 2*4))) + (X))
		*(*int32)(unsafe.Pointer(S + 2*4)) = ((in32) + (X))

		/* Second all-pass section for odd output sample */
		Y = ((out32_1) - (*(*int32)(unsafe.Pointer(S + 3*4))))
		X = ((Y) + ((((Y) >> 16) * (int32(resampler_up2_hq_1[1]))) + ((((Y) & 0x0000FFFF) * (int32(resampler_up2_hq_1[1]))) >> 16)))
		out32_2 = ((*(*int32)(unsafe.Pointer(S + 3*4))) + (X))
		*(*int32)(unsafe.Pointer(S + 3*4)) = ((out32_1) + (X))

		/* Biquad notch filter */
		out32_2 = ((out32_2) + ((((*(*int32)(unsafe.Pointer(S + 4*4))) >> 16) * (int32(resampler_up2_hq_notch[2]))) + ((((*(*int32)(unsafe.Pointer(S + 4*4))) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[2]))) >> 16)))
		out32_2 = ((out32_2) + ((((*(*int32)(unsafe.Pointer(S + 5*4))) >> 16) * (int32(resampler_up2_hq_notch[1]))) + ((((*(*int32)(unsafe.Pointer(S + 5*4))) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[1]))) >> 16)))
		out32_1 = ((out32_2) + ((((*(*int32)(unsafe.Pointer(S + 5*4))) >> 16) * (int32(resampler_up2_hq_notch[0]))) + ((((*(*int32)(unsafe.Pointer(S + 5*4))) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[0]))) >> 16)))
		*(*int32)(unsafe.Pointer(S + 4*4)) = ((out32_2) - (*(*int32)(unsafe.Pointer(S + 4*4))))

		/* Apply gain in Q15, convert back to int16 and store to output */
		*(*int16)(unsafe.Pointer(out + uintptr(((2*k)+1))*2)) = func() int16 {
			if (((256) + ((((out32_1) >> 16) * (int32(resampler_up2_hq_notch[3]))) + ((((out32_1) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[3]))) >> 16))) >> (9)) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (((256) + ((((out32_1) >> 16) * (int32(resampler_up2_hq_notch[3]))) + ((((out32_1) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[3]))) >> 16))) >> (9)) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return (int16(((256) + ((((out32_1) >> 16) * (int32(resampler_up2_hq_notch[3]))) + ((((out32_1) & 0x0000FFFF) * (int32(resampler_up2_hq_notch[3]))) >> 16))) >> (9)))
			}()
		}()
	}
}

func resampler_private_up2_HQ_wrapper(tls *libc.TLS, SS uintptr, out uintptr, in uintptr, len int32) { /* resampler_private_up2_HQ.c:109:6: */
	var S uintptr = SS
	resampler_private_up2_HQ(tls, S /* &.sIIR */, out, in, len)
}

/* Upsample by a factor 4, Note: very low quality, only use with output sampling rates above 96 kHz. */
func resampler_private_up4(tls *libc.TLS, S uintptr, out uintptr, in uintptr, len int32) { /* resampler_private_up4.c:40:6: */
	var k int32
	var in32 int32
	var out32 int32
	var Y int32
	var X int32
	var out16 int16

	/* Internal variables and state are in Q10 format */
	for k = 0; k < len; k++ {
		/* Convert to Q10 */
		in32 = ((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (10))

		/* All-pass section for even output sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S))))
		X = ((((Y) >> 16) * (int32(resampler_up2_lq_0))) + ((((Y) & 0x0000FFFF) * (int32(resampler_up2_lq_0))) >> 16))
		out32 = ((*(*int32)(unsafe.Pointer(S))) + (X))
		*(*int32)(unsafe.Pointer(S)) = ((in32) + (X))

		/* Convert back to int16 and store to output */
		out16 = func() int16 {
			if (func() int32 {
				if (10) == 1 {
					return (((out32) >> 1) + ((out32) & 1))
				}
				return ((((out32) >> ((10) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((out32) >> 1) + ((out32) & 1))
					}
					return ((((out32) >> ((10) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (10) == 1 {
						return (int16(((out32) >> 1) + ((out32) & 1)))
					}
					return (int16((((out32) >> ((10) - 1)) + 1) >> 1))
				}()
			}()
		}()
		*(*int16)(unsafe.Pointer(out + uintptr((4*k))*2)) = out16
		*(*int16)(unsafe.Pointer(out + uintptr(((4*k)+1))*2)) = out16

		/* All-pass section for odd output sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S + 1*4))))
		X = ((Y) + ((((Y) >> 16) * (int32(resampler_up2_lq_1))) + ((((Y) & 0x0000FFFF) * (int32(resampler_up2_lq_1))) >> 16)))
		out32 = ((*(*int32)(unsafe.Pointer(S + 1*4))) + (X))
		*(*int32)(unsafe.Pointer(S + 1*4)) = ((in32) + (X))

		/* Convert back to int16 and store to output */
		out16 = func() int16 {
			if (func() int32 {
				if (10) == 1 {
					return (((out32) >> 1) + ((out32) & 1))
				}
				return ((((out32) >> ((10) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((out32) >> 1) + ((out32) & 1))
					}
					return ((((out32) >> ((10) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (10) == 1 {
						return (int16(((out32) >> 1) + ((out32) & 1)))
					}
					return (int16((((out32) >> ((10) - 1)) + 1) >> 1))
				}()
			}()
		}()
		*(*int16)(unsafe.Pointer(out + uintptr(((4*k)+2))*2)) = out16
		*(*int16)(unsafe.Pointer(out + uintptr(((4*k)+3))*2)) = out16
	}
}

/* Tables for 2x downsampler */
var resampler_down2_0 int16 = int16(9872)            /* resampler_rom.c:41:17 */
var resampler_down2_1 int16 = (int16(39809 - 65536)) /* resampler_rom.c:42:17 */

/* Tables for 2x upsampler, low quality */
var resampler_up2_lq_0 int16 = int16(8102)            /* resampler_rom.c:45:17 */
var resampler_up2_lq_1 int16 = (int16(36783 - 65536)) /* resampler_rom.c:46:17 */

/* Tables for 2x upsampler, high quality */
var resampler_up2_hq_0 = [2]int16{int16(4280), (int16(33727 - 65536))}  /* resampler_rom.c:49:17 */
var resampler_up2_hq_1 = [2]int16{int16(16295), (int16(54015 - 65536))} /* resampler_rom.c:50:17 */
/* Matlab code for the notch filter coefficients: */
/* B = [1, 0.12, 1];  A = [1, 0.055, 0.8]; G = 0.87; freqz(G * B, A, 2^14, 16e3); axis([0, 8000, -10, 1]);  */
/* fprintf('\t%6d, %6d, %6d, %6d\n', round(B(2)*2^16), round(-A(2)*2^16), round((1-A(3))*2^16), round(G*2^15)) */
var resampler_up2_hq_notch = [4]int16{int16(7864), int16(-3604), int16(13107), int16(28508)} /* resampler_rom.c:54:17 */

/* Tables with IIR and FIR coefficients for fractional downsamplers (70 Words) */
var Resampler_3_4_COEFS = [20]int16{
	int16(-18249), int16(-12532),
	int16(-97), int16(284), int16(-495), int16(309), int16(10268), int16(20317),
	int16(-94), int16(156), int16(-48), int16(-720), int16(5984), int16(18278),
	int16(-45), int16(-4), int16(237), int16(-847), int16(2540), int16(14662),
} /* resampler_rom.c:58:33 */

var Resampler_2_3_COEFS = [14]int16{
	int16(-11891), int16(-12486),
	int16(20), int16(211), int16(-657), int16(688), int16(8423), int16(15911),
	int16(-44), int16(197), int16(-152), int16(-653), int16(3855), int16(13015),
} /* resampler_rom.c:65:33 */

var Resampler_1_2_COEFS = [8]int16{
	int16(2415), int16(-13101),
	int16(158), int16(-295), int16(-400), int16(1265), int16(4832), int16(7968),
} /* resampler_rom.c:71:33 */

var Resampler_3_8_COEFS = [20]int16{
	int16(13270), int16(-13738),
	int16(-294), int16(-123), int16(747), int16(2043), int16(3339), int16(3995),
	int16(-151), int16(-311), int16(414), int16(1583), int16(2947), int16(3877),
	int16(-33), int16(-389), int16(143), int16(1141), int16(2503), int16(3653),
} /* resampler_rom.c:76:33 */

var Resampler_1_3_COEFS = [8]int16{
	int16(16643), int16(-14000),
	int16(-331), int16(19), int16(581), int16(1421), int16(2290), int16(2845),
} /* resampler_rom.c:83:33 */

var Resampler_2_3_COEFS_LQ = [6]int16{
	int16(-2797), int16(-6507),
	int16(4697), int16(10739),
	int16(1567), int16(8276),
} /* resampler_rom.c:88:33 */

var Resampler_1_3_COEFS_LQ = [5]int16{
	int16(16777), int16(-9792),
	int16(890), int16(1614), int16(2148),
} /* resampler_rom.c:94:33 */

/* Tables with coefficients for 4th order ARMA filter (35 Words), in a packed format:       */
/*    { B1_Q14[1], B2_Q14[1], -A1_Q14[1], -A1_Q14[2], -A2_Q14[1], -A2_Q14[2], gain_Q16 }    */
/* where it is assumed that B*_Q14[0], B*_Q14[2], A*_Q14[0] are all 16384                   */
var Resampler_320_441_ARMA4_COEFS = [7]int16{
	int16(31454), int16(24746), int16(-9706), int16(-3386), int16(-17911), int16(-13243), int16(24797),
} /* resampler_rom.c:103:33 */

var Resampler_240_441_ARMA4_COEFS = [7]int16{
	int16(28721), int16(11254), int16(3189), int16(-2546), int16(-1495), int16(-12618), int16(11562),
} /* resampler_rom.c:107:33 */

var Resampler_160_441_ARMA4_COEFS = [7]int16{
	int16(23492), int16(-6457), int16(14358), int16(-4856), int16(14654), int16(-13008), int16(4456),
} /* resampler_rom.c:111:33 */

var Resampler_120_441_ARMA4_COEFS = [7]int16{
	int16(19311), int16(-15569), int16(19489), int16(-6950), int16(21441), int16(-13559), int16(2370),
} /* resampler_rom.c:115:33 */

var Resampler_80_441_ARMA4_COEFS = [7]int16{
	int16(13248), int16(-23849), int16(24126), int16(-9486), int16(26806), int16(-14286), int16(1065),
} /* resampler_rom.c:119:33 */

/* Table with interplation fractions of 1/288 : 2/288 : 287/288 (432 Words) */
var resampler_frac_FIR_144 = [144][3]int16{
	{int16(-647), int16(1884), int16(30078)},
	{int16(-625), int16(1736), int16(30044)},
	{int16(-603), int16(1591), int16(30005)},
	{int16(-581), int16(1448), int16(29963)},
	{int16(-559), int16(1308), int16(29917)},
	{int16(-537), int16(1169), int16(29867)},
	{int16(-515), int16(1032), int16(29813)},
	{int16(-494), int16(898), int16(29755)},
	{int16(-473), int16(766), int16(29693)},
	{int16(-452), int16(636), int16(29627)},
	{int16(-431), int16(508), int16(29558)},
	{int16(-410), int16(383), int16(29484)},
	{int16(-390), int16(260), int16(29407)},
	{int16(-369), int16(139), int16(29327)},
	{int16(-349), int16(20), int16(29242)},
	{int16(-330), int16(-97), int16(29154)},
	{int16(-310), int16(-211), int16(29062)},
	{int16(-291), int16(-324), int16(28967)},
	{int16(-271), int16(-434), int16(28868)},
	{int16(-253), int16(-542), int16(28765)},
	{int16(-234), int16(-647), int16(28659)},
	{int16(-215), int16(-751), int16(28550)},
	{int16(-197), int16(-852), int16(28436)},
	{int16(-179), int16(-951), int16(28320)},
	{int16(-162), int16(-1048), int16(28200)},
	{int16(-144), int16(-1143), int16(28077)},
	{int16(-127), int16(-1235), int16(27950)},
	{int16(-110), int16(-1326), int16(27820)},
	{int16(-94), int16(-1414), int16(27687)},
	{int16(-77), int16(-1500), int16(27550)},
	{int16(-61), int16(-1584), int16(27410)},
	{int16(-45), int16(-1665), int16(27268)},
	{int16(-30), int16(-1745), int16(27122)},
	{int16(-15), int16(-1822), int16(26972)},
	{int16(0), int16(-1897), int16(26820)},
	{int16(15), int16(-1970), int16(26665)},
	{int16(29), int16(-2041), int16(26507)},
	{int16(44), int16(-2110), int16(26346)},
	{int16(57), int16(-2177), int16(26182)},
	{int16(71), int16(-2242), int16(26015)},
	{int16(84), int16(-2305), int16(25845)},
	{int16(97), int16(-2365), int16(25673)},
	{int16(110), int16(-2424), int16(25498)},
	{int16(122), int16(-2480), int16(25320)},
	{int16(134), int16(-2534), int16(25140)},
	{int16(146), int16(-2587), int16(24956)},
	{int16(157), int16(-2637), int16(24771)},
	{int16(168), int16(-2685), int16(24583)},
	{int16(179), int16(-2732), int16(24392)},
	{int16(190), int16(-2776), int16(24199)},
	{int16(200), int16(-2819), int16(24003)},
	{int16(210), int16(-2859), int16(23805)},
	{int16(220), int16(-2898), int16(23605)},
	{int16(229), int16(-2934), int16(23403)},
	{int16(238), int16(-2969), int16(23198)},
	{int16(247), int16(-3002), int16(22992)},
	{int16(255), int16(-3033), int16(22783)},
	{int16(263), int16(-3062), int16(22572)},
	{int16(271), int16(-3089), int16(22359)},
	{int16(279), int16(-3114), int16(22144)},
	{int16(286), int16(-3138), int16(21927)},
	{int16(293), int16(-3160), int16(21709)},
	{int16(300), int16(-3180), int16(21488)},
	{int16(306), int16(-3198), int16(21266)},
	{int16(312), int16(-3215), int16(21042)},
	{int16(318), int16(-3229), int16(20816)},
	{int16(323), int16(-3242), int16(20589)},
	{int16(328), int16(-3254), int16(20360)},
	{int16(333), int16(-3263), int16(20130)},
	{int16(338), int16(-3272), int16(19898)},
	{int16(342), int16(-3278), int16(19665)},
	{int16(346), int16(-3283), int16(19430)},
	{int16(350), int16(-3286), int16(19194)},
	{int16(353), int16(-3288), int16(18957)},
	{int16(356), int16(-3288), int16(18718)},
	{int16(359), int16(-3286), int16(18478)},
	{int16(362), int16(-3283), int16(18238)},
	{int16(364), int16(-3279), int16(17996)},
	{int16(366), int16(-3273), int16(17753)},
	{int16(368), int16(-3266), int16(17509)},
	{int16(369), int16(-3257), int16(17264)},
	{int16(371), int16(-3247), int16(17018)},
	{int16(372), int16(-3235), int16(16772)},
	{int16(372), int16(-3222), int16(16525)},
	{int16(373), int16(-3208), int16(16277)},
	{int16(373), int16(-3192), int16(16028)},
	{int16(373), int16(-3175), int16(15779)},
	{int16(373), int16(-3157), int16(15529)},
	{int16(372), int16(-3138), int16(15279)},
	{int16(371), int16(-3117), int16(15028)},
	{int16(370), int16(-3095), int16(14777)},
	{int16(369), int16(-3072), int16(14526)},
	{int16(368), int16(-3048), int16(14274)},
	{int16(366), int16(-3022), int16(14022)},
	{int16(364), int16(-2996), int16(13770)},
	{int16(362), int16(-2968), int16(13517)},
	{int16(359), int16(-2940), int16(13265)},
	{int16(357), int16(-2910), int16(13012)},
	{int16(354), int16(-2880), int16(12760)},
	{int16(351), int16(-2848), int16(12508)},
	{int16(348), int16(-2815), int16(12255)},
	{int16(344), int16(-2782), int16(12003)},
	{int16(341), int16(-2747), int16(11751)},
	{int16(337), int16(-2712), int16(11500)},
	{int16(333), int16(-2676), int16(11248)},
	{int16(328), int16(-2639), int16(10997)},
	{int16(324), int16(-2601), int16(10747)},
	{int16(320), int16(-2562), int16(10497)},
	{int16(315), int16(-2523), int16(10247)},
	{int16(310), int16(-2482), int16(9998)},
	{int16(305), int16(-2442), int16(9750)},
	{int16(300), int16(-2400), int16(9502)},
	{int16(294), int16(-2358), int16(9255)},
	{int16(289), int16(-2315), int16(9009)},
	{int16(283), int16(-2271), int16(8763)},
	{int16(277), int16(-2227), int16(8519)},
	{int16(271), int16(-2182), int16(8275)},
	{int16(265), int16(-2137), int16(8032)},
	{int16(259), int16(-2091), int16(7791)},
	{int16(252), int16(-2045), int16(7550)},
	{int16(246), int16(-1998), int16(7311)},
	{int16(239), int16(-1951), int16(7072)},
	{int16(232), int16(-1904), int16(6835)},
	{int16(226), int16(-1856), int16(6599)},
	{int16(219), int16(-1807), int16(6364)},
	{int16(212), int16(-1758), int16(6131)},
	{int16(204), int16(-1709), int16(5899)},
	{int16(197), int16(-1660), int16(5668)},
	{int16(190), int16(-1611), int16(5439)},
	{int16(183), int16(-1561), int16(5212)},
	{int16(175), int16(-1511), int16(4986)},
	{int16(168), int16(-1460), int16(4761)},
	{int16(160), int16(-1410), int16(4538)},
	{int16(152), int16(-1359), int16(4317)},
	{int16(145), int16(-1309), int16(4098)},
	{int16(137), int16(-1258), int16(3880)},
	{int16(129), int16(-1207), int16(3664)},
	{int16(121), int16(-1156), int16(3450)},
	{int16(113), int16(-1105), int16(3238)},
	{int16(105), int16(-1054), int16(3028)},
	{int16(97), int16(-1003), int16(2820)},
	{int16(89), int16(-952), int16(2614)},
	{int16(81), int16(-901), int16(2409)},
	{int16(73), int16(-851), int16(2207)},
} /* resampler_rom.c:124:33 */

/* Upsample by a factor 2, low quality */
func resampler_up2(tls *libc.TLS, S uintptr, out uintptr, in uintptr, len int32) { /* resampler_up2.c:40:6: */
	var k int32
	var in32 int32
	var out32 int32
	var Y int32
	var X int32

	/* Internal variables and state are in Q10 format */
	for k = 0; k < len; k++ {
		/* Convert to Q10 */
		in32 = ((int32(*(*int16)(unsafe.Pointer(in + uintptr(k)*2)))) << (10))

		/* All-pass section for even output sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S))))
		X = ((((Y) >> 16) * (int32(resampler_up2_lq_0))) + ((((Y) & 0x0000FFFF) * (int32(resampler_up2_lq_0))) >> 16))
		out32 = ((*(*int32)(unsafe.Pointer(S))) + (X))
		*(*int32)(unsafe.Pointer(S)) = ((in32) + (X))

		/* Convert back to int16 and store to output */
		*(*int16)(unsafe.Pointer(out + uintptr((2*k))*2)) = func() int16 {
			if (func() int32 {
				if (10) == 1 {
					return (((out32) >> 1) + ((out32) & 1))
				}
				return ((((out32) >> ((10) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((out32) >> 1) + ((out32) & 1))
					}
					return ((((out32) >> ((10) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (10) == 1 {
						return (int16(((out32) >> 1) + ((out32) & 1)))
					}
					return (int16((((out32) >> ((10) - 1)) + 1) >> 1))
				}()
			}()
		}()

		/* All-pass section for odd output sample */
		Y = ((in32) - (*(*int32)(unsafe.Pointer(S + 1*4))))
		X = ((Y) + ((((Y) >> 16) * (int32(resampler_up2_lq_1))) + ((((Y) & 0x0000FFFF) * (int32(resampler_up2_lq_1))) >> 16)))
		out32 = ((*(*int32)(unsafe.Pointer(S + 1*4))) + (X))
		*(*int32)(unsafe.Pointer(S + 1*4)) = ((in32) + (X))

		/* Convert back to int16 and store to output */
		*(*int16)(unsafe.Pointer(out + uintptr(((2*k)+1))*2)) = func() int16 {
			if (func() int32 {
				if (10) == 1 {
					return (((out32) >> 1) + ((out32) & 1))
				}
				return ((((out32) >> ((10) - 1)) + 1) >> 1)
			}()) > 0x7FFF {
				return int16(0x7FFF)
			}
			return func() int16 {
				if (func() int32 {
					if (10) == 1 {
						return (((out32) >> 1) + ((out32) & 1))
					}
					return ((((out32) >> ((10) - 1)) + 1) >> 1)
				}()) < (int32(libc.Int16FromInt32(0x8000))) {
					return libc.Int16FromInt32(0x8000)
				}
				return func() int16 {
					if (10) == 1 {
						return (int16(((out32) >> 1) + ((out32) & 1)))
					}
					return (int16((((out32) >> ((10) - 1)) + 1) >> 1))
				}()
			}()
		}()
	}
}

/* Residual energy: nrg = wxx - 2 * wXx * c + c' * wXX * c */
func residual_energy16_covar_FIX(tls *libc.TLS, c uintptr, wXX uintptr, wXx uintptr, wxx int32, D int32, cQ int32) int32 { /* residual_energy16_FIX.c:31:11: */
	bp := tls.Alloc(64)
	defer tls.Free(64)

	var i int32
	var j int32
	var lshifts int32
	var Qxtra int32
	var c_max int32
	var w_max int32
	var tmp int32
	var tmp2 int32
	var nrg int32
	// var cn [16]int32 at bp, 64

	var pRow uintptr

	/* Safety checks */

	lshifts = (16 - cQ)
	Qxtra = lshifts

	c_max = 0
	for i = 0; i < D; i++ {
		c_max = max_32(tls, c_max, func() int32 {
			if (int32(*(*int16)(unsafe.Pointer(c + uintptr(i)*2)))) > 0 {
				return int32(*(*int16)(unsafe.Pointer(c + uintptr(i)*2)))
			}
			return -int32(*(*int16)(unsafe.Pointer(c + uintptr(i)*2)))
		}())
	}
	Qxtra = min_int(tls, Qxtra, (CLZ32(tls, c_max) - 17))

	w_max = max_32(tls, *(*int32)(unsafe.Pointer(wXX)), *(*int32)(unsafe.Pointer(wXX + uintptr(((D*D)-1))*4)))
	Qxtra = min_int(tls, Qxtra, (CLZ32(tls, ((D)*(((((w_max)>>16)*(int32(int16(c_max))))+((((w_max)&0x0000FFFF)*(int32(int16(c_max))))>>16))>>(4)))) - 5))
	Qxtra = max_int(tls, Qxtra, 0)
	for i = 0; i < D; i++ {
		*(*int32)(unsafe.Pointer(bp /* &cn[0] */ + uintptr(i)*4)) = ((int32(*(*int16)(unsafe.Pointer(c + uintptr(i)*2)))) << (Qxtra))
		/* Check that SMLAWB can be used */
	}
	lshifts = lshifts - (Qxtra)

	/* Compute wxx - 2 * wXx * c */
	tmp = 0
	for i = 0; i < D; i++ {
		tmp = ((tmp) + ((((*(*int32)(unsafe.Pointer(wXx + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &cn[0] */ + uintptr(i)*4)))))) + ((((*(*int32)(unsafe.Pointer(wXx + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &cn[0] */ + uintptr(i)*4)))))) >> 16)))
	}
	nrg = (((wxx) >> (1 + lshifts)) - tmp) /* Q: -lshifts - 1 */

	/* Add c' * wXX * c, assuming wXX is symmetric */
	tmp2 = 0
	for i = 0; i < D; i++ {
		tmp = 0
		pRow = (wXX + uintptr((i*D))*4)
		for j = (i + 1); j < D; j++ {
			tmp = ((tmp) + ((((*(*int32)(unsafe.Pointer(pRow + uintptr(j)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &cn[0] */ + uintptr(j)*4)))))) + ((((*(*int32)(unsafe.Pointer(pRow + uintptr(j)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &cn[0] */ + uintptr(j)*4)))))) >> 16)))
		}
		tmp = ((tmp) + (((((*(*int32)(unsafe.Pointer(pRow + uintptr(i)*4))) >> (1)) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &cn[0] */ + uintptr(i)*4)))))) + (((((*(*int32)(unsafe.Pointer(pRow + uintptr(i)*4))) >> (1)) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &cn[0] */ + uintptr(i)*4)))))) >> 16)))
		tmp2 = ((tmp2) + ((((tmp) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &cn[0] */ + uintptr(i)*4)))))) + ((((tmp) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(bp /* &cn[0] */ + uintptr(i)*4)))))) >> 16)))
	}
	nrg = ((nrg) + ((tmp2) << (lshifts))) /* Q: -lshifts - 1 */

	/* Keep one bit free always, because we add them for LSF interpolation */
	if nrg < 1 {
		nrg = 1
	} else if nrg > (int32((0x7FFFFFFF)) >> (lshifts + 2)) {
		nrg = (int32(0x7FFFFFFF) >> 1)
	} else {
		nrg = ((nrg) << (lshifts + 1)) /* Q0 */
	}
	return nrg

}

/* Calculates residual energies of input subframes where all subframes have LPC_order   */
/* of preceeding samples                                                                */
func residual_energy_FIX(tls *libc.TLS, nrgs uintptr, nrgsQ uintptr, x uintptr, a_Q12 uintptr, gains uintptr, subfr_length int32, LPC_order int32) { /* residual_energy_FIX.c:32:6: */
	bp := tls.Alloc(580)
	defer tls.Free(580)

	var offset int32
	var i int32
	var j int32
	// var rshift int32 at bp+576, 4

	var lz1 int32
	var lz2 int32
	var LPC_res_ptr uintptr
	// var LPC_res [272]int16 at bp+32, 544

	var x_ptr uintptr
	// var S [16]int16 at bp, 32

	var tmp32 int32

	x_ptr = x
	offset = (LPC_order + subfr_length)

	/* Filter input to create the LPC residual for each frame half, and measure subframe energies */
	for i = 0; i < 2; i++ {
		/* Calculate half frame LPC residual signal including preceeding samples */
		libc.Xmemset(tls, bp /* &S[0] */, 0, (uint32(LPC_order) * uint32(unsafe.Sizeof(int16(0)))))
		LPC_analysis_filter(tls, x_ptr, (a_Q12 + uintptr(i)*32), bp /* &S[0] */, bp+32 /* &LPC_res[0] */, ((int32(4) >> 1) * offset), LPC_order)

		/* Point to first subframe of the just calculated LPC residual signal */
		LPC_res_ptr = (bp + 32 /* &LPC_res[0] */ + uintptr(LPC_order)*2)
		for j = 0; j < (int32(4) >> 1); j++ {
			/* Measure subframe energy */
			sum_sqr_shift(tls, (nrgs + uintptr(((i*(int32(4)>>1))+j))*4), bp+576 /* &rshift */, LPC_res_ptr, subfr_length)

			/* Set Q values for the measured energy */
			*(*int32)(unsafe.Pointer(nrgsQ + uintptr(((i*(int32(4)>>1))+j))*4)) = -*(*int32)(unsafe.Pointer(bp + 576 /* rshift */))

			/* Move to next subframe */
			LPC_res_ptr += 2 * (uintptr(offset))
		}
		/* Move to next frame half */
		x_ptr += 2 * (uintptr((int32(4) >> 1) * offset))
	}

	/* Apply the squared subframe gains */
	for i = 0; i < 4; i++ {
		/* Fully upscale gains and energies */
		lz1 = (CLZ32(tls, *(*int32)(unsafe.Pointer(nrgs + uintptr(i)*4))) - 1)
		lz2 = (CLZ32(tls, *(*int32)(unsafe.Pointer(gains + uintptr(i)*4))) - 1)

		tmp32 = ((*(*int32)(unsafe.Pointer(gains + uintptr(i)*4))) << (lz2))

		/* Find squared gains */
		tmp32 = (int32(((int64_t(tmp32)) * (int64_t(tmp32))) >> (32))) // Q( 2 * lz2 - 32 )

		/* Scale energies */
		*(*int32)(unsafe.Pointer(nrgs + uintptr(i)*4)) = (int32(((int64_t(tmp32)) * (int64_t((*(*int32)(unsafe.Pointer(nrgs + uintptr(i)*4))) << (lz1)))) >> (32))) // Q( nrgsQ[ i ] + lz1 + 2 * lz2 - 32 - 32 )
		*(*int32)(unsafe.Pointer(nrgsQ + uintptr(i)*4)) += (((lz1 + (2 * lz2)) - 32) - 32)
	}
}

/* Copy and multiply a vector by a constant */
func scale_copy_vector16(tls *libc.TLS, data_out uintptr, data_in uintptr, gain_Q16 int32, dataSize int32) { /* scale_copy_vector16.c:31:6: */
	var i int32
	var tmp32 int32

	for i = 0; i < dataSize; i++ {
		tmp32 = ((((gain_Q16) >> 16) * (int32(*(*int16)(unsafe.Pointer(data_in + uintptr(i)*2))))) + ((((gain_Q16) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(data_in + uintptr(i)*2))))) >> 16))
		*(*int16)(unsafe.Pointer(data_out + uintptr(i)*2)) = int16(tmp32)
	}
}

/* Multiply a vector by a constant */
func scale_vector32_Q26_lshift_18(tls *libc.TLS, data1 uintptr, gain_Q26 int32, dataSize int32) { /* scale_vector.c:31:6: */
	var i int32

	for i = 0; i < dataSize; i++ {
		*(*int32)(unsafe.Pointer(data1 + uintptr(i)*4)) = (int32(((int64_t(*(*int32)(unsafe.Pointer(data1 + uintptr(i)*4)))) * (int64_t(gain_Q26))) >> (8))) // OUTPUT: Q18
	}
}

/* Faster than schur64(), but much less accurate.                       */
/* uses SMLAWB(), requiring armv5E and higher.                          */
func schur(tls *libc.TLS, rc_Q15 uintptr, c uintptr, order int32) int32 { /* schur.c:40:11: */
	bp := tls.Alloc(136)
	defer tls.Free(136)

	var k int32
	var n int32
	var lz int32
	// var C [17][2]int32 at bp, 136

	var Ctmp1 int32
	var Ctmp2 int32
	var rc_tmp_Q15 int32

	/* Get number of leading zeros */
	lz = CLZ32(tls, *(*int32)(unsafe.Pointer(c)))

	/* Copy correlations and adjust level to Q30 */
	if lz < 2 {
		/* lz must be 1, so shift one to the right */
		for k = 0; k < (order + 1); k++ {
			*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(k)*8))) = libc.AssignPtrInt32((bp /* &C */ +uintptr(k)*8)+1*4, ((*(*int32)(unsafe.Pointer(c + uintptr(k)*4))) >> (1)))
		}
	} else if lz > 2 {
		/* Shift to the left */
		lz = lz - (2)
		for k = 0; k < (order + 1); k++ {
			*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(k)*8))) = libc.AssignPtrInt32((bp /* &C */ +uintptr(k)*8)+1*4, ((*(*int32)(unsafe.Pointer(c + uintptr(k)*4))) << (lz)))
		}
	} else {
		/* No need to shift */
		for k = 0; k < (order + 1); k++ {
			*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(k)*8))) = libc.AssignPtrInt32((bp /* &C */ +uintptr(k)*8)+1*4, *(*int32)(unsafe.Pointer(c + uintptr(k)*4)))
		}
	}

	for k = 0; k < order; k++ {

		/* Get reflection coefficient */
		rc_tmp_Q15 = -((*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr((k+1))*8)))) / (max_32(tls, ((*(*int32)(unsafe.Pointer((bp /* &C[0] */) + 1*4))) >> (15)), 1)))

		/* Clip (shouldn't happen for properly conditioned inputs) */
		rc_tmp_Q15 = func() int32 {
			if (rc_tmp_Q15) > 0x7FFF {
				return 0x7FFF
			}
			return func() int32 {
				if (rc_tmp_Q15) < (int32(libc.Int16FromInt32(0x8000))) {
					return int32(libc.Int16FromInt32(0x8000))
				}
				return rc_tmp_Q15
			}()
		}()

		/* Store */
		*(*int16)(unsafe.Pointer(rc_Q15 + uintptr(k)*2)) = int16(rc_tmp_Q15)

		/* Update correlations */
		for n = 0; n < (order - k); n++ {
			Ctmp1 = *(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(((n+k)+1))*8)))
			Ctmp2 = *(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(n)*8) + 1*4))
			*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(((n+k)+1))*8))) = ((Ctmp1) + (((((Ctmp2) << (1)) >> 16) * (int32(int16(rc_tmp_Q15)))) + (((((Ctmp2) << (1)) & 0x0000FFFF) * (int32(int16(rc_tmp_Q15)))) >> 16)))
			*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(n)*8) + 1*4)) = ((Ctmp2) + (((((Ctmp1) << (1)) >> 16) * (int32(int16(rc_tmp_Q15)))) + (((((Ctmp1) << (1)) & 0x0000FFFF) * (int32(int16(rc_tmp_Q15)))) >> 16)))
		}
	}

	/* return residual energy */
	return *(*int32)(unsafe.Pointer((bp /* &C[0] */) + 1*4))
}

/* Slower than schur(), but more accurate.                              */
/* Uses SMULL(), available on armv4                                     */
func schur64(tls *libc.TLS, rc_Q16 uintptr, c uintptr, order int32) int32 { /* schur64.c:41:11: */
	bp := tls.Alloc(136)
	defer tls.Free(136)

	var k int32
	var n int32
	// var C [17][2]int32 at bp, 136

	var Ctmp1_Q30 int32
	var Ctmp2_Q30 int32
	var rc_tmp_Q31 int32

	/* Check for invalid input */
	if *(*int32)(unsafe.Pointer(c)) <= 0 {
		libc.Xmemset(tls, rc_Q16, 0, (uint32(order) * uint32(unsafe.Sizeof(int32(0)))))
		return 0
	}

	for k = 0; k < (order + 1); k++ {
		*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(k)*8))) = libc.AssignPtrInt32((bp /* &C */ +uintptr(k)*8)+1*4, *(*int32)(unsafe.Pointer(c + uintptr(k)*4)))
	}

	for k = 0; k < order; k++ {
		/* Get reflection coefficient: divide two Q30 values and get result in Q31 */
		rc_tmp_Q31 = DIV32_varQ(tls, -*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr((k+1))*8))), *(*int32)(unsafe.Pointer((bp /* &C[0] */) + 1*4)), 31)

		/* Save the output */
		*(*int32)(unsafe.Pointer(rc_Q16 + uintptr(k)*4)) = func() int32 {
			if (15) == 1 {
				return (((rc_tmp_Q31) >> 1) + ((rc_tmp_Q31) & 1))
			}
			return ((((rc_tmp_Q31) >> ((15) - 1)) + 1) >> 1)
		}()

		/* Update correlations */
		for n = 0; n < (order - k); n++ {
			Ctmp1_Q30 = *(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(((n+k)+1))*8)))
			Ctmp2_Q30 = *(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(n)*8) + 1*4))

			/* Multiply and add the highest int32 */
			*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(((n+k)+1))*8))) = (Ctmp1_Q30 + (int32(((int64_t((Ctmp2_Q30) << (1))) * (int64_t(rc_tmp_Q31))) >> (32))))
			*(*int32)(unsafe.Pointer((bp /* &C[0] */ + uintptr(n)*8) + 1*4)) = (Ctmp2_Q30 + (int32(((int64_t((Ctmp1_Q30) << (1))) * (int64_t(rc_tmp_Q31))) >> (32))))
		}
	}

	return *(*int32)(unsafe.Pointer((bp /* &C[0] */) + 1*4))
}

/* shell coder; pulse-subframe length is hardcoded */

func combine_pulses(tls *libc.TLS, out uintptr, in uintptr, len int32) { /* shell_coder.c:32:17: */
	var k int32
	for k = 0; k < len; k++ {
		*(*int32)(unsafe.Pointer(out + uintptr(k)*4)) = (*(*int32)(unsafe.Pointer(in + uintptr((2*k))*4)) + *(*int32)(unsafe.Pointer(in + uintptr(((2*k)+1))*4)))
	}
}

func encode_split(tls *libc.TLS, sRC uintptr, p_child1 int32, p int32, shell_table uintptr) { /* shell_coder.c:44:17: */
	var cdf uintptr

	if p > 0 {
		cdf = (shell_table + uintptr(shell_code_table_offsets[p])*2)
		range_encoder(tls, sRC, p_child1, cdf)
	}
}

func decode_split(tls *libc.TLS, p_child1 uintptr, p_child2 uintptr, sRC uintptr, p int32, shell_table uintptr) { /* shell_coder.c:59:17: */
	var cdf_middle int32
	var cdf uintptr

	if p > 0 {
		cdf_middle = ((p) >> (1))
		cdf = (shell_table + uintptr(shell_code_table_offsets[p])*2)
		range_decoder(tls, p_child1, sRC, cdf, cdf_middle)
		*(*int32)(unsafe.Pointer(p_child2)) = (p - *(*int32)(unsafe.Pointer(p_child1)))
	} else {
		*(*int32)(unsafe.Pointer(p_child1)) = 0
		*(*int32)(unsafe.Pointer(p_child2)) = 0
	}
}

/* Shell encoder, operates on one shell code frame of 16 pulses */
func shell_encoder(tls *libc.TLS, sRC uintptr, pulses0 uintptr) { /* shell_coder.c:82:6: */
	bp := tls.Alloc(60)
	defer tls.Free(60)

	// var pulses1 [8]int32 at bp, 32

	// var pulses2 [4]int32 at bp+32, 16

	// var pulses3 [2]int32 at bp+48, 8

	// var pulses4 [1]int32 at bp+56, 4

	/* this function operates on one shell code frame of 16 pulses */

	/* tree representation per pulse-subframe */
	combine_pulses(tls, bp /* &pulses1[0] */, pulses0, 8)
	combine_pulses(tls, bp+32 /* &pulses2[0] */, bp /* &pulses1[0] */, 4)
	combine_pulses(tls, bp+48 /* &pulses3[0] */, bp+32 /* &pulses2[0] */, 2)
	combine_pulses(tls, bp+56 /* &pulses4[0] */, bp+48 /* &pulses3[0] */, 1)

	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(bp + 48 /* &pulses3[0] */)), *(*int32)(unsafe.Pointer(bp + 56 /* &pulses4[0] */)), uintptr(unsafe.Pointer(&shell_code_table3)))

	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(bp + 32 /* &pulses2[0] */)), *(*int32)(unsafe.Pointer(bp + 48 /* &pulses3[0] */)), uintptr(unsafe.Pointer(&shell_code_table2)))

	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */)), *(*int32)(unsafe.Pointer(bp + 32 /* &pulses2[0] */)), uintptr(unsafe.Pointer(&shell_code_table1)))
	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(pulses0)), *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */)), uintptr(unsafe.Pointer(&shell_code_table0)))
	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(pulses0 + 2*4)), *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 1*4)), uintptr(unsafe.Pointer(&shell_code_table0)))

	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 2*4)), *(*int32)(unsafe.Pointer(bp + 32 /* &pulses2[0] */ + 1*4)), uintptr(unsafe.Pointer(&shell_code_table1)))
	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(pulses0 + 4*4)), *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 2*4)), uintptr(unsafe.Pointer(&shell_code_table0)))
	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(pulses0 + 6*4)), *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 3*4)), uintptr(unsafe.Pointer(&shell_code_table0)))

	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(bp + 32 /* &pulses2[0] */ + 2*4)), *(*int32)(unsafe.Pointer(bp + 48 /* &pulses3[0] */ + 1*4)), uintptr(unsafe.Pointer(&shell_code_table2)))

	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 4*4)), *(*int32)(unsafe.Pointer(bp + 32 /* &pulses2[0] */ + 2*4)), uintptr(unsafe.Pointer(&shell_code_table1)))
	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(pulses0 + 8*4)), *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 4*4)), uintptr(unsafe.Pointer(&shell_code_table0)))
	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(pulses0 + 10*4)), *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 5*4)), uintptr(unsafe.Pointer(&shell_code_table0)))

	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 6*4)), *(*int32)(unsafe.Pointer(bp + 32 /* &pulses2[0] */ + 3*4)), uintptr(unsafe.Pointer(&shell_code_table1)))
	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(pulses0 + 12*4)), *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 6*4)), uintptr(unsafe.Pointer(&shell_code_table0)))
	encode_split(tls, sRC, *(*int32)(unsafe.Pointer(pulses0 + 14*4)), *(*int32)(unsafe.Pointer(bp /* &pulses1[0] */ + 7*4)), uintptr(unsafe.Pointer(&shell_code_table0)))
}

/* Shell decoder, operates on one shell code frame of 16 pulses */
func shell_decoder(tls *libc.TLS, pulses0 uintptr, sRC uintptr, pulses4 int32) { /* shell_coder.c:123:6: */
	bp := tls.Alloc(56)
	defer tls.Free(56)

	// var pulses3 [2]int32 at bp, 8

	// var pulses2 [4]int32 at bp+8, 16

	// var pulses1 [8]int32 at bp+24, 32

	/* this function operates on one shell code frame of 16 pulses */

	decode_split(tls, (bp /* &pulses3 */), (bp /* &pulses3 */ + 1*4), sRC, pulses4, uintptr(unsafe.Pointer(&shell_code_table3)))

	decode_split(tls, (bp + 8 /* &pulses2 */), (bp + 8 /* &pulses2 */ + 1*4), sRC, *(*int32)(unsafe.Pointer(bp /* &pulses3[0] */)), uintptr(unsafe.Pointer(&shell_code_table2)))

	decode_split(tls, (bp + 24 /* &pulses1 */), (bp + 24 /* &pulses1 */ + 1*4), sRC, *(*int32)(unsafe.Pointer(bp + 8 /* &pulses2[0] */)), uintptr(unsafe.Pointer(&shell_code_table1)))
	decode_split(tls, (pulses0), (pulses0 + 1*4), sRC, *(*int32)(unsafe.Pointer(bp + 24 /* &pulses1[0] */)), uintptr(unsafe.Pointer(&shell_code_table0)))
	decode_split(tls, (pulses0 + 2*4), (pulses0 + 3*4), sRC, *(*int32)(unsafe.Pointer(bp + 24 /* &pulses1[0] */ + 1*4)), uintptr(unsafe.Pointer(&shell_code_table0)))

	decode_split(tls, (bp + 24 /* &pulses1 */ + 2*4), (bp + 24 /* &pulses1 */ + 3*4), sRC, *(*int32)(unsafe.Pointer(bp + 8 /* &pulses2[0] */ + 1*4)), uintptr(unsafe.Pointer(&shell_code_table1)))
	decode_split(tls, (pulses0 + 4*4), (pulses0 + 5*4), sRC, *(*int32)(unsafe.Pointer(bp + 24 /* &pulses1[0] */ + 2*4)), uintptr(unsafe.Pointer(&shell_code_table0)))
	decode_split(tls, (pulses0 + 6*4), (pulses0 + 7*4), sRC, *(*int32)(unsafe.Pointer(bp + 24 /* &pulses1[0] */ + 3*4)), uintptr(unsafe.Pointer(&shell_code_table0)))

	decode_split(tls, (bp + 8 /* &pulses2 */ + 2*4), (bp + 8 /* &pulses2 */ + 3*4), sRC, *(*int32)(unsafe.Pointer(bp /* &pulses3[0] */ + 1*4)), uintptr(unsafe.Pointer(&shell_code_table2)))

	decode_split(tls, (bp + 24 /* &pulses1 */ + 4*4), (bp + 24 /* &pulses1 */ + 5*4), sRC, *(*int32)(unsafe.Pointer(bp + 8 /* &pulses2[0] */ + 2*4)), uintptr(unsafe.Pointer(&shell_code_table1)))
	decode_split(tls, (pulses0 + 8*4), (pulses0 + 9*4), sRC, *(*int32)(unsafe.Pointer(bp + 24 /* &pulses1[0] */ + 4*4)), uintptr(unsafe.Pointer(&shell_code_table0)))
	decode_split(tls, (pulses0 + 10*4), (pulses0 + 11*4), sRC, *(*int32)(unsafe.Pointer(bp + 24 /* &pulses1[0] */ + 5*4)), uintptr(unsafe.Pointer(&shell_code_table0)))

	decode_split(tls, (bp + 24 /* &pulses1 */ + 6*4), (bp + 24 /* &pulses1 */ + 7*4), sRC, *(*int32)(unsafe.Pointer(bp + 8 /* &pulses2[0] */ + 3*4)), uintptr(unsafe.Pointer(&shell_code_table1)))
	decode_split(tls, (pulses0 + 12*4), (pulses0 + 13*4), sRC, *(*int32)(unsafe.Pointer(bp + 24 /* &pulses1[0] */ + 6*4)), uintptr(unsafe.Pointer(&shell_code_table0)))
	decode_split(tls, (pulses0 + 14*4), (pulses0 + 15*4), sRC, *(*int32)(unsafe.Pointer(bp + 24 /* &pulses1[0] */ + 7*4)), uintptr(unsafe.Pointer(&shell_code_table0)))
}

/********************************/
/* approximate sigmoid function */
/********************************/
/* fprintf(1, '%d, ', round(1024 * ([1 ./ (1 + exp(-(1:5))), 1] - 1 ./ (1 + exp(-(0:5)))))); */
var sigm_LUT_slope_Q10 = [6]int32{
	237, 153, 73, 30, 12, 7,
} /* sigm_Q15.c:41:24 */
/* fprintf(1, '%d, ', round(32767 * 1 ./ (1 + exp(-(0:5))))); */
var sigm_LUT_pos_Q15 = [6]int32{
	16384, 23955, 28861, 31213, 32178, 32548,
} /* sigm_Q15.c:45:24 */
/* fprintf(1, '%d, ', round(32767 * 1 ./ (1 + exp((0:5))))); */
var sigm_LUT_neg_Q15 = [6]int32{
	16384, 8812, 3906, 1554, 589, 219,
} /* sigm_Q15.c:49:24 */

func sigm_Q15(tls *libc.TLS, in_Q5 int32) int32 { /* sigm_Q15.c:53:9: */
	var ind int32

	if in_Q5 < 0 {
		/* Negative input */
		in_Q5 = -in_Q5
		if in_Q5 >= (6 * 32) {
			return 0 /* Clip */
		} else {
			/* Linear interpolation of look up table */
			ind = ((in_Q5) >> (5))
			return (sigm_LUT_neg_Q15[ind] - ((int32(int16(sigm_LUT_slope_Q10[ind]))) * (int32((int16(in_Q5 & 0x1F))))))
		}
	} else {
		/* Positive input */
		if in_Q5 >= (6 * 32) {
			return 32767 /* clip */
		} else {
			/* Linear interpolation of look up table */
			ind = ((in_Q5) >> (5))
			return (sigm_LUT_pos_Q15[ind] + ((int32(int16(sigm_LUT_slope_Q10[ind]))) * (int32((int16(in_Q5 & 0x1F))))))
		}
	}
	return int32(0)
}

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*******************/
/* Pitch estimator */
/*******************/

/* Level of noise floor for whitening filter LPC analysis in pitch analysis */

/* Bandwidth expansion for whitening filter in pitch analysis */

/* Threshold used by pitch estimator for early escape */

/*********************/
/* Linear prediction */
/*********************/

/* LPC analysis defines: regularization and bandwidth expansion */

/* LTP analysis defines */

/* LTP quantization settings */

/***********************/
/* High pass filtering */
/***********************/

/* Smoothing parameters for low end of pitch frequency range estimation */

/* Min and max values for low end of pitch frequency range estimation */

/* Max absolute difference between log2 of pitch frequency and smoother state, to enter the smoother */

/***********/
/* Various */
/***********/

/* Required speech activity for counting frame as active */

/* Speech Activity LBRR enable threshold (needs tuning) */

/*************************/
/* Perceptual parameters */
/*************************/

/* reduction in coding SNR during low speech activity */

/* factor for reducing quantization noise during voiced speech */

/* factor for reducing quantization noise for unvoiced sparse signals */

/* threshold for sparseness measure above which to use lower quantization offset during unvoiced */

/* warping control */

/* fraction added to first autocorrelation value */

/* noise shaping filter chirp factor */

/* difference between chirp factors for analysis and synthesis noise shaping filters at low bitrates */

/* gain reduction for fricatives */

/* extra harmonic boosting (signal shaping) at low bitrates */

/* extra harmonic boosting (signal shaping) for noisy input signals */

/* harmonic noise shaping */

/* extra harmonic noise shaping for high bitrates or noisy input */

/* parameter for shaping noise towards higher frequencies */

/* parameter for shaping noise even more towards higher frequencies during voiced speech */

/* parameter for applying a high-pass tilt to the input signal */

/* parameter for extra high-pass tilt to the input signal at high rates */

/* parameter for reducing noise at the very low frequencies */

/* less reduction of noise at the very low frequencies for signals with low SNR at low frequencies */

/* noise floor to put a lower limit on the quantization step size */

/* noise floor relative to active speech gain level */

/* subframe smoothing coefficient for determining active speech gain level (lower -> more smoothing) */

/* subframe smoothing coefficient for HarmBoost, HarmShapeGain, Tilt (lower -> more smoothing) */

/* parameters defining the R/D tradeoff in the residual quantizer */

/*****************************/
/* Internal function headers */
/*****************************/

type inv_D_t struct {
	FQ36_part int32
	FQ48_part int32
} /* solve_LS_FIX.c:38:3 */

/* Solves Ax = b, assuming A is symmetric */
func solve_LDL_FIX(tls *libc.TLS, A uintptr, M int32, b uintptr, x_Q16 uintptr) { /* solve_LS_FIX.c:71:6: */
	bp := tls.Alloc(1216)
	defer tls.Free(1216)

	// var L_Q16 [256]int32 at bp, 1024

	// var Y [16]int32 at bp+1152, 64

	// var inv_D [16]inv_D_t at bp+1024, 128

	/***************************************************
	  Factorize A by LDL such that A = L*D*L',
	  where L is lower triangular with ones on diagonal
	  ****************************************************/
	LDL_factorize_FIX(tls, A, M, bp /* &L_Q16[0] */, bp+1024 /* &inv_D[0] */)

	/****************************************************
	  * substitute D*L'*x = Y. ie:
	  L*D*L'*x = b => L*Y = b <=> Y = inv(L)*b
	  ******************************************************/
	LS_SolveFirst_FIX(tls, bp /* &L_Q16[0] */, M, b, bp+1152 /* &Y[0] */)

	/****************************************************
	  D*L'*x = Y <=> L'*x = inv(D)*Y, because D is
	  diagonal just multiply with 1/d_i
	  ****************************************************/
	LS_divide_Q16_FIX(tls, bp+1152 /* &Y[0] */, bp+1024 /* &inv_D[0] */, M)

	/****************************************************
	  x = inv(L') * inv(D) * Y
	  *****************************************************/
	LS_SolveLast_FIX(tls, bp /* &L_Q16[0] */, M, bp+1152 /* &Y[0] */, x_Q16)
}

func LDL_factorize_FIX(tls *libc.TLS, A uintptr, M int32, L_Q16 uintptr, inv_D uintptr) { /* solve_LS_FIX.c:108:17: */
	bp := tls.Alloc(128)
	defer tls.Free(128)

	var i int32
	var j int32
	var k int32
	var status int32
	var loop_count int32
	var ptr1 uintptr
	var ptr2 uintptr
	var diag_min_value int32
	var tmp_32 int32
	var err int32
	// var v_Q0 [16]int32 at bp, 64

	// var D_Q0 [16]int32 at bp+64, 64

	var one_div_diag_Q36 int32
	var one_div_diag_Q40 int32
	var one_div_diag_Q48 int32

	status = 1
	diag_min_value = max_32(tls, (int32(((func() int64 {
		if ((uint32((*(*int32)(unsafe.Pointer(A))) + (*(*int32)(unsafe.Pointer(A + uintptr((((int32(int16(M)))*(int32(int16(M))))-1))*4))))) & 0x80000000) == uint32(0) {
			return func() int64 {
				if ((uint32((*(*int32)(unsafe.Pointer(A))) & (*(*int32)(unsafe.Pointer(A + uintptr((((int32(int16(M)))*(int32(int16(M))))-1))*4))))) & 0x80000000) != uint32(0) {
					return int64(libc.Int32FromUint32(0x80000000))
				}
				return (int64((*(*int32)(unsafe.Pointer(A))) + (*(*int32)(unsafe.Pointer(A + uintptr((((int32(int16(M)))*(int32(int16(M))))-1))*4)))))
			}()
		}
		return func() int64 {
			if ((uint32((*(*int32)(unsafe.Pointer(A))) | (*(*int32)(unsafe.Pointer(A + uintptr((((int32(int16(M)))*(int32(int16(M))))-1))*4))))) & 0x80000000) == uint32(0) {
				return int64(0x7FFFFFFF)
			}
			return (int64((*(*int32)(unsafe.Pointer(A))) + (*(*int32)(unsafe.Pointer(A + uintptr((((int32(int16(M)))*(int32(int16(M))))-1))*4)))))
		}()
	}()) * (int64_t(FIX_CONST(tls, 1e-5, 31)))) >> (32))), (int32(1) << 9))
	for loop_count = 0; (loop_count < M) && (status == 1); loop_count++ {
		status = 0
		for j = 0; j < M; j++ {
			ptr1 = (L_Q16 + uintptr((((j)*(M))+(0)))*4)
			tmp_32 = 0
			for i = 0; i < j; i++ {
				*(*int32)(unsafe.Pointer(bp /* &v_Q0[0] */ + uintptr(i)*4)) = (((((*(*int32)(unsafe.Pointer(bp + 64 /* &D_Q0[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp + 64 /* &D_Q0[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4)))))) >> 16)) + ((*(*int32)(unsafe.Pointer(bp + 64 /* &D_Q0[0] */ + uintptr(i)*4))) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
				}()))) /* Q0 */
				tmp_32 = (((tmp_32) + ((((*(*int32)(unsafe.Pointer(bp /* &v_Q0[0] */ + uintptr(i)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp /* &v_Q0[0] */ + uintptr(i)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4)))))) >> 16))) + ((*(*int32)(unsafe.Pointer(bp /* &v_Q0[0] */ + uintptr(i)*4))) * (func() int32 {
					if (16) == 1 {
						return (((*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4))) & 1))
					}
					return ((((*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4))) >> ((16) - 1)) + 1) >> 1)
				}()))) /* Q0 */
			}
			tmp_32 = ((*(*int32)(unsafe.Pointer((A + uintptr((((j)*(M))+(j)))*4)))) - (tmp_32))

			if tmp_32 < diag_min_value {
				tmp_32 = (((int32((int16(loop_count + 1)))) * (int32(int16(diag_min_value)))) - (tmp_32))
				/* Matrix not positive semi-definite, or ill conditioned */
				for i = 0; i < M; i++ {
					*(*int32)(unsafe.Pointer((A + uintptr((((i)*(M))+(i)))*4))) = ((*(*int32)(unsafe.Pointer((A + uintptr((((i)*(M))+(i)))*4)))) + (tmp_32))
				}
				status = 1
				break
			}
			*(*int32)(unsafe.Pointer(bp + 64 /* &D_Q0[0] */ + uintptr(j)*4)) = tmp_32 /* always < max(Correlation) */

			/* two-step division */
			one_div_diag_Q36 = INVERSE32_varQ(tls, tmp_32, 36) /* Q36 */
			one_div_diag_Q40 = ((one_div_diag_Q36) << (4))     /* Q40 */
			err = ((int32(1) << 24) - (((((tmp_32) >> 16) * (int32(int16(one_div_diag_Q40)))) + ((((tmp_32) & 0x0000FFFF) * (int32(int16(one_div_diag_Q40)))) >> 16)) + ((tmp_32) * (func() int32 {
				if (16) == 1 {
					return (((one_div_diag_Q40) >> 1) + ((one_div_diag_Q40) & 1))
				}
				return ((((one_div_diag_Q40) >> ((16) - 1)) + 1) >> 1)
			}())))) /* Q24 */
			one_div_diag_Q48 = (((((err) >> 16) * (int32(int16(one_div_diag_Q40)))) + ((((err) & 0x0000FFFF) * (int32(int16(one_div_diag_Q40)))) >> 16)) + ((err) * (func() int32 {
				if (16) == 1 {
					return (((one_div_diag_Q40) >> 1) + ((one_div_diag_Q40) & 1))
				}
				return ((((one_div_diag_Q40) >> ((16) - 1)) + 1) >> 1)
			}()))) /* Q48 */

			/* Save 1/Ds */
			(*inv_D_t)(unsafe.Pointer(inv_D + uintptr(j)*8)).FQ36_part = one_div_diag_Q36
			(*inv_D_t)(unsafe.Pointer(inv_D + uintptr(j)*8)).FQ48_part = one_div_diag_Q48

			*(*int32)(unsafe.Pointer((L_Q16 + uintptr((((j)*(M))+(j)))*4))) = 65536 /* 1.0 in Q16 */
			ptr1 = (A + uintptr((((j)*(M))+(0)))*4)
			ptr2 = (L_Q16 + uintptr((((j+1)*(M))+(0)))*4)
			for i = (j + 1); i < M; i++ {
				tmp_32 = 0
				for k = 0; k < j; k++ {
					tmp_32 = (((tmp_32) + ((((*(*int32)(unsafe.Pointer(bp /* &v_Q0[0] */ + uintptr(k)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(ptr2 + uintptr(k)*4)))))) + ((((*(*int32)(unsafe.Pointer(bp /* &v_Q0[0] */ + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(ptr2 + uintptr(k)*4)))))) >> 16))) + ((*(*int32)(unsafe.Pointer(bp /* &v_Q0[0] */ + uintptr(k)*4))) * (func() int32 {
						if (16) == 1 {
							return (((*(*int32)(unsafe.Pointer(ptr2 + uintptr(k)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(ptr2 + uintptr(k)*4))) & 1))
						}
						return ((((*(*int32)(unsafe.Pointer(ptr2 + uintptr(k)*4))) >> ((16) - 1)) + 1) >> 1)
					}()))) /* Q0 */
				}
				tmp_32 = ((*(*int32)(unsafe.Pointer(ptr1 + uintptr(i)*4))) - (tmp_32)) /* always < max(Correlation) */

				/* tmp_32 / D_Q0[j] : Divide to Q16 */
				*(*int32)(unsafe.Pointer((L_Q16 + uintptr((((i)*(M))+(j)))*4))) = ((int32(((int64_t(tmp_32)) * (int64_t(one_div_diag_Q48))) >> (32))) + ((((((tmp_32) >> 16) * (int32(int16(one_div_diag_Q36)))) + ((((tmp_32) & 0x0000FFFF) * (int32(int16(one_div_diag_Q36)))) >> 16)) + ((tmp_32) * (func() int32 {
					if (16) == 1 {
						return (((one_div_diag_Q36) >> 1) + ((one_div_diag_Q36) & 1))
					}
					return ((((one_div_diag_Q36) >> ((16) - 1)) + 1) >> 1)
				}()))) >> (4)))

				/* go to next column */
				ptr2 += 4 * (uintptr(M))
			}
		}
	}

}

func LS_divide_Q16_FIX(tls *libc.TLS, T uintptr, inv_D uintptr, M int32) { /* solve_LS_FIX.c:180:17: */
	var i int32
	var tmp_32 int32
	var one_div_diag_Q36 int32
	var one_div_diag_Q48 int32

	for i = 0; i < M; i++ {
		one_div_diag_Q36 = (*inv_D_t)(unsafe.Pointer(inv_D + uintptr(i)*8)).FQ36_part
		one_div_diag_Q48 = (*inv_D_t)(unsafe.Pointer(inv_D + uintptr(i)*8)).FQ48_part

		tmp_32 = *(*int32)(unsafe.Pointer(T + uintptr(i)*4))
		*(*int32)(unsafe.Pointer(T + uintptr(i)*4)) = ((int32(((int64_t(tmp_32)) * (int64_t(one_div_diag_Q48))) >> (32))) + ((((((tmp_32) >> 16) * (int32(int16(one_div_diag_Q36)))) + ((((tmp_32) & 0x0000FFFF) * (int32(int16(one_div_diag_Q36)))) >> 16)) + ((tmp_32) * (func() int32 {
			if (16) == 1 {
				return (((one_div_diag_Q36) >> 1) + ((one_div_diag_Q36) & 1))
			}
			return ((((one_div_diag_Q36) >> ((16) - 1)) + 1) >> 1)
		}()))) >> (4)))
	}
}

/* Solve Lx = b, when L is lower triangular and has ones on the diagonal */
func LS_SolveFirst_FIX(tls *libc.TLS, L_Q16 uintptr, M int32, b uintptr, x_Q16 uintptr) { /* solve_LS_FIX.c:200:17: */
	var i int32
	var j int32
	var ptr32 uintptr
	var tmp_32 int32

	for i = 0; i < M; i++ {
		ptr32 = (L_Q16 + uintptr((((i)*(M))+(0)))*4)
		tmp_32 = 0
		for j = 0; j < i; j++ {
			tmp_32 = (((tmp_32) + ((((*(*int32)(unsafe.Pointer(ptr32 + uintptr(j)*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4)))))) + ((((*(*int32)(unsafe.Pointer(ptr32 + uintptr(j)*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4)))))) >> 16))) + ((*(*int32)(unsafe.Pointer(ptr32 + uintptr(j)*4))) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}
		*(*int32)(unsafe.Pointer(x_Q16 + uintptr(i)*4)) = ((*(*int32)(unsafe.Pointer(b + uintptr(i)*4))) - (tmp_32))
	}
}

/* Solve L^t*x = b, where L is lower triangular with ones on the diagonal */
func LS_SolveLast_FIX(tls *libc.TLS, L_Q16 uintptr, M int32, b uintptr, x_Q16 uintptr) { /* solve_LS_FIX.c:222:17: */
	var i int32
	var j int32
	var ptr32 uintptr
	var tmp_32 int32

	for i = (M - 1); i >= 0; i-- {
		ptr32 = (L_Q16 + uintptr((((0)*(M))+(i)))*4)
		tmp_32 = 0
		for j = (M - 1); j > i; j-- {
			tmp_32 = (((tmp_32) + ((((*(*int32)(unsafe.Pointer(ptr32 + uintptr(((int32(int16(j)))*(int32(int16(M)))))*4))) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4)))))) + ((((*(*int32)(unsafe.Pointer(ptr32 + uintptr(((int32(int16(j)))*(int32(int16(M)))))*4))) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4)))))) >> 16))) + ((*(*int32)(unsafe.Pointer(ptr32 + uintptr(((int32(int16(j)))*(int32(int16(M)))))*4))) * (func() int32 {
				if (16) == 1 {
					return (((*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4))) >> 1) + ((*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4))) & 1))
				}
				return ((((*(*int32)(unsafe.Pointer(x_Q16 + uintptr(j)*4))) >> ((16) - 1)) + 1) >> 1)
			}())))
		}
		*(*int32)(unsafe.Pointer(x_Q16 + uintptr(i)*4)) = ((*(*int32)(unsafe.Pointer(b + uintptr(i)*4))) - (tmp_32))
	}
}

func insertion_sort_increasing(tls *libc.TLS, a uintptr, index uintptr, L int32, K int32) { /* sort.c:34:6: */
	var value int32
	var i int32
	var j int32

	/* Safety checks */

	/* Write start indices in index vector */
	for i = 0; i < K; i++ {
		*(*int32)(unsafe.Pointer(index + uintptr(i)*4)) = i
	}

	/* Sort vector elements by value, increasing order */
	for i = 1; i < K; i++ {
		value = *(*int32)(unsafe.Pointer(a + uintptr(i)*4))
		for j = (i - 1); (j >= 0) && (value < *(*int32)(unsafe.Pointer(a + uintptr(j)*4))); j-- {
			*(*int32)(unsafe.Pointer(a + uintptr((j+1))*4)) = *(*int32)(unsafe.Pointer(a + uintptr(j)*4))         /* Shift value */
			*(*int32)(unsafe.Pointer(index + uintptr((j+1))*4)) = *(*int32)(unsafe.Pointer(index + uintptr(j)*4)) /* Shift index */
		}
		*(*int32)(unsafe.Pointer(a + uintptr((j+1))*4)) = value /* Write value */
		*(*int32)(unsafe.Pointer(index + uintptr((j+1))*4)) = i /* Write index */
	}

	/* If less than L values are asked for, check the remaining values, */
	/* but only spend CPU to ensure that the K first values are correct */
	for i = K; i < L; i++ {
		value = *(*int32)(unsafe.Pointer(a + uintptr(i)*4))
		if value < *(*int32)(unsafe.Pointer(a + uintptr((K-1))*4)) {
			for j = (K - 2); (j >= 0) && (value < *(*int32)(unsafe.Pointer(a + uintptr(j)*4))); j-- {
				*(*int32)(unsafe.Pointer(a + uintptr((j+1))*4)) = *(*int32)(unsafe.Pointer(a + uintptr(j)*4))         /* Shift value */
				*(*int32)(unsafe.Pointer(index + uintptr((j+1))*4)) = *(*int32)(unsafe.Pointer(index + uintptr(j)*4)) /* Shift index */
			}
			*(*int32)(unsafe.Pointer(a + uintptr((j+1))*4)) = value /* Write value */
			*(*int32)(unsafe.Pointer(index + uintptr((j+1))*4)) = i /* Write index */
		}
	}
}

func insertion_sort_decreasing_int16(tls *libc.TLS, a uintptr, index uintptr, L int32, K int32) { /* sort.c:80:6: */
	var i int32
	var j int32
	var value int32

	/* Safety checks */

	/* Write start indices in index vector */
	for i = 0; i < K; i++ {
		*(*int32)(unsafe.Pointer(index + uintptr(i)*4)) = i
	}

	/* Sort vector elements by value, decreasing order */
	for i = 1; i < K; i++ {
		value = int32(*(*int16)(unsafe.Pointer(a + uintptr(i)*2)))
		for j = (i - 1); (j >= 0) && (value > int32(*(*int16)(unsafe.Pointer(a + uintptr(j)*2)))); j-- {
			*(*int16)(unsafe.Pointer(a + uintptr((j+1))*2)) = *(*int16)(unsafe.Pointer(a + uintptr(j)*2))         /* Shift value */
			*(*int32)(unsafe.Pointer(index + uintptr((j+1))*4)) = *(*int32)(unsafe.Pointer(index + uintptr(j)*4)) /* Shift index */
		}
		*(*int16)(unsafe.Pointer(a + uintptr((j+1))*2)) = int16(value) /* Write value */
		*(*int32)(unsafe.Pointer(index + uintptr((j+1))*4)) = i        /* Write index */
	}

	/* If less than L values are asked for, check the remaining values, */
	/* but only spend CPU to ensure that the K first values are correct */
	for i = K; i < L; i++ {
		value = int32(*(*int16)(unsafe.Pointer(a + uintptr(i)*2)))
		if value > int32(*(*int16)(unsafe.Pointer(a + uintptr((K-1))*2))) {
			for j = (K - 2); (j >= 0) && (value > int32(*(*int16)(unsafe.Pointer(a + uintptr(j)*2)))); j-- {
				*(*int16)(unsafe.Pointer(a + uintptr((j+1))*2)) = *(*int16)(unsafe.Pointer(a + uintptr(j)*2))         /* Shift value */
				*(*int32)(unsafe.Pointer(index + uintptr((j+1))*4)) = *(*int32)(unsafe.Pointer(index + uintptr(j)*4)) /* Shift index */
			}
			*(*int16)(unsafe.Pointer(a + uintptr((j+1))*2)) = int16(value) /* Write value */
			*(*int32)(unsafe.Pointer(index + uintptr((j+1))*4)) = i        /* Write index */
		}
	}
}

func insertion_sort_increasing_all_values(tls *libc.TLS, a uintptr, L int32) { /* sort.c:126:6: */
	var value int32
	var i int32
	var j int32

	/* Safety checks */

	/* Sort vector elements by value, increasing order */
	for i = 1; i < L; i++ {
		value = *(*int32)(unsafe.Pointer(a + uintptr(i)*4))
		for j = (i - 1); (j >= 0) && (value < *(*int32)(unsafe.Pointer(a + uintptr(j)*4))); j-- {
			*(*int32)(unsafe.Pointer(a + uintptr((j+1))*4)) = *(*int32)(unsafe.Pointer(a + uintptr(j)*4)) /* Shift value */
		}
		*(*int32)(unsafe.Pointer(a + uintptr((j+1))*4)) = value /* Write value */
	}
}

/* Compute number of bits to right shift the sum of squares of a vector */
/* of int16s to make it fit in an int32                                 */
func sum_sqr_shift(tls *libc.TLS, energy uintptr, shift uintptr, x uintptr, len int32) { /* sum_sqr_shift.c:39:6: */
	var i int32
	var shft int32
	var in32 int32
	var nrg_tmp int32
	var nrg int32

	if (intptr_t(x) & 2) != 0 {
		/* Input is not 4-byte aligned */
		nrg = ((int32(*(*int16)(unsafe.Pointer(x)))) * (int32(*(*int16)(unsafe.Pointer(x)))))
		i = 1
	} else {
		nrg = 0
		i = 0
	}
	shft = 0
	len--
	for i < len {
		/* Load two values at once */
		in32 = *(*int32)(unsafe.Pointer((x + uintptr(i)*2)))
		nrg = (int32((uint32(nrg)) + (uint32((int32(int16(in32))) * (int32(int16(in32)))))))
		nrg = (int32((uint32(nrg)) + (uint32(((in32) >> 16) * ((in32) >> 16)))))
		i = i + (2)
		if nrg < 0 {
			/* Scale down */
			nrg = (int32((uint32(nrg)) >> (2)))
			shft = 2
			break
		}
	}
	for ; i < len; i = i + (2) {
		/* Load two values at once */
		in32 = *(*int32)(unsafe.Pointer((x + uintptr(i)*2)))
		nrg_tmp = ((int32(int16(in32))) * (int32(int16(in32))))
		nrg_tmp = (int32((uint32(nrg_tmp)) + (uint32(((in32) >> 16) * ((in32) >> 16)))))
		nrg = (int32((uint32(nrg)) + ((uint32(nrg_tmp)) >> (shft))))
		if nrg < 0 {
			/* Scale down */
			nrg = (int32((uint32(nrg)) >> (2)))
			shft = shft + (2)
		}
	}
	if i == len {
		/* One sample left to process */
		nrg_tmp = ((int32(*(*int16)(unsafe.Pointer(x + uintptr(i)*2)))) * (int32(*(*int16)(unsafe.Pointer(x + uintptr(i)*2)))))
		nrg = ((nrg) + ((nrg_tmp) >> (shft)))
	}

	/* Make sure to have at least one extra leading zero (two leading zeros in total) */
	if (uint32(nrg) & 0xC0000000) != 0 {
		nrg = (int32((uint32(nrg)) >> (2)))
		shft = shft + (2)
	}

	/* Output arguments */
	*(*int32)(unsafe.Pointer(shift)) = shft
	*(*int32)(unsafe.Pointer(energy)) = nrg
}

var gain_CDF = [2][65]uint16{
	{
		uint16(0), uint16(18), uint16(45), uint16(94), uint16(181), uint16(320), uint16(519), uint16(777),
		uint16(1093), uint16(1468), uint16(1909), uint16(2417), uint16(2997), uint16(3657), uint16(4404), uint16(5245),
		uint16(6185), uint16(7228), uint16(8384), uint16(9664), uint16(11069), uint16(12596), uint16(14244), uint16(16022),
		uint16(17937), uint16(19979), uint16(22121), uint16(24345), uint16(26646), uint16(29021), uint16(31454), uint16(33927),
		uint16(36438), uint16(38982), uint16(41538), uint16(44068), uint16(46532), uint16(48904), uint16(51160), uint16(53265),
		uint16(55184), uint16(56904), uint16(58422), uint16(59739), uint16(60858), uint16(61793), uint16(62568), uint16(63210),
		uint16(63738), uint16(64165), uint16(64504), uint16(64769), uint16(64976), uint16(65133), uint16(65249), uint16(65330),
		uint16(65386), uint16(65424), uint16(65451), uint16(65471), uint16(65487), uint16(65501), uint16(65513), uint16(65524),
		uint16(65535),
	},
	{
		uint16(0), uint16(214), uint16(581), uint16(1261), uint16(2376), uint16(3920), uint16(5742), uint16(7632),
		uint16(9449), uint16(11157), uint16(12780), uint16(14352), uint16(15897), uint16(17427), uint16(18949), uint16(20462),
		uint16(21957), uint16(23430), uint16(24889), uint16(26342), uint16(27780), uint16(29191), uint16(30575), uint16(31952),
		uint16(33345), uint16(34763), uint16(36200), uint16(37642), uint16(39083), uint16(40519), uint16(41930), uint16(43291),
		uint16(44602), uint16(45885), uint16(47154), uint16(48402), uint16(49619), uint16(50805), uint16(51959), uint16(53069),
		uint16(54127), uint16(55140), uint16(56128), uint16(57101), uint16(58056), uint16(58979), uint16(59859), uint16(60692),
		uint16(61468), uint16(62177), uint16(62812), uint16(63368), uint16(63845), uint16(64242), uint16(64563), uint16(64818),
		uint16(65023), uint16(65184), uint16(65306), uint16(65391), uint16(65447), uint16(65482), uint16(65505), uint16(65521),
		uint16(65535),
	},
} /* tables_gain.c:35:18 */

var gain_CDF_offset int32 = 32 /* tables_gain.c:61:15 */

var delta_gain_CDF = [46]uint16{
	uint16(0), uint16(2358), uint16(3856), uint16(7023), uint16(15376), uint16(53058), uint16(59135), uint16(61555),
	uint16(62784), uint16(63498), uint16(63949), uint16(64265), uint16(64478), uint16(64647), uint16(64783), uint16(64894),
	uint16(64986), uint16(65052), uint16(65113), uint16(65169), uint16(65213), uint16(65252), uint16(65284), uint16(65314),
	uint16(65338), uint16(65359), uint16(65377), uint16(65392), uint16(65403), uint16(65415), uint16(65424), uint16(65432),
	uint16(65440), uint16(65448), uint16(65455), uint16(65462), uint16(65470), uint16(65477), uint16(65484), uint16(65491),
	uint16(65499), uint16(65506), uint16(65513), uint16(65521), uint16(65528), uint16(65535),
} /* tables_gain.c:64:18 */

var delta_gain_CDF_offset int32 = 5 /* tables_gain.c:73:15 */

var LTP_per_index_CDF = [4]uint16{
	uint16(0), uint16(20992), uint16(40788), uint16(65535),
} /* tables_LTP.c:30:18 */

var LTP_per_index_CDF_offset int32 = 1 /* tables_LTP.c:34:15 */

var LTP_gain_CDF_0 = [11]uint16{
	uint16(0), uint16(49380), uint16(54463), uint16(56494), uint16(58437), uint16(60101), uint16(61683), uint16(62985),
	uint16(64066), uint16(64823), uint16(65535),
} /* tables_LTP.c:37:18 */

var LTP_gain_CDF_1 = [21]uint16{
	uint16(0), uint16(25290), uint16(30654), uint16(35710), uint16(40386), uint16(42937), uint16(45250), uint16(47459),
	uint16(49411), uint16(51348), uint16(52974), uint16(54517), uint16(55976), uint16(57423), uint16(58865), uint16(60285),
	uint16(61667), uint16(62895), uint16(63827), uint16(64724), uint16(65535),
} /* tables_LTP.c:42:18 */

var LTP_gain_CDF_2 = [41]uint16{
	uint16(0), uint16(4958), uint16(9439), uint16(13581), uint16(17638), uint16(21651), uint16(25015), uint16(28025),
	uint16(30287), uint16(32406), uint16(34330), uint16(36240), uint16(38130), uint16(39790), uint16(41281), uint16(42764),
	uint16(44229), uint16(45676), uint16(47081), uint16(48431), uint16(49675), uint16(50849), uint16(51932), uint16(52966),
	uint16(53957), uint16(54936), uint16(55869), uint16(56789), uint16(57708), uint16(58504), uint16(59285), uint16(60043),
	uint16(60796), uint16(61542), uint16(62218), uint16(62871), uint16(63483), uint16(64076), uint16(64583), uint16(65062),
	uint16(65535),
} /* tables_LTP.c:48:18 */

var LTP_gain_CDF_offsets = [3]int32{
	1, 3, 10,
} /* tables_LTP.c:57:15 */

var LTP_gain_middle_avg_RD_Q14 int32 = 11010 /* tables_LTP.c:61:17 */

var LTP_gain_BITS_Q6_0 = [10]int16{
	int16(26), int16(236), int16(321), int16(325), int16(339), int16(344), int16(362), int16(379),
	int16(412), int16(418),
} /* tables_LTP.c:63:17 */

var LTP_gain_BITS_Q6_1 = [20]int16{
	int16(88), int16(231), int16(237), int16(244), int16(300), int16(309), int16(313), int16(324),
	int16(325), int16(341), int16(346), int16(351), int16(352), int16(352), int16(354), int16(356),
	int16(367), int16(393), int16(396), int16(406),
} /* tables_LTP.c:68:17 */

var LTP_gain_BITS_Q6_2 = [40]int16{
	int16(238), int16(248), int16(255), int16(257), int16(258), int16(274), int16(284), int16(311),
	int16(317), int16(326), int16(326), int16(327), int16(339), int16(349), int16(350), int16(351),
	int16(352), int16(355), int16(358), int16(366), int16(371), int16(379), int16(383), int16(387),
	int16(388), int16(393), int16(394), int16(394), int16(407), int16(409), int16(412), int16(412),
	int16(413), int16(422), int16(426), int16(432), int16(434), int16(449), int16(454), int16(455),
} /* tables_LTP.c:74:17 */

var LTP_gain_CDF_ptrs = [3]uintptr{
	0,
	0,
	0,
} /* tables_LTP.c:82:18 */

var LTP_gain_BITS_Q6_ptrs = [3]uintptr{
	0,
	0,
	0,
} /* tables_LTP.c:88:17 */

var LTP_gain_vq_0_Q14 = [10][5]int16{
	{
		int16(594), int16(984), int16(2840), int16(1021), int16(669),
	},
	{
		int16(10), int16(35), int16(304), int16(-1), int16(23),
	},
	{
		int16(-694), int16(1923), int16(4603), int16(2975), int16(2335),
	},
	{
		int16(2437), int16(3176), int16(3778), int16(1940), int16(481),
	},
	{
		int16(214), int16(-46), int16(7870), int16(4406), int16(-521),
	},
	{
		int16(-896), int16(4818), int16(8501), int16(1623), int16(-887),
	},
	{
		int16(-696), int16(3178), int16(6480), int16(-302), int16(1081),
	},
	{
		int16(517), int16(599), int16(1002), int16(567), int16(560),
	},
	{
		int16(-2075), int16(-834), int16(4712), int16(-340), int16(896),
	},
	{
		int16(1435), int16(-644), int16(3993), int16(-612), int16(-2063),
	},
} /* tables_LTP.c:94:17 */

var LTP_gain_vq_1_Q14 = [20][5]int16{
	{
		int16(1655), int16(2918), int16(5001), int16(3010), int16(1775),
	},
	{
		int16(113), int16(198), int16(856), int16(176), int16(178),
	},
	{
		int16(-843), int16(2479), int16(7858), int16(5371), int16(574),
	},
	{
		int16(59), int16(5356), int16(7648), int16(2850), int16(-315),
	},
	{
		int16(3840), int16(4851), int16(6527), int16(1583), int16(-1233),
	},
	{
		int16(1620), int16(1760), int16(2330), int16(1876), int16(2045),
	},
	{
		int16(-545), int16(1854), int16(11792), int16(1547), int16(-307),
	},
	{
		int16(-604), int16(689), int16(5369), int16(5074), int16(4265),
	},
	{
		int16(521), int16(-1331), int16(9829), int16(6209), int16(-1211),
	},
	{
		int16(-1315), int16(6747), int16(9929), int16(-1410), int16(546),
	},
	{
		int16(117), int16(-144), int16(2810), int16(1649), int16(5240),
	},
	{
		int16(5392), int16(3476), int16(2425), int16(-38), int16(633),
	},
	{
		int16(14), int16(-449), int16(5274), int16(3547), int16(-171),
	},
	{
		int16(-98), int16(395), int16(9114), int16(1676), int16(844),
	},
	{
		int16(-908), int16(3843), int16(8861), int16(-957), int16(1474),
	},
	{
		int16(396), int16(6747), int16(5379), int16(-329), int16(1269),
	},
	{
		int16(-335), int16(2830), int16(4281), int16(270), int16(-54),
	},
	{
		int16(1502), int16(5609), int16(8958), int16(6045), int16(2059),
	},
	{
		int16(-370), int16(479), int16(5267), int16(5726), int16(1174),
	},
	{
		int16(5237), int16(-1144), int16(6510), int16(455), int16(512),
	},
} /* tables_LTP.c:128:17 */

var LTP_gain_vq_2_Q14 = [40][5]int16{
	{
		int16(-278), int16(415), int16(9345), int16(7106), int16(-431),
	},
	{
		int16(-1006), int16(3863), int16(9524), int16(4724), int16(-871),
	},
	{
		int16(-954), int16(4624), int16(11722), int16(973), int16(-300),
	},
	{
		int16(-117), int16(7066), int16(8331), int16(1959), int16(-901),
	},
	{
		int16(593), int16(3412), int16(6070), int16(4914), int16(1567),
	},
	{
		int16(54), int16(-51), int16(12618), int16(4228), int16(-844),
	},
	{
		int16(3157), int16(4822), int16(5229), int16(2313), int16(717),
	},
	{
		int16(-244), int16(1161), int16(14198), int16(779), int16(69),
	},
	{
		int16(-1218), int16(5603), int16(12894), int16(-2301), int16(1001),
	},
	{
		int16(-132), int16(3960), int16(9526), int16(577), int16(1806),
	},
	{
		int16(-1633), int16(8815), int16(10484), int16(-2452), int16(895),
	},
	{
		int16(235), int16(450), int16(1243), int16(667), int16(437),
	},
	{
		int16(959), int16(-2630), int16(10897), int16(8772), int16(-1852),
	},
	{
		int16(2420), int16(2046), int16(8893), int16(4427), int16(-1569),
	},
	{
		int16(23), int16(7091), int16(8356), int16(-1285), int16(1508),
	},
	{
		int16(-1133), int16(835), int16(7662), int16(6043), int16(2800),
	},
	{
		int16(439), int16(391), int16(11016), int16(2253), int16(1362),
	},
	{
		int16(-1020), int16(2876), int16(13436), int16(4015), int16(-3020),
	},
	{
		int16(1060), int16(-2690), int16(13512), int16(5565), int16(-1394),
	},
	{
		int16(-1420), int16(8007), int16(11421), int16(-152), int16(-1672),
	},
	{
		int16(-893), int16(2895), int16(15434), int16(-1490), int16(159),
	},
	{
		int16(-1054), int16(428), int16(12208), int16(8538), int16(-3344),
	},
	{
		int16(1772), int16(-1304), int16(7593), int16(6185), int16(561),
	},
	{
		int16(525), int16(-1207), int16(6659), int16(11151), int16(-1170),
	},
	{
		int16(439), int16(2667), int16(4743), int16(2359), int16(5515),
	},
	{
		int16(2951), int16(7432), int16(7909), int16(-230), int16(-1564),
	},
	{
		int16(-72), int16(2140), int16(5477), int16(1391), int16(1580),
	},
	{
		int16(476), int16(-1312), int16(15912), int16(2174), int16(-1027),
	},
	{
		int16(5737), int16(441), int16(2493), int16(2043), int16(2757),
	},
	{
		int16(228), int16(-43), int16(1803), int16(6663), int16(7064),
	},
	{
		int16(4596), int16(9182), int16(1917), int16(-200), int16(203),
	},
	{
		int16(-704), int16(12039), int16(5451), int16(-1188), int16(542),
	},
	{
		int16(1782), int16(-1040), int16(10078), int16(7513), int16(-2767),
	},
	{
		int16(-2626), int16(7747), int16(9019), int16(62), int16(1710),
	},
	{
		int16(235), int16(-233), int16(2954), int16(10921), int16(1947),
	},
	{
		int16(10854), int16(2814), int16(1232), int16(-111), int16(222),
	},
	{
		int16(2267), int16(2778), int16(12325), int16(156), int16(-1658),
	},
	{
		int16(-2950), int16(8095), int16(16330), int16(268), int16(-3626),
	},
	{
		int16(67), int16(2083), int16(7950), int16(-80), int16(-2432),
	},
	{
		int16(518), int16(-66), int16(1718), int16(415), int16(11435),
	},
} /* tables_LTP.c:192:17 */

var LTP_vq_ptrs_Q14 = [3]uintptr{
	0,
	0,
	0,
} /* tables_LTP.c:316:17 */

var LTP_vq_sizes = [3]int32{
	10, 20, 40,
} /* tables_LTP.c:322:15 */

var NLSF_MSVQ_CB0_10_CDF = [126]uint16{
	uint16(0),
	uint16(2658),
	uint16(4420),
	uint16(6107),
	uint16(7757),
	uint16(9408),
	uint16(10955),
	uint16(12502),
	uint16(13983),
	uint16(15432),
	uint16(16882),
	uint16(18331),
	uint16(19750),
	uint16(21108),
	uint16(22409),
	uint16(23709),
	uint16(25010),
	uint16(26256),
	uint16(27501),
	uint16(28747),
	uint16(29965),
	uint16(31158),
	uint16(32351),
	uint16(33544),
	uint16(34736),
	uint16(35904),
	uint16(36997),
	uint16(38091),
	uint16(39185),
	uint16(40232),
	uint16(41280),
	uint16(42327),
	uint16(43308),
	uint16(44290),
	uint16(45271),
	uint16(46232),
	uint16(47192),
	uint16(48132),
	uint16(49032),
	uint16(49913),
	uint16(50775),
	uint16(51618),
	uint16(52462),
	uint16(53287),
	uint16(54095),
	uint16(54885),
	uint16(55675),
	uint16(56449),
	uint16(57222),
	uint16(57979),
	uint16(58688),
	uint16(59382),
	uint16(60076),
	uint16(60726),
	uint16(61363),
	uint16(61946),
	uint16(62505),
	uint16(63052),
	uint16(63543),
	uint16(63983),
	uint16(64396),
	uint16(64766),
	uint16(65023),
	uint16(65279),
	uint16(65535),
	uint16(0),
	uint16(4977),
	uint16(9542),
	uint16(14106),
	uint16(18671),
	uint16(23041),
	uint16(27319),
	uint16(31596),
	uint16(35873),
	uint16(39969),
	uint16(43891),
	uint16(47813),
	uint16(51652),
	uint16(55490),
	uint16(59009),
	uint16(62307),
	uint16(65535),
	uint16(0),
	uint16(8571),
	uint16(17142),
	uint16(25529),
	uint16(33917),
	uint16(42124),
	uint16(49984),
	uint16(57844),
	uint16(65535),
	uint16(0),
	uint16(8732),
	uint16(17463),
	uint16(25825),
	uint16(34007),
	uint16(42189),
	uint16(50196),
	uint16(58032),
	uint16(65535),
	uint16(0),
	uint16(8948),
	uint16(17704),
	uint16(25733),
	uint16(33762),
	uint16(41791),
	uint16(49821),
	uint16(57678),
	uint16(65535),
	uint16(0),
	uint16(4374),
	uint16(8655),
	uint16(12936),
	uint16(17125),
	uint16(21313),
	uint16(25413),
	uint16(29512),
	uint16(33611),
	uint16(37710),
	uint16(41809),
	uint16(45820),
	uint16(49832),
	uint16(53843),
	uint16(57768),
	uint16(61694),
	uint16(65535),
} /* tables_NLSF_CB0_10.c:38:18 */

var NLSF_MSVQ_CB0_10_CDF_start_ptr = [6]uintptr{
	0,
	0,
	0,
	0,
	0,
	0,
} /* tables_NLSF_CB0_10.c:168:18 */

var NLSF_MSVQ_CB0_10_CDF_middle_idx = [6]int32{
	23,
	8,
	5,
	5,
	5,
	9,
} /* tables_NLSF_CB0_10.c:178:15 */

var NLSF_MSVQ_CB0_10_rates_Q5 = [120]int16{
	int16(148), int16(167),
	int16(169), int16(170),
	int16(170), int16(173),
	int16(173), int16(175),
	int16(176), int16(176),
	int16(176), int16(177),
	int16(179), int16(181),
	int16(181), int16(181),
	int16(183), int16(183),
	int16(183), int16(184),
	int16(185), int16(185),
	int16(185), int16(185),
	int16(186), int16(189),
	int16(189), int16(189),
	int16(191), int16(191),
	int16(191), int16(194),
	int16(194), int16(194),
	int16(195), int16(195),
	int16(196), int16(198),
	int16(199), int16(200),
	int16(201), int16(201),
	int16(202), int16(203),
	int16(204), int16(204),
	int16(205), int16(205),
	int16(206), int16(209),
	int16(210), int16(210),
	int16(213), int16(214),
	int16(218), int16(220),
	int16(221), int16(226),
	int16(231), int16(234),
	int16(239), int16(256),
	int16(256), int16(256),
	int16(119), int16(123),
	int16(123), int16(123),
	int16(125), int16(126),
	int16(126), int16(126),
	int16(128), int16(130),
	int16(130), int16(131),
	int16(131), int16(135),
	int16(138), int16(139),
	int16(94), int16(94),
	int16(95), int16(95),
	int16(96), int16(98),
	int16(98), int16(99),
	int16(93), int16(93),
	int16(95), int16(96),
	int16(96), int16(97),
	int16(98), int16(100),
	int16(92), int16(93),
	int16(97), int16(97),
	int16(97), int16(97),
	int16(98), int16(98),
	int16(125), int16(126),
	int16(126), int16(127),
	int16(127), int16(128),
	int16(128), int16(128),
	int16(128), int16(128),
	int16(129), int16(129),
	int16(129), int16(130),
	int16(130), int16(131),
} /* tables_NLSF_CB0_10.c:188:17 */

var NLSF_MSVQ_CB0_10_ndelta_min_Q15 = [11]int32{
	563,
	3,
	22,
	20,
	3,
	3,
	132,
	119,
	358,
	86,
	964,
} /* tables_NLSF_CB0_10.c:252:15 */

var NLSF_MSVQ_CB0_10_Q15 = [1200]int16{
	int16(2210), int16(4023),
	int16(6981), int16(9260),
	int16(12573), int16(15687),
	int16(19207), int16(22383),
	int16(25981), int16(29142),
	int16(3285), int16(4172),
	int16(6116), int16(10856),
	int16(15289), int16(16826),
	int16(19701), int16(22010),
	int16(24721), int16(29313),
	int16(1554), int16(2511),
	int16(6577), int16(10337),
	int16(13837), int16(16511),
	int16(20086), int16(23214),
	int16(26480), int16(29464),
	int16(3062), int16(4017),
	int16(5771), int16(10037),
	int16(13365), int16(14952),
	int16(20140), int16(22891),
	int16(25229), int16(29603),
	int16(2085), int16(3457),
	int16(5934), int16(8718),
	int16(11501), int16(13670),
	int16(17997), int16(21817),
	int16(24935), int16(28745),
	int16(2776), int16(4093),
	int16(6421), int16(10413),
	int16(15111), int16(16806),
	int16(20825), int16(23826),
	int16(26308), int16(29411),
	int16(2717), int16(4034),
	int16(5697), int16(8463),
	int16(14301), int16(16354),
	int16(19007), int16(23413),
	int16(25812), int16(28506),
	int16(2872), int16(3702),
	int16(5881), int16(11034),
	int16(17141), int16(18879),
	int16(21146), int16(23451),
	int16(25817), int16(29600),
	int16(2999), int16(4015),
	int16(7357), int16(11219),
	int16(12866), int16(17307),
	int16(20081), int16(22644),
	int16(26774), int16(29107),
	int16(2942), int16(3866),
	int16(5918), int16(11915),
	int16(13909), int16(16072),
	int16(20453), int16(22279),
	int16(27310), int16(29826),
	int16(2271), int16(3527),
	int16(6606), int16(9729),
	int16(12943), int16(17382),
	int16(20224), int16(22345),
	int16(24602), int16(28290),
	int16(2207), int16(3310),
	int16(5844), int16(9339),
	int16(11141), int16(15651),
	int16(18576), int16(21177),
	int16(25551), int16(28228),
	int16(3963), int16(4975),
	int16(6901), int16(11588),
	int16(13466), int16(15577),
	int16(19231), int16(21368),
	int16(25510), int16(27759),
	int16(2749), int16(3549),
	int16(6966), int16(13808),
	int16(15653), int16(17645),
	int16(20090), int16(22599),
	int16(26467), int16(28537),
	int16(2126), int16(3504),
	int16(5109), int16(9954),
	int16(12550), int16(14620),
	int16(19703), int16(21687),
	int16(26457), int16(29106),
	int16(3966), int16(5745),
	int16(7442), int16(9757),
	int16(14468), int16(16404),
	int16(19135), int16(23048),
	int16(25375), int16(28391),
	int16(3197), int16(4751),
	int16(6451), int16(9298),
	int16(13038), int16(14874),
	int16(17962), int16(20627),
	int16(23835), int16(28464),
	int16(3195), int16(4081),
	int16(6499), int16(12252),
	int16(14289), int16(16040),
	int16(18357), int16(20730),
	int16(26980), int16(29309),
	int16(1533), int16(2471),
	int16(4486), int16(7796),
	int16(12332), int16(15758),
	int16(19567), int16(22298),
	int16(25673), int16(29051),
	int16(2002), int16(2971),
	int16(4985), int16(8083),
	int16(13181), int16(15435),
	int16(18237), int16(21517),
	int16(24595), int16(28351),
	int16(3808), int16(4925),
	int16(6710), int16(10201),
	int16(12011), int16(14300),
	int16(18457), int16(20391),
	int16(26525), int16(28956),
	int16(2281), int16(3418),
	int16(4979), int16(8726),
	int16(15964), int16(18104),
	int16(20250), int16(22771),
	int16(25286), int16(28954),
	int16(3051), int16(5479),
	int16(7290), int16(9848),
	int16(12744), int16(14503),
	int16(18665), int16(23684),
	int16(26065), int16(28947),
	int16(2364), int16(3565),
	int16(5502), int16(9621),
	int16(14922), int16(16621),
	int16(19005), int16(20996),
	int16(26310), int16(29302),
	int16(4093), int16(5212),
	int16(6833), int16(9880),
	int16(16303), int16(18286),
	int16(20571), int16(23614),
	int16(26067), int16(29128),
	int16(2941), int16(3996),
	int16(6038), int16(10638),
	int16(12668), int16(14451),
	int16(16798), int16(19392),
	int16(26051), int16(28517),
	int16(3863), int16(5212),
	int16(7019), int16(9468),
	int16(11039), int16(13214),
	int16(19942), int16(22344),
	int16(25126), int16(29539),
	int16(4615), int16(6172),
	int16(7853), int16(10252),
	int16(12611), int16(14445),
	int16(19719), int16(22441),
	int16(24922), int16(29341),
	int16(3566), int16(4512),
	int16(6985), int16(8684),
	int16(10544), int16(16097),
	int16(18058), int16(22475),
	int16(26066), int16(28167),
	int16(4481), int16(5489),
	int16(7432), int16(11414),
	int16(13191), int16(15225),
	int16(20161), int16(22258),
	int16(26484), int16(29716),
	int16(3320), int16(4320),
	int16(6621), int16(9867),
	int16(11581), int16(14034),
	int16(21168), int16(23210),
	int16(26588), int16(29903),
	int16(3794), int16(4689),
	int16(6916), int16(8655),
	int16(10143), int16(16144),
	int16(19568), int16(21588),
	int16(27557), int16(29593),
	int16(2446), int16(3276),
	int16(5918), int16(12643),
	int16(16601), int16(18013),
	int16(21126), int16(23175),
	int16(27300), int16(29634),
	int16(2450), int16(3522),
	int16(5437), int16(8560),
	int16(15285), int16(19911),
	int16(21826), int16(24097),
	int16(26567), int16(29078),
	int16(2580), int16(3796),
	int16(5580), int16(8338),
	int16(9969), int16(12675),
	int16(18907), int16(22753),
	int16(25450), int16(29292),
	int16(3325), int16(4312),
	int16(6241), int16(7709),
	int16(9164), int16(14452),
	int16(21665), int16(23797),
	int16(27096), int16(29857),
	int16(3338), int16(4163),
	int16(7738), int16(11114),
	int16(12668), int16(14753),
	int16(16931), int16(22736),
	int16(25671), int16(28093),
	int16(3840), int16(4755),
	int16(7755), int16(13471),
	int16(15338), int16(17180),
	int16(20077), int16(22353),
	int16(27181), int16(29743),
	int16(2504), int16(4079),
	int16(8351), int16(12118),
	int16(15046), int16(18595),
	int16(21684), int16(24704),
	int16(27519), int16(29937),
	int16(5234), int16(6342),
	int16(8267), int16(11821),
	int16(15155), int16(16760),
	int16(20667), int16(23488),
	int16(25949), int16(29307),
	int16(2681), int16(3562),
	int16(6028), int16(10827),
	int16(18458), int16(20458),
	int16(22303), int16(24701),
	int16(26912), int16(29956),
	int16(3374), int16(4528),
	int16(6230), int16(8256),
	int16(9513), int16(12730),
	int16(18666), int16(20720),
	int16(26007), int16(28425),
	int16(2731), int16(3629),
	int16(8320), int16(12450),
	int16(14112), int16(16431),
	int16(18548), int16(22098),
	int16(25329), int16(27718),
	int16(3481), int16(4401),
	int16(7321), int16(9319),
	int16(11062), int16(13093),
	int16(15121), int16(22315),
	int16(26331), int16(28740),
	int16(3577), int16(4945),
	int16(6669), int16(8792),
	int16(10299), int16(12645),
	int16(19505), int16(24766),
	int16(26996), int16(29634),
	int16(4058), int16(5060),
	int16(7288), int16(10190),
	int16(11724), int16(13936),
	int16(15849), int16(18539),
	int16(26701), int16(29845),
	int16(4262), int16(5390),
	int16(7057), int16(8982),
	int16(10187), int16(15264),
	int16(20480), int16(22340),
	int16(25958), int16(28072),
	int16(3404), int16(4329),
	int16(6629), int16(7946),
	int16(10121), int16(17165),
	int16(19640), int16(22244),
	int16(25062), int16(27472),
	int16(3157), int16(4168),
	int16(6195), int16(9319),
	int16(10771), int16(13325),
	int16(15416), int16(19816),
	int16(24672), int16(27634),
	int16(2503), int16(3473),
	int16(5130), int16(6767),
	int16(8571), int16(14902),
	int16(19033), int16(21926),
	int16(26065), int16(28728),
	int16(4133), int16(5102),
	int16(7553), int16(10054),
	int16(11757), int16(14924),
	int16(17435), int16(20186),
	int16(23987), int16(26272),
	int16(4972), int16(6139),
	int16(7894), int16(9633),
	int16(11320), int16(14295),
	int16(21737), int16(24306),
	int16(26919), int16(29907),
	int16(2958), int16(3816),
	int16(6851), int16(9204),
	int16(10895), int16(18052),
	int16(20791), int16(23338),
	int16(27556), int16(29609),
	int16(5234), int16(6028),
	int16(8034), int16(10154),
	int16(11242), int16(14789),
	int16(18948), int16(20966),
	int16(26585), int16(29127),
	int16(5241), int16(6838),
	int16(10526), int16(12819),
	int16(14681), int16(17328),
	int16(19928), int16(22336),
	int16(26193), int16(28697),
	int16(3412), int16(4251),
	int16(5988), int16(7094),
	int16(9907), int16(18243),
	int16(21669), int16(23777),
	int16(26969), int16(29087),
	int16(2470), int16(3217),
	int16(7797), int16(15296),
	int16(17365), int16(19135),
	int16(21979), int16(24256),
	int16(27322), int16(29442),
	int16(4939), int16(5804),
	int16(8145), int16(11809),
	int16(13873), int16(15598),
	int16(17234), int16(19423),
	int16(26476), int16(29645),
	int16(5051), int16(6167),
	int16(8223), int16(9655),
	int16(12159), int16(17995),
	int16(20464), int16(22832),
	int16(26616), int16(28462),
	int16(4987), int16(5907),
	int16(9319), int16(11245),
	int16(13132), int16(15024),
	int16(17485), int16(22687),
	int16(26011), int16(28273),
	int16(5137), int16(6884),
	int16(11025), int16(14950),
	int16(17191), int16(19425),
	int16(21807), int16(24393),
	int16(26938), int16(29288),
	int16(7057), int16(7884),
	int16(9528), int16(10483),
	int16(10960), int16(14811),
	int16(19070), int16(21675),
	int16(25645), int16(28019),
	int16(6759), int16(7160),
	int16(8546), int16(11779),
	int16(12295), int16(13023),
	int16(16627), int16(21099),
	int16(24697), int16(28287),
	int16(3863), int16(9762),
	int16(11068), int16(11445),
	int16(12049), int16(13960),
	int16(18085), int16(21507),
	int16(25224), int16(28997),
	int16(397), int16(335),
	int16(651), int16(1168),
	int16(640), int16(765),
	int16(465), int16(331),
	int16(214), int16(-194),
	int16(-578), int16(-647),
	int16(-657), int16(750),
	int16(564), int16(613),
	int16(549), int16(630),
	int16(304), int16(-52),
	int16(828), int16(922),
	int16(443), int16(111),
	int16(138), int16(124),
	int16(169), int16(14),
	int16(144), int16(83),
	int16(132), int16(58),
	int16(-413), int16(-752),
	int16(869), int16(336),
	int16(385), int16(69),
	int16(56), int16(830),
	int16(-227), int16(-266),
	int16(-368), int16(-440),
	int16(-1195), int16(163),
	int16(126), int16(-228),
	int16(802), int16(156),
	int16(188), int16(120),
	int16(376), int16(59),
	int16(-358), int16(-558),
	int16(-1326), int16(-254),
	int16(-202), int16(-789),
	int16(296), int16(92),
	int16(-70), int16(-129),
	int16(-718), int16(-1135),
	int16(292), int16(-29),
	int16(-631), int16(487),
	int16(-157), int16(-153),
	int16(-279), int16(2),
	int16(-419), int16(-342),
	int16(-34), int16(-514),
	int16(-799), int16(-1571),
	int16(-687), int16(-609),
	int16(-546), int16(-130),
	int16(-215), int16(-252),
	int16(-446), int16(-574),
	int16(-1337), int16(207),
	int16(-72), int16(32),
	int16(103), int16(-642),
	int16(942), int16(733),
	int16(187), int16(29),
	int16(-211), int16(-814),
	int16(143), int16(225),
	int16(20), int16(24),
	int16(-268), int16(-377),
	int16(1623), int16(1133),
	int16(667), int16(164),
	int16(307), int16(366),
	int16(187), int16(34),
	int16(62), int16(-313),
	int16(-832), int16(-1482),
	int16(-1181), int16(483),
	int16(-42), int16(-39),
	int16(-450), int16(-1406),
	int16(-587), int16(-52),
	int16(-760), int16(334),
	int16(98), int16(-60),
	int16(-500), int16(-488),
	int16(-1058), int16(299),
	int16(131), int16(-250),
	int16(-251), int16(-703),
	int16(1037), int16(568),
	int16(-413), int16(-265),
	int16(1687), int16(573),
	int16(345), int16(323),
	int16(98), int16(61),
	int16(-102), int16(31),
	int16(135), int16(149),
	int16(617), int16(365),
	int16(-39), int16(34),
	int16(-611), int16(1201),
	int16(1421), int16(736),
	int16(-414), int16(-393),
	int16(-492), int16(-343),
	int16(-316), int16(-532),
	int16(528), int16(172),
	int16(90), int16(322),
	int16(-294), int16(-319),
	int16(-541), int16(503),
	int16(639), int16(401),
	int16(1), int16(-149),
	int16(-73), int16(-167),
	int16(150), int16(118),
	int16(308), int16(218),
	int16(121), int16(195),
	int16(-143), int16(-261),
	int16(-1013), int16(-802),
	int16(387), int16(436),
	int16(130), int16(-427),
	int16(-448), int16(-681),
	int16(123), int16(-87),
	int16(-251), int16(-113),
	int16(274), int16(310),
	int16(445), int16(501),
	int16(354), int16(272),
	int16(141), int16(-285),
	int16(569), int16(656),
	int16(37), int16(-49),
	int16(251), int16(-386),
	int16(-263), int16(1122),
	int16(604), int16(606),
	int16(336), int16(95),
	int16(34), int16(0),
	int16(85), int16(180),
	int16(207), int16(-367),
	int16(-622), int16(1070),
	int16(-6), int16(-79),
	int16(-160), int16(-92),
	int16(-137), int16(-276),
	int16(-323), int16(-371),
	int16(-696), int16(-1036),
	int16(407), int16(102),
	int16(-86), int16(-214),
	int16(-482), int16(-647),
	int16(-28), int16(-291),
	int16(-97), int16(-180),
	int16(-250), int16(-435),
	int16(-18), int16(-76),
	int16(-332), int16(410),
	int16(407), int16(168),
	int16(539), int16(411),
	int16(254), int16(111),
	int16(58), int16(-145),
	int16(200), int16(30),
	int16(187), int16(116),
	int16(131), int16(-367),
	int16(-475), int16(781),
	int16(-559), int16(561),
	int16(195), int16(-115),
	int16(8), int16(-168),
	int16(30), int16(55),
	int16(-122), int16(131),
	int16(82), int16(-5),
	int16(-273), int16(-50),
	int16(-632), int16(668),
	int16(4), int16(32),
	int16(-26), int16(-279),
	int16(315), int16(165),
	int16(197), int16(377),
	int16(155), int16(-41),
	int16(-138), int16(-324),
	int16(-109), int16(-617),
	int16(360), int16(98),
	int16(-53), int16(-319),
	int16(-114), int16(-245),
	int16(-82), int16(507),
	int16(468), int16(263),
	int16(-137), int16(-389),
	int16(652), int16(354),
	int16(-18), int16(-227),
	int16(-462), int16(-135),
	int16(317), int16(53),
	int16(-16), int16(66),
	int16(-72), int16(-126),
	int16(-356), int16(-347),
	int16(-328), int16(-72),
	int16(-337), int16(324),
	int16(152), int16(349),
	int16(169), int16(-196),
	int16(179), int16(254),
	int16(260), int16(325),
	int16(-74), int16(-80),
	int16(75), int16(-31),
	int16(270), int16(275),
	int16(87), int16(278),
	int16(-446), int16(-301),
	int16(309), int16(71),
	int16(-25), int16(-242),
	int16(516), int16(161),
	int16(-162), int16(-83),
	int16(329), int16(230),
	int16(-311), int16(-259),
	int16(177), int16(-26),
	int16(-462), int16(89),
	int16(257), int16(6),
	int16(-130), int16(-93),
	int16(-456), int16(-317),
	int16(-221), int16(-206),
	int16(-417), int16(-182),
	int16(-74), int16(234),
	int16(48), int16(261),
	int16(359), int16(231),
	int16(258), int16(85),
	int16(-282), int16(252),
	int16(-147), int16(-222),
	int16(251), int16(-207),
	int16(443), int16(123),
	int16(-417), int16(-36),
	int16(273), int16(-241),
	int16(240), int16(-112),
	int16(44), int16(-167),
	int16(126), int16(-124),
	int16(-77), int16(58),
	int16(-401), int16(333),
	int16(-118), int16(82),
	int16(126), int16(151),
	int16(-433), int16(359),
	int16(-130), int16(-102),
	int16(131), int16(-244),
	int16(86), int16(85),
	int16(-462), int16(414),
	int16(-240), int16(16),
	int16(145), int16(28),
	int16(-205), int16(-481),
	int16(373), int16(293),
	int16(-72), int16(-174),
	int16(62), int16(259),
	int16(-8), int16(-18),
	int16(362), int16(233),
	int16(185), int16(43),
	int16(278), int16(27),
	int16(193), int16(570),
	int16(-248), int16(189),
	int16(92), int16(31),
	int16(-275), int16(-3),
	int16(243), int16(176),
	int16(438), int16(209),
	int16(206), int16(-51),
	int16(79), int16(109),
	int16(168), int16(-185),
	int16(-308), int16(-68),
	int16(-618), int16(385),
	int16(-310), int16(-108),
	int16(-164), int16(165),
	int16(61), int16(-152),
	int16(-101), int16(-412),
	int16(-268), int16(-257),
	int16(-40), int16(-20),
	int16(-28), int16(-158),
	int16(-301), int16(271),
	int16(380), int16(-338),
	int16(-367), int16(-132),
	int16(64), int16(114),
	int16(-131), int16(-225),
	int16(-156), int16(-260),
	int16(-63), int16(-116),
	int16(155), int16(-586),
	int16(-202), int16(254),
	int16(-287), int16(178),
	int16(227), int16(-106),
	int16(-294), int16(164),
	int16(298), int16(-100),
	int16(185), int16(317),
	int16(193), int16(-45),
	int16(28), int16(80),
	int16(-87), int16(-433),
	int16(22), int16(-48),
	int16(48), int16(-237),
	int16(-229), int16(-139),
	int16(120), int16(-364),
	int16(268), int16(-136),
	int16(396), int16(125),
	int16(130), int16(-89),
	int16(-272), int16(118),
	int16(-256), int16(-68),
	int16(-451), int16(488),
	int16(143), int16(-165),
	int16(-48), int16(-190),
	int16(106), int16(219),
	int16(47), int16(435),
	int16(245), int16(97),
	int16(75), int16(-418),
	int16(121), int16(-187),
	int16(570), int16(-200),
	int16(-351), int16(225),
	int16(-21), int16(-217),
	int16(234), int16(-111),
	int16(194), int16(14),
	int16(242), int16(118),
	int16(140), int16(-397),
	int16(355), int16(361),
	int16(-45), int16(-195),
} /* tables_NLSF_CB0_10.c:267:17 */

var NLSF_CB0_10_Stage_info = [6]NLSF_CBS{
	{FnVectors: 64, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 16, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 16, FCB_NLSF_Q15: 0, FRates_Q5: 0},
} /* tables_NLSF_CB0_10.c:871:25 */

var NLSF_CB0_10 = NLSF_CB_struct{
	FnStages:       6,
	FCBStages:      0,
	FNDeltaMin_Q15: 0,
	FCDF:           0,
	FStartPtr:      0,
	FMiddleIx:      0,
} /* tables_NLSF_CB0_10.c:881:31 */

var NLSF_MSVQ_CB0_16_CDF = [226]uint16{
	uint16(0),
	uint16(1449),
	uint16(2749),
	uint16(4022),
	uint16(5267),
	uint16(6434),
	uint16(7600),
	uint16(8647),
	uint16(9695),
	uint16(10742),
	uint16(11681),
	uint16(12601),
	uint16(13444),
	uint16(14251),
	uint16(15008),
	uint16(15764),
	uint16(16521),
	uint16(17261),
	uint16(18002),
	uint16(18710),
	uint16(19419),
	uint16(20128),
	uint16(20837),
	uint16(21531),
	uint16(22225),
	uint16(22919),
	uint16(23598),
	uint16(24277),
	uint16(24956),
	uint16(25620),
	uint16(26256),
	uint16(26865),
	uint16(27475),
	uint16(28071),
	uint16(28667),
	uint16(29263),
	uint16(29859),
	uint16(30443),
	uint16(31026),
	uint16(31597),
	uint16(32168),
	uint16(32727),
	uint16(33273),
	uint16(33808),
	uint16(34332),
	uint16(34855),
	uint16(35379),
	uint16(35902),
	uint16(36415),
	uint16(36927),
	uint16(37439),
	uint16(37941),
	uint16(38442),
	uint16(38932),
	uint16(39423),
	uint16(39914),
	uint16(40404),
	uint16(40884),
	uint16(41364),
	uint16(41844),
	uint16(42324),
	uint16(42805),
	uint16(43285),
	uint16(43754),
	uint16(44224),
	uint16(44694),
	uint16(45164),
	uint16(45623),
	uint16(46083),
	uint16(46543),
	uint16(46993),
	uint16(47443),
	uint16(47892),
	uint16(48333),
	uint16(48773),
	uint16(49213),
	uint16(49653),
	uint16(50084),
	uint16(50515),
	uint16(50946),
	uint16(51377),
	uint16(51798),
	uint16(52211),
	uint16(52614),
	uint16(53018),
	uint16(53422),
	uint16(53817),
	uint16(54212),
	uint16(54607),
	uint16(55002),
	uint16(55388),
	uint16(55775),
	uint16(56162),
	uint16(56548),
	uint16(56910),
	uint16(57273),
	uint16(57635),
	uint16(57997),
	uint16(58352),
	uint16(58698),
	uint16(59038),
	uint16(59370),
	uint16(59702),
	uint16(60014),
	uint16(60325),
	uint16(60630),
	uint16(60934),
	uint16(61239),
	uint16(61537),
	uint16(61822),
	uint16(62084),
	uint16(62346),
	uint16(62602),
	uint16(62837),
	uint16(63072),
	uint16(63302),
	uint16(63517),
	uint16(63732),
	uint16(63939),
	uint16(64145),
	uint16(64342),
	uint16(64528),
	uint16(64701),
	uint16(64867),
	uint16(65023),
	uint16(65151),
	uint16(65279),
	uint16(65407),
	uint16(65535),
	uint16(0),
	uint16(5099),
	uint16(9982),
	uint16(14760),
	uint16(19538),
	uint16(24213),
	uint16(28595),
	uint16(32976),
	uint16(36994),
	uint16(41012),
	uint16(44944),
	uint16(48791),
	uint16(52557),
	uint16(56009),
	uint16(59388),
	uint16(62694),
	uint16(65535),
	uint16(0),
	uint16(9955),
	uint16(19697),
	uint16(28825),
	uint16(36842),
	uint16(44686),
	uint16(52198),
	uint16(58939),
	uint16(65535),
	uint16(0),
	uint16(8949),
	uint16(17335),
	uint16(25720),
	uint16(33926),
	uint16(41957),
	uint16(49987),
	uint16(57845),
	uint16(65535),
	uint16(0),
	uint16(9724),
	uint16(18642),
	uint16(26998),
	uint16(35355),
	uint16(43532),
	uint16(51534),
	uint16(59365),
	uint16(65535),
	uint16(0),
	uint16(8750),
	uint16(17499),
	uint16(26249),
	uint16(34448),
	uint16(42471),
	uint16(50494),
	uint16(58178),
	uint16(65535),
	uint16(0),
	uint16(8730),
	uint16(17273),
	uint16(25816),
	uint16(34176),
	uint16(42536),
	uint16(50203),
	uint16(57869),
	uint16(65535),
	uint16(0),
	uint16(8769),
	uint16(17538),
	uint16(26307),
	uint16(34525),
	uint16(42742),
	uint16(50784),
	uint16(58319),
	uint16(65535),
	uint16(0),
	uint16(8736),
	uint16(17101),
	uint16(25466),
	uint16(33653),
	uint16(41839),
	uint16(50025),
	uint16(57864),
	uint16(65535),
	uint16(0),
	uint16(4368),
	uint16(8735),
	uint16(12918),
	uint16(17100),
	uint16(21283),
	uint16(25465),
	uint16(29558),
	uint16(33651),
	uint16(37744),
	uint16(41836),
	uint16(45929),
	uint16(50022),
	uint16(54027),
	uint16(57947),
	uint16(61782),
	uint16(65535),
} /* tables_NLSF_CB0_16.c:38:18 */

var NLSF_MSVQ_CB0_16_CDF_start_ptr = [10]uintptr{
	0,
	0,
	0,
	0,
	0,
	0,
	0,
	0,
	0,
	0,
} /* tables_NLSF_CB0_16.c:268:18 */

var NLSF_MSVQ_CB0_16_CDF_middle_idx = [10]int32{
	42,
	8,
	4,
	5,
	5,
	5,
	5,
	5,
	5,
	9,
} /* tables_NLSF_CB0_16.c:282:15 */

var NLSF_MSVQ_CB0_16_rates_Q5 = [216]int16{
	int16(176), int16(181),
	int16(182), int16(183),
	int16(186), int16(186),
	int16(191), int16(191),
	int16(191), int16(196),
	int16(197), int16(201),
	int16(203), int16(206),
	int16(206), int16(206),
	int16(207), int16(207),
	int16(209), int16(209),
	int16(209), int16(209),
	int16(210), int16(210),
	int16(210), int16(211),
	int16(211), int16(211),
	int16(212), int16(214),
	int16(216), int16(216),
	int16(217), int16(217),
	int16(217), int16(217),
	int16(218), int16(218),
	int16(219), int16(219),
	int16(220), int16(221),
	int16(222), int16(223),
	int16(223), int16(223),
	int16(223), int16(224),
	int16(224), int16(224),
	int16(225), int16(225),
	int16(226), int16(226),
	int16(226), int16(226),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(228), int16(228),
	int16(228), int16(228),
	int16(229), int16(229),
	int16(229), int16(230),
	int16(230), int16(230),
	int16(231), int16(231),
	int16(231), int16(231),
	int16(232), int16(232),
	int16(232), int16(232),
	int16(233), int16(234),
	int16(235), int16(235),
	int16(235), int16(236),
	int16(236), int16(236),
	int16(236), int16(237),
	int16(237), int16(237),
	int16(237), int16(240),
	int16(240), int16(240),
	int16(240), int16(241),
	int16(242), int16(243),
	int16(244), int16(244),
	int16(247), int16(247),
	int16(248), int16(248),
	int16(248), int16(249),
	int16(251), int16(255),
	int16(255), int16(256),
	int16(260), int16(260),
	int16(261), int16(264),
	int16(264), int16(266),
	int16(266), int16(268),
	int16(271), int16(274),
	int16(276), int16(279),
	int16(288), int16(288),
	int16(288), int16(288),
	int16(118), int16(120),
	int16(121), int16(121),
	int16(122), int16(125),
	int16(125), int16(129),
	int16(129), int16(130),
	int16(131), int16(132),
	int16(136), int16(137),
	int16(138), int16(145),
	int16(87), int16(88),
	int16(91), int16(97),
	int16(98), int16(100),
	int16(105), int16(106),
	int16(92), int16(95),
	int16(95), int16(96),
	int16(97), int16(97),
	int16(98), int16(99),
	int16(88), int16(92),
	int16(95), int16(95),
	int16(96), int16(97),
	int16(98), int16(109),
	int16(93), int16(93),
	int16(93), int16(96),
	int16(97), int16(97),
	int16(99), int16(101),
	int16(93), int16(94),
	int16(94), int16(95),
	int16(95), int16(99),
	int16(99), int16(99),
	int16(93), int16(93),
	int16(93), int16(96),
	int16(96), int16(97),
	int16(100), int16(102),
	int16(93), int16(95),
	int16(95), int16(96),
	int16(96), int16(96),
	int16(98), int16(99),
	int16(125), int16(125),
	int16(127), int16(127),
	int16(127), int16(127),
	int16(128), int16(128),
	int16(128), int16(128),
	int16(128), int16(128),
	int16(129), int16(130),
	int16(131), int16(132),
} /* tables_NLSF_CB0_16.c:296:17 */

var NLSF_MSVQ_CB0_16_ndelta_min_Q15 = [17]int32{
	266,
	3,
	40,
	3,
	3,
	16,
	78,
	89,
	107,
	141,
	188,
	146,
	272,
	240,
	235,
	215,
	632,
} /* tables_NLSF_CB0_16.c:408:15 */

var NLSF_MSVQ_CB0_16_Q15 = [3456]int16{
	int16(1170), int16(2278), int16(3658), int16(5374),
	int16(7666), int16(9113), int16(11298), int16(13304),
	int16(15371), int16(17549), int16(19587), int16(21487),
	int16(23798), int16(26038), int16(28318), int16(30201),
	int16(1628), int16(2334), int16(4115), int16(6036),
	int16(7818), int16(9544), int16(11777), int16(14021),
	int16(15787), int16(17408), int16(19466), int16(21261),
	int16(22886), int16(24565), int16(26714), int16(28059),
	int16(1724), int16(2670), int16(4056), int16(6532),
	int16(8357), int16(10119), int16(12093), int16(14061),
	int16(16491), int16(18795), int16(20417), int16(22402),
	int16(24251), int16(26224), int16(28410), int16(29956),
	int16(1493), int16(3427), int16(4789), int16(6399),
	int16(8435), int16(10168), int16(12000), int16(14066),
	int16(16229), int16(18210), int16(20040), int16(22098),
	int16(24153), int16(26095), int16(28183), int16(30121),
	int16(1119), int16(2089), int16(4295), int16(6245),
	int16(8691), int16(10741), int16(12688), int16(15057),
	int16(17028), int16(18792), int16(20717), int16(22514),
	int16(24497), int16(26548), int16(28619), int16(30630),
	int16(1363), int16(2417), int16(3927), int16(5556),
	int16(7422), int16(9315), int16(11879), int16(13767),
	int16(16143), int16(18520), int16(20458), int16(22578),
	int16(24539), int16(26436), int16(28318), int16(30318),
	int16(1122), int16(2503), int16(5216), int16(7148),
	int16(9310), int16(11078), int16(13175), int16(14800),
	int16(16864), int16(18700), int16(20436), int16(22488),
	int16(24572), int16(26602), int16(28555), int16(30426),
	int16(600), int16(1317), int16(2970), int16(5609),
	int16(7694), int16(9784), int16(12169), int16(14087),
	int16(16379), int16(18378), int16(20551), int16(22686),
	int16(24739), int16(26697), int16(28646), int16(30355),
	int16(941), int16(1882), int16(4274), int16(5540),
	int16(8482), int16(9858), int16(11940), int16(14287),
	int16(16091), int16(18501), int16(20326), int16(22612),
	int16(24711), int16(26638), int16(28814), int16(30430),
	int16(635), int16(1699), int16(4376), int16(5948),
	int16(8097), int16(10115), int16(12274), int16(14178),
	int16(16111), int16(17813), int16(19695), int16(21773),
	int16(23927), int16(25866), int16(28022), int16(30134),
	int16(1408), int16(2222), int16(3524), int16(5615),
	int16(7345), int16(8849), int16(10989), int16(12772),
	int16(15352), int16(17026), int16(18919), int16(21062),
	int16(23329), int16(25215), int16(27209), int16(29023),
	int16(701), int16(1307), int16(3548), int16(6301),
	int16(7744), int16(9574), int16(11227), int16(12978),
	int16(15170), int16(17565), int16(19775), int16(22097),
	int16(24230), int16(26335), int16(28377), int16(30231),
	int16(1752), int16(2364), int16(4879), int16(6569),
	int16(7813), int16(9796), int16(11199), int16(14290),
	int16(15795), int16(18000), int16(20396), int16(22417),
	int16(24308), int16(26124), int16(28360), int16(30633),
	int16(901), int16(1629), int16(3356), int16(4635),
	int16(7256), int16(8767), int16(9971), int16(11558),
	int16(15215), int16(17544), int16(19523), int16(21852),
	int16(23900), int16(25978), int16(28133), int16(30184),
	int16(981), int16(1669), int16(3323), int16(4693),
	int16(6213), int16(8692), int16(10614), int16(12956),
	int16(15211), int16(17711), int16(19856), int16(22122),
	int16(24344), int16(26592), int16(28723), int16(30481),
	int16(1607), int16(2577), int16(4220), int16(5512),
	int16(8532), int16(10388), int16(11627), int16(13671),
	int16(15752), int16(17199), int16(19840), int16(21859),
	int16(23494), int16(25786), int16(28091), int16(30131),
	int16(811), int16(1471), int16(3144), int16(5041),
	int16(7430), int16(9389), int16(11174), int16(13255),
	int16(15157), int16(16741), int16(19583), int16(22167),
	int16(24115), int16(26142), int16(28383), int16(30395),
	int16(1543), int16(2144), int16(3629), int16(6347),
	int16(7333), int16(9339), int16(10710), int16(13596),
	int16(15099), int16(17340), int16(20102), int16(21886),
	int16(23732), int16(25637), int16(27818), int16(29917),
	int16(492), int16(1185), int16(2940), int16(5488),
	int16(7095), int16(8751), int16(11596), int16(13579),
	int16(16045), int16(18015), int16(20178), int16(22127),
	int16(24265), int16(26406), int16(28484), int16(30357),
	int16(1547), int16(2282), int16(3693), int16(6341),
	int16(7758), int16(9607), int16(11848), int16(13236),
	int16(16564), int16(18069), int16(19759), int16(21404),
	int16(24110), int16(26606), int16(28786), int16(30655),
	int16(685), int16(1338), int16(3409), int16(5262),
	int16(6950), int16(9222), int16(11414), int16(14523),
	int16(16337), int16(17893), int16(19436), int16(21298),
	int16(23293), int16(25181), int16(27973), int16(30520),
	int16(887), int16(1581), int16(3057), int16(4318),
	int16(7192), int16(8617), int16(10047), int16(13106),
	int16(16265), int16(17893), int16(20233), int16(22350),
	int16(24379), int16(26384), int16(28314), int16(30189),
	int16(2285), int16(3745), int16(5662), int16(7576),
	int16(9323), int16(11320), int16(13239), int16(15191),
	int16(17175), int16(19225), int16(21108), int16(22972),
	int16(24821), int16(26655), int16(28561), int16(30460),
	int16(1496), int16(2108), int16(3448), int16(6898),
	int16(8328), int16(9656), int16(11252), int16(12823),
	int16(14979), int16(16482), int16(18180), int16(20085),
	int16(22962), int16(25160), int16(27705), int16(29629),
	int16(575), int16(1261), int16(3861), int16(6627),
	int16(8294), int16(10809), int16(12705), int16(14768),
	int16(17076), int16(19047), int16(20978), int16(23055),
	int16(24972), int16(26703), int16(28720), int16(30345),
	int16(1682), int16(2213), int16(3882), int16(6238),
	int16(7208), int16(9646), int16(10877), int16(13431),
	int16(14805), int16(16213), int16(17941), int16(20873),
	int16(23550), int16(25765), int16(27756), int16(29461),
	int16(888), int16(1616), int16(3924), int16(5195),
	int16(7206), int16(8647), int16(9842), int16(11473),
	int16(16067), int16(18221), int16(20343), int16(22774),
	int16(24503), int16(26412), int16(28054), int16(29731),
	int16(805), int16(1454), int16(2683), int16(4472),
	int16(7936), int16(9360), int16(11398), int16(14345),
	int16(16205), int16(17832), int16(19453), int16(21646),
	int16(23899), int16(25928), int16(28387), int16(30463),
	int16(1640), int16(2383), int16(3484), int16(5082),
	int16(6032), int16(8606), int16(11640), int16(12966),
	int16(15842), int16(17368), int16(19346), int16(21182),
	int16(23638), int16(25889), int16(28368), int16(30299),
	int16(1632), int16(2204), int16(4510), int16(7580),
	int16(8718), int16(10512), int16(11962), int16(14096),
	int16(15640), int16(17194), int16(19143), int16(22247),
	int16(24563), int16(26561), int16(28604), int16(30509),
	int16(2043), int16(2612), int16(3985), int16(6851),
	int16(8038), int16(9514), int16(10979), int16(12789),
	int16(15426), int16(16728), int16(18899), int16(20277),
	int16(22902), int16(26209), int16(28711), int16(30618),
	int16(2224), int16(2798), int16(4465), int16(5320),
	int16(7108), int16(9436), int16(10986), int16(13222),
	int16(14599), int16(18317), int16(20141), int16(21843),
	int16(23601), int16(25700), int16(28184), int16(30582),
	int16(835), int16(1541), int16(4083), int16(5769),
	int16(7386), int16(9399), int16(10971), int16(12456),
	int16(15021), int16(18642), int16(20843), int16(23100),
	int16(25292), int16(26966), int16(28952), int16(30422),
	int16(1795), int16(2343), int16(4809), int16(5896),
	int16(7178), int16(8545), int16(10223), int16(13370),
	int16(14606), int16(16469), int16(18273), int16(20736),
	int16(23645), int16(26257), int16(28224), int16(30390),
	int16(1734), int16(2254), int16(4031), int16(5188),
	int16(6506), int16(7872), int16(9651), int16(13025),
	int16(14419), int16(17305), int16(19495), int16(22190),
	int16(24403), int16(26302), int16(28195), int16(30177),
	int16(1841), int16(2349), int16(3968), int16(4764),
	int16(6376), int16(9825), int16(11048), int16(13345),
	int16(14682), int16(16252), int16(18183), int16(21363),
	int16(23918), int16(26156), int16(28031), int16(29935),
	int16(1432), int16(2047), int16(5631), int16(6927),
	int16(8198), int16(9675), int16(11358), int16(13506),
	int16(14802), int16(16419), int16(18339), int16(22019),
	int16(24124), int16(26177), int16(28130), int16(30586),
	int16(1730), int16(2320), int16(3744), int16(4808),
	int16(6007), int16(9666), int16(10997), int16(13622),
	int16(15234), int16(17495), int16(20088), int16(22002),
	int16(23603), int16(25400), int16(27379), int16(29254),
	int16(1267), int16(1915), int16(5483), int16(6812),
	int16(8229), int16(9919), int16(11589), int16(13337),
	int16(14747), int16(17965), int16(20552), int16(22167),
	int16(24519), int16(26819), int16(28883), int16(30642),
	int16(1526), int16(2229), int16(4240), int16(7388),
	int16(8953), int16(10450), int16(11899), int16(13718),
	int16(16861), int16(18323), int16(20379), int16(22672),
	int16(24797), int16(26906), int16(28906), int16(30622),
	int16(2175), int16(2791), int16(4104), int16(6875),
	int16(8612), int16(9798), int16(12152), int16(13536),
	int16(15623), int16(17682), int16(19213), int16(21060),
	int16(24382), int16(26760), int16(28633), int16(30248),
	int16(454), int16(1231), int16(4339), int16(5738),
	int16(7550), int16(9006), int16(10320), int16(13525),
	int16(16005), int16(17849), int16(20071), int16(21992),
	int16(23949), int16(26043), int16(28245), int16(30175),
	int16(2250), int16(2791), int16(4230), int16(5283),
	int16(6762), int16(10607), int16(11879), int16(13821),
	int16(15797), int16(17264), int16(20029), int16(22266),
	int16(24588), int16(26437), int16(28244), int16(30419),
	int16(1696), int16(2216), int16(4308), int16(8385),
	int16(9766), int16(11030), int16(12556), int16(14099),
	int16(16322), int16(17640), int16(19166), int16(20590),
	int16(23967), int16(26858), int16(28798), int16(30562),
	int16(2452), int16(3236), int16(4369), int16(6118),
	int16(7156), int16(9003), int16(11509), int16(12796),
	int16(15749), int16(17291), int16(19491), int16(22241),
	int16(24530), int16(26474), int16(28273), int16(30073),
	int16(1811), int16(2541), int16(3555), int16(5480),
	int16(9123), int16(10527), int16(11894), int16(13659),
	int16(15262), int16(16899), int16(19366), int16(21069),
	int16(22694), int16(24314), int16(27256), int16(29983),
	int16(1553), int16(2246), int16(4559), int16(5500),
	int16(6754), int16(7874), int16(11739), int16(13571),
	int16(15188), int16(17879), int16(20281), int16(22510),
	int16(24614), int16(26649), int16(28786), int16(30755),
	int16(1982), int16(2768), int16(3834), int16(5964),
	int16(8732), int16(9908), int16(11797), int16(14813),
	int16(16311), int16(17946), int16(21097), int16(22851),
	int16(24456), int16(26304), int16(28166), int16(29755),
	int16(1824), int16(2529), int16(3817), int16(5449),
	int16(6854), int16(8714), int16(10381), int16(12286),
	int16(14194), int16(15774), int16(19524), int16(21374),
	int16(23695), int16(26069), int16(28096), int16(30212),
	int16(2212), int16(2854), int16(3947), int16(5898),
	int16(9930), int16(11556), int16(12854), int16(14788),
	int16(16328), int16(17700), int16(20321), int16(22098),
	int16(23672), int16(25291), int16(26976), int16(28586),
	int16(2023), int16(2599), int16(4024), int16(4916),
	int16(6613), int16(11149), int16(12457), int16(14626),
	int16(16320), int16(17822), int16(19673), int16(21172),
	int16(23115), int16(26051), int16(28825), int16(30758),
	int16(1628), int16(2206), int16(3467), int16(4364),
	int16(8679), int16(10173), int16(11864), int16(13679),
	int16(14998), int16(16938), int16(19207), int16(21364),
	int16(23850), int16(26115), int16(28124), int16(30273),
	int16(2014), int16(2603), int16(4114), int16(7254),
	int16(8516), int16(10043), int16(11822), int16(13503),
	int16(16329), int16(17826), int16(19697), int16(21280),
	int16(23151), int16(24661), int16(26807), int16(30161),
	int16(2376), int16(2980), int16(4422), int16(5770),
	int16(7016), int16(9723), int16(11125), int16(13516),
	int16(15485), int16(16985), int16(19160), int16(20587),
	int16(24401), int16(27180), int16(29046), int16(30647),
	int16(2454), int16(3502), int16(4624), int16(6019),
	int16(7632), int16(8849), int16(10792), int16(13964),
	int16(15523), int16(17085), int16(19611), int16(21238),
	int16(22856), int16(25108), int16(28106), int16(29890),
	int16(1573), int16(2274), int16(3308), int16(5999),
	int16(8977), int16(10104), int16(12457), int16(14258),
	int16(15749), int16(18180), int16(19974), int16(21253),
	int16(23045), int16(25058), int16(27741), int16(30315),
	int16(1943), int16(2730), int16(4140), int16(6160),
	int16(7491), int16(8986), int16(11309), int16(12775),
	int16(14820), int16(16558), int16(17909), int16(19757),
	int16(21512), int16(23605), int16(27274), int16(29527),
	int16(2021), int16(2582), int16(4494), int16(5835),
	int16(6993), int16(8245), int16(9827), int16(14733),
	int16(16462), int16(17894), int16(19647), int16(21083),
	int16(23764), int16(26667), int16(29072), int16(30990),
	int16(1052), int16(1775), int16(3218), int16(4378),
	int16(7666), int16(9403), int16(11248), int16(13327),
	int16(14972), int16(17962), int16(20758), int16(22354),
	int16(25071), int16(27209), int16(29001), int16(30609),
	int16(2218), int16(2866), int16(4223), int16(5352),
	int16(6581), int16(9980), int16(11587), int16(13121),
	int16(15193), int16(16583), int16(18386), int16(20080),
	int16(22013), int16(25317), int16(28127), int16(29880),
	int16(2146), int16(2840), int16(4397), int16(5840),
	int16(7449), int16(8721), int16(10512), int16(11936),
	int16(13595), int16(17253), int16(19310), int16(20891),
	int16(23417), int16(25627), int16(27749), int16(30231),
	int16(1972), int16(2619), int16(3756), int16(6367),
	int16(7641), int16(8814), int16(12286), int16(13768),
	int16(15309), int16(18036), int16(19557), int16(20904),
	int16(22582), int16(24876), int16(27800), int16(30440),
	int16(2005), int16(2577), int16(4272), int16(7373),
	int16(8558), int16(10223), int16(11770), int16(13402),
	int16(16502), int16(18000), int16(19645), int16(21104),
	int16(22990), int16(26806), int16(29505), int16(30942),
	int16(1153), int16(1822), int16(3724), int16(5443),
	int16(6990), int16(8702), int16(10289), int16(11899),
	int16(13856), int16(15315), int16(17601), int16(21064),
	int16(23692), int16(26083), int16(28586), int16(30639),
	int16(1304), int16(1869), int16(3318), int16(7195),
	int16(9613), int16(10733), int16(12393), int16(13728),
	int16(15822), int16(17474), int16(18882), int16(20692),
	int16(23114), int16(25540), int16(27684), int16(29244),
	int16(2093), int16(2691), int16(4018), int16(6658),
	int16(7947), int16(9147), int16(10497), int16(11881),
	int16(15888), int16(17821), int16(19333), int16(21233),
	int16(23371), int16(25234), int16(27553), int16(29998),
	int16(575), int16(1331), int16(5304), int16(6910),
	int16(8425), int16(10086), int16(11577), int16(13498),
	int16(16444), int16(18527), int16(20565), int16(22847),
	int16(24914), int16(26692), int16(28759), int16(30157),
	int16(1435), int16(2024), int16(3283), int16(4156),
	int16(7611), int16(10592), int16(12049), int16(13927),
	int16(15459), int16(18413), int16(20495), int16(22270),
	int16(24222), int16(26093), int16(28065), int16(30099),
	int16(1632), int16(2168), int16(5540), int16(7478),
	int16(8630), int16(10391), int16(11644), int16(14321),
	int16(15741), int16(17357), int16(18756), int16(20434),
	int16(22799), int16(26060), int16(28542), int16(30696),
	int16(1407), int16(2245), int16(3405), int16(5639),
	int16(9419), int16(10685), int16(12104), int16(13495),
	int16(15535), int16(18357), int16(19996), int16(21689),
	int16(24351), int16(26550), int16(28853), int16(30564),
	int16(1675), int16(2226), int16(4005), int16(8223),
	int16(9975), int16(11155), int16(12822), int16(14316),
	int16(16504), int16(18137), int16(19574), int16(21050),
	int16(22759), int16(24912), int16(28296), int16(30634),
	int16(1080), int16(1614), int16(3622), int16(7565),
	int16(8748), int16(10303), int16(11713), int16(13848),
	int16(15633), int16(17434), int16(19761), int16(21825),
	int16(23571), int16(25393), int16(27406), int16(29063),
	int16(1693), int16(2229), int16(3456), int16(4354),
	int16(5670), int16(10890), int16(12563), int16(14167),
	int16(15879), int16(17377), int16(19817), int16(21971),
	int16(24094), int16(26131), int16(28298), int16(30099),
	int16(2042), int16(2959), int16(4195), int16(5740),
	int16(7106), int16(8267), int16(11126), int16(14973),
	int16(16914), int16(18295), int16(20532), int16(21982),
	int16(23711), int16(25769), int16(27609), int16(29351),
	int16(984), int16(1612), int16(3808), int16(5265),
	int16(6885), int16(8411), int16(9547), int16(10889),
	int16(12522), int16(16520), int16(19549), int16(21639),
	int16(23746), int16(26058), int16(28310), int16(30374),
	int16(2036), int16(2538), int16(4166), int16(7761),
	int16(9146), int16(10412), int16(12144), int16(13609),
	int16(15588), int16(17169), int16(18559), int16(20113),
	int16(21820), int16(24313), int16(28029), int16(30612),
	int16(1871), int16(2355), int16(4061), int16(5143),
	int16(7464), int16(10129), int16(11941), int16(15001),
	int16(16680), int16(18354), int16(19957), int16(22279),
	int16(24861), int16(26872), int16(28988), int16(30615),
	int16(2566), int16(3161), int16(4643), int16(6227),
	int16(7406), int16(9970), int16(11618), int16(13416),
	int16(15889), int16(17364), int16(19121), int16(20817),
	int16(22592), int16(24720), int16(28733), int16(31082),
	int16(1700), int16(2327), int16(4828), int16(5939),
	int16(7567), int16(9154), int16(11087), int16(12771),
	int16(14209), int16(16121), int16(20222), int16(22671),
	int16(24648), int16(26656), int16(28696), int16(30745),
	int16(3169), int16(3873), int16(5046), int16(6868),
	int16(8184), int16(9480), int16(12335), int16(14068),
	int16(15774), int16(17971), int16(20231), int16(21711),
	int16(23520), int16(25245), int16(27026), int16(28730),
	int16(1564), int16(2391), int16(4229), int16(6730),
	int16(8905), int16(10459), int16(13026), int16(15033),
	int16(17265), int16(19809), int16(21849), int16(23741),
	int16(25490), int16(27312), int16(29061), int16(30527),
	int16(2864), int16(3559), int16(4719), int16(6441),
	int16(9592), int16(11055), int16(12763), int16(14784),
	int16(16428), int16(18164), int16(20486), int16(22262),
	int16(24183), int16(26263), int16(28383), int16(30224),
	int16(2673), int16(3449), int16(4581), int16(5983),
	int16(6863), int16(8311), int16(12464), int16(13911),
	int16(15738), int16(17791), int16(19416), int16(21182),
	int16(24025), int16(26561), int16(28723), int16(30440),
	int16(2419), int16(3049), int16(4274), int16(6384),
	int16(8564), int16(9661), int16(11288), int16(12676),
	int16(14447), int16(17578), int16(19816), int16(21231),
	int16(23099), int16(25270), int16(26899), int16(28926),
	int16(1278), int16(2001), int16(3000), int16(5353),
	int16(9995), int16(11777), int16(13018), int16(14570),
	int16(16050), int16(17762), int16(19982), int16(21617),
	int16(23371), int16(25083), int16(27656), int16(30172),
	int16(932), int16(1624), int16(2798), int16(4570),
	int16(8592), int16(9988), int16(11552), int16(13050),
	int16(16921), int16(18677), int16(20415), int16(22810),
	int16(24817), int16(26819), int16(28804), int16(30385),
	int16(2324), int16(2973), int16(4156), int16(5702),
	int16(6919), int16(8806), int16(10259), int16(12503),
	int16(15015), int16(16567), int16(19418), int16(21375),
	int16(22943), int16(24550), int16(27024), int16(29849),
	int16(1564), int16(2373), int16(3455), int16(4907),
	int16(5975), int16(7436), int16(11786), int16(14505),
	int16(16107), int16(18148), int16(20019), int16(21653),
	int16(23740), int16(25814), int16(28578), int16(30372),
	int16(3025), int16(3729), int16(4866), int16(6520),
	int16(9487), int16(10943), int16(12358), int16(14258),
	int16(16174), int16(17501), int16(19476), int16(21408),
	int16(23227), int16(24906), int16(27347), int16(29407),
	int16(1270), int16(1965), int16(6802), int16(7995),
	int16(9204), int16(10828), int16(12507), int16(14230),
	int16(15759), int16(17860), int16(20369), int16(22502),
	int16(24633), int16(26514), int16(28535), int16(30525),
	int16(2210), int16(2749), int16(4266), int16(7487),
	int16(9878), int16(11018), int16(12823), int16(14431),
	int16(16247), int16(18626), int16(20450), int16(22054),
	int16(23739), int16(25291), int16(27074), int16(29169),
	int16(1275), int16(1926), int16(4330), int16(6573),
	int16(8441), int16(10920), int16(13260), int16(15008),
	int16(16927), int16(18573), int16(20644), int16(22217),
	int16(23983), int16(25474), int16(27372), int16(28645),
	int16(3015), int16(3670), int16(5086), int16(6372),
	int16(7888), int16(9309), int16(10966), int16(12642),
	int16(14495), int16(16172), int16(18080), int16(19972),
	int16(22454), int16(24899), int16(27362), int16(29975),
	int16(2882), int16(3733), int16(5113), int16(6482),
	int16(8125), int16(9685), int16(11598), int16(13288),
	int16(15405), int16(17192), int16(20178), int16(22426),
	int16(24801), int16(27014), int16(29212), int16(30811),
	int16(2300), int16(2968), int16(4101), int16(5442),
	int16(6327), int16(7910), int16(12455), int16(13862),
	int16(15747), int16(17505), int16(19053), int16(20679),
	int16(22615), int16(24658), int16(27499), int16(30065),
	int16(2257), int16(2940), int16(4430), int16(5991),
	int16(7042), int16(8364), int16(9414), int16(11224),
	int16(15723), int16(17420), int16(19253), int16(21469),
	int16(23915), int16(26053), int16(28430), int16(30384),
	int16(1227), int16(2045), int16(3818), int16(5011),
	int16(6990), int16(9231), int16(11024), int16(13011),
	int16(17341), int16(19017), int16(20583), int16(22799),
	int16(25195), int16(26876), int16(29351), int16(30805),
	int16(1354), int16(1924), int16(3789), int16(8077),
	int16(10453), int16(11639), int16(13352), int16(14817),
	int16(16743), int16(18189), int16(20095), int16(22014),
	int16(24593), int16(26677), int16(28647), int16(30256),
	int16(3142), int16(4049), int16(6197), int16(7417),
	int16(8753), int16(10156), int16(11533), int16(13181),
	int16(15947), int16(17655), int16(19606), int16(21402),
	int16(23487), int16(25659), int16(28123), int16(30304),
	int16(1317), int16(2263), int16(4725), int16(7611),
	int16(9667), int16(11634), int16(14143), int16(16258),
	int16(18724), int16(20698), int16(22379), int16(24007),
	int16(25775), int16(27251), int16(28930), int16(30593),
	int16(1570), int16(2323), int16(3818), int16(6215),
	int16(9893), int16(11556), int16(13070), int16(14631),
	int16(16152), int16(18290), int16(21386), int16(23346),
	int16(25114), int16(26923), int16(28712), int16(30168),
	int16(2297), int16(3905), int16(6287), int16(8558),
	int16(10668), int16(12766), int16(15019), int16(17102),
	int16(19036), int16(20677), int16(22341), int16(23871),
	int16(25478), int16(27085), int16(28851), int16(30520),
	int16(1915), int16(2507), int16(4033), int16(5749),
	int16(7059), int16(8871), int16(10659), int16(12198),
	int16(13937), int16(15383), int16(16869), int16(18707),
	int16(23175), int16(25818), int16(28514), int16(30501),
	int16(2404), int16(2918), int16(5190), int16(6252),
	int16(7426), int16(9887), int16(12387), int16(14795),
	int16(16754), int16(18368), int16(20338), int16(22003),
	int16(24236), int16(26456), int16(28490), int16(30397),
	int16(1621), int16(2227), int16(3479), int16(5085),
	int16(9425), int16(12892), int16(14246), int16(15652),
	int16(17205), int16(18674), int16(20446), int16(22209),
	int16(23778), int16(25867), int16(27931), int16(30093),
	int16(1869), int16(2390), int16(4105), int16(7021),
	int16(11221), int16(12775), int16(14059), int16(15590),
	int16(17024), int16(18608), int16(20595), int16(22075),
	int16(23649), int16(25154), int16(26914), int16(28671),
	int16(2551), int16(3252), int16(4688), int16(6562),
	int16(7869), int16(9125), int16(10475), int16(11800),
	int16(15402), int16(18780), int16(20992), int16(22555),
	int16(24289), int16(25968), int16(27465), int16(29232),
	int16(2705), int16(3493), int16(4735), int16(6360),
	int16(7905), int16(9352), int16(11538), int16(13430),
	int16(15239), int16(16919), int16(18619), int16(20094),
	int16(21800), int16(23342), int16(25200), int16(29257),
	int16(2166), int16(2791), int16(4011), int16(5081),
	int16(5896), int16(9038), int16(13407), int16(14703),
	int16(16543), int16(18189), int16(19896), int16(21857),
	int16(24872), int16(26971), int16(28955), int16(30514),
	int16(1865), int16(3021), int16(4696), int16(6534),
	int16(8343), int16(9914), int16(12789), int16(14103),
	int16(16533), int16(17729), int16(21340), int16(22439),
	int16(24873), int16(26330), int16(28428), int16(30154),
	int16(3369), int16(4345), int16(6573), int16(8763),
	int16(10309), int16(11713), int16(13367), int16(14784),
	int16(16483), int16(18145), int16(19839), int16(21247),
	int16(23292), int16(25477), int16(27555), int16(29447),
	int16(1265), int16(2184), int16(5443), int16(7893),
	int16(10591), int16(13139), int16(15105), int16(16639),
	int16(18402), int16(19826), int16(21419), int16(22995),
	int16(24719), int16(26437), int16(28363), int16(30125),
	int16(1584), int16(2004), int16(3535), int16(4450),
	int16(8662), int16(10764), int16(12832), int16(14978),
	int16(16972), int16(18794), int16(20932), int16(22547),
	int16(24636), int16(26521), int16(28701), int16(30567),
	int16(3419), int16(4528), int16(6602), int16(7890),
	int16(9508), int16(10875), int16(12771), int16(14357),
	int16(16051), int16(18330), int16(20630), int16(22490),
	int16(25070), int16(26936), int16(28946), int16(30542),
	int16(1726), int16(2252), int16(4597), int16(6950),
	int16(8379), int16(9823), int16(11363), int16(12794),
	int16(14306), int16(15476), int16(16798), int16(18018),
	int16(21671), int16(25550), int16(28148), int16(30367),
	int16(3385), int16(3870), int16(5307), int16(6388),
	int16(7141), int16(8684), int16(12695), int16(14939),
	int16(16480), int16(18277), int16(20537), int16(22048),
	int16(23947), int16(25965), int16(28214), int16(29956),
	int16(2771), int16(3306), int16(4450), int16(5560),
	int16(6453), int16(9493), int16(13548), int16(14754),
	int16(16743), int16(18447), int16(20028), int16(21736),
	int16(23746), int16(25353), int16(27141), int16(29066),
	int16(3028), int16(3900), int16(6617), int16(7893),
	int16(9211), int16(10480), int16(12047), int16(13583),
	int16(15182), int16(16662), int16(18502), int16(20092),
	int16(22190), int16(24358), int16(26302), int16(28957),
	int16(2000), int16(2550), int16(4067), int16(6837),
	int16(9628), int16(11002), int16(12594), int16(14098),
	int16(15589), int16(17195), int16(18679), int16(20099),
	int16(21530), int16(23085), int16(24641), int16(29022),
	int16(2844), int16(3302), int16(5103), int16(6107),
	int16(6911), int16(8598), int16(12416), int16(14054),
	int16(16026), int16(18567), int16(20672), int16(22270),
	int16(23952), int16(25771), int16(27658), int16(30026),
	int16(4043), int16(5150), int16(7268), int16(9056),
	int16(10916), int16(12638), int16(14543), int16(16184),
	int16(17948), int16(19691), int16(21357), int16(22981),
	int16(24825), int16(26591), int16(28479), int16(30233),
	int16(2109), int16(2625), int16(4320), int16(5525),
	int16(7454), int16(10220), int16(12980), int16(14698),
	int16(17627), int16(19263), int16(20485), int16(22381),
	int16(24279), int16(25777), int16(27847), int16(30458),
	int16(1550), int16(2667), int16(6473), int16(9496),
	int16(10985), int16(12352), int16(13795), int16(15233),
	int16(17099), int16(18642), int16(20461), int16(22116),
	int16(24197), int16(26291), int16(28403), int16(30132),
	int16(2411), int16(3084), int16(4145), int16(5394),
	int16(6367), int16(8154), int16(13125), int16(16049),
	int16(17561), int16(19125), int16(21258), int16(22762),
	int16(24459), int16(26317), int16(28255), int16(29702),
	int16(4159), int16(4516), int16(5956), int16(7635),
	int16(8254), int16(8980), int16(11208), int16(14133),
	int16(16210), int16(17875), int16(20196), int16(21864),
	int16(23840), int16(25747), int16(28058), int16(30012),
	int16(2026), int16(2431), int16(2845), int16(3618),
	int16(7950), int16(9802), int16(12721), int16(14460),
	int16(16576), int16(18984), int16(21376), int16(23319),
	int16(24961), int16(26718), int16(28971), int16(30640),
	int16(3429), int16(3833), int16(4472), int16(4912),
	int16(7723), int16(10386), int16(12981), int16(15322),
	int16(16699), int16(18807), int16(20778), int16(22551),
	int16(24627), int16(26494), int16(28334), int16(30482),
	int16(4740), int16(5169), int16(5796), int16(6485),
	int16(6998), int16(8830), int16(11777), int16(14414),
	int16(16831), int16(18413), int16(20789), int16(22369),
	int16(24236), int16(25835), int16(27807), int16(30021),
	int16(150), int16(168), int16(-17), int16(-107),
	int16(-142), int16(-229), int16(-320), int16(-406),
	int16(-503), int16(-620), int16(-867), int16(-935),
	int16(-902), int16(-680), int16(-398), int16(-114),
	int16(-398), int16(-355), int16(49), int16(255),
	int16(114), int16(260), int16(399), int16(264),
	int16(317), int16(431), int16(514), int16(531),
	int16(435), int16(356), int16(238), int16(106),
	int16(-43), int16(-36), int16(-169), int16(-224),
	int16(-391), int16(-633), int16(-776), int16(-970),
	int16(-844), int16(-455), int16(-181), int16(-12),
	int16(85), int16(85), int16(164), int16(195),
	int16(122), int16(85), int16(-158), int16(-640),
	int16(-903), int16(9), int16(7), int16(-124),
	int16(149), int16(32), int16(220), int16(369),
	int16(242), int16(115), int16(79), int16(84),
	int16(-146), int16(-216), int16(-70), int16(1024),
	int16(751), int16(574), int16(440), int16(377),
	int16(352), int16(203), int16(30), int16(16),
	int16(-3), int16(81), int16(161), int16(100),
	int16(-148), int16(-176), int16(933), int16(750),
	int16(404), int16(171), int16(-2), int16(-146),
	int16(-411), int16(-442), int16(-541), int16(-552),
	int16(-442), int16(-269), int16(-240), int16(-52),
	int16(603), int16(635), int16(405), int16(178),
	int16(215), int16(19), int16(-153), int16(-167),
	int16(-290), int16(-219), int16(151), int16(271),
	int16(151), int16(119), int16(303), int16(266),
	int16(100), int16(69), int16(-293), int16(-657),
	int16(939), int16(659), int16(442), int16(351),
	int16(132), int16(98), int16(-16), int16(-1),
	int16(-135), int16(-200), int16(-223), int16(-89),
	int16(167), int16(154), int16(172), int16(237),
	int16(-45), int16(-183), int16(-228), int16(-486),
	int16(263), int16(608), int16(158), int16(-125),
	int16(-390), int16(-227), int16(-118), int16(43),
	int16(-457), int16(-392), int16(-769), int16(-840),
	int16(20), int16(-117), int16(-194), int16(-189),
	int16(-173), int16(-173), int16(-33), int16(32),
	int16(174), int16(144), int16(115), int16(167),
	int16(57), int16(44), int16(14), int16(147),
	int16(96), int16(-54), int16(-142), int16(-129),
	int16(-254), int16(-331), int16(304), int16(310),
	int16(-52), int16(-419), int16(-846), int16(-1060),
	int16(-88), int16(-123), int16(-202), int16(-343),
	int16(-554), int16(-961), int16(-951), int16(327),
	int16(159), int16(81), int16(255), int16(227),
	int16(120), int16(203), int16(256), int16(192),
	int16(164), int16(224), int16(290), int16(195),
	int16(216), int16(209), int16(128), int16(832),
	int16(1028), int16(889), int16(698), int16(504),
	int16(408), int16(355), int16(218), int16(32),
	int16(-115), int16(-84), int16(-276), int16(-100),
	int16(-312), int16(-484), int16(899), int16(682),
	int16(465), int16(456), int16(241), int16(-12),
	int16(-275), int16(-425), int16(-461), int16(-367),
	int16(-33), int16(-28), int16(-102), int16(-194),
	int16(-527), int16(863), int16(906), int16(463),
	int16(245), int16(13), int16(-212), int16(-305),
	int16(-105), int16(163), int16(279), int16(176),
	int16(93), int16(67), int16(115), int16(192),
	int16(61), int16(-50), int16(-132), int16(-175),
	int16(-224), int16(-271), int16(-629), int16(-252),
	int16(1158), int16(972), int16(638), int16(280),
	int16(300), int16(326), int16(143), int16(-152),
	int16(-214), int16(-287), int16(53), int16(-42),
	int16(-236), int16(-352), int16(-423), int16(-248),
	int16(-129), int16(-163), int16(-178), int16(-119),
	int16(85), int16(57), int16(514), int16(382),
	int16(374), int16(402), int16(424), int16(423),
	int16(271), int16(197), int16(97), int16(40),
	int16(39), int16(-97), int16(-191), int16(-164),
	int16(-230), int16(-256), int16(-410), int16(396),
	int16(327), int16(127), int16(10), int16(-119),
	int16(-167), int16(-291), int16(-274), int16(-141),
	int16(-99), int16(-226), int16(-218), int16(-139),
	int16(-224), int16(-209), int16(-268), int16(-442),
	int16(-413), int16(222), int16(58), int16(521),
	int16(344), int16(258), int16(76), int16(-42),
	int16(-142), int16(-165), int16(-123), int16(-92),
	int16(47), int16(8), int16(-3), int16(-191),
	int16(-11), int16(-164), int16(-167), int16(-351),
	int16(-740), int16(311), int16(538), int16(291),
	int16(184), int16(29), int16(-105), int16(9),
	int16(-30), int16(-54), int16(-17), int16(-77),
	int16(-271), int16(-412), int16(-622), int16(-648),
	int16(476), int16(186), int16(-66), int16(-197),
	int16(-73), int16(-94), int16(-15), int16(47),
	int16(28), int16(112), int16(-58), int16(-33),
	int16(65), int16(19), int16(84), int16(86),
	int16(276), int16(114), int16(472), int16(786),
	int16(799), int16(625), int16(415), int16(178),
	int16(-35), int16(-26), int16(5), int16(9),
	int16(83), int16(39), int16(37), int16(39),
	int16(-184), int16(-374), int16(-265), int16(-362),
	int16(-501), int16(337), int16(716), int16(478),
	int16(-60), int16(-125), int16(-163), int16(362),
	int16(17), int16(-122), int16(-233), int16(279),
	int16(138), int16(157), int16(318), int16(193),
	int16(189), int16(209), int16(266), int16(252),
	int16(-46), int16(-56), int16(-277), int16(-429),
	int16(464), int16(386), int16(142), int16(44),
	int16(-43), int16(66), int16(264), int16(182),
	int16(47), int16(14), int16(-26), int16(-79),
	int16(49), int16(15), int16(-128), int16(-203),
	int16(-400), int16(-478), int16(325), int16(27),
	int16(234), int16(411), int16(205), int16(129),
	int16(12), int16(58), int16(123), int16(57),
	int16(171), int16(137), int16(96), int16(128),
	int16(-32), int16(134), int16(-12), int16(57),
	int16(119), int16(26), int16(-22), int16(-165),
	int16(-500), int16(-701), int16(-528), int16(-116),
	int16(64), int16(-8), int16(97), int16(-9),
	int16(-162), int16(-66), int16(-156), int16(-194),
	int16(-303), int16(-546), int16(-341), int16(546),
	int16(358), int16(95), int16(45), int16(76),
	int16(270), int16(403), int16(205), int16(100),
	int16(123), int16(50), int16(-53), int16(-144),
	int16(-110), int16(-13), int16(32), int16(-228),
	int16(-130), int16(353), int16(296), int16(56),
	int16(-372), int16(-253), int16(365), int16(73),
	int16(10), int16(-34), int16(-139), int16(-191),
	int16(-96), int16(5), int16(44), int16(-85),
	int16(-179), int16(-129), int16(-192), int16(-246),
	int16(-85), int16(-110), int16(-155), int16(-44),
	int16(-27), int16(145), int16(138), int16(79),
	int16(32), int16(-148), int16(-577), int16(-634),
	int16(191), int16(94), int16(-9), int16(-35),
	int16(-77), int16(-84), int16(-56), int16(-171),
	int16(-298), int16(-271), int16(-243), int16(-156),
	int16(-328), int16(-235), int16(-76), int16(-128),
	int16(-121), int16(129), int16(13), int16(-22),
	int16(32), int16(45), int16(-248), int16(-65),
	int16(193), int16(-81), int16(299), int16(57),
	int16(-147), int16(192), int16(-165), int16(-354),
	int16(-334), int16(-106), int16(-156), int16(-40),
	int16(-3), int16(-68), int16(124), int16(-257),
	int16(78), int16(124), int16(170), int16(412),
	int16(227), int16(105), int16(-104), int16(12),
	int16(154), int16(250), int16(274), int16(258),
	int16(4), int16(-27), int16(235), int16(152),
	int16(51), int16(338), int16(300), int16(7),
	int16(-314), int16(-411), int16(215), int16(170),
	int16(-9), int16(-93), int16(-77), int16(76),
	int16(67), int16(54), int16(200), int16(315),
	int16(163), int16(72), int16(-91), int16(-402),
	int16(158), int16(187), int16(-156), int16(-91),
	int16(290), int16(267), int16(167), int16(91),
	int16(140), int16(171), int16(112), int16(9),
	int16(-42), int16(-177), int16(-440), int16(385),
	int16(80), int16(15), int16(172), int16(129),
	int16(41), int16(-129), int16(-372), int16(-24),
	int16(-75), int16(-30), int16(-170), int16(10),
	int16(-118), int16(57), int16(78), int16(-101),
	int16(232), int16(161), int16(123), int16(256),
	int16(277), int16(101), int16(-192), int16(-629),
	int16(-100), int16(-60), int16(-232), int16(66),
	int16(13), int16(-13), int16(-80), int16(-239),
	int16(239), int16(37), int16(32), int16(89),
	int16(-319), int16(-579), int16(450), int16(360),
	int16(3), int16(-29), int16(-299), int16(-89),
	int16(-54), int16(-110), int16(-246), int16(-164),
	int16(6), int16(-188), int16(338), int16(176),
	int16(-92), int16(197), int16(137), int16(134),
	int16(12), int16(-2), int16(56), int16(-183),
	int16(114), int16(-36), int16(-131), int16(-204),
	int16(75), int16(-25), int16(-174), int16(191),
	int16(-15), int16(-290), int16(-429), int16(-267),
	int16(79), int16(37), int16(106), int16(23),
	int16(-384), int16(425), int16(70), int16(-14),
	int16(212), int16(105), int16(15), int16(-2),
	int16(-42), int16(-37), int16(-123), int16(108),
	int16(28), int16(-48), int16(193), int16(197),
	int16(173), int16(-33), int16(37), int16(73),
	int16(-57), int16(256), int16(137), int16(-58),
	int16(-430), int16(-228), int16(217), int16(-51),
	int16(-10), int16(-58), int16(-6), int16(22),
	int16(104), int16(61), int16(-119), int16(169),
	int16(144), int16(16), int16(-46), int16(-394),
	int16(60), int16(454), int16(-80), int16(-298),
	int16(-65), int16(25), int16(0), int16(-24),
	int16(-65), int16(-417), int16(465), int16(276),
	int16(-3), int16(-194), int16(-13), int16(130),
	int16(19), int16(-6), int16(-21), int16(-24),
	int16(-180), int16(-53), int16(-85), int16(20),
	int16(118), int16(147), int16(113), int16(-75),
	int16(-289), int16(226), int16(-122), int16(227),
	int16(270), int16(125), int16(109), int16(197),
	int16(125), int16(138), int16(44), int16(60),
	int16(25), int16(-55), int16(-167), int16(-32),
	int16(-139), int16(-193), int16(-173), int16(-316),
	int16(287), int16(-208), int16(253), int16(239),
	int16(27), int16(-80), int16(-188), int16(-28),
	int16(-182), int16(-235), int16(156), int16(-117),
	int16(128), int16(-48), int16(-58), int16(-226),
	int16(172), int16(181), int16(167), int16(19),
	int16(62), int16(10), int16(2), int16(181),
	int16(151), int16(108), int16(-16), int16(-11),
	int16(-78), int16(-331), int16(411), int16(133),
	int16(17), int16(104), int16(64), int16(-184),
	int16(24), int16(-30), int16(-3), int16(-283),
	int16(121), int16(204), int16(-8), int16(-199),
	int16(-21), int16(-80), int16(-169), int16(-157),
	int16(-191), int16(-136), int16(81), int16(155),
	int16(14), int16(-131), int16(244), int16(74),
	int16(-57), int16(-47), int16(-280), int16(347),
	int16(111), int16(-77), int16(-128), int16(-142),
	int16(-194), int16(-125), int16(-6), int16(-68),
	int16(91), int16(1), int16(23), int16(14),
	int16(-154), int16(-34), int16(23), int16(-38),
	int16(-343), int16(503), int16(146), int16(-38),
	int16(-46), int16(-41), int16(58), int16(31),
	int16(63), int16(-48), int16(-117), int16(45),
	int16(28), int16(1), int16(-89), int16(-5),
	int16(-44), int16(-29), int16(-448), int16(487),
	int16(204), int16(81), int16(46), int16(-106),
	int16(-302), int16(380), int16(120), int16(-38),
	int16(-12), int16(-39), int16(70), int16(-3),
	int16(25), int16(-65), int16(30), int16(-11),
	int16(34), int16(-15), int16(22), int16(-115),
	int16(0), int16(-79), int16(-83), int16(45),
	int16(114), int16(43), int16(150), int16(36),
	int16(233), int16(149), int16(195), int16(5),
	int16(25), int16(-52), int16(-475), int16(274),
	int16(28), int16(-39), int16(-8), int16(-66),
	int16(-255), int16(258), int16(56), int16(143),
	int16(-45), int16(-190), int16(165), int16(-60),
	int16(20), int16(2), int16(125), int16(-129),
	int16(51), int16(-8), int16(-335), int16(288),
	int16(38), int16(59), int16(25), int16(-42),
	int16(23), int16(-118), int16(-112), int16(11),
	int16(-55), int16(-133), int16(-109), int16(24),
	int16(-105), int16(78), int16(-64), int16(-245),
	int16(202), int16(-65), int16(-127), int16(162),
	int16(40), int16(-94), int16(89), int16(-85),
	int16(-119), int16(-103), int16(97), int16(9),
	int16(-70), int16(-28), int16(194), int16(86),
	int16(-112), int16(-92), int16(-114), int16(74),
	int16(-49), int16(46), int16(-84), int16(-178),
	int16(113), int16(52), int16(-205), int16(333),
	int16(88), int16(222), int16(56), int16(-55),
	int16(13), int16(86), int16(4), int16(-77),
	int16(224), int16(114), int16(-105), int16(112),
	int16(125), int16(-29), int16(-18), int16(-144),
	int16(22), int16(-58), int16(-99), int16(28),
	int16(114), int16(-66), int16(-32), int16(-169),
	int16(-314), int16(285), int16(72), int16(-74),
	int16(179), int16(28), int16(-79), int16(-182),
	int16(13), int16(-55), int16(147), int16(13),
	int16(12), int16(-54), int16(31), int16(-84),
	int16(-17), int16(-75), int16(-228), int16(83),
	int16(-375), int16(436), int16(110), int16(-63),
	int16(-27), int16(-136), int16(169), int16(-56),
	int16(-8), int16(-171), int16(184), int16(-42),
	int16(148), int16(68), int16(204), int16(235),
	int16(110), int16(-229), int16(91), int16(171),
	int16(-43), int16(-3), int16(-26), int16(-99),
	int16(-111), int16(71), int16(-170), int16(202),
	int16(-67), int16(181), int16(-37), int16(109),
	int16(-120), int16(3), int16(-55), int16(-260),
	int16(-16), int16(152), int16(91), int16(142),
	int16(42), int16(44), int16(134), int16(47),
	int16(17), int16(-35), int16(22), int16(79),
	int16(-169), int16(41), int16(46), int16(277),
	int16(-93), int16(-49), int16(-126), int16(37),
	int16(-103), int16(-34), int16(-22), int16(-90),
	int16(-134), int16(-205), int16(92), int16(-9),
	int16(1), int16(-195), int16(-239), int16(45),
	int16(54), int16(18), int16(-23), int16(-1),
	int16(-80), int16(-98), int16(-20), int16(-261),
	int16(306), int16(72), int16(20), int16(-89),
	int16(-217), int16(11), int16(6), int16(-82),
	int16(89), int16(13), int16(-129), int16(-89),
	int16(83), int16(-71), int16(-55), int16(130),
	int16(-98), int16(-146), int16(-27), int16(-57),
	int16(53), int16(275), int16(17), int16(170),
	int16(-5), int16(-54), int16(132), int16(-64),
	int16(72), int16(160), int16(-125), int16(-168),
	int16(72), int16(40), int16(170), int16(78),
	int16(248), int16(116), int16(20), int16(84),
	int16(31), int16(-34), int16(190), int16(38),
	int16(13), int16(-106), int16(225), int16(27),
	int16(-168), int16(24), int16(-157), int16(-122),
	int16(165), int16(11), int16(-161), int16(-213),
	int16(-12), int16(-51), int16(-101), int16(42),
	int16(101), int16(27), int16(55), int16(111),
	int16(75), int16(71), int16(-96), int16(-1),
	int16(65), int16(-277), int16(393), int16(-26),
	int16(-44), int16(-68), int16(-84), int16(-66),
	int16(-95), int16(235), int16(179), int16(-25),
	int16(-41), int16(27), int16(-91), int16(-128),
	int16(-222), int16(146), int16(-72), int16(-30),
	int16(-24), int16(55), int16(-126), int16(-68),
	int16(-58), int16(-127), int16(13), int16(-97),
	int16(-106), int16(174), int16(-100), int16(155),
	int16(101), int16(-146), int16(-21), int16(261),
	int16(22), int16(38), int16(-66), int16(65),
	int16(4), int16(70), int16(64), int16(144),
	int16(59), int16(213), int16(71), int16(-337),
	int16(303), int16(-52), int16(51), int16(-56),
	int16(1), int16(10), int16(-15), int16(-5),
	int16(34), int16(52), int16(228), int16(131),
	int16(161), int16(-127), int16(-214), int16(238),
	int16(123), int16(64), int16(-147), int16(-50),
	int16(-34), int16(-127), int16(204), int16(162),
	int16(85), int16(41), int16(5), int16(-140),
	int16(73), int16(-150), int16(56), int16(-96),
	int16(-66), int16(-20), int16(2), int16(-235),
	int16(59), int16(-22), int16(-107), int16(150),
	int16(-16), int16(-47), int16(-4), int16(81),
	int16(-67), int16(167), int16(149), int16(149),
	int16(-157), int16(288), int16(-156), int16(-27),
	int16(-8), int16(18), int16(83), int16(-24),
	int16(-41), int16(-167), int16(158), int16(-100),
	int16(93), int16(53), int16(201), int16(15),
	int16(42), int16(266), int16(278), int16(-12),
	int16(-6), int16(-37), int16(85), int16(6),
	int16(20), int16(-188), int16(-271), int16(107),
	int16(-13), int16(-80), int16(51), int16(202),
	int16(173), int16(-69), int16(78), int16(-188),
	int16(46), int16(4), int16(153), int16(12),
	int16(-138), int16(169), int16(5), int16(-58),
	int16(-123), int16(-108), int16(-243), int16(150),
	int16(10), int16(-191), int16(246), int16(-15),
	int16(38), int16(25), int16(-10), int16(14),
	int16(61), int16(50), int16(-206), int16(-215),
	int16(-220), int16(90), int16(5), int16(-149),
	int16(-219), int16(56), int16(142), int16(24),
	int16(-376), int16(77), int16(-80), int16(75),
	int16(6), int16(42), int16(-101), int16(16),
	int16(56), int16(14), int16(-57), int16(3),
	int16(-17), int16(80), int16(57), int16(-36),
	int16(88), int16(-59), int16(-97), int16(-19),
	int16(-148), int16(46), int16(-219), int16(226),
	int16(114), int16(-4), int16(-72), int16(-15),
	int16(37), int16(-49), int16(-28), int16(247),
	int16(44), int16(123), int16(47), int16(-122),
	int16(-38), int16(17), int16(4), int16(-113),
	int16(-32), int16(-224), int16(154), int16(-134),
	int16(196), int16(71), int16(-267), int16(-85),
	int16(28), int16(-70), int16(89), int16(-120),
	int16(99), int16(-2), int16(64), int16(76),
	int16(-166), int16(-48), int16(189), int16(-35),
	int16(-92), int16(-169), int16(-123), int16(339),
	int16(38), int16(-25), int16(38), int16(-35),
	int16(225), int16(-139), int16(-50), int16(-63),
	int16(246), int16(60), int16(-185), int16(-109),
	int16(-49), int16(-53), int16(-167), int16(51),
	int16(149), int16(60), int16(-101), int16(-33),
	int16(25), int16(-76), int16(120), int16(32),
	int16(-30), int16(-83), int16(102), int16(91),
	int16(-186), int16(-261), int16(131), int16(-197),
} /* tables_NLSF_CB0_16.c:429:17 */

var NLSF_CB0_16_Stage_info = [10]NLSF_CBS{
	{FnVectors: 128, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 16, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 16, FCB_NLSF_Q15: 0, FRates_Q5: 0},
} /* tables_NLSF_CB0_16.c:1297:25 */

var NLSF_CB0_16 = NLSF_CB_struct{
	FnStages:       10,
	FCBStages:      0,
	FNDeltaMin_Q15: 0,
	FCDF:           0,
	FStartPtr:      0,
	FMiddleIx:      0,
} /* tables_NLSF_CB0_16.c:1311:31 */

var NLSF_MSVQ_CB1_10_CDF = [78]uint16{
	uint16(0),
	uint16(17096),
	uint16(24130),
	uint16(28997),
	uint16(33179),
	uint16(36696),
	uint16(40213),
	uint16(42493),
	uint16(44252),
	uint16(45973),
	uint16(47551),
	uint16(49095),
	uint16(50542),
	uint16(51898),
	uint16(53196),
	uint16(54495),
	uint16(55685),
	uint16(56851),
	uint16(57749),
	uint16(58628),
	uint16(59435),
	uint16(60207),
	uint16(60741),
	uint16(61220),
	uint16(61700),
	uint16(62179),
	uint16(62659),
	uint16(63138),
	uint16(63617),
	uint16(64097),
	uint16(64576),
	uint16(65056),
	uint16(65535),
	uint16(0),
	uint16(20378),
	uint16(33032),
	uint16(40395),
	uint16(46721),
	uint16(51707),
	uint16(56585),
	uint16(61157),
	uint16(65535),
	uint16(0),
	uint16(15055),
	uint16(25472),
	uint16(35447),
	uint16(42501),
	uint16(48969),
	uint16(54773),
	uint16(60212),
	uint16(65535),
	uint16(0),
	uint16(12069),
	uint16(22440),
	uint16(32812),
	uint16(40145),
	uint16(46870),
	uint16(53595),
	uint16(59630),
	uint16(65535),
	uint16(0),
	uint16(10839),
	uint16(19954),
	uint16(27957),
	uint16(35961),
	uint16(43965),
	uint16(51465),
	uint16(58805),
	uint16(65535),
	uint16(0),
	uint16(8933),
	uint16(17674),
	uint16(26415),
	uint16(34785),
	uint16(42977),
	uint16(50820),
	uint16(58496),
	uint16(65535),
} /* tables_NLSF_CB1_10.c:38:18 */

var NLSF_MSVQ_CB1_10_CDF_start_ptr = [6]uintptr{
	0,
	0,
	0,
	0,
	0,
	0,
} /* tables_NLSF_CB1_10.c:120:18 */

var NLSF_MSVQ_CB1_10_CDF_middle_idx = [6]int32{
	5,
	3,
	4,
	4,
	5,
	5,
} /* tables_NLSF_CB1_10.c:130:15 */

var NLSF_MSVQ_CB1_10_rates_Q5 = [72]int16{
	int16(62), int16(103),
	int16(120), int16(127),
	int16(135), int16(135),
	int16(155), int16(167),
	int16(168), int16(172),
	int16(173), int16(176),
	int16(179), int16(181),
	int16(181), int16(185),
	int16(186), int16(198),
	int16(199), int16(203),
	int16(205), int16(222),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(54), int16(76),
	int16(101), int16(108),
	int16(119), int16(120),
	int16(123), int16(125),
	int16(68), int16(85),
	int16(87), int16(103),
	int16(107), int16(112),
	int16(115), int16(116),
	int16(78), int16(85),
	int16(85), int16(101),
	int16(105), int16(105),
	int16(110), int16(111),
	int16(83), int16(91),
	int16(97), int16(97),
	int16(97), int16(100),
	int16(101), int16(105),
	int16(92), int16(93),
	int16(93), int16(95),
	int16(96), int16(98),
	int16(99), int16(103),
} /* tables_NLSF_CB1_10.c:140:17 */

var NLSF_MSVQ_CB1_10_ndelta_min_Q15 = [11]int32{
	462,
	3,
	64,
	74,
	98,
	50,
	97,
	68,
	120,
	53,
	639,
} /* tables_NLSF_CB1_10.c:180:15 */

var NLSF_MSVQ_CB1_10_Q15 = [720]int16{
	int16(1877), int16(4646),
	int16(7712), int16(10745),
	int16(13964), int16(17028),
	int16(20239), int16(23182),
	int16(26471), int16(29287),
	int16(1612), int16(3278),
	int16(7086), int16(9975),
	int16(13228), int16(16264),
	int16(19596), int16(22690),
	int16(26037), int16(28965),
	int16(2169), int16(3830),
	int16(6460), int16(8958),
	int16(11960), int16(14750),
	int16(18408), int16(21659),
	int16(25018), int16(28043),
	int16(3680), int16(6024),
	int16(8986), int16(12256),
	int16(15201), int16(18188),
	int16(21741), int16(24460),
	int16(27484), int16(30059),
	int16(2584), int16(5187),
	int16(7799), int16(10902),
	int16(13179), int16(15765),
	int16(19017), int16(22431),
	int16(25891), int16(28698),
	int16(3731), int16(5751),
	int16(8650), int16(11742),
	int16(15090), int16(17407),
	int16(20391), int16(23421),
	int16(26228), int16(29247),
	int16(2107), int16(6323),
	int16(8915), int16(12226),
	int16(14775), int16(17791),
	int16(20664), int16(23679),
	int16(26829), int16(29353),
	int16(1677), int16(2870),
	int16(5386), int16(8077),
	int16(11817), int16(15176),
	int16(18657), int16(22006),
	int16(25513), int16(28689),
	int16(2111), int16(3625),
	int16(7027), int16(10588),
	int16(14059), int16(17193),
	int16(21137), int16(24260),
	int16(27577), int16(30036),
	int16(2428), int16(4010),
	int16(5765), int16(9376),
	int16(13805), int16(15821),
	int16(19444), int16(22389),
	int16(25295), int16(29310),
	int16(2256), int16(4628),
	int16(8377), int16(12441),
	int16(15283), int16(19462),
	int16(22257), int16(25551),
	int16(28432), int16(30304),
	int16(2352), int16(3675),
	int16(6129), int16(11868),
	int16(14551), int16(16655),
	int16(19624), int16(21883),
	int16(26526), int16(28849),
	int16(5243), int16(7248),
	int16(10558), int16(13269),
	int16(15651), int16(17919),
	int16(21141), int16(23827),
	int16(27102), int16(29519),
	int16(4422), int16(6725),
	int16(10449), int16(13273),
	int16(16124), int16(19921),
	int16(22826), int16(26061),
	int16(28763), int16(30583),
	int16(4508), int16(6291),
	int16(9504), int16(11809),
	int16(13827), int16(15950),
	int16(19077), int16(22084),
	int16(25740), int16(28658),
	int16(2540), int16(4297),
	int16(8579), int16(13578),
	int16(16634), int16(19101),
	int16(21547), int16(23887),
	int16(26777), int16(29146),
	int16(3377), int16(6358),
	int16(10224), int16(14518),
	int16(17905), int16(21056),
	int16(23637), int16(25784),
	int16(28161), int16(30109),
	int16(4177), int16(5942),
	int16(8159), int16(10108),
	int16(12130), int16(15470),
	int16(20191), int16(23326),
	int16(26782), int16(29359),
	int16(2492), int16(3801),
	int16(6144), int16(9825),
	int16(16000), int16(18671),
	int16(20893), int16(23663),
	int16(25899), int16(28974),
	int16(3011), int16(4727),
	int16(6834), int16(10505),
	int16(12465), int16(14496),
	int16(17065), int16(20052),
	int16(25265), int16(28057),
	int16(4149), int16(7197),
	int16(12338), int16(15076),
	int16(18002), int16(20190),
	int16(22187), int16(24723),
	int16(27083), int16(29125),
	int16(2975), int16(4578),
	int16(6448), int16(8378),
	int16(9671), int16(13225),
	int16(19502), int16(22277),
	int16(26058), int16(28850),
	int16(4102), int16(5760),
	int16(7744), int16(9484),
	int16(10744), int16(12308),
	int16(14677), int16(19607),
	int16(24841), int16(28381),
	int16(4931), int16(9287),
	int16(12477), int16(13395),
	int16(13712), int16(14351),
	int16(16048), int16(19867),
	int16(24188), int16(28994),
	int16(4141), int16(7867),
	int16(13140), int16(17720),
	int16(20064), int16(21108),
	int16(21692), int16(22722),
	int16(23736), int16(27449),
	int16(4011), int16(8720),
	int16(13234), int16(16206),
	int16(17601), int16(18289),
	int16(18524), int16(19689),
	int16(23234), int16(27882),
	int16(3420), int16(5995),
	int16(11230), int16(15117),
	int16(15907), int16(16783),
	int16(17762), int16(23347),
	int16(26898), int16(29946),
	int16(3080), int16(6786),
	int16(10465), int16(13676),
	int16(18059), int16(23615),
	int16(27058), int16(29082),
	int16(29563), int16(29905),
	int16(3038), int16(5620),
	int16(9266), int16(12870),
	int16(18803), int16(19610),
	int16(20010), int16(20802),
	int16(23882), int16(29306),
	int16(3314), int16(6420),
	int16(9046), int16(13262),
	int16(15869), int16(23117),
	int16(23667), int16(24215),
	int16(24487), int16(25915),
	int16(3469), int16(6963),
	int16(10103), int16(15282),
	int16(20531), int16(23240),
	int16(25024), int16(26021),
	int16(26736), int16(27255),
	int16(3041), int16(6459),
	int16(9777), int16(12896),
	int16(16315), int16(19410),
	int16(24070), int16(29353),
	int16(31795), int16(32075),
	int16(-200), int16(-134),
	int16(-113), int16(-204),
	int16(-347), int16(-440),
	int16(-352), int16(-211),
	int16(-418), int16(-172),
	int16(-313), int16(59),
	int16(495), int16(772),
	int16(721), int16(614),
	int16(334), int16(444),
	int16(225), int16(242),
	int16(161), int16(16),
	int16(274), int16(564),
	int16(-73), int16(-188),
	int16(-395), int16(-171),
	int16(777), int16(508),
	int16(1340), int16(1145),
	int16(699), int16(196),
	int16(223), int16(173),
	int16(90), int16(25),
	int16(-26), int16(18),
	int16(133), int16(-105),
	int16(-360), int16(-277),
	int16(859), int16(634),
	int16(41), int16(-557),
	int16(-768), int16(-926),
	int16(-601), int16(-1021),
	int16(-1189), int16(-365),
	int16(225), int16(107),
	int16(374), int16(-50),
	int16(433), int16(417),
	int16(156), int16(39),
	int16(-597), int16(-1397),
	int16(-1594), int16(-592),
	int16(-485), int16(-292),
	int16(253), int16(87),
	int16(-0), int16(-6),
	int16(-25), int16(-345),
	int16(-240), int16(120),
	int16(1261), int16(946),
	int16(166), int16(-277),
	int16(241), int16(167),
	int16(170), int16(429),
	int16(518), int16(714),
	int16(602), int16(254),
	int16(134), int16(92),
	int16(-152), int16(-324),
	int16(-394), int16(49),
	int16(-151), int16(-304),
	int16(-724), int16(-657),
	int16(-162), int16(-369),
	int16(-35), int16(3),
	int16(-2), int16(-312),
	int16(-200), int16(-92),
	int16(-227), int16(242),
	int16(628), int16(565),
	int16(-124), int16(1056),
	int16(770), int16(101),
	int16(-84), int16(-33),
	int16(4), int16(-192),
	int16(-272), int16(5),
	int16(-627), int16(-977),
	int16(419), int16(472),
	int16(53), int16(-103),
	int16(145), int16(322),
	int16(-95), int16(-31),
	int16(-100), int16(-303),
	int16(-560), int16(-1067),
	int16(-413), int16(714),
	int16(283), int16(2),
	int16(-223), int16(-367),
	int16(523), int16(360),
	int16(-38), int16(-115),
	int16(378), int16(-591),
	int16(-718), int16(448),
	int16(-481), int16(-274),
	int16(180), int16(-88),
	int16(-581), int16(-157),
	int16(-696), int16(-1265),
	int16(394), int16(-479),
	int16(-23), int16(124),
	int16(-43), int16(19),
	int16(-113), int16(-236),
	int16(-412), int16(-659),
	int16(-200), int16(2),
	int16(-69), int16(-342),
	int16(199), int16(55),
	int16(58), int16(-36),
	int16(-51), int16(-62),
	int16(507), int16(507),
	int16(427), int16(442),
	int16(36), int16(601),
	int16(-141), int16(68),
	int16(274), int16(274),
	int16(68), int16(-12),
	int16(-4), int16(71),
	int16(-193), int16(-464),
	int16(-425), int16(-383),
	int16(408), int16(203),
	int16(-337), int16(236),
	int16(410), int16(-59),
	int16(-25), int16(-341),
	int16(-449), int16(28),
	int16(-9), int16(90),
	int16(332), int16(-14),
	int16(-905), int16(96),
	int16(-540), int16(-242),
	int16(679), int16(-59),
	int16(192), int16(-24),
	int16(60), int16(-217),
	int16(5), int16(-37),
	int16(179), int16(-20),
	int16(311), int16(519),
	int16(274), int16(72),
	int16(-326), int16(-1030),
	int16(-262), int16(213),
	int16(380), int16(82),
	int16(328), int16(411),
	int16(-540), int16(574),
	int16(-283), int16(151),
	int16(181), int16(-402),
	int16(-278), int16(-240),
	int16(-110), int16(-227),
	int16(-264), int16(-89),
	int16(-250), int16(-259),
	int16(-27), int16(106),
	int16(-239), int16(-98),
	int16(-390), int16(118),
	int16(61), int16(104),
	int16(294), int16(532),
	int16(92), int16(-13),
	int16(60), int16(-233),
	int16(335), int16(541),
	int16(307), int16(-26),
	int16(-110), int16(-91),
	int16(-231), int16(-460),
	int16(170), int16(201),
	int16(96), int16(-372),
	int16(132), int16(435),
	int16(-302), int16(216),
	int16(-279), int16(-41),
	int16(74), int16(190),
	int16(368), int16(273),
	int16(-186), int16(-608),
	int16(-157), int16(159),
	int16(12), int16(278),
	int16(245), int16(307),
	int16(25), int16(-187),
	int16(-16), int16(55),
	int16(30), int16(-163),
	int16(548), int16(-307),
	int16(106), int16(-5),
	int16(27), int16(330),
	int16(-416), int16(475),
	int16(438), int16(-235),
	int16(104), int16(137),
	int16(21), int16(-5),
	int16(-300), int16(-468),
	int16(521), int16(-347),
	int16(170), int16(-200),
	int16(-219), int16(308),
	int16(-122), int16(-133),
	int16(219), int16(-16),
	int16(359), int16(412),
	int16(-89), int16(-111),
	int16(48), int16(322),
	int16(142), int16(177),
	int16(-286), int16(-127),
	int16(-39), int16(-63),
	int16(-42), int16(-451),
	int16(160), int16(308),
	int16(-57), int16(193),
	int16(-48), int16(74),
	int16(-346), int16(59),
	int16(-27), int16(27),
	int16(-469), int16(-277),
	int16(-344), int16(282),
	int16(262), int16(122),
	int16(171), int16(-249),
	int16(27), int16(258),
	int16(188), int16(-3),
	int16(67), int16(-206),
	int16(-284), int16(291),
	int16(-117), int16(-88),
	int16(-477), int16(375),
	int16(50), int16(106),
	int16(99), int16(-182),
	int16(438), int16(-376),
	int16(-401), int16(-49),
	int16(119), int16(-23),
	int16(-10), int16(-48),
	int16(-116), int16(-200),
	int16(-310), int16(121),
	int16(73), int16(7),
	int16(237), int16(-226),
	int16(139), int16(-456),
	int16(397), int16(35),
	int16(3), int16(-108),
	int16(323), int16(-75),
	int16(332), int16(198),
	int16(-99), int16(-21),
} /* tables_NLSF_CB1_10.c:195:17 */

var NLSF_CB1_10_Stage_info = [6]NLSF_CBS{
	{FnVectors: 32, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
} /* tables_NLSF_CB1_10.c:559:25 */

var NLSF_CB1_10 = NLSF_CB_struct{
	FnStages:       6,
	FCBStages:      0,
	FNDeltaMin_Q15: 0,
	FCDF:           0,
	FStartPtr:      0,
	FMiddleIx:      0,
} /* tables_NLSF_CB1_10.c:569:31 */

var NLSF_MSVQ_CB1_16_CDF = [114]uint16{
	uint16(0),
	uint16(19099),
	uint16(26957),
	uint16(30639),
	uint16(34242),
	uint16(37546),
	uint16(40447),
	uint16(43287),
	uint16(46005),
	uint16(48445),
	uint16(49865),
	uint16(51284),
	uint16(52673),
	uint16(53975),
	uint16(55221),
	uint16(56441),
	uint16(57267),
	uint16(58025),
	uint16(58648),
	uint16(59232),
	uint16(59768),
	uint16(60248),
	uint16(60729),
	uint16(61210),
	uint16(61690),
	uint16(62171),
	uint16(62651),
	uint16(63132),
	uint16(63613),
	uint16(64093),
	uint16(64574),
	uint16(65054),
	uint16(65535),
	uint16(0),
	uint16(28808),
	uint16(38775),
	uint16(46801),
	uint16(51785),
	uint16(55886),
	uint16(59410),
	uint16(62572),
	uint16(65535),
	uint16(0),
	uint16(27376),
	uint16(38639),
	uint16(45052),
	uint16(51465),
	uint16(55448),
	uint16(59021),
	uint16(62594),
	uint16(65535),
	uint16(0),
	uint16(33403),
	uint16(39569),
	uint16(45102),
	uint16(49961),
	uint16(54047),
	uint16(57959),
	uint16(61788),
	uint16(65535),
	uint16(0),
	uint16(25851),
	uint16(43356),
	uint16(47828),
	uint16(52204),
	uint16(55964),
	uint16(59413),
	uint16(62507),
	uint16(65535),
	uint16(0),
	uint16(34277),
	uint16(40337),
	uint16(45432),
	uint16(50311),
	uint16(54326),
	uint16(58171),
	uint16(61853),
	uint16(65535),
	uint16(0),
	uint16(33538),
	uint16(39865),
	uint16(45302),
	uint16(50076),
	uint16(54549),
	uint16(58478),
	uint16(62159),
	uint16(65535),
	uint16(0),
	uint16(27445),
	uint16(35258),
	uint16(40665),
	uint16(46072),
	uint16(51362),
	uint16(56540),
	uint16(61086),
	uint16(65535),
	uint16(0),
	uint16(22080),
	uint16(30779),
	uint16(37065),
	uint16(43085),
	uint16(48849),
	uint16(54613),
	uint16(60133),
	uint16(65535),
	uint16(0),
	uint16(13417),
	uint16(21748),
	uint16(30078),
	uint16(38231),
	uint16(46383),
	uint16(53091),
	uint16(59515),
	uint16(65535),
} /* tables_NLSF_CB1_16.c:38:18 */

var NLSF_MSVQ_CB1_16_CDF_start_ptr = [10]uintptr{
	0,
	0,
	0,
	0,
	0,
	0,
	0,
	0,
	0,
	0,
} /* tables_NLSF_CB1_16.c:156:18 */

var NLSF_MSVQ_CB1_16_CDF_middle_idx = [10]int32{
	5,
	2,
	2,
	2,
	2,
	2,
	2,
	3,
	3,
	4,
} /* tables_NLSF_CB1_16.c:170:15 */

var NLSF_MSVQ_CB1_16_rates_Q5 = [104]int16{
	int16(57), int16(98),
	int16(133), int16(134),
	int16(138), int16(144),
	int16(145), int16(147),
	int16(152), int16(177),
	int16(177), int16(178),
	int16(181), int16(183),
	int16(184), int16(202),
	int16(206), int16(215),
	int16(218), int16(222),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(227), int16(227),
	int16(38), int16(87),
	int16(97), int16(119),
	int16(128), int16(135),
	int16(140), int16(143),
	int16(40), int16(81),
	int16(107), int16(107),
	int16(129), int16(134),
	int16(134), int16(143),
	int16(31), int16(109),
	int16(114), int16(120),
	int16(128), int16(130),
	int16(131), int16(132),
	int16(43), int16(61),
	int16(124), int16(125),
	int16(132), int16(136),
	int16(141), int16(142),
	int16(30), int16(110),
	int16(118), int16(120),
	int16(129), int16(131),
	int16(133), int16(133),
	int16(31), int16(108),
	int16(115), int16(121),
	int16(124), int16(130),
	int16(133), int16(137),
	int16(40), int16(98),
	int16(115), int16(115),
	int16(116), int16(117),
	int16(123), int16(124),
	int16(50), int16(93),
	int16(108), int16(110),
	int16(112), int16(112),
	int16(114), int16(115),
	int16(73), int16(95),
	int16(95), int16(96),
	int16(96), int16(105),
	int16(107), int16(110),
} /* tables_NLSF_CB1_16.c:184:17 */

var NLSF_MSVQ_CB1_16_ndelta_min_Q15 = [17]int32{
	148,
	3,
	60,
	68,
	117,
	86,
	121,
	124,
	152,
	153,
	207,
	151,
	225,
	239,
	126,
	183,
	792,
} /* tables_NLSF_CB1_16.c:240:15 */

var NLSF_MSVQ_CB1_16_Q15 = [1664]int16{
	int16(1309), int16(3060), int16(5071), int16(6996),
	int16(9028), int16(10938), int16(12934), int16(14891),
	int16(16933), int16(18854), int16(20792), int16(22764),
	int16(24753), int16(26659), int16(28626), int16(30501),
	int16(1264), int16(2745), int16(4610), int16(6408),
	int16(8286), int16(10043), int16(12084), int16(14108),
	int16(16118), int16(18163), int16(20095), int16(22164),
	int16(24264), int16(26316), int16(28329), int16(30251),
	int16(1044), int16(2080), int16(3672), int16(5179),
	int16(7140), int16(9100), int16(11070), int16(13065),
	int16(15423), int16(17790), int16(19931), int16(22101),
	int16(24290), int16(26361), int16(28499), int16(30418),
	int16(1131), int16(2476), int16(4478), int16(6149),
	int16(7902), int16(9875), int16(11938), int16(13809),
	int16(15869), int16(17730), int16(19948), int16(21707),
	int16(23761), int16(25535), int16(27426), int16(28917),
	int16(1040), int16(2004), int16(4026), int16(6100),
	int16(8432), int16(10494), int16(12610), int16(14694),
	int16(16797), int16(18775), int16(20799), int16(22782),
	int16(24772), int16(26682), int16(28631), int16(30516),
	int16(2310), int16(3812), int16(5913), int16(7933),
	int16(10033), int16(11881), int16(13885), int16(15798),
	int16(17751), int16(19576), int16(21482), int16(23276),
	int16(25157), int16(27010), int16(28833), int16(30623),
	int16(1254), int16(2847), int16(5013), int16(6781),
	int16(8626), int16(10370), int16(12726), int16(14633),
	int16(16281), int16(17852), int16(19870), int16(21472),
	int16(23002), int16(24629), int16(26710), int16(27960),
	int16(1468), int16(3059), int16(4987), int16(7026),
	int16(8741), int16(10412), int16(12281), int16(14020),
	int16(15970), int16(17723), int16(19640), int16(21522),
	int16(23472), int16(25661), int16(27986), int16(30225),
	int16(2171), int16(3566), int16(5605), int16(7384),
	int16(9404), int16(11220), int16(13030), int16(14758),
	int16(16687), int16(18417), int16(20346), int16(22091),
	int16(24055), int16(26212), int16(28356), int16(30397),
	int16(2409), int16(4676), int16(7543), int16(9786),
	int16(11419), int16(12935), int16(14368), int16(15653),
	int16(17366), int16(18943), int16(20762), int16(22477),
	int16(24440), int16(26327), int16(28284), int16(30242),
	int16(2354), int16(4222), int16(6820), int16(9107),
	int16(11596), int16(13934), int16(15973), int16(17682),
	int16(19158), int16(20517), int16(21991), int16(23420),
	int16(25178), int16(26936), int16(28794), int16(30527),
	int16(1323), int16(2414), int16(4184), int16(6039),
	int16(7534), int16(9398), int16(11099), int16(13097),
	int16(14799), int16(16451), int16(18434), int16(20887),
	int16(23490), int16(25838), int16(28046), int16(30225),
	int16(1361), int16(3243), int16(6048), int16(8511),
	int16(11001), int16(13145), int16(15073), int16(16608),
	int16(18126), int16(19381), int16(20912), int16(22607),
	int16(24660), int16(26668), int16(28663), int16(30566),
	int16(1216), int16(2648), int16(5901), int16(8422),
	int16(10037), int16(11425), int16(12973), int16(14603),
	int16(16686), int16(18600), int16(20555), int16(22415),
	int16(24450), int16(26280), int16(28206), int16(30077),
	int16(2417), int16(4048), int16(6316), int16(8433),
	int16(10510), int16(12757), int16(15072), int16(17295),
	int16(19573), int16(21503), int16(23329), int16(24782),
	int16(26235), int16(27689), int16(29214), int16(30819),
	int16(1012), int16(2345), int16(4991), int16(7377),
	int16(9465), int16(11916), int16(14296), int16(16566),
	int16(18672), int16(20544), int16(22292), int16(23838),
	int16(25415), int16(27050), int16(28848), int16(30551),
	int16(1937), int16(3693), int16(6267), int16(8019),
	int16(10372), int16(12194), int16(14287), int16(15657),
	int16(17431), int16(18864), int16(20769), int16(22206),
	int16(24037), int16(25463), int16(27383), int16(28602),
	int16(1969), int16(3305), int16(5017), int16(6726),
	int16(8375), int16(9993), int16(11634), int16(13280),
	int16(15078), int16(16751), int16(18464), int16(20119),
	int16(21959), int16(23858), int16(26224), int16(29298),
	int16(1198), int16(2647), int16(5428), int16(7423),
	int16(9775), int16(12155), int16(14665), int16(16344),
	int16(18121), int16(19790), int16(21557), int16(22847),
	int16(24484), int16(25742), int16(27639), int16(28711),
	int16(1636), int16(3353), int16(5447), int16(7597),
	int16(9837), int16(11647), int16(13964), int16(16019),
	int16(17862), int16(20116), int16(22319), int16(24037),
	int16(25966), int16(28086), int16(29914), int16(31294),
	int16(2676), int16(4105), int16(6378), int16(8223),
	int16(10058), int16(11549), int16(13072), int16(14453),
	int16(15956), int16(17355), int16(18931), int16(20402),
	int16(22183), int16(23884), int16(25717), int16(27723),
	int16(1373), int16(2593), int16(4449), int16(5633),
	int16(7300), int16(8425), int16(9474), int16(10818),
	int16(12769), int16(15722), int16(19002), int16(21429),
	int16(23682), int16(25924), int16(28135), int16(30333),
	int16(1596), int16(3183), int16(5378), int16(7164),
	int16(8670), int16(10105), int16(11470), int16(12834),
	int16(13991), int16(15042), int16(16642), int16(17903),
	int16(20759), int16(25283), int16(27770), int16(30240),
	int16(2037), int16(3987), int16(6237), int16(8117),
	int16(9954), int16(12245), int16(14217), int16(15892),
	int16(17775), int16(20114), int16(22314), int16(25942),
	int16(26305), int16(26483), int16(26796), int16(28561),
	int16(2181), int16(3858), int16(5760), int16(7924),
	int16(10041), int16(11577), int16(13769), int16(15700),
	int16(17429), int16(19879), int16(23583), int16(24538),
	int16(25212), int16(25693), int16(28688), int16(30507),
	int16(1992), int16(3882), int16(6474), int16(7883),
	int16(9381), int16(12672), int16(14340), int16(15701),
	int16(16658), int16(17832), int16(20850), int16(22885),
	int16(24677), int16(26457), int16(28491), int16(30460),
	int16(2391), int16(3988), int16(5448), int16(7432),
	int16(11014), int16(12579), int16(13140), int16(14146),
	int16(15898), int16(18592), int16(21104), int16(22993),
	int16(24673), int16(27186), int16(28142), int16(29612),
	int16(1713), int16(5102), int16(6989), int16(7798),
	int16(8670), int16(10110), int16(12746), int16(14881),
	int16(16709), int16(18407), int16(20126), int16(22107),
	int16(24181), int16(26198), int16(28237), int16(30137),
	int16(1612), int16(3617), int16(6148), int16(8359),
	int16(9576), int16(11528), int16(14936), int16(17809),
	int16(18287), int16(18729), int16(19001), int16(21111),
	int16(24631), int16(26596), int16(28740), int16(30643),
	int16(2266), int16(4168), int16(7862), int16(9546),
	int16(9618), int16(9703), int16(10134), int16(13897),
	int16(16265), int16(18432), int16(20587), int16(22605),
	int16(24754), int16(26994), int16(29125), int16(30840),
	int16(1840), int16(3917), int16(6272), int16(7809),
	int16(9714), int16(11438), int16(13767), int16(15799),
	int16(19244), int16(21972), int16(22980), int16(23180),
	int16(23723), int16(25650), int16(29117), int16(31085),
	int16(1458), int16(3612), int16(6008), int16(7488),
	int16(9827), int16(11893), int16(14086), int16(15734),
	int16(17440), int16(19535), int16(22424), int16(24767),
	int16(29246), int16(29928), int16(30516), int16(30947),
	int16(-102), int16(-121), int16(-31), int16(-6),
	int16(5), int16(-2), int16(8), int16(-18),
	int16(-4), int16(6), int16(14), int16(-2),
	int16(-12), int16(-16), int16(-12), int16(-60),
	int16(-126), int16(-353), int16(-574), int16(-677),
	int16(-657), int16(-617), int16(-498), int16(-393),
	int16(-348), int16(-277), int16(-225), int16(-164),
	int16(-102), int16(-70), int16(-31), int16(33),
	int16(4), int16(379), int16(387), int16(551),
	int16(605), int16(620), int16(532), int16(482),
	int16(442), int16(454), int16(385), int16(347),
	int16(322), int16(299), int16(266), int16(200),
	int16(1168), int16(951), int16(672), int16(246),
	int16(60), int16(-161), int16(-259), int16(-234),
	int16(-253), int16(-282), int16(-203), int16(-187),
	int16(-155), int16(-176), int16(-198), int16(-178),
	int16(10), int16(170), int16(393), int16(609),
	int16(555), int16(208), int16(-330), int16(-571),
	int16(-769), int16(-633), int16(-319), int16(-43),
	int16(95), int16(105), int16(106), int16(116),
	int16(-152), int16(-140), int16(-125), int16(5),
	int16(173), int16(274), int16(264), int16(331),
	int16(-37), int16(-293), int16(-609), int16(-786),
	int16(-959), int16(-814), int16(-645), int16(-238),
	int16(-91), int16(36), int16(-11), int16(-101),
	int16(-279), int16(-227), int16(-40), int16(90),
	int16(530), int16(677), int16(890), int16(1104),
	int16(999), int16(835), int16(564), int16(295),
	int16(-280), int16(-364), int16(-340), int16(-331),
	int16(-284), int16(288), int16(761), int16(880),
	int16(988), int16(627), int16(146), int16(-226),
	int16(-203), int16(-181), int16(-142), int16(39),
	int16(24), int16(-26), int16(-107), int16(-92),
	int16(-161), int16(-135), int16(-131), int16(-88),
	int16(-160), int16(-156), int16(-75), int16(-43),
	int16(-36), int16(-6), int16(-33), int16(33),
	int16(-324), int16(-415), int16(-108), int16(124),
	int16(157), int16(191), int16(203), int16(197),
	int16(144), int16(109), int16(152), int16(176),
	int16(190), int16(122), int16(101), int16(159),
	int16(663), int16(668), int16(480), int16(400),
	int16(379), int16(444), int16(446), int16(458),
	int16(343), int16(351), int16(310), int16(228),
	int16(133), int16(44), int16(75), int16(63),
	int16(-84), int16(39), int16(-29), int16(35),
	int16(-94), int16(-233), int16(-261), int16(-354),
	int16(77), int16(262), int16(-24), int16(-145),
	int16(-333), int16(-409), int16(-404), int16(-597),
	int16(-488), int16(-300), int16(910), int16(592),
	int16(412), int16(120), int16(130), int16(-51),
	int16(-37), int16(-77), int16(-172), int16(-181),
	int16(-159), int16(-148), int16(-72), int16(-62),
	int16(510), int16(516), int16(113), int16(-585),
	int16(-1075), int16(-957), int16(-417), int16(-195),
	int16(9), int16(7), int16(-88), int16(-173),
	int16(-91), int16(54), int16(98), int16(95),
	int16(-28), int16(197), int16(-527), int16(-621),
	int16(157), int16(122), int16(-168), int16(147),
	int16(309), int16(300), int16(336), int16(315),
	int16(396), int16(408), int16(376), int16(106),
	int16(-162), int16(-170), int16(-315), int16(98),
	int16(821), int16(908), int16(570), int16(-33),
	int16(-312), int16(-568), int16(-572), int16(-378),
	int16(-107), int16(23), int16(156), int16(93),
	int16(-129), int16(-87), int16(20), int16(-72),
	int16(-37), int16(40), int16(21), int16(27),
	int16(48), int16(75), int16(77), int16(65),
	int16(46), int16(71), int16(66), int16(47),
	int16(136), int16(344), int16(236), int16(322),
	int16(170), int16(283), int16(269), int16(291),
	int16(162), int16(-43), int16(-204), int16(-259),
	int16(-240), int16(-305), int16(-350), int16(-312),
	int16(447), int16(348), int16(345), int16(257),
	int16(71), int16(-131), int16(-77), int16(-190),
	int16(-202), int16(-40), int16(35), int16(133),
	int16(261), int16(365), int16(438), int16(303),
	int16(-8), int16(22), int16(140), int16(137),
	int16(-300), int16(-641), int16(-764), int16(-268),
	int16(-23), int16(-25), int16(73), int16(-162),
	int16(-150), int16(-212), int16(-72), int16(6),
	int16(39), int16(78), int16(104), int16(-93),
	int16(-308), int16(-136), int16(117), int16(-71),
	int16(-513), int16(-820), int16(-700), int16(-450),
	int16(-161), int16(-23), int16(29), int16(78),
	int16(337), int16(106), int16(-406), int16(-782),
	int16(-112), int16(233), int16(383), int16(62),
	int16(-126), int16(6), int16(-77), int16(-29),
	int16(-146), int16(-123), int16(-51), int16(-27),
	int16(-27), int16(-381), int16(-641), int16(402),
	int16(539), int16(8), int16(-207), int16(-366),
	int16(-36), int16(-27), int16(-204), int16(-227),
	int16(-237), int16(-189), int16(-64), int16(51),
	int16(-92), int16(-137), int16(-281), int16(62),
	int16(233), int16(92), int16(148), int16(294),
	int16(363), int16(416), int16(564), int16(625),
	int16(370), int16(-36), int16(-469), int16(-462),
	int16(102), int16(168), int16(32), int16(117),
	int16(-21), int16(97), int16(139), int16(89),
	int16(104), int16(35), int16(4), int16(82),
	int16(66), int16(58), int16(73), int16(93),
	int16(-76), int16(-320), int16(-236), int16(-189),
	int16(-203), int16(-142), int16(-27), int16(-73),
	int16(9), int16(-9), int16(-25), int16(12),
	int16(-15), int16(4), int16(4), int16(-50),
	int16(314), int16(180), int16(162), int16(-49),
	int16(199), int16(-108), int16(-227), int16(-66),
	int16(-447), int16(-67), int16(-264), int16(-394),
	int16(5), int16(55), int16(-133), int16(-176),
	int16(-116), int16(-241), int16(272), int16(109),
	int16(282), int16(262), int16(192), int16(-64),
	int16(-392), int16(-514), int16(156), int16(203),
	int16(154), int16(72), int16(-34), int16(-160),
	int16(-73), int16(3), int16(-33), int16(-431),
	int16(321), int16(18), int16(-567), int16(-590),
	int16(-108), int16(88), int16(66), int16(51),
	int16(-31), int16(-193), int16(-46), int16(65),
	int16(-29), int16(-23), int16(215), int16(-31),
	int16(101), int16(-113), int16(32), int16(304),
	int16(88), int16(320), int16(448), int16(5),
	int16(-439), int16(-562), int16(-508), int16(-135),
	int16(-13), int16(-171), int16(-8), int16(182),
	int16(-99), int16(-181), int16(-149), int16(376),
	int16(476), int16(64), int16(-396), int16(-652),
	int16(-150), int16(176), int16(222), int16(65),
	int16(-590), int16(719), int16(271), int16(399),
	int16(245), int16(72), int16(-156), int16(-152),
	int16(-176), int16(59), int16(94), int16(125),
	int16(-9), int16(-7), int16(9), int16(1),
	int16(-61), int16(-116), int16(-82), int16(1),
	int16(79), int16(22), int16(-44), int16(-15),
	int16(-48), int16(-65), int16(-62), int16(-101),
	int16(-102), int16(-54), int16(-70), int16(-78),
	int16(-80), int16(-25), int16(398), int16(71),
	int16(139), int16(38), int16(90), int16(194),
	int16(222), int16(249), int16(165), int16(94),
	int16(221), int16(262), int16(163), int16(91),
	int16(-206), int16(573), int16(200), int16(-287),
	int16(-147), int16(5), int16(-18), int16(-85),
	int16(-74), int16(-125), int16(-87), int16(85),
	int16(141), int16(4), int16(-4), int16(28),
	int16(234), int16(48), int16(-150), int16(-111),
	int16(-506), int16(237), int16(-209), int16(345),
	int16(94), int16(-124), int16(77), int16(121),
	int16(143), int16(12), int16(-80), int16(-48),
	int16(191), int16(144), int16(-93), int16(-65),
	int16(-151), int16(-643), int16(435), int16(106),
	int16(87), int16(7), int16(65), int16(102),
	int16(94), int16(68), int16(5), int16(99),
	int16(222), int16(93), int16(94), int16(355),
	int16(-13), int16(-89), int16(-228), int16(-503),
	int16(287), int16(109), int16(108), int16(449),
	int16(253), int16(-29), int16(-109), int16(-116),
	int16(15), int16(-73), int16(-20), int16(131),
	int16(-147), int16(72), int16(59), int16(-150),
	int16(-594), int16(273), int16(316), int16(132),
	int16(199), int16(106), int16(198), int16(212),
	int16(220), int16(82), int16(45), int16(-13),
	int16(223), int16(137), int16(270), int16(38),
	int16(252), int16(135), int16(-177), int16(-207),
	int16(-360), int16(-102), int16(403), int16(406),
	int16(-14), int16(83), int16(64), int16(51),
	int16(-7), int16(-99), int16(-97), int16(-88),
	int16(-124), int16(-65), int16(42), int16(32),
	int16(28), int16(29), int16(12), int16(20),
	int16(119), int16(-26), int16(-212), int16(-201),
	int16(373), int16(251), int16(141), int16(103),
	int16(36), int16(-52), int16(66), int16(18),
	int16(-6), int16(-95), int16(-196), int16(5),
	int16(98), int16(-85), int16(-108), int16(218),
	int16(-164), int16(20), int16(356), int16(172),
	int16(37), int16(266), int16(23), int16(112),
	int16(-24), int16(-99), int16(-92), int16(-178),
	int16(29), int16(-278), int16(388), int16(-60),
	int16(-220), int16(300), int16(-13), int16(154),
	int16(191), int16(15), int16(-37), int16(-110),
	int16(-153), int16(-150), int16(-114), int16(-7),
	int16(-94), int16(-31), int16(-62), int16(-177),
	int16(4), int16(-70), int16(35), int16(453),
	int16(147), int16(-247), int16(-328), int16(101),
	int16(20), int16(-114), int16(147), int16(108),
	int16(-119), int16(-109), int16(-102), int16(-238),
	int16(55), int16(-102), int16(173), int16(-89),
	int16(129), int16(138), int16(-330), int16(-160),
	int16(485), int16(154), int16(-59), int16(-170),
	int16(-20), int16(-34), int16(-261), int16(-40),
	int16(-129), int16(77), int16(-84), int16(69),
	int16(83), int16(160), int16(169), int16(63),
	int16(-516), int16(30), int16(336), int16(52),
	int16(-0), int16(-52), int16(-124), int16(158),
	int16(19), int16(197), int16(-10), int16(-375),
	int16(405), int16(285), int16(114), int16(-395),
	int16(-47), int16(196), int16(62), int16(87),
	int16(-106), int16(-65), int16(-75), int16(-69),
	int16(-13), int16(34), int16(99), int16(59),
	int16(83), int16(98), int16(44), int16(0),
	int16(24), int16(18), int16(17), int16(70),
	int16(-22), int16(194), int16(208), int16(144),
	int16(-79), int16(-15), int16(32), int16(-104),
	int16(-28), int16(-105), int16(-186), int16(-212),
	int16(-228), int16(-79), int16(-76), int16(51),
	int16(-71), int16(72), int16(118), int16(-34),
	int16(-3), int16(-171), int16(5), int16(2),
	int16(-108), int16(-125), int16(62), int16(-58),
	int16(58), int16(-121), int16(73), int16(-466),
	int16(92), int16(63), int16(-94), int16(-78),
	int16(-76), int16(212), int16(36), int16(-225),
	int16(-71), int16(-354), int16(152), int16(143),
	int16(-79), int16(-246), int16(-51), int16(-31),
	int16(-6), int16(-270), int16(240), int16(210),
	int16(30), int16(-157), int16(-231), int16(74),
	int16(-146), int16(88), int16(-273), int16(156),
	int16(92), int16(56), int16(71), int16(2),
	int16(318), int16(164), int16(32), int16(-110),
	int16(-35), int16(-41), int16(-95), int16(-106),
	int16(11), int16(132), int16(-68), int16(55),
	int16(123), int16(-83), int16(-149), int16(212),
	int16(132), int16(0), int16(-194), int16(55),
	int16(206), int16(-108), int16(-353), int16(289),
	int16(-195), int16(1), int16(233), int16(-22),
	int16(-60), int16(20), int16(26), int16(68),
	int16(166), int16(27), int16(-58), int16(130),
	int16(112), int16(107), int16(27), int16(-165),
	int16(115), int16(-93), int16(-37), int16(38),
	int16(83), int16(483), int16(65), int16(-229),
	int16(-13), int16(157), int16(85), int16(50),
	int16(136), int16(10), int16(32), int16(83),
	int16(82), int16(55), int16(5), int16(-9),
	int16(-52), int16(-78), int16(-81), int16(-51),
	int16(40), int16(18), int16(-127), int16(-224),
	int16(-41), int16(53), int16(-210), int16(-113),
	int16(24), int16(-17), int16(-187), int16(-89),
	int16(8), int16(121), int16(83), int16(77),
	int16(91), int16(-74), int16(-35), int16(-112),
	int16(-161), int16(-173), int16(102), int16(132),
	int16(-125), int16(-61), int16(103), int16(-260),
	int16(52), int16(166), int16(-32), int16(-156),
	int16(-87), int16(-56), int16(60), int16(-70),
	int16(-124), int16(242), int16(114), int16(-251),
	int16(-166), int16(201), int16(127), int16(28),
	int16(-11), int16(23), int16(-80), int16(-115),
	int16(-20), int16(-51), int16(-348), int16(340),
	int16(-34), int16(133), int16(13), int16(92),
	int16(-124), int16(-136), int16(-120), int16(-26),
	int16(-6), int16(17), int16(28), int16(21),
	int16(120), int16(-168), int16(160), int16(-35),
	int16(115), int16(28), int16(9), int16(7),
	int16(-56), int16(39), int16(156), int16(256),
	int16(-18), int16(1), int16(277), int16(82),
	int16(-70), int16(-144), int16(-88), int16(-13),
	int16(-59), int16(-157), int16(8), int16(-134),
	int16(21), int16(-40), int16(58), int16(-21),
	int16(194), int16(-276), int16(97), int16(279),
	int16(-56), int16(-140), int16(125), int16(57),
	int16(-184), int16(-204), int16(-70), int16(-2),
	int16(128), int16(-202), int16(-78), int16(230),
	int16(-23), int16(161), int16(-102), int16(1),
	int16(1), int16(180), int16(-31), int16(-86),
	int16(-167), int16(-57), int16(-60), int16(27),
	int16(-13), int16(99), int16(108), int16(111),
	int16(76), int16(69), int16(34), int16(-21),
	int16(53), int16(38), int16(34), int16(78),
	int16(73), int16(219), int16(51), int16(15),
	int16(-72), int16(-103), int16(-207), int16(30),
	int16(213), int16(-14), int16(31), int16(-94),
	int16(-40), int16(-144), int16(67), int16(4),
	int16(105), int16(59), int16(-240), int16(25),
	int16(244), int16(69), int16(58), int16(23),
	int16(-24), int16(-5), int16(-15), int16(-133),
	int16(-71), int16(-67), int16(181), int16(29),
	int16(-45), int16(121), int16(96), int16(51),
	int16(-72), int16(-53), int16(56), int16(-153),
	int16(-27), int16(85), int16(183), int16(211),
	int16(105), int16(-34), int16(-46), int16(43),
	int16(-72), int16(-93), int16(36), int16(-128),
	int16(29), int16(111), int16(-95), int16(-156),
	int16(-179), int16(-235), int16(21), int16(-39),
	int16(-71), int16(-33), int16(-61), int16(-252),
	int16(230), int16(-131), int16(157), int16(-21),
	int16(-85), int16(-28), int16(-123), int16(80),
	int16(-160), int16(63), int16(47), int16(-6),
	int16(-49), int16(-96), int16(-19), int16(17),
	int16(-58), int16(17), int16(-0), int16(-13),
	int16(-170), int16(25), int16(-35), int16(59),
	int16(10), int16(-31), int16(-413), int16(81),
	int16(62), int16(18), int16(-164), int16(245),
	int16(92), int16(-165), int16(42), int16(26),
	int16(126), int16(-248), int16(193), int16(-55),
	int16(16), int16(39), int16(14), int16(50),
} /* tables_NLSF_CB1_16.c:261:17 */

var NLSF_CB1_16_Stage_info = [10]NLSF_CBS{
	{FnVectors: 32, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
	{FnVectors: 8, FCB_NLSF_Q15: 0, FRates_Q5: 0},
} /* tables_NLSF_CB1_16.c:681:25 */

var NLSF_CB1_16 = NLSF_CB_struct{
	FnStages:       10,
	FCBStages:      0,
	FNDeltaMin_Q15: 0,
	FCDF:           0,
	FStartPtr:      0,
	FMiddleIx:      0,
} /* tables_NLSF_CB1_16.c:695:31 */

/* Piece-wise linear mapping from bitrate in kbps to coding quality in dB SNR */
var TargetRate_table_NB = [8]int32{
	0, 8000, 9000, 11000, 13000, 16000, 22000, 100000,
} /* tables_other.c:37:17 */
var TargetRate_table_MB = [8]int32{
	0, 10000, 12000, 14000, 17000, 21000, 28000, 100000,
} /* tables_other.c:40:17 */
var TargetRate_table_WB = [8]int32{
	0, 11000, 14000, 17000, 21000, 26000, 36000, 100000,
} /* tables_other.c:43:17 */
var TargetRate_table_SWB = [8]int32{
	0, 13000, 16000, 19000, 25000, 32000, 46000, 100000,
} /* tables_other.c:46:17 */
var SNR_table_Q1 = [8]int32{
	19, 31, 35, 39, 43, 47, 54, 64,
} /* tables_other.c:49:17 */

var SNR_table_one_bit_per_sample_Q7 = [4]int32{
	1984, 2240, 2408, 2708,
} /* tables_other.c:53:17 */

/* Filter coeficicnts for HP filter: 4. Order filter implementad as two biquad filters  */
var SWB_detect_B_HP_Q13 = [3][3]int16{
	//{400, -550, 400}, {400, 130, 400}, {400, 390, 400}
	{int16(575), int16(-948), int16(575)}, {int16(575), int16(-221), int16(575)}, {int16(575), int16(104), int16(575)},
} /* tables_other.c:58:17 */
var SWB_detect_A_HP_Q13 = [3][2]int16{
	{int16(14613), int16(6868)}, {int16(12883), int16(7337)}, {int16(11586), int16(7911)},
	//{14880, 6900}, {14400, 7300}, {13700, 7800}
} /* tables_other.c:62:17 */

/* Decoder high-pass filter coefficients for 24 kHz sampling, -6 dB @ 44 Hz */
var Dec_A_HP_24 = [2]int16{int16(-16220), int16(8030)}              /* tables_other.c:68:17 */ // second order AR coefs, Q13
var Dec_B_HP_24 = [3]int16{int16(8000), int16(-16000), int16(8000)} /* tables_other.c:69:17 */ // second order MA coefs, Q13

/* Decoder high-pass filter coefficients for 16 kHz sampling, - 6 dB @ 46 Hz */
var Dec_A_HP_16 = [2]int16{int16(-16127), int16(7940)}              /* tables_other.c:72:17 */ // second order AR coefs, Q13
var Dec_B_HP_16 = [3]int16{int16(8000), int16(-16000), int16(8000)} /* tables_other.c:73:17 */ // second order MA coefs, Q13

/* Decoder high-pass filter coefficients for 12 kHz sampling, -6 dB @ 44 Hz */
var Dec_A_HP_12 = [2]int16{int16(-16043), int16(7859)}              /* tables_other.c:76:17 */ // second order AR coefs, Q13
var Dec_B_HP_12 = [3]int16{int16(8000), int16(-16000), int16(8000)} /* tables_other.c:77:17 */ // second order MA coefs, Q13

/* Decoder high-pass filter coefficients for 8 kHz sampling, -6 dB @ 43 Hz */
var Dec_A_HP_8 = [2]int16{int16(-15885), int16(7710)}              /* tables_other.c:80:17 */ // second order AR coefs, Q13
var Dec_B_HP_8 = [3]int16{int16(8000), int16(-16000), int16(8000)} /* tables_other.c:81:17 */ // second order MA coefs, Q13

/* table for LSB coding */
var lsb_CDF = [3]uint16{uint16(0), uint16(40000), uint16(65535)} /* tables_other.c:84:18 */

/* tables for LTPScale */
var LTPscale_CDF = [4]uint16{uint16(0), uint16(32000), uint16(48000), uint16(65535)} /* tables_other.c:87:18 */
var LTPscale_offset int32 = 2                                                        /* tables_other.c:88:18 */

/* tables for VAD flag */
var vadflag_CDF = [3]uint16{uint16(0), uint16(22000), uint16(65535)} /* tables_other.c:91:18 */ // 66% for speech, 33% for no speech
var vadflag_offset int32 = 1                                         /* tables_other.c:92:18 */

/* tables for sampling rate */
var SamplingRates_table = [4]int32{8, 12, 16, 24}                                                        /* tables_other.c:95:18 */
var SamplingRates_CDF = [5]uint16{uint16(0), uint16(16000), uint16(32000), uint16(48000), uint16(65535)} /* tables_other.c:96:18 */
var SamplingRates_offset int32 = 2                                                                       /* tables_other.c:97:18 */

/* tables for NLSF interpolation factor */
var NLSF_interpolation_factor_CDF = [6]uint16{uint16(0), uint16(3706), uint16(8703), uint16(19226), uint16(30926), uint16(65535)} /* tables_other.c:100:18 */
var NLSF_interpolation_factor_offset int32 = 4                                                                                    /* tables_other.c:101:18 */

/* Table for frame termination indication */
var FrameTermination_CDF = [5]uint16{uint16(0), uint16(20000), uint16(45000), uint16(56000), uint16(65535)} /* tables_other.c:104:18 */
var FrameTermination_offset int32 = 2                                                                       /* tables_other.c:105:18 */

/* Table for random seed */
var Seed_CDF = [5]uint16{uint16(0), uint16(16384), uint16(32768), uint16(49152), uint16(65535)} /* tables_other.c:108:18 */
var Seed_offset int32 = 2                                                                       /* tables_other.c:109:18 */

/* Quantization offsets */
var Quantization_Offsets_Q10 = [2][2]int16{
	{int16(32), int16(100)}, {int16(100), int16(256)},
} /* tables_other.c:112:18 */

/* Table for LTPScale */
var LTPScales_table_Q14 = [3]int16{int16(15565), int16(11469), int16(8192)} /* tables_other.c:117:17 */

/*  Elliptic/Cauer filters designed with 0.1 dB passband ripple,
    80 dB minimum stopband attenuation, and
    [0.95 : 0.15 : 0.35] normalized cut off frequencies. */

/* Interpolation points for filter coefficients used in the bandwidth transition smoother */
var Transition_LP_B_Q28 = [5][3]int32{
	{250767114, 501534038, 250767114},
	{209867381, 419732057, 209867381},
	{170987846, 341967853, 170987846},
	{131531482, 263046905, 131531482},
	{89306658, 178584282, 89306658},
} /* tables_other.c:125:17 */

/* Interpolation points for filter coefficients used in the bandwidth transition smoother */
var Transition_LP_A_Q28 = [5][2]int32{
	{506393414, 239854379},
	{411067935, 169683996},
	{306733530, 116694253},
	{185807084, 77959395},
	{35497197, 57401098},
} /* tables_other.c:135:17 */

var pitch_lag_NB_CDF = [130]uint16{
	uint16(0), uint16(194), uint16(395), uint16(608), uint16(841), uint16(1099), uint16(1391), uint16(1724),
	uint16(2105), uint16(2544), uint16(3047), uint16(3624), uint16(4282), uint16(5027), uint16(5865), uint16(6799),
	uint16(7833), uint16(8965), uint16(10193), uint16(11510), uint16(12910), uint16(14379), uint16(15905), uint16(17473),
	uint16(19065), uint16(20664), uint16(22252), uint16(23814), uint16(25335), uint16(26802), uint16(28206), uint16(29541),
	uint16(30803), uint16(31992), uint16(33110), uint16(34163), uint16(35156), uint16(36098), uint16(36997), uint16(37861),
	uint16(38698), uint16(39515), uint16(40319), uint16(41115), uint16(41906), uint16(42696), uint16(43485), uint16(44273),
	uint16(45061), uint16(45847), uint16(46630), uint16(47406), uint16(48175), uint16(48933), uint16(49679), uint16(50411),
	uint16(51126), uint16(51824), uint16(52502), uint16(53161), uint16(53799), uint16(54416), uint16(55011), uint16(55584),
	uint16(56136), uint16(56666), uint16(57174), uint16(57661), uint16(58126), uint16(58570), uint16(58993), uint16(59394),
	uint16(59775), uint16(60134), uint16(60472), uint16(60790), uint16(61087), uint16(61363), uint16(61620), uint16(61856),
	uint16(62075), uint16(62275), uint16(62458), uint16(62625), uint16(62778), uint16(62918), uint16(63045), uint16(63162),
	uint16(63269), uint16(63368), uint16(63459), uint16(63544), uint16(63623), uint16(63698), uint16(63769), uint16(63836),
	uint16(63901), uint16(63963), uint16(64023), uint16(64081), uint16(64138), uint16(64194), uint16(64248), uint16(64301),
	uint16(64354), uint16(64406), uint16(64457), uint16(64508), uint16(64558), uint16(64608), uint16(64657), uint16(64706),
	uint16(64754), uint16(64803), uint16(64851), uint16(64899), uint16(64946), uint16(64994), uint16(65041), uint16(65088),
	uint16(65135), uint16(65181), uint16(65227), uint16(65272), uint16(65317), uint16(65361), uint16(65405), uint16(65449),
	uint16(65492), uint16(65535),
} /* tables_pitch_lag.c:30:18 */

var pitch_lag_NB_CDF_offset int32 = 43 /* tables_pitch_lag.c:50:15 */

var pitch_contour_NB_CDF = [12]uint16{
	uint16(0), uint16(14445), uint16(18587), uint16(25628), uint16(30013), uint16(34859), uint16(40597), uint16(48426),
	uint16(54460), uint16(59033), uint16(62990), uint16(65535),
} /* tables_pitch_lag.c:52:18 */

var pitch_contour_NB_CDF_offset int32 = 5 /* tables_pitch_lag.c:57:15 */

var pitch_lag_MB_CDF = [194]uint16{
	uint16(0), uint16(132), uint16(266), uint16(402), uint16(542), uint16(686), uint16(838), uint16(997),
	uint16(1167), uint16(1349), uint16(1546), uint16(1760), uint16(1993), uint16(2248), uint16(2528), uint16(2835),
	uint16(3173), uint16(3544), uint16(3951), uint16(4397), uint16(4882), uint16(5411), uint16(5984), uint16(6604),
	uint16(7270), uint16(7984), uint16(8745), uint16(9552), uint16(10405), uint16(11300), uint16(12235), uint16(13206),
	uint16(14209), uint16(15239), uint16(16289), uint16(17355), uint16(18430), uint16(19507), uint16(20579), uint16(21642),
	uint16(22688), uint16(23712), uint16(24710), uint16(25677), uint16(26610), uint16(27507), uint16(28366), uint16(29188),
	uint16(29971), uint16(30717), uint16(31427), uint16(32104), uint16(32751), uint16(33370), uint16(33964), uint16(34537),
	uint16(35091), uint16(35630), uint16(36157), uint16(36675), uint16(37186), uint16(37692), uint16(38195), uint16(38697),
	uint16(39199), uint16(39701), uint16(40206), uint16(40713), uint16(41222), uint16(41733), uint16(42247), uint16(42761),
	uint16(43277), uint16(43793), uint16(44309), uint16(44824), uint16(45336), uint16(45845), uint16(46351), uint16(46851),
	uint16(47347), uint16(47836), uint16(48319), uint16(48795), uint16(49264), uint16(49724), uint16(50177), uint16(50621),
	uint16(51057), uint16(51484), uint16(51902), uint16(52312), uint16(52714), uint16(53106), uint16(53490), uint16(53866),
	uint16(54233), uint16(54592), uint16(54942), uint16(55284), uint16(55618), uint16(55944), uint16(56261), uint16(56571),
	uint16(56873), uint16(57167), uint16(57453), uint16(57731), uint16(58001), uint16(58263), uint16(58516), uint16(58762),
	uint16(58998), uint16(59226), uint16(59446), uint16(59656), uint16(59857), uint16(60050), uint16(60233), uint16(60408),
	uint16(60574), uint16(60732), uint16(60882), uint16(61024), uint16(61159), uint16(61288), uint16(61410), uint16(61526),
	uint16(61636), uint16(61742), uint16(61843), uint16(61940), uint16(62033), uint16(62123), uint16(62210), uint16(62293),
	uint16(62374), uint16(62452), uint16(62528), uint16(62602), uint16(62674), uint16(62744), uint16(62812), uint16(62879),
	uint16(62945), uint16(63009), uint16(63072), uint16(63135), uint16(63196), uint16(63256), uint16(63316), uint16(63375),
	uint16(63434), uint16(63491), uint16(63549), uint16(63605), uint16(63661), uint16(63717), uint16(63772), uint16(63827),
	uint16(63881), uint16(63935), uint16(63988), uint16(64041), uint16(64094), uint16(64147), uint16(64199), uint16(64252),
	uint16(64304), uint16(64356), uint16(64409), uint16(64461), uint16(64513), uint16(64565), uint16(64617), uint16(64669),
	uint16(64721), uint16(64773), uint16(64824), uint16(64875), uint16(64925), uint16(64975), uint16(65024), uint16(65072),
	uint16(65121), uint16(65168), uint16(65215), uint16(65262), uint16(65308), uint16(65354), uint16(65399), uint16(65445),
	uint16(65490), uint16(65535),
} /* tables_pitch_lag.c:59:18 */

var pitch_lag_MB_CDF_offset int32 = 64 /* tables_pitch_lag.c:87:15 */

var pitch_lag_WB_CDF = [258]uint16{
	uint16(0), uint16(106), uint16(213), uint16(321), uint16(429), uint16(539), uint16(651), uint16(766),
	uint16(884), uint16(1005), uint16(1132), uint16(1264), uint16(1403), uint16(1549), uint16(1705), uint16(1870),
	uint16(2047), uint16(2236), uint16(2439), uint16(2658), uint16(2893), uint16(3147), uint16(3420), uint16(3714),
	uint16(4030), uint16(4370), uint16(4736), uint16(5127), uint16(5546), uint16(5993), uint16(6470), uint16(6978),
	uint16(7516), uint16(8086), uint16(8687), uint16(9320), uint16(9985), uint16(10680), uint16(11405), uint16(12158),
	uint16(12938), uint16(13744), uint16(14572), uint16(15420), uint16(16286), uint16(17166), uint16(18057), uint16(18955),
	uint16(19857), uint16(20759), uint16(21657), uint16(22547), uint16(23427), uint16(24293), uint16(25141), uint16(25969),
	uint16(26774), uint16(27555), uint16(28310), uint16(29037), uint16(29736), uint16(30406), uint16(31048), uint16(31662),
	uint16(32248), uint16(32808), uint16(33343), uint16(33855), uint16(34345), uint16(34815), uint16(35268), uint16(35704),
	uint16(36127), uint16(36537), uint16(36938), uint16(37330), uint16(37715), uint16(38095), uint16(38471), uint16(38844),
	uint16(39216), uint16(39588), uint16(39959), uint16(40332), uint16(40707), uint16(41084), uint16(41463), uint16(41844),
	uint16(42229), uint16(42615), uint16(43005), uint16(43397), uint16(43791), uint16(44186), uint16(44583), uint16(44982),
	uint16(45381), uint16(45780), uint16(46179), uint16(46578), uint16(46975), uint16(47371), uint16(47765), uint16(48156),
	uint16(48545), uint16(48930), uint16(49312), uint16(49690), uint16(50064), uint16(50433), uint16(50798), uint16(51158),
	uint16(51513), uint16(51862), uint16(52206), uint16(52544), uint16(52877), uint16(53204), uint16(53526), uint16(53842),
	uint16(54152), uint16(54457), uint16(54756), uint16(55050), uint16(55338), uint16(55621), uint16(55898), uint16(56170),
	uint16(56436), uint16(56697), uint16(56953), uint16(57204), uint16(57449), uint16(57689), uint16(57924), uint16(58154),
	uint16(58378), uint16(58598), uint16(58812), uint16(59022), uint16(59226), uint16(59426), uint16(59620), uint16(59810),
	uint16(59994), uint16(60173), uint16(60348), uint16(60517), uint16(60681), uint16(60840), uint16(60993), uint16(61141),
	uint16(61284), uint16(61421), uint16(61553), uint16(61679), uint16(61800), uint16(61916), uint16(62026), uint16(62131),
	uint16(62231), uint16(62326), uint16(62417), uint16(62503), uint16(62585), uint16(62663), uint16(62737), uint16(62807),
	uint16(62874), uint16(62938), uint16(62999), uint16(63057), uint16(63113), uint16(63166), uint16(63217), uint16(63266),
	uint16(63314), uint16(63359), uint16(63404), uint16(63446), uint16(63488), uint16(63528), uint16(63567), uint16(63605),
	uint16(63642), uint16(63678), uint16(63713), uint16(63748), uint16(63781), uint16(63815), uint16(63847), uint16(63879),
	uint16(63911), uint16(63942), uint16(63973), uint16(64003), uint16(64033), uint16(64063), uint16(64092), uint16(64121),
	uint16(64150), uint16(64179), uint16(64207), uint16(64235), uint16(64263), uint16(64291), uint16(64319), uint16(64347),
	uint16(64374), uint16(64401), uint16(64428), uint16(64455), uint16(64481), uint16(64508), uint16(64534), uint16(64560),
	uint16(64585), uint16(64610), uint16(64635), uint16(64660), uint16(64685), uint16(64710), uint16(64734), uint16(64758),
	uint16(64782), uint16(64807), uint16(64831), uint16(64855), uint16(64878), uint16(64902), uint16(64926), uint16(64950),
	uint16(64974), uint16(64998), uint16(65022), uint16(65045), uint16(65069), uint16(65093), uint16(65116), uint16(65139),
	uint16(65163), uint16(65186), uint16(65209), uint16(65231), uint16(65254), uint16(65276), uint16(65299), uint16(65321),
	uint16(65343), uint16(65364), uint16(65386), uint16(65408), uint16(65429), uint16(65450), uint16(65471), uint16(65493),
	uint16(65514), uint16(65535),
} /* tables_pitch_lag.c:89:18 */

var pitch_lag_WB_CDF_offset int32 = 86 /* tables_pitch_lag.c:125:15 */

var pitch_lag_SWB_CDF = [386]uint16{
	uint16(0), uint16(253), uint16(505), uint16(757), uint16(1008), uint16(1258), uint16(1507), uint16(1755),
	uint16(2003), uint16(2249), uint16(2494), uint16(2738), uint16(2982), uint16(3225), uint16(3469), uint16(3713),
	uint16(3957), uint16(4202), uint16(4449), uint16(4698), uint16(4949), uint16(5203), uint16(5460), uint16(5720),
	uint16(5983), uint16(6251), uint16(6522), uint16(6798), uint16(7077), uint16(7361), uint16(7650), uint16(7942),
	uint16(8238), uint16(8539), uint16(8843), uint16(9150), uint16(9461), uint16(9775), uint16(10092), uint16(10411),
	uint16(10733), uint16(11057), uint16(11383), uint16(11710), uint16(12039), uint16(12370), uint16(12701), uint16(13034),
	uint16(13368), uint16(13703), uint16(14040), uint16(14377), uint16(14716), uint16(15056), uint16(15398), uint16(15742),
	uint16(16087), uint16(16435), uint16(16785), uint16(17137), uint16(17492), uint16(17850), uint16(18212), uint16(18577),
	uint16(18946), uint16(19318), uint16(19695), uint16(20075), uint16(20460), uint16(20849), uint16(21243), uint16(21640),
	uint16(22041), uint16(22447), uint16(22856), uint16(23269), uint16(23684), uint16(24103), uint16(24524), uint16(24947),
	uint16(25372), uint16(25798), uint16(26225), uint16(26652), uint16(27079), uint16(27504), uint16(27929), uint16(28352),
	uint16(28773), uint16(29191), uint16(29606), uint16(30018), uint16(30427), uint16(30831), uint16(31231), uint16(31627),
	uint16(32018), uint16(32404), uint16(32786), uint16(33163), uint16(33535), uint16(33902), uint16(34264), uint16(34621),
	uint16(34973), uint16(35320), uint16(35663), uint16(36000), uint16(36333), uint16(36662), uint16(36985), uint16(37304),
	uint16(37619), uint16(37929), uint16(38234), uint16(38535), uint16(38831), uint16(39122), uint16(39409), uint16(39692),
	uint16(39970), uint16(40244), uint16(40513), uint16(40778), uint16(41039), uint16(41295), uint16(41548), uint16(41796),
	uint16(42041), uint16(42282), uint16(42520), uint16(42754), uint16(42985), uint16(43213), uint16(43438), uint16(43660),
	uint16(43880), uint16(44097), uint16(44312), uint16(44525), uint16(44736), uint16(44945), uint16(45153), uint16(45359),
	uint16(45565), uint16(45769), uint16(45972), uint16(46175), uint16(46377), uint16(46578), uint16(46780), uint16(46981),
	uint16(47182), uint16(47383), uint16(47585), uint16(47787), uint16(47989), uint16(48192), uint16(48395), uint16(48599),
	uint16(48804), uint16(49009), uint16(49215), uint16(49422), uint16(49630), uint16(49839), uint16(50049), uint16(50259),
	uint16(50470), uint16(50682), uint16(50894), uint16(51107), uint16(51320), uint16(51533), uint16(51747), uint16(51961),
	uint16(52175), uint16(52388), uint16(52601), uint16(52813), uint16(53025), uint16(53236), uint16(53446), uint16(53655),
	uint16(53863), uint16(54069), uint16(54274), uint16(54477), uint16(54679), uint16(54879), uint16(55078), uint16(55274),
	uint16(55469), uint16(55662), uint16(55853), uint16(56042), uint16(56230), uint16(56415), uint16(56598), uint16(56779),
	uint16(56959), uint16(57136), uint16(57311), uint16(57484), uint16(57654), uint16(57823), uint16(57989), uint16(58152),
	uint16(58314), uint16(58473), uint16(58629), uint16(58783), uint16(58935), uint16(59084), uint16(59230), uint16(59373),
	uint16(59514), uint16(59652), uint16(59787), uint16(59919), uint16(60048), uint16(60174), uint16(60297), uint16(60417),
	uint16(60533), uint16(60647), uint16(60757), uint16(60865), uint16(60969), uint16(61070), uint16(61167), uint16(61262),
	uint16(61353), uint16(61442), uint16(61527), uint16(61609), uint16(61689), uint16(61765), uint16(61839), uint16(61910),
	uint16(61979), uint16(62045), uint16(62109), uint16(62170), uint16(62230), uint16(62287), uint16(62343), uint16(62396),
	uint16(62448), uint16(62498), uint16(62547), uint16(62594), uint16(62640), uint16(62685), uint16(62728), uint16(62770),
	uint16(62811), uint16(62852), uint16(62891), uint16(62929), uint16(62967), uint16(63004), uint16(63040), uint16(63075),
	uint16(63110), uint16(63145), uint16(63178), uint16(63212), uint16(63244), uint16(63277), uint16(63308), uint16(63340),
	uint16(63371), uint16(63402), uint16(63432), uint16(63462), uint16(63491), uint16(63521), uint16(63550), uint16(63578),
	uint16(63607), uint16(63635), uint16(63663), uint16(63690), uint16(63718), uint16(63744), uint16(63771), uint16(63798),
	uint16(63824), uint16(63850), uint16(63875), uint16(63900), uint16(63925), uint16(63950), uint16(63975), uint16(63999),
	uint16(64023), uint16(64046), uint16(64069), uint16(64092), uint16(64115), uint16(64138), uint16(64160), uint16(64182),
	uint16(64204), uint16(64225), uint16(64247), uint16(64268), uint16(64289), uint16(64310), uint16(64330), uint16(64351),
	uint16(64371), uint16(64391), uint16(64411), uint16(64431), uint16(64450), uint16(64470), uint16(64489), uint16(64508),
	uint16(64527), uint16(64545), uint16(64564), uint16(64582), uint16(64600), uint16(64617), uint16(64635), uint16(64652),
	uint16(64669), uint16(64686), uint16(64702), uint16(64719), uint16(64735), uint16(64750), uint16(64766), uint16(64782),
	uint16(64797), uint16(64812), uint16(64827), uint16(64842), uint16(64857), uint16(64872), uint16(64886), uint16(64901),
	uint16(64915), uint16(64930), uint16(64944), uint16(64959), uint16(64974), uint16(64988), uint16(65003), uint16(65018),
	uint16(65033), uint16(65048), uint16(65063), uint16(65078), uint16(65094), uint16(65109), uint16(65125), uint16(65141),
	uint16(65157), uint16(65172), uint16(65188), uint16(65204), uint16(65220), uint16(65236), uint16(65252), uint16(65268),
	uint16(65283), uint16(65299), uint16(65314), uint16(65330), uint16(65345), uint16(65360), uint16(65375), uint16(65390),
	uint16(65405), uint16(65419), uint16(65434), uint16(65449), uint16(65463), uint16(65477), uint16(65492), uint16(65506),
	uint16(65521), uint16(65535),
} /* tables_pitch_lag.c:128:18 */

var pitch_lag_SWB_CDF_offset int32 = 128 /* tables_pitch_lag.c:180:15 */

var pitch_contour_CDF = [35]uint16{
	uint16(0), uint16(372), uint16(843), uint16(1315), uint16(1836), uint16(2644), uint16(3576), uint16(4719),
	uint16(6088), uint16(7621), uint16(9396), uint16(11509), uint16(14245), uint16(17618), uint16(20777), uint16(24294),
	uint16(27992), uint16(33116), uint16(40100), uint16(44329), uint16(47558), uint16(50679), uint16(53130), uint16(55557),
	uint16(57510), uint16(59022), uint16(60285), uint16(61345), uint16(62316), uint16(63140), uint16(63762), uint16(64321),
	uint16(64729), uint16(65099), uint16(65535),
} /* tables_pitch_lag.c:183:18 */

var pitch_contour_CDF_offset int32 = 17 /* tables_pitch_lag.c:191:15 */

var pitch_delta_CDF = [23]uint16{
	uint16(0), uint16(343), uint16(740), uint16(1249), uint16(1889), uint16(2733), uint16(3861), uint16(5396),
	uint16(7552), uint16(10890), uint16(16053), uint16(24152), uint16(30220), uint16(34680), uint16(37973), uint16(40405),
	uint16(42243), uint16(43708), uint16(44823), uint16(45773), uint16(46462), uint16(47055), uint16(65535),
} /* tables_pitch_lag.c:193:18 */

var pitch_delta_CDF_offset int32 = 11 /* tables_pitch_lag.c:199:15 */

var max_pulses_table = [4]int32{
	6, 8, 12, 18,
} /* tables_pulses_per_block.c:30:15 */

var pulses_per_block_CDF = [10][21]uint16{
	{
		uint16(0), uint16(47113), uint16(61501), uint16(64590), uint16(65125), uint16(65277), uint16(65352), uint16(65407),
		uint16(65450), uint16(65474), uint16(65488), uint16(65501), uint16(65508), uint16(65514), uint16(65516), uint16(65520),
		uint16(65521), uint16(65523), uint16(65524), uint16(65526), uint16(65535),
	},
	{
		uint16(0), uint16(26368), uint16(47760), uint16(58803), uint16(63085), uint16(64567), uint16(65113), uint16(65333),
		uint16(65424), uint16(65474), uint16(65498), uint16(65511), uint16(65517), uint16(65520), uint16(65523), uint16(65525),
		uint16(65526), uint16(65528), uint16(65529), uint16(65530), uint16(65535),
	},
	{
		uint16(0), uint16(9601), uint16(28014), uint16(45877), uint16(57210), uint16(62560), uint16(64611), uint16(65260),
		uint16(65447), uint16(65500), uint16(65511), uint16(65519), uint16(65521), uint16(65525), uint16(65526), uint16(65529),
		uint16(65530), uint16(65531), uint16(65532), uint16(65534), uint16(65535),
	},
	{
		uint16(0), uint16(3351), uint16(12462), uint16(25972), uint16(39782), uint16(50686), uint16(57644), uint16(61525),
		uint16(63521), uint16(64506), uint16(65009), uint16(65255), uint16(65375), uint16(65441), uint16(65471), uint16(65488),
		uint16(65497), uint16(65505), uint16(65509), uint16(65512), uint16(65535),
	},
	{
		uint16(0), uint16(488), uint16(2944), uint16(9295), uint16(19712), uint16(32160), uint16(43976), uint16(53121),
		uint16(59144), uint16(62518), uint16(64213), uint16(65016), uint16(65346), uint16(65470), uint16(65511), uint16(65515),
		uint16(65525), uint16(65529), uint16(65531), uint16(65534), uint16(65535),
	},
	{
		uint16(0), uint16(17013), uint16(30405), uint16(40812), uint16(48142), uint16(53466), uint16(57166), uint16(59845),
		uint16(61650), uint16(62873), uint16(63684), uint16(64223), uint16(64575), uint16(64811), uint16(64959), uint16(65051),
		uint16(65111), uint16(65143), uint16(65165), uint16(65183), uint16(65535),
	},
	{
		uint16(0), uint16(2994), uint16(8323), uint16(15845), uint16(24196), uint16(32300), uint16(39340), uint16(45140),
		uint16(49813), uint16(53474), uint16(56349), uint16(58518), uint16(60167), uint16(61397), uint16(62313), uint16(62969),
		uint16(63410), uint16(63715), uint16(63906), uint16(64056), uint16(65535),
	},
	{
		uint16(0), uint16(88), uint16(721), uint16(2795), uint16(7542), uint16(14888), uint16(24420), uint16(34593),
		uint16(43912), uint16(51484), uint16(56962), uint16(60558), uint16(62760), uint16(64037), uint16(64716), uint16(65069),
		uint16(65262), uint16(65358), uint16(65398), uint16(65420), uint16(65535),
	},
	{
		uint16(0), uint16(287), uint16(789), uint16(2064), uint16(4398), uint16(8174), uint16(13534), uint16(20151),
		uint16(27347), uint16(34533), uint16(41295), uint16(47242), uint16(52070), uint16(55772), uint16(58458), uint16(60381),
		uint16(61679), uint16(62533), uint16(63109), uint16(63519), uint16(65535),
	},
	{
		uint16(0), uint16(1), uint16(3), uint16(91), uint16(4521), uint16(14708), uint16(28329), uint16(41955),
		uint16(52116), uint16(58375), uint16(61729), uint16(63534), uint16(64459), uint16(64924), uint16(65092), uint16(65164),
		uint16(65182), uint16(65198), uint16(65203), uint16(65211), uint16(65535),
	},
} /* tables_pulses_per_block.c:34:18 */

var pulses_per_block_CDF_offset int32 = 6 /* tables_pulses_per_block.c:88:15 */

var pulses_per_block_BITS_Q6 = [9][20]int16{
	{
		int16(30), int16(140), int16(282), int16(444), int16(560), int16(625), int16(654), int16(677),
		int16(731), int16(780), int16(787), int16(844), int16(859), int16(960), int16(896), int16(1024),
		int16(960), int16(1024), int16(960), int16(821),
	},
	{
		int16(84), int16(103), int16(164), int16(252), int16(350), int16(442), int16(526), int16(607),
		int16(663), int16(731), int16(787), int16(859), int16(923), int16(923), int16(960), int16(1024),
		int16(960), int16(1024), int16(1024), int16(875),
	},
	{
		int16(177), int16(117), int16(120), int16(162), int16(231), int16(320), int16(426), int16(541),
		int16(657), int16(803), int16(832), int16(960), int16(896), int16(1024), int16(923), int16(1024),
		int16(1024), int16(1024), int16(960), int16(1024),
	},
	{
		int16(275), int16(182), int16(146), int16(144), int16(166), int16(207), int16(261), int16(322),
		int16(388), int16(450), int16(516), int16(582), int16(637), int16(710), int16(762), int16(821),
		int16(832), int16(896), int16(923), int16(734),
	},
	{
		int16(452), int16(303), int16(216), int16(170), int16(153), int16(158), int16(182), int16(220),
		int16(274), int16(337), int16(406), int16(489), int16(579), int16(681), int16(896), int16(811),
		int16(896), int16(960), int16(923), int16(1024),
	},
	{
		int16(125), int16(147), int16(170), int16(202), int16(232), int16(265), int16(295), int16(332),
		int16(368), int16(406), int16(443), int16(483), int16(520), int16(563), int16(606), int16(646),
		int16(704), int16(739), int16(757), int16(483),
	},
	{
		int16(285), int16(232), int16(200), int16(190), int16(193), int16(206), int16(224), int16(244),
		int16(266), int16(289), int16(315), int16(340), int16(367), int16(394), int16(425), int16(462),
		int16(496), int16(539), int16(561), int16(350),
	},
	{
		int16(611), int16(428), int16(319), int16(242), int16(202), int16(178), int16(172), int16(180),
		int16(199), int16(229), int16(268), int16(313), int16(364), int16(422), int16(482), int16(538),
		int16(603), int16(683), int16(739), int16(586),
	},
	{
		int16(501), int16(450), int16(364), int16(308), int16(264), int16(231), int16(212), int16(204),
		int16(204), int16(210), int16(222), int16(241), int16(265), int16(295), int16(326), int16(362),
		int16(401), int16(437), int16(469), int16(321),
	},
} /* tables_pulses_per_block.c:91:17 */

var rate_levels_CDF = [2][10]uint16{
	{
		uint16(0), uint16(2005), uint16(12717), uint16(20281), uint16(31328), uint16(36234), uint16(45816), uint16(57753),
		uint16(63104), uint16(65535),
	},
	{
		uint16(0), uint16(8553), uint16(23489), uint16(36031), uint16(46295), uint16(53519), uint16(56519), uint16(59151),
		uint16(64185), uint16(65535),
	},
} /* tables_pulses_per_block.c:140:18 */

var rate_levels_CDF_offset int32 = 4 /* tables_pulses_per_block.c:152:15 */

var rate_levels_BITS_Q6 = [2][9]int16{
	{
		int16(322), int16(167), int16(199), int16(164), int16(239), int16(178), int16(157), int16(231),
		int16(304),
	},
	{
		int16(188), int16(137), int16(153), int16(171), int16(204), int16(285), int16(297), int16(237),
		int16(358),
	},
} /* tables_pulses_per_block.c:155:17 */

var shell_code_table0 = [33]uint16{
	uint16(0), uint16(32748), uint16(65535), uint16(0), uint16(9505), uint16(56230), uint16(65535), uint16(0),
	uint16(4093), uint16(32204), uint16(61720), uint16(65535), uint16(0), uint16(2285), uint16(16207), uint16(48750),
	uint16(63424), uint16(65535), uint16(0), uint16(1709), uint16(9446), uint16(32026), uint16(55752), uint16(63876),
	uint16(65535), uint16(0), uint16(1623), uint16(6986), uint16(21845), uint16(45381), uint16(59147), uint16(64186),
	uint16(65535),
} /* tables_pulses_per_block.c:167:18 */

var shell_code_table1 = [52]uint16{
	uint16(0), uint16(32691), uint16(65535), uint16(0), uint16(12782), uint16(52752), uint16(65535), uint16(0),
	uint16(4847), uint16(32665), uint16(60899), uint16(65535), uint16(0), uint16(2500), uint16(17305), uint16(47989),
	uint16(63369), uint16(65535), uint16(0), uint16(1843), uint16(10329), uint16(32419), uint16(55433), uint16(64277),
	uint16(65535), uint16(0), uint16(1485), uint16(7062), uint16(21465), uint16(43414), uint16(59079), uint16(64623),
	uint16(65535), uint16(0), uint16(0), uint16(4841), uint16(14797), uint16(31799), uint16(49667), uint16(61309),
	uint16(65535), uint16(65535), uint16(0), uint16(0), uint16(0), uint16(8032), uint16(21695), uint16(41078),
	uint16(56317), uint16(65535), uint16(65535), uint16(65535),
} /* tables_pulses_per_block.c:175:18 */

var shell_code_table2 = [102]uint16{
	uint16(0), uint16(32615), uint16(65535), uint16(0), uint16(14447), uint16(50912), uint16(65535), uint16(0),
	uint16(6301), uint16(32587), uint16(59361), uint16(65535), uint16(0), uint16(3038), uint16(18640), uint16(46809),
	uint16(62852), uint16(65535), uint16(0), uint16(1746), uint16(10524), uint16(32509), uint16(55273), uint16(64278),
	uint16(65535), uint16(0), uint16(1234), uint16(6360), uint16(21259), uint16(43712), uint16(59651), uint16(64805),
	uint16(65535), uint16(0), uint16(1020), uint16(4461), uint16(14030), uint16(32286), uint16(51249), uint16(61904),
	uint16(65100), uint16(65535), uint16(0), uint16(851), uint16(3435), uint16(10006), uint16(23241), uint16(40797),
	uint16(55444), uint16(63009), uint16(65252), uint16(65535), uint16(0), uint16(0), uint16(2075), uint16(7137),
	uint16(17119), uint16(31499), uint16(46982), uint16(58723), uint16(63976), uint16(65535), uint16(65535), uint16(0),
	uint16(0), uint16(0), uint16(3820), uint16(11572), uint16(23038), uint16(37789), uint16(51969), uint16(61243),
	uint16(65535), uint16(65535), uint16(65535), uint16(0), uint16(0), uint16(0), uint16(0), uint16(6882),
	uint16(16828), uint16(30444), uint16(44844), uint16(57365), uint16(65535), uint16(65535), uint16(65535), uint16(65535),
	uint16(0), uint16(0), uint16(0), uint16(0), uint16(0), uint16(10093), uint16(22963), uint16(38779),
	uint16(54426), uint16(65535), uint16(65535), uint16(65535), uint16(65535), uint16(65535),
} /* tables_pulses_per_block.c:185:18 */

var shell_code_table3 = [207]uint16{
	uint16(0), uint16(32324), uint16(65535), uint16(0), uint16(15328), uint16(49505), uint16(65535), uint16(0),
	uint16(7474), uint16(32344), uint16(57955), uint16(65535), uint16(0), uint16(3944), uint16(19450), uint16(45364),
	uint16(61873), uint16(65535), uint16(0), uint16(2338), uint16(11698), uint16(32435), uint16(53915), uint16(63734),
	uint16(65535), uint16(0), uint16(1506), uint16(7074), uint16(21778), uint16(42972), uint16(58861), uint16(64590),
	uint16(65535), uint16(0), uint16(1027), uint16(4490), uint16(14383), uint16(32264), uint16(50980), uint16(61712),
	uint16(65043), uint16(65535), uint16(0), uint16(760), uint16(3022), uint16(9696), uint16(23264), uint16(41465),
	uint16(56181), uint16(63253), uint16(65251), uint16(65535), uint16(0), uint16(579), uint16(2256), uint16(6873),
	uint16(16661), uint16(31951), uint16(48250), uint16(59403), uint16(64198), uint16(65360), uint16(65535), uint16(0),
	uint16(464), uint16(1783), uint16(5181), uint16(12269), uint16(24247), uint16(39877), uint16(53490), uint16(61502),
	uint16(64591), uint16(65410), uint16(65535), uint16(0), uint16(366), uint16(1332), uint16(3880), uint16(9273),
	uint16(18585), uint16(32014), uint16(45928), uint16(56659), uint16(62616), uint16(64899), uint16(65483), uint16(65535),
	uint16(0), uint16(286), uint16(1065), uint16(3089), uint16(6969), uint16(14148), uint16(24859), uint16(38274),
	uint16(50715), uint16(59078), uint16(63448), uint16(65091), uint16(65481), uint16(65535), uint16(0), uint16(0),
	uint16(482), uint16(2010), uint16(5302), uint16(10408), uint16(18988), uint16(30698), uint16(43634), uint16(54233),
	uint16(60828), uint16(64119), uint16(65288), uint16(65535), uint16(65535), uint16(0), uint16(0), uint16(0),
	uint16(1006), uint16(3531), uint16(7857), uint16(14832), uint16(24543), uint16(36272), uint16(47547), uint16(56883),
	uint16(62327), uint16(64746), uint16(65535), uint16(65535), uint16(65535), uint16(0), uint16(0), uint16(0),
	uint16(0), uint16(1863), uint16(4950), uint16(10730), uint16(19284), uint16(29397), uint16(41382), uint16(52335),
	uint16(59755), uint16(63834), uint16(65535), uint16(65535), uint16(65535), uint16(65535), uint16(0), uint16(0),
	uint16(0), uint16(0), uint16(0), uint16(2513), uint16(7290), uint16(14487), uint16(24275), uint16(35312),
	uint16(46240), uint16(55841), uint16(62007), uint16(65535), uint16(65535), uint16(65535), uint16(65535), uint16(65535),
	uint16(0), uint16(0), uint16(0), uint16(0), uint16(0), uint16(0), uint16(3606), uint16(9573),
	uint16(18764), uint16(28667), uint16(40220), uint16(51290), uint16(59924), uint16(65535), uint16(65535), uint16(65535),
	uint16(65535), uint16(65535), uint16(65535), uint16(0), uint16(0), uint16(0), uint16(0), uint16(0),
	uint16(0), uint16(0), uint16(4879), uint16(13091), uint16(23376), uint16(36061), uint16(49395), uint16(59315),
	uint16(65535), uint16(65535), uint16(65535), uint16(65535), uint16(65535), uint16(65535), uint16(65535),
} /* tables_pulses_per_block.c:201:18 */

var shell_code_table_offsets = [19]uint16{
	uint16(0), uint16(0), uint16(3), uint16(7), uint16(12), uint16(18), uint16(25), uint16(33),
	uint16(42), uint16(52), uint16(63), uint16(75), uint16(88), uint16(102), uint16(117), uint16(133),
	uint16(150), uint16(168), uint16(187),
} /* tables_pulses_per_block.c:230:18 */

var sign_CDF = [36]uint16{
	uint16(37840), uint16(36944), uint16(36251), uint16(35304),
	uint16(34715), uint16(35503), uint16(34529), uint16(34296),
	uint16(34016), uint16(47659), uint16(44945), uint16(42503),
	uint16(40235), uint16(38569), uint16(40254), uint16(37851),
	uint16(37243), uint16(36595), uint16(43410), uint16(44121),
	uint16(43127), uint16(40978), uint16(38845), uint16(40433),
	uint16(38252), uint16(37795), uint16(36637), uint16(59159),
	uint16(55630), uint16(51806), uint16(48073), uint16(45036),
	uint16(48416), uint16(43857), uint16(42678), uint16(41146),
} /* tables_sign.c:30:18 */

var type_offset_CDF = [5]uint16{
	uint16(0), uint16(37522), uint16(41030), uint16(44212), uint16(65535),
} /* tables_type_offset.c:30:18 */

var type_offset_CDF_offset int32 = 2 /* tables_type_offset.c:34:15 */

var type_offset_joint_CDF = [4][5]uint16{
	{
		uint16(0), uint16(57686), uint16(61230), uint16(62358), uint16(65535),
	},
	{
		uint16(0), uint16(18346), uint16(40067), uint16(43659), uint16(65535),
	},
	{
		uint16(0), uint16(22694), uint16(24279), uint16(35507), uint16(65535),
	},
	{
		uint16(0), uint16(6067), uint16(7215), uint16(13010), uint16(65535),
	},
} /* tables_type_offset.c:37:18 */

/***********************************************************************
Copyright (c) 2006-2012, Skype Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, (subject to the limitations in the disclaimer below)
are permitted provided that the following conditions are met:
- Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.
- Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
- Neither the name of Skype Limited, nor the names of specific
contributors, may be used to endorse or promote products derived from
this software without specific prior written permission.
NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED
BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
CONTRIBUTORS ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
***********************************************************************/

/*******************/
/* Pitch estimator */
/*******************/

/* Level of noise floor for whitening filter LPC analysis in pitch analysis */

/* Bandwidth expansion for whitening filter in pitch analysis */

/* Threshold used by pitch estimator for early escape */

/*********************/
/* Linear prediction */
/*********************/

/* LPC analysis defines: regularization and bandwidth expansion */

/* LTP analysis defines */

/* LTP quantization settings */

/***********************/
/* High pass filtering */
/***********************/

/* Smoothing parameters for low end of pitch frequency range estimation */

/* Min and max values for low end of pitch frequency range estimation */

/* Max absolute difference between log2 of pitch frequency and smoother state, to enter the smoother */

/***********/
/* Various */
/***********/

/* Required speech activity for counting frame as active */

/* Speech Activity LBRR enable threshold (needs tuning) */

/*************************/
/* Perceptual parameters */
/*************************/

/* reduction in coding SNR during low speech activity */

/* factor for reducing quantization noise during voiced speech */

/* factor for reducing quantization noise for unvoiced sparse signals */

/* threshold for sparseness measure above which to use lower quantization offset during unvoiced */

/* warping control */

/* fraction added to first autocorrelation value */

/* noise shaping filter chirp factor */

/* difference between chirp factors for analysis and synthesis noise shaping filters at low bitrates */

/* gain reduction for fricatives */

/* extra harmonic boosting (signal shaping) at low bitrates */

/* extra harmonic boosting (signal shaping) for noisy input signals */

/* harmonic noise shaping */

/* extra harmonic noise shaping for high bitrates or noisy input */

/* parameter for shaping noise towards higher frequencies */

/* parameter for shaping noise even more towards higher frequencies during voiced speech */

/* parameter for applying a high-pass tilt to the input signal */

/* parameter for extra high-pass tilt to the input signal at high rates */

/* parameter for reducing noise at the very low frequencies */

/* less reduction of noise at the very low frequencies for signals with low SNR at low frequencies */

/* noise floor to put a lower limit on the quantization step size */

/* noise floor relative to active speech gain level */

/* subframe smoothing coefficient for determining active speech gain level (lower -> more smoothing) */

/* subframe smoothing coefficient for HarmBoost, HarmShapeGain, Tilt (lower -> more smoothing) */

/* parameters defining the R/D tradeoff in the residual quantizer */

/**********************************/
/* Initialization of the Silk VAD */
/**********************************/
func VAD_Init(tls *libc.TLS, psSilk_VAD uintptr) int32 { /* VAD.c:39:9: */
	var b int32
	var ret int32 = 0

	/* reset state memory */
	libc.Xmemset(tls, psSilk_VAD, 0, uint32(unsafe.Sizeof(VAD_state{})))

	/* init noise levels */
	/* Initialize array with approx pink noise levels (psd proportional to inverse of frequency) */
	for b = 0; b < 4; b++ {
		*(*int32)(unsafe.Pointer((psSilk_VAD + 92 /* &.NoiseLevelBias */) + uintptr(b)*4)) = max_32(tls, ((50) / (b + 1)), 1)
	}

	/* Initialize state */
	for b = 0; b < 4; b++ {
		*(*int32)(unsafe.Pointer((psSilk_VAD + 60 /* &.NL */) + uintptr(b)*4)) = ((100) * (*(*int32)(unsafe.Pointer((psSilk_VAD + 92 /* &.NoiseLevelBias */) + uintptr(b)*4))))
		*(*int32)(unsafe.Pointer((psSilk_VAD + 76 /* &.inv_NL */) + uintptr(b)*4)) = ((0x7FFFFFFF) / (*(*int32)(unsafe.Pointer((psSilk_VAD + 60 /* &.NL */) + uintptr(b)*4))))
	}
	(*VAD_state)(unsafe.Pointer(psSilk_VAD)).Fcounter = 15

	/* init smoothed energy-to-noise ratio*/
	for b = 0; b < 4; b++ {
		*(*int32)(unsafe.Pointer((psSilk_VAD + 40 /* &.NrgRatioSmth_Q8 */) + uintptr(b)*4)) = (100 * 256) /* 100 * 256 --> 20 dB SNR */
	}

	return ret
}

/* Weighting factors for tilt measure */
var tiltWeights = [4]int32{30000, 6000, -12000, -12000} /* VAD.c:70:24 */

/***************************************/
/* Get the speech activity level in Q8 */
/***************************************/
func VAD_GetSA_Q8(tls *libc.TLS, psSilk_VAD uintptr, pSA_Q8 uintptr, pSNR_dB_Q7 uintptr, pQuality_Q15 uintptr, pTilt_Q15 uintptr, pIn uintptr, framelength int32) int32 { /* VAD.c:75:9: */
	bp := tls.Alloc(4832)
	defer tls.Free(4832)

	var SA_Q15 int32
	var input_tilt int32
	// var scratch [720]int32 at bp+1920, 2880

	var decimated_framelength int32
	var dec_subframe_length int32
	var dec_subframe_offset int32
	var SNR_Q7 int32
	var i int32
	var b int32
	var s int32
	var sumSquared int32
	var smooth_coef_Q16 int32
	var HPstateTmp int16
	// var X [4][240]int16 at bp, 1920

	// var Xnrg [4]int32 at bp+4800, 16

	// var NrgToNoiseRatio_Q8 [4]int32 at bp+4816, 16

	var speech_nrg int32
	var x_tmp int32
	var ret int32 = 0

	/* Safety checks */

	/***********************/
	/* Filter and Decimate */
	/***********************/
	/* 0-8 kHz to 0-4 kHz and 4-8 kHz */
	ana_filt_bank_1(tls, pIn, (psSilk_VAD /* &.AnaState */), (bp /* &X */), (bp /* &X */ + 3*480), (bp + 1920 /* &scratch */), framelength)

	/* 0-4 kHz to 0-2 kHz and 2-4 kHz */
	ana_filt_bank_1(tls, (bp /* &X */), (psSilk_VAD + 8 /* &.AnaState1 */), (bp /* &X */), (bp /* &X */ + 2*480), (bp + 1920 /* &scratch */), ((framelength) >> (1)))

	/* 0-2 kHz to 0-1 kHz and 1-2 kHz */
	ana_filt_bank_1(tls, (bp /* &X */), (psSilk_VAD + 16 /* &.AnaState2 */), (bp /* &X */), (bp /* &X */ + 1*480), (bp + 1920 /* &scratch */), ((framelength) >> (2)))

	/*********************************************/
	/* HP filter on lowest band (differentiator) */
	/*********************************************/
	decimated_framelength = ((framelength) >> (3))
	*(*int16)(unsafe.Pointer((bp /* &X[0] */) + uintptr((decimated_framelength-1))*2)) = (int16((int32(*(*int16)(unsafe.Pointer((bp /* &X[0] */) + uintptr((decimated_framelength-1))*2)))) >> (1)))
	HPstateTmp = *(*int16)(unsafe.Pointer((bp /* &X[0] */) + uintptr((decimated_framelength-1))*2))
	for i = (decimated_framelength - 1); i > 0; i-- {
		*(*int16)(unsafe.Pointer((bp /* &X[0] */) + uintptr((i-1))*2)) = (int16((int32(*(*int16)(unsafe.Pointer((bp /* &X[0] */) + uintptr((i-1))*2)))) >> (1)))
		*(*int16)(unsafe.Pointer((bp /* &X */) + uintptr(i)*2)) -= int16((int32(*(*int16)(unsafe.Pointer((bp /* &X[0] */) + uintptr((i-1))*2)))))
	}
	*(*int16)(unsafe.Pointer((bp /* &X */))) -= int16((int32((*VAD_state)(unsafe.Pointer(psSilk_VAD)).FHPstate)))
	(*VAD_state)(unsafe.Pointer(psSilk_VAD)).FHPstate = HPstateTmp

	/*************************************/
	/* Calculate the energy in each band */
	/*************************************/
	for b = 0; b < 4; b++ {
		/* Find the decimated framelength in the non-uniformly divided bands */
		decimated_framelength = ((framelength) >> (min_int(tls, (4 - b), (4 - 1))))

		/* Split length into subframe lengths */
		dec_subframe_length = ((decimated_framelength) >> (2))
		dec_subframe_offset = 0

		/* Compute energy per sub-frame */
		/* initialize with summed energy of last subframe */
		*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4)) = *(*int32)(unsafe.Pointer((psSilk_VAD + 24 /* &.XnrgSubfr */) + uintptr(b)*4))
		for s = 0; s < (int32(1) << 2); s++ {
			sumSquared = 0
			for i = 0; i < dec_subframe_length; i++ {
				/* The energy will be less than dec_subframe_length * ( int16_MIN / 8 ) ^ 2.            */
				/* Therefore we can accumulate with no risk of overflow (unless dec_subframe_length > 128)  */
				x_tmp = ((int32(*(*int16)(unsafe.Pointer((bp /* &X[0] */ + uintptr(b)*480) + uintptr((i+dec_subframe_offset))*2)))) >> (3))
				sumSquared = ((sumSquared) + ((int32(int16(x_tmp))) * (int32(int16(x_tmp)))))

				/* Safety check */

			}

			/* Add/saturate summed energy of current subframe */
			if s < ((int32(1) << 2) - 1) {
				*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4)) = func() int32 {
					if ((uint32((*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4))) + (sumSquared))) & 0x80000000) != 0 {
						return 0x7FFFFFFF
					}
					return ((*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4))) + (sumSquared))
				}()
			} else {
				/* Look-ahead subframe */
				*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4)) = func() int32 {
					if ((uint32((*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4))) + ((sumSquared) >> (1)))) & 0x80000000) != 0 {
						return 0x7FFFFFFF
					}
					return ((*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4))) + ((sumSquared) >> (1)))
				}()
			}

			dec_subframe_offset = dec_subframe_offset + (dec_subframe_length)
		}
		*(*int32)(unsafe.Pointer((psSilk_VAD + 24 /* &.XnrgSubfr */) + uintptr(b)*4)) = sumSquared
	}

	/********************/
	/* Noise estimation */
	/********************/
	VAD_GetNoiseLevels(tls, (bp + 4800 /* &Xnrg */), psSilk_VAD)

	/***********************************************/
	/* Signal-plus-noise to noise ratio estimation */
	/***********************************************/
	sumSquared = 0
	input_tilt = 0
	for b = 0; b < 4; b++ {
		speech_nrg = (*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4)) - *(*int32)(unsafe.Pointer((psSilk_VAD + 60 /* &.NL */) + uintptr(b)*4)))
		if speech_nrg > 0 {
			/* Divide, with sufficient resolution */
			if (uint32(*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4))) & 0xFF800000) == uint32(0) {
				*(*int32)(unsafe.Pointer(bp + 4816 /* &NrgToNoiseRatio_Q8[0] */ + uintptr(b)*4)) = (((*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4))) << (8)) / (*(*int32)(unsafe.Pointer((psSilk_VAD + 60 /* &.NL */) + uintptr(b)*4)) + 1))
			} else {
				*(*int32)(unsafe.Pointer(bp + 4816 /* &NrgToNoiseRatio_Q8[0] */ + uintptr(b)*4)) = ((*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4))) / (((*(*int32)(unsafe.Pointer((psSilk_VAD + 60 /* &.NL */) + uintptr(b)*4))) >> (8)) + 1))
			}

			/* Convert to log domain */
			SNR_Q7 = (lin2log(tls, *(*int32)(unsafe.Pointer(bp + 4816 /* &NrgToNoiseRatio_Q8[0] */ + uintptr(b)*4))) - (8 * 128))

			/* Sum-of-squares */
			sumSquared = ((sumSquared) + ((int32(int16(SNR_Q7))) * (int32(int16(SNR_Q7))))) /* Q14 */

			/* Tilt measure */
			if speech_nrg < (int32(1) << 20) {
				/* Scale down SNR value for small subband speech energies */
				SNR_Q7 = (((((SQRT_APPROX(tls, speech_nrg)) << (6)) >> 16) * (int32(int16(SNR_Q7)))) + (((((SQRT_APPROX(tls, speech_nrg)) << (6)) & 0x0000FFFF) * (int32(int16(SNR_Q7)))) >> 16))
			}
			input_tilt = ((input_tilt) + ((((tiltWeights[b]) >> 16) * (int32(int16(SNR_Q7)))) + ((((tiltWeights[b]) & 0x0000FFFF) * (int32(int16(SNR_Q7)))) >> 16)))
		} else {
			*(*int32)(unsafe.Pointer(bp + 4816 /* &NrgToNoiseRatio_Q8[0] */ + uintptr(b)*4)) = 256
		}
	}

	/* Mean-of-squares */
	sumSquared = ((sumSquared) / (4)) /* Q14 */

	/* Root-mean-square approximation, scale to dBs, and write to output pointer */
	*(*int32)(unsafe.Pointer(pSNR_dB_Q7)) = int32((int16(3 * SQRT_APPROX(tls, sumSquared)))) /* Q7 */

	/*********************************/
	/* Speech Probability Estimation */
	/*********************************/
	SA_Q15 = sigm_Q15(tls, ((((int32((45000)) >> 16) * (int32(int16(*(*int32)(unsafe.Pointer(pSNR_dB_Q7)))))) + ((((45000) & 0x0000FFFF) * (int32(int16(*(*int32)(unsafe.Pointer(pSNR_dB_Q7)))))) >> 16)) - 128))

	/**************************/
	/* Frequency Tilt Measure */
	/**************************/
	*(*int32)(unsafe.Pointer(pTilt_Q15)) = ((sigm_Q15(tls, input_tilt) - 16384) << (1))

	/**************************************************/
	/* Scale the sigmoid output based on power levels */
	/**************************************************/
	speech_nrg = 0
	for b = 0; b < 4; b++ {
		/* Accumulate signal-without-noise energies, higher frequency bands have more weight */
		speech_nrg = speech_nrg + ((b + 1) * ((*(*int32)(unsafe.Pointer(bp + 4800 /* &Xnrg[0] */ + uintptr(b)*4)) - *(*int32)(unsafe.Pointer((psSilk_VAD + 60 /* &.NL */) + uintptr(b)*4))) >> (4)))
	}

	/* Power scaling */
	if speech_nrg <= 0 {
		SA_Q15 = ((SA_Q15) >> (1))
	} else if speech_nrg < 32768 {
		/* square-root */
		speech_nrg = SQRT_APPROX(tls, ((speech_nrg) << (15)))
		SA_Q15 = ((((32768 + speech_nrg) >> 16) * (int32(int16(SA_Q15)))) + ((((32768 + speech_nrg) & 0x0000FFFF) * (int32(int16(SA_Q15)))) >> 16))
	}

	/* Copy the resulting speech activity in Q8 to *pSA_Q8 */
	*(*int32)(unsafe.Pointer(pSA_Q8)) = min_int(tls, ((SA_Q15) >> (7)), 0xFF)

	/***********************************/
	/* Energy Level and SNR estimation */
	/***********************************/
	/* Smoothing coefficient */
	smooth_coef_Q16 = (((int32((4096)) >> 16) * (int32((int16((((SA_Q15) >> 16) * (int32(int16(SA_Q15)))) + ((((SA_Q15) & 0x0000FFFF) * (int32(int16(SA_Q15)))) >> 16)))))) + ((((4096) & 0x0000FFFF) * (int32((int16((((SA_Q15) >> 16) * (int32(int16(SA_Q15)))) + ((((SA_Q15) & 0x0000FFFF) * (int32(int16(SA_Q15)))) >> 16)))))) >> 16))
	for b = 0; b < 4; b++ {
		/* compute smoothed energy-to-noise ratio per band */
		*(*int32)(unsafe.Pointer((psSilk_VAD + 40 /* &.NrgRatioSmth_Q8 */) + uintptr(b)*4)) = ((*(*int32)(unsafe.Pointer((psSilk_VAD + 40 /* &.NrgRatioSmth_Q8 */) + uintptr(b)*4))) + ((((*(*int32)(unsafe.Pointer(bp + 4816 /* &NrgToNoiseRatio_Q8[0] */ + uintptr(b)*4)) - *(*int32)(unsafe.Pointer((psSilk_VAD + 40 /* &.NrgRatioSmth_Q8 */) + uintptr(b)*4))) >> 16) * (int32(int16(smooth_coef_Q16)))) + ((((*(*int32)(unsafe.Pointer(bp + 4816 /* &NrgToNoiseRatio_Q8[0] */ + uintptr(b)*4)) - *(*int32)(unsafe.Pointer((psSilk_VAD + 40 /* &.NrgRatioSmth_Q8 */) + uintptr(b)*4))) & 0x0000FFFF) * (int32(int16(smooth_coef_Q16)))) >> 16)))

		/* signal to noise ratio in dB per band */
		SNR_Q7 = (3 * (lin2log(tls, *(*int32)(unsafe.Pointer((psSilk_VAD + 40 /* &.NrgRatioSmth_Q8 */) + uintptr(b)*4))) - (8 * 128)))
		/* quality = sigmoid( 0.25 * ( SNR_dB - 16 ) ); */
		*(*int32)(unsafe.Pointer(pQuality_Q15 + uintptr(b)*4)) = sigm_Q15(tls, ((SNR_Q7 - (16 * 128)) >> (4)))
	}

	return ret
}

/**************************/
/* Noise level estimation */
/**************************/
func VAD_GetNoiseLevels(tls *libc.TLS, pX uintptr, psSilk_VAD uintptr) { /* VAD.c:262:6: */
	var k int32
	var nl int32
	var nrg int32
	var inv_nrg int32
	var coef int32
	var min_coef int32

	/* Initially faster smoothing */
	if (*VAD_state)(unsafe.Pointer(psSilk_VAD)).Fcounter < 1000 { /* 1000 = 20 sec */
		min_coef = ((0x7FFF) / ((((*VAD_state)(unsafe.Pointer(psSilk_VAD)).Fcounter) >> (4)) + 1))
	} else {
		min_coef = 0
	}

	for k = 0; k < 4; k++ {
		/* Get old noise level estimate for current band */
		nl = *(*int32)(unsafe.Pointer((psSilk_VAD + 60 /* &.NL */) + uintptr(k)*4))

		/* Add bias */
		nrg = func() int32 {
			if ((uint32((*(*int32)(unsafe.Pointer(pX + uintptr(k)*4))) + (*(*int32)(unsafe.Pointer((psSilk_VAD + 92 /* &.NoiseLevelBias */) + uintptr(k)*4))))) & 0x80000000) != 0 {
				return 0x7FFFFFFF
			}
			return ((*(*int32)(unsafe.Pointer(pX + uintptr(k)*4))) + (*(*int32)(unsafe.Pointer((psSilk_VAD + 92 /* &.NoiseLevelBias */) + uintptr(k)*4))))
		}()

		/* Invert energies */
		inv_nrg = ((0x7FFFFFFF) / (nrg))

		/* Less update when subband energy is high */
		if nrg > ((nl) << (3)) {
			coef = (int32(1024) >> 3)
		} else if nrg < nl {
			coef = 1024
		} else {
			coef = ((((((((inv_nrg) >> 16) * (int32(int16(nl)))) + ((((inv_nrg) & 0x0000FFFF) * (int32(int16(nl)))) >> 16)) + ((inv_nrg) * (func() int32 {
				if (16) == 1 {
					return (((nl) >> 1) + ((nl) & 1))
				}
				return ((((nl) >> ((16) - 1)) + 1) >> 1)
			}()))) >> 16) * (int32((int16(int32(1024) << 1))))) + ((((((((inv_nrg) >> 16) * (int32(int16(nl)))) + ((((inv_nrg) & 0x0000FFFF) * (int32(int16(nl)))) >> 16)) + ((inv_nrg) * (func() int32 {
				if (16) == 1 {
					return (((nl) >> 1) + ((nl) & 1))
				}
				return ((((nl) >> ((16) - 1)) + 1) >> 1)
			}()))) & 0x0000FFFF) * (int32((int16(int32(1024) << 1))))) >> 16))
		}

		/* Initially faster smoothing */
		coef = max_int(tls, coef, min_coef)

		/* Smooth inverse energies */
		*(*int32)(unsafe.Pointer((psSilk_VAD + 76 /* &.inv_NL */) + uintptr(k)*4)) = ((*(*int32)(unsafe.Pointer((psSilk_VAD + 76 /* &.inv_NL */) + uintptr(k)*4))) + ((((inv_nrg - *(*int32)(unsafe.Pointer((psSilk_VAD + 76 /* &.inv_NL */) + uintptr(k)*4))) >> 16) * (int32(int16(coef)))) + ((((inv_nrg - *(*int32)(unsafe.Pointer((psSilk_VAD + 76 /* &.inv_NL */) + uintptr(k)*4))) & 0x0000FFFF) * (int32(int16(coef)))) >> 16)))

		/* Compute noise level by inverting again */
		nl = ((0x7FFFFFFF) / (*(*int32)(unsafe.Pointer((psSilk_VAD + 76 /* &.inv_NL */) + uintptr(k)*4))))

		/* Limit noise levels (guarantee 7 bits of head room) */
		nl = func() int32 {
			if (nl) < (0x00FFFFFF) {
				return nl
			}
			return 0x00FFFFFF
		}()

		/* Store as part of state */
		*(*int32)(unsafe.Pointer((psSilk_VAD + 60 /* &.NL */) + uintptr(k)*4)) = nl
	}

	/* Increment frame counter */
	(*VAD_state)(unsafe.Pointer(psSilk_VAD)).Fcounter++
}

/* Entropy constrained MATRIX-weighted VQ, hard-coded to 5-element vectors, for a single input data vector */
func VQ_WMat_EC_FIX(tls *libc.TLS, ind uintptr, rate_dist_Q14 uintptr, in_Q14 uintptr, W_Q18 uintptr, cb_Q14 uintptr, cl_Q6 uintptr, mu_Q8 int32, L int32) { /* VQ_nearest_neighbor_FIX.c:31:6: */
	bp := tls.Alloc(10)
	defer tls.Free(10)

	var k int32
	var cb_row_Q14 uintptr
	// var diff_Q14 [5]int16 at bp, 10

	var sum1_Q14 int32
	var sum2_Q16 int32

	/* Loop over codebook */
	*(*int32)(unsafe.Pointer(rate_dist_Q14)) = 0x7FFFFFFF
	cb_row_Q14 = cb_Q14
	for k = 0; k < L; k++ {
		*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */)) = (int16(int32(*(*int16)(unsafe.Pointer(in_Q14))) - int32(*(*int16)(unsafe.Pointer(cb_row_Q14)))))
		*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 1*2)) = (int16(int32(*(*int16)(unsafe.Pointer(in_Q14 + 1*2))) - int32(*(*int16)(unsafe.Pointer(cb_row_Q14 + 1*2)))))
		*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 2*2)) = (int16(int32(*(*int16)(unsafe.Pointer(in_Q14 + 2*2))) - int32(*(*int16)(unsafe.Pointer(cb_row_Q14 + 2*2)))))
		*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2)) = (int16(int32(*(*int16)(unsafe.Pointer(in_Q14 + 3*2))) - int32(*(*int16)(unsafe.Pointer(cb_row_Q14 + 3*2)))))
		*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2)) = (int16(int32(*(*int16)(unsafe.Pointer(in_Q14 + 4*2))) - int32(*(*int16)(unsafe.Pointer(cb_row_Q14 + 4*2)))))

		/* Weighted rate */
		sum1_Q14 = ((int32(int16(mu_Q8))) * (int32(*(*int16)(unsafe.Pointer(cl_Q6 + uintptr(k)*2)))))

		/* first row of W_Q18 */
		sum2_Q16 = ((((*(*int32)(unsafe.Pointer(W_Q18 + 1*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 1*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 1*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 1*2))))) >> 16))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 2*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 2*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 2*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 2*2))))) >> 16)))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 3*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 3*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) >> 16)))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 4*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 4*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) >> 16)))
		sum2_Q16 = ((sum2_Q16) << (1))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */))))) + ((((*(*int32)(unsafe.Pointer(W_Q18))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */))))) >> 16)))
		sum1_Q14 = ((sum1_Q14) + ((((sum2_Q16) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */))))) + ((((sum2_Q16) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */))))) >> 16)))

		/* second row of W_Q18 */
		sum2_Q16 = ((((*(*int32)(unsafe.Pointer(W_Q18 + 7*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 2*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 7*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 2*2))))) >> 16))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 8*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 8*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) >> 16)))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 9*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 9*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) >> 16)))
		sum2_Q16 = ((sum2_Q16) << (1))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 6*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 1*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 6*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 1*2))))) >> 16)))
		sum1_Q14 = ((sum1_Q14) + ((((sum2_Q16) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 1*2))))) + ((((sum2_Q16) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 1*2))))) >> 16)))

		/* third row of W_Q18 */
		sum2_Q16 = ((((*(*int32)(unsafe.Pointer(W_Q18 + 13*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 13*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) >> 16))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 14*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 14*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) >> 16)))
		sum2_Q16 = ((sum2_Q16) << (1))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 12*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 2*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 12*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 2*2))))) >> 16)))
		sum1_Q14 = ((sum1_Q14) + ((((sum2_Q16) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 2*2))))) + ((((sum2_Q16) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 2*2))))) >> 16)))

		/* fourth row of W_Q18 */
		sum2_Q16 = ((((*(*int32)(unsafe.Pointer(W_Q18 + 19*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 19*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) >> 16))
		sum2_Q16 = ((sum2_Q16) << (1))
		sum2_Q16 = ((sum2_Q16) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 18*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 18*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) >> 16)))
		sum1_Q14 = ((sum1_Q14) + ((((sum2_Q16) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) + ((((sum2_Q16) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 3*2))))) >> 16)))

		/* last row of W_Q18 */
		sum2_Q16 = ((((*(*int32)(unsafe.Pointer(W_Q18 + 24*4))) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) + ((((*(*int32)(unsafe.Pointer(W_Q18 + 24*4))) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) >> 16))
		sum1_Q14 = ((sum1_Q14) + ((((sum2_Q16) >> 16) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) + ((((sum2_Q16) & 0x0000FFFF) * (int32(*(*int16)(unsafe.Pointer(bp /* &diff_Q14[0] */ + 4*2))))) >> 16)))

		/* find best */
		if sum1_Q14 < *(*int32)(unsafe.Pointer(rate_dist_Q14)) {
			*(*int32)(unsafe.Pointer(rate_dist_Q14)) = sum1_Q14
			*(*int32)(unsafe.Pointer(ind)) = k
		}

		/* Go to next cbk vector */
		cb_row_Q14 += 2 * (uintptr(5))
	}
}

/* Autocorrelations for a warped frequency axis */
func warped_autocorrelation_FIX(tls *libc.TLS, corr uintptr, scale uintptr, input uintptr, warping_Q16 int16, length int32, order int32) { /* warped_autocorrelation_FIX.c:35:6: */
	bp := tls.Alloc(208)
	defer tls.Free(208)

	var n int32
	var i int32
	var lsh int32
	var tmp1_QS int32
	var tmp2_QS int32
	*(*[17]int32)(unsafe.Pointer(bp /* state_QS */)) = [17]int32{0: 0}
	*(*[17]int64_t)(unsafe.Pointer(bp + 72 /* corr_QC */)) = [17]int64_t{0: int64(0)}

	/* Order must be even */

	/* Loop over samples */
	for n = 0; n < length; n++ {
		tmp1_QS = ((int32(*(*int16)(unsafe.Pointer(input + uintptr(n)*2)))) << (14))
		/* Loop over allpass sections */
		for i = 0; i < order; i = i + (2) {
			/* Output of allpass section */
			tmp2_QS = ((*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */ + uintptr(i)*4))) + ((((*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */ + uintptr((i+1))*4)) - tmp1_QS) >> 16) * (int32(warping_Q16))) + ((((*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */ + uintptr((i+1))*4)) - tmp1_QS) & 0x0000FFFF) * (int32(warping_Q16))) >> 16)))
			*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */ + uintptr(i)*4)) = tmp1_QS
			*(*int64_t)(unsafe.Pointer(bp + 72 /* &corr_QC */ + uintptr(i)*8)) += (((int64_t(tmp1_QS)) * (int64_t(*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */))))) >> ((2 * 14) - 10))
			/* Output of allpass section */
			tmp1_QS = ((*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */ + uintptr((i+1))*4))) + ((((*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */ + uintptr((i+2))*4)) - tmp2_QS) >> 16) * (int32(warping_Q16))) + ((((*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */ + uintptr((i+2))*4)) - tmp2_QS) & 0x0000FFFF) * (int32(warping_Q16))) >> 16)))
			*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */ + uintptr((i+1))*4)) = tmp2_QS
			*(*int64_t)(unsafe.Pointer(bp + 72 /* &corr_QC */ + uintptr((i+1))*8)) += (((int64_t(tmp2_QS)) * (int64_t(*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */))))) >> ((2 * 14) - 10))
		}
		*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */ + uintptr(order)*4)) = tmp1_QS
		*(*int64_t)(unsafe.Pointer(bp + 72 /* &corr_QC */ + uintptr(order)*8)) += (((int64_t(tmp1_QS)) * (int64_t(*(*int32)(unsafe.Pointer(bp /* &state_QS[0] */))))) >> ((2 * 14) - 10))
	}

	lsh = (CLZ64(tls, *(*int64_t)(unsafe.Pointer(bp + 72 /* &corr_QC[0] */))) - 35)
	lsh = func() int32 {
		if (-12 - 10) > (30 - 10) {
			return func() int32 {
				if (lsh) > (-12 - 10) {
					return (-12 - 10)
				}
				return func() int32 {
					if (lsh) < (30 - 10) {
						return (30 - 10)
					}
					return lsh
				}()
			}()
		}
		return func() int32 {
			if (lsh) > (30 - 10) {
				return (30 - 10)
			}
			return func() int32 {
				if (lsh) < (-12 - 10) {
					return (-12 - 10)
				}
				return lsh
			}()
		}()
	}()
	*(*int32)(unsafe.Pointer(scale)) = -(10 + lsh)

	if lsh >= 0 {
		for i = 0; i < (order + 1); i++ {
			*(*int32)(unsafe.Pointer(corr + uintptr(i)*4)) = (int32((*(*int64_t)(unsafe.Pointer(bp + 72 /* &corr_QC[0] */ + uintptr(i)*8))) << (lsh)))
		}
	} else {
		for i = 0; i < (order + 1); i++ {
			*(*int32)(unsafe.Pointer(corr + uintptr(i)*4)) = (int32((*(*int64_t)(unsafe.Pointer(bp + 72 /* &corr_QC[0] */ + uintptr(i)*8))) >> (-lsh)))
		}
	}
	// If breaking, decrease QC
}

func init() {
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_ptrs)) + 0)) = uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_0))                                     // tables_LTP.c:89:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_ptrs)) + 4)) = uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_1))                                     // tables_LTP.c:90:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_ptrs)) + 8)) = uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_2))                                     // tables_LTP.c:91:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_ptrs)) + 0)) = uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_0))                                     // tables_LTP.c:89:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_ptrs)) + 4)) = uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_1))                                     // tables_LTP.c:90:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_ptrs)) + 8)) = uintptr(unsafe.Pointer(&LTP_gain_BITS_Q6_2))                                     // tables_LTP.c:91:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_CDF_ptrs)) + 0)) = uintptr(unsafe.Pointer(&LTP_gain_CDF_0))                                             // tables_LTP.c:83:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_CDF_ptrs)) + 4)) = uintptr(unsafe.Pointer(&LTP_gain_CDF_1))                                             // tables_LTP.c:84:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_CDF_ptrs)) + 8)) = uintptr(unsafe.Pointer(&LTP_gain_CDF_2))                                             // tables_LTP.c:85:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_CDF_ptrs)) + 0)) = uintptr(unsafe.Pointer(&LTP_gain_CDF_0))                                             // tables_LTP.c:83:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_CDF_ptrs)) + 4)) = uintptr(unsafe.Pointer(&LTP_gain_CDF_1))                                             // tables_LTP.c:84:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_gain_CDF_ptrs)) + 8)) = uintptr(unsafe.Pointer(&LTP_gain_CDF_2))                                             // tables_LTP.c:85:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_vq_ptrs_Q14)) + 0)) = (uintptr(unsafe.Pointer(&LTP_gain_vq_0_Q14)))                                          // tables_LTP.c:317:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_vq_ptrs_Q14)) + 4)) = (uintptr(unsafe.Pointer(&LTP_gain_vq_1_Q14)))                                          // tables_LTP.c:318:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_vq_ptrs_Q14)) + 8)) = (uintptr(unsafe.Pointer(&LTP_gain_vq_2_Q14)))                                          // tables_LTP.c:319:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_vq_ptrs_Q14)) + 0)) = (uintptr(unsafe.Pointer(&LTP_gain_vq_0_Q14)))                                          // tables_LTP.c:317:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_vq_ptrs_Q14)) + 4)) = (uintptr(unsafe.Pointer(&LTP_gain_vq_1_Q14)))                                          // tables_LTP.c:318:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&LTP_vq_ptrs_Q14)) + 8)) = (uintptr(unsafe.Pointer(&LTP_gain_vq_2_Q14)))                                          // tables_LTP.c:319:5:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 4 /* .CBStages */)) = uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info))                           // tables_NLSF_CB0_10.c:884:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 8 /* .NDeltaMin_Q15 */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_ndelta_min_Q15))             // tables_NLSF_CB0_10.c:885:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 12 /* .CDF */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF))                                 // tables_NLSF_CB0_10.c:886:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 16 /* .StartPtr */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr))                  // tables_NLSF_CB0_10.c:887:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 20 /* .MiddleIx */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_middle_idx))                 // tables_NLSF_CB0_10.c:888:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 4 /* .CBStages */)) = uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info))                           // tables_NLSF_CB0_10.c:884:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 8 /* .NDeltaMin_Q15 */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_ndelta_min_Q15))             // tables_NLSF_CB0_10.c:885:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 12 /* .CDF */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF))                                 // tables_NLSF_CB0_10.c:886:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 16 /* .StartPtr */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr))                  // tables_NLSF_CB0_10.c:887:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10)) + 20 /* .MiddleIx */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_middle_idx))                 // tables_NLSF_CB0_10.c:888:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 4 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_Q15)))             // tables_NLSF_CB0_10.c:873:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 8 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_rates_Q5)))           // tables_NLSF_CB0_10.c:873:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 16 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_Q15)) + 640*2)    // tables_NLSF_CB0_10.c:874:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 20 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_rates_Q5)) + 64*2)   // tables_NLSF_CB0_10.c:874:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 28 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_Q15)) + 800*2)    // tables_NLSF_CB0_10.c:875:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 32 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_rates_Q5)) + 80*2)   // tables_NLSF_CB0_10.c:875:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 40 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_Q15)) + 880*2)    // tables_NLSF_CB0_10.c:876:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 44 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_rates_Q5)) + 88*2)   // tables_NLSF_CB0_10.c:876:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 52 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_Q15)) + 960*2)    // tables_NLSF_CB0_10.c:877:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 56 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_rates_Q5)) + 96*2)   // tables_NLSF_CB0_10.c:877:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 64 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_Q15)) + 1040*2)   // tables_NLSF_CB0_10.c:878:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_10_Stage_info)) + 68 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_rates_Q5)) + 104*2)  // tables_NLSF_CB0_10.c:878:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 4 /* .CBStages */)) = uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info))                           // tables_NLSF_CB0_16.c:1314:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 8 /* .NDeltaMin_Q15 */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_ndelta_min_Q15))             // tables_NLSF_CB0_16.c:1315:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 12 /* .CDF */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF))                                 // tables_NLSF_CB0_16.c:1316:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 16 /* .StartPtr */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr))                  // tables_NLSF_CB0_16.c:1317:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 20 /* .MiddleIx */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_middle_idx))                 // tables_NLSF_CB0_16.c:1318:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 4 /* .CBStages */)) = uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info))                           // tables_NLSF_CB0_16.c:1314:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 8 /* .NDeltaMin_Q15 */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_ndelta_min_Q15))             // tables_NLSF_CB0_16.c:1315:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 12 /* .CDF */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF))                                 // tables_NLSF_CB0_16.c:1316:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 16 /* .StartPtr */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr))                  // tables_NLSF_CB0_16.c:1317:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16)) + 20 /* .MiddleIx */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_middle_idx))                 // tables_NLSF_CB0_16.c:1318:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 4 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)))             // tables_NLSF_CB0_16.c:1299:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 8 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)))           // tables_NLSF_CB0_16.c:1299:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 16 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)) + 2048*2)   // tables_NLSF_CB0_16.c:1300:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 20 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)) + 128*2)  // tables_NLSF_CB0_16.c:1300:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 28 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)) + 2304*2)   // tables_NLSF_CB0_16.c:1301:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 32 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)) + 144*2)  // tables_NLSF_CB0_16.c:1301:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 40 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)) + 2432*2)   // tables_NLSF_CB0_16.c:1302:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 44 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)) + 152*2)  // tables_NLSF_CB0_16.c:1302:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 52 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)) + 2560*2)   // tables_NLSF_CB0_16.c:1303:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 56 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)) + 160*2)  // tables_NLSF_CB0_16.c:1303:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 64 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)) + 2688*2)   // tables_NLSF_CB0_16.c:1304:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 68 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)) + 168*2)  // tables_NLSF_CB0_16.c:1304:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 76 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)) + 2816*2)   // tables_NLSF_CB0_16.c:1305:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 80 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)) + 176*2)  // tables_NLSF_CB0_16.c:1305:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 88 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)) + 2944*2)   // tables_NLSF_CB0_16.c:1306:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 92 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)) + 184*2)  // tables_NLSF_CB0_16.c:1306:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 100 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)) + 3072*2)  // tables_NLSF_CB0_16.c:1307:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 104 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)) + 192*2) // tables_NLSF_CB0_16.c:1307:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 112 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_Q15)) + 3200*2)  // tables_NLSF_CB0_16.c:1308:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB0_16_Stage_info)) + 116 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_rates_Q5)) + 200*2) // tables_NLSF_CB0_16.c:1308:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 4 /* .CBStages */)) = uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info))                           // tables_NLSF_CB1_10.c:572:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 8 /* .NDeltaMin_Q15 */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_ndelta_min_Q15))             // tables_NLSF_CB1_10.c:573:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 12 /* .CDF */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF))                                 // tables_NLSF_CB1_10.c:574:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 16 /* .StartPtr */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr))                  // tables_NLSF_CB1_10.c:575:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 20 /* .MiddleIx */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_middle_idx))                 // tables_NLSF_CB1_10.c:576:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 4 /* .CBStages */)) = uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info))                           // tables_NLSF_CB1_10.c:572:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 8 /* .NDeltaMin_Q15 */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_ndelta_min_Q15))             // tables_NLSF_CB1_10.c:573:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 12 /* .CDF */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF))                                 // tables_NLSF_CB1_10.c:574:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 16 /* .StartPtr */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr))                  // tables_NLSF_CB1_10.c:575:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10)) + 20 /* .MiddleIx */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_middle_idx))                 // tables_NLSF_CB1_10.c:576:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 4 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_Q15)))             // tables_NLSF_CB1_10.c:561:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 8 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_rates_Q5)))           // tables_NLSF_CB1_10.c:561:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 16 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_Q15)) + 320*2)    // tables_NLSF_CB1_10.c:562:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 20 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_rates_Q5)) + 32*2)   // tables_NLSF_CB1_10.c:562:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 28 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_Q15)) + 400*2)    // tables_NLSF_CB1_10.c:563:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 32 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_rates_Q5)) + 40*2)   // tables_NLSF_CB1_10.c:563:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 40 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_Q15)) + 480*2)    // tables_NLSF_CB1_10.c:564:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 44 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_rates_Q5)) + 48*2)   // tables_NLSF_CB1_10.c:564:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 52 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_Q15)) + 560*2)    // tables_NLSF_CB1_10.c:565:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 56 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_rates_Q5)) + 56*2)   // tables_NLSF_CB1_10.c:565:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 64 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_Q15)) + 640*2)    // tables_NLSF_CB1_10.c:566:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_10_Stage_info)) + 68 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_rates_Q5)) + 64*2)   // tables_NLSF_CB1_10.c:566:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 4 /* .CBStages */)) = uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info))                           // tables_NLSF_CB1_16.c:698:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 8 /* .NDeltaMin_Q15 */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_ndelta_min_Q15))             // tables_NLSF_CB1_16.c:699:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 12 /* .CDF */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF))                                 // tables_NLSF_CB1_16.c:700:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 16 /* .StartPtr */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr))                  // tables_NLSF_CB1_16.c:701:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 20 /* .MiddleIx */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_middle_idx))                 // tables_NLSF_CB1_16.c:702:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 4 /* .CBStages */)) = uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info))                           // tables_NLSF_CB1_16.c:698:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 8 /* .NDeltaMin_Q15 */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_ndelta_min_Q15))             // tables_NLSF_CB1_16.c:699:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 12 /* .CDF */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF))                                 // tables_NLSF_CB1_16.c:700:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 16 /* .StartPtr */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr))                  // tables_NLSF_CB1_16.c:701:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16)) + 20 /* .MiddleIx */)) = uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_middle_idx))                 // tables_NLSF_CB1_16.c:702:9:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 4 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)))             // tables_NLSF_CB1_16.c:683:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 8 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)))           // tables_NLSF_CB1_16.c:683:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 16 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)) + 512*2)    // tables_NLSF_CB1_16.c:684:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 20 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)) + 32*2)   // tables_NLSF_CB1_16.c:684:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 28 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)) + 640*2)    // tables_NLSF_CB1_16.c:685:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 32 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)) + 40*2)   // tables_NLSF_CB1_16.c:685:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 40 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)) + 768*2)    // tables_NLSF_CB1_16.c:686:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 44 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)) + 48*2)   // tables_NLSF_CB1_16.c:686:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 52 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)) + 896*2)    // tables_NLSF_CB1_16.c:687:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 56 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)) + 56*2)   // tables_NLSF_CB1_16.c:687:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 64 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)) + 1024*2)   // tables_NLSF_CB1_16.c:688:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 68 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)) + 64*2)   // tables_NLSF_CB1_16.c:688:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 76 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)) + 1152*2)   // tables_NLSF_CB1_16.c:689:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 80 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)) + 72*2)   // tables_NLSF_CB1_16.c:689:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 88 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)) + 1280*2)   // tables_NLSF_CB1_16.c:690:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 92 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)) + 80*2)   // tables_NLSF_CB1_16.c:690:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 100 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)) + 1408*2)  // tables_NLSF_CB1_16.c:691:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 104 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)) + 88*2)  // tables_NLSF_CB1_16.c:691:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 112 /* .CB_NLSF_Q15 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_Q15)) + 1536*2)  // tables_NLSF_CB1_16.c:692:16:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_CB1_16_Stage_info)) + 116 /* .Rates_Q5 */)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_rates_Q5)) + 96*2)  // tables_NLSF_CB1_16.c:692:60:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 0)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)))                        // tables_NLSF_CB0_10.c:170:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 4)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 65*2)                 // tables_NLSF_CB0_10.c:171:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 8)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 82*2)                 // tables_NLSF_CB0_10.c:172:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 12)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 91*2)                // tables_NLSF_CB0_10.c:173:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 16)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 100*2)               // tables_NLSF_CB0_10.c:174:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 20)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 109*2)               // tables_NLSF_CB0_10.c:175:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 0)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)))                        // tables_NLSF_CB0_10.c:170:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 4)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 65*2)                 // tables_NLSF_CB0_10.c:171:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 8)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 82*2)                 // tables_NLSF_CB0_10.c:172:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 12)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 91*2)                // tables_NLSF_CB0_10.c:173:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 16)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 100*2)               // tables_NLSF_CB0_10.c:174:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF_start_ptr)) + 20)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_10_CDF)) + 109*2)               // tables_NLSF_CB0_10.c:175:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 0)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)))                        // tables_NLSF_CB0_16.c:270:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 4)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 129*2)                // tables_NLSF_CB0_16.c:271:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 8)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 146*2)                // tables_NLSF_CB0_16.c:272:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 12)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 155*2)               // tables_NLSF_CB0_16.c:273:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 16)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 164*2)               // tables_NLSF_CB0_16.c:274:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 20)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 173*2)               // tables_NLSF_CB0_16.c:275:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 24)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 182*2)               // tables_NLSF_CB0_16.c:276:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 28)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 191*2)               // tables_NLSF_CB0_16.c:277:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 32)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 200*2)               // tables_NLSF_CB0_16.c:278:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 36)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 209*2)               // tables_NLSF_CB0_16.c:279:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 0)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)))                        // tables_NLSF_CB0_16.c:270:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 4)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 129*2)                // tables_NLSF_CB0_16.c:271:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 8)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 146*2)                // tables_NLSF_CB0_16.c:272:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 12)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 155*2)               // tables_NLSF_CB0_16.c:273:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 16)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 164*2)               // tables_NLSF_CB0_16.c:274:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 20)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 173*2)               // tables_NLSF_CB0_16.c:275:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 24)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 182*2)               // tables_NLSF_CB0_16.c:276:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 28)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 191*2)               // tables_NLSF_CB0_16.c:277:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 32)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 200*2)               // tables_NLSF_CB0_16.c:278:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF_start_ptr)) + 36)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB0_16_CDF)) + 209*2)               // tables_NLSF_CB0_16.c:279:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 0)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)))                        // tables_NLSF_CB1_10.c:122:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 4)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 33*2)                 // tables_NLSF_CB1_10.c:123:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 8)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 42*2)                 // tables_NLSF_CB1_10.c:124:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 12)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 51*2)                // tables_NLSF_CB1_10.c:125:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 16)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 60*2)                // tables_NLSF_CB1_10.c:126:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 20)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 69*2)                // tables_NLSF_CB1_10.c:127:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 0)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)))                        // tables_NLSF_CB1_10.c:122:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 4)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 33*2)                 // tables_NLSF_CB1_10.c:123:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 8)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 42*2)                 // tables_NLSF_CB1_10.c:124:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 12)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 51*2)                // tables_NLSF_CB1_10.c:125:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 16)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 60*2)                // tables_NLSF_CB1_10.c:126:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF_start_ptr)) + 20)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_10_CDF)) + 69*2)                // tables_NLSF_CB1_10.c:127:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 0)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)))                        // tables_NLSF_CB1_16.c:158:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 4)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 33*2)                 // tables_NLSF_CB1_16.c:159:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 8)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 42*2)                 // tables_NLSF_CB1_16.c:160:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 12)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 51*2)                // tables_NLSF_CB1_16.c:161:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 16)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 60*2)                // tables_NLSF_CB1_16.c:162:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 20)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 69*2)                // tables_NLSF_CB1_16.c:163:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 24)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 78*2)                // tables_NLSF_CB1_16.c:164:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 28)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 87*2)                // tables_NLSF_CB1_16.c:165:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 32)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 96*2)                // tables_NLSF_CB1_16.c:166:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 36)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 105*2)               // tables_NLSF_CB1_16.c:167:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 0)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)))                        // tables_NLSF_CB1_16.c:158:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 4)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 33*2)                 // tables_NLSF_CB1_16.c:159:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 8)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 42*2)                 // tables_NLSF_CB1_16.c:160:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 12)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 51*2)                // tables_NLSF_CB1_16.c:161:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 16)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 60*2)                // tables_NLSF_CB1_16.c:162:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 20)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 69*2)                // tables_NLSF_CB1_16.c:163:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 24)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 78*2)                // tables_NLSF_CB1_16.c:164:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 28)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 87*2)                // tables_NLSF_CB1_16.c:165:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 32)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 96*2)                // tables_NLSF_CB1_16.c:166:6:
	*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF_start_ptr)) + 36)) = (uintptr(unsafe.Pointer(&NLSF_MSVQ_CB1_16_CDF)) + 105*2)               // tables_NLSF_CB1_16.c:167:6:
}

var ts1 = "1.0.9\x00"
var ts = (*reflect.StringHeader)(unsafe.Pointer(&ts1)).Data
